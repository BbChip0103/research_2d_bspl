{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import os.path as path\n",
    "import itertools\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.layers import Input,InputLayer, Dense, Activation, BatchNormalization, Flatten, Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D, Dropout\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,LearningRateScheduler, \\\n",
    "                                        EarlyStopping\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.utils import to_categorical, multi_gpu_model, Sequence\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data = np.load(path.join(data_dir, 'imagenet_6_class_172_train_data.npz'))\n",
    "# val_data = np.load(path.join(data_dir, 'imagenet_6_class_172_val_data.npz'))\n",
    "\n",
    "x_train = np.load(path.join(data_dir, 'imagenet_6_class_172_x_train.npy'))\n",
    "y_train = np.load(path.join(data_dir, 'imagenet_6_class_172_y_train.npy'))\n",
    "x_val = np.load(path.join(data_dir, 'imagenet_6_class_172_x_val.npy'))\n",
    "y_val = np.load(path.join(data_dir, 'imagenet_6_class_172_y_val.npy'))\n",
    "y_list = np.load(path.join(data_dir, 'imagenet_6_class_172_y_list.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((235111, 172, 172, 3),\n",
       " (235111,),\n",
       " (3183, 172, 172, 3),\n",
       " (3183,),\n",
       " (3183, 172, 172, 3),\n",
       " (3183,),\n",
       " (6,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# x_train = train_data['x_data']\n",
    "# y_train = train_data['y_data']\n",
    "# x_val = val_data['x_data']\n",
    "# y_val = val_data['y_data']\n",
    "x_test = x_val\n",
    "y_test = y_val\n",
    "# y_list = val_data['y_list']\n",
    "\n",
    "x_train.shape, y_train.shape, x_val.shape, y_val.shape, x_test.shape, y_test.shape, y_list.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((235111, 172, 172, 3),\n",
       " (235111, 6),\n",
       " (3183, 172, 172, 3),\n",
       " (3183, 6),\n",
       " (3183, 172, 172, 3),\n",
       " (3183, 6))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = to_categorical(y_train)\n",
    "y_val = to_categorical(y_val)\n",
    "y_test = y_val\n",
    "\n",
    "x_train.shape, y_train.shape, x_val.shape, y_val.shape, x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = x_train[0].shape\n",
    "output_size = len(y_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_2d_cnn_custom_ch_32_DO(conv_num=1):\n",
    "    input_layer = Input(shape=input_shape)\n",
    "    x = input_layer\n",
    "\n",
    "    for i in range(conv_num):\n",
    "        x = Conv2D(kernel_size=5, filters=32*(2**(i//2)), strides=(1,1), padding='same')(x)\n",
    "#         x = BatchNormalization()(x)\n",
    "        x = Activation('relu')(x)\n",
    "        x = MaxPooling2D(pool_size=3, strides=(2,2), padding='same')(x)\n",
    "\n",
    "    x = Flatten()(x)\n",
    "  \n",
    "    x = Dropout(0.75)(x)\n",
    "    output_layer = Dense(output_size, activation='softmax')(x)\n",
    "    \n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 172, 172, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 172, 172, 32)      2432      \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 172, 172, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 86, 86, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 236672)            0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 236672)            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 6)                 1420038   \n",
      "=================================================================\n",
      "Total params: 1,422,470\n",
      "Trainable params: 1,422,470\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 172, 172, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 172, 172, 32)      2432      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 172, 172, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 86, 86, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 86, 86, 32)        25632     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 86, 86, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 43, 43, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 59168)             0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 59168)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 6)                 355014    \n",
      "=================================================================\n",
      "Total params: 383,078\n",
      "Trainable params: 383,078\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 172, 172, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 172, 172, 32)      2432      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 172, 172, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 86, 86, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 86, 86, 32)        25632     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 86, 86, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 43, 43, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 43, 43, 64)        51264     \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 43, 43, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 22, 22, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 30976)             0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 30976)             0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 6)                 185862    \n",
      "=================================================================\n",
      "Total params: 265,190\n",
      "Trainable params: 265,190\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, 172, 172, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 172, 172, 32)      2432      \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 172, 172, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 86, 86, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 86, 86, 32)        25632     \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 86, 86, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 43, 43, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 43, 43, 64)        51264     \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 43, 43, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 22, 22, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 22, 22, 64)        102464    \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 22, 22, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 7744)              0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 7744)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 6)                 46470     \n",
      "=================================================================\n",
      "Total params: 228,262\n",
      "Trainable params: 228,262\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         (None, 172, 172, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 172, 172, 32)      2432      \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 172, 172, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 86, 86, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 86, 86, 32)        25632     \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 86, 86, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 43, 43, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 43, 43, 64)        51264     \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 43, 43, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 22, 22, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 22, 22, 64)        102464    \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 22, 22, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 11, 11, 128)       204928    \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 11, 11, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 6)                 27654     \n",
      "=================================================================\n",
      "Total params: 414,374\n",
      "Trainable params: 414,374\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         (None, 172, 172, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 172, 172, 32)      2432      \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 172, 172, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling (None, 86, 86, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 86, 86, 32)        25632     \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 86, 86, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling (None, 43, 43, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 43, 43, 64)        51264     \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 43, 43, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_17 (MaxPooling (None, 22, 22, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 22, 22, 64)        102464    \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 22, 22, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_18 (MaxPooling (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 11, 11, 128)       204928    \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 11, 11, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_19 (MaxPooling (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 6, 6, 128)         409728    \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_20 (MaxPooling (None, 3, 3, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 6)                 6918      \n",
      "=================================================================\n",
      "Total params: 803,366\n",
      "Trainable params: 803,366\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_7 (InputLayer)         (None, 172, 172, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 172, 172, 32)      2432      \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 172, 172, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_21 (MaxPooling (None, 86, 86, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_22 (Conv2D)           (None, 86, 86, 32)        25632     \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 86, 86, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_22 (MaxPooling (None, 43, 43, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 43, 43, 64)        51264     \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 43, 43, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_23 (MaxPooling (None, 22, 22, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_24 (Conv2D)           (None, 22, 22, 64)        102464    \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 22, 22, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_24 (MaxPooling (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_25 (Conv2D)           (None, 11, 11, 128)       204928    \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 11, 11, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_25 (MaxPooling (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_26 (Conv2D)           (None, 6, 6, 128)         409728    \n",
      "_________________________________________________________________\n",
      "activation_26 (Activation)   (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_26 (MaxPooling (None, 3, 3, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_27 (Conv2D)           (None, 3, 3, 256)         819456    \n",
      "_________________________________________________________________\n",
      "activation_27 (Activation)   (None, 3, 3, 256)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_27 (MaxPooling (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 6)                 6150      \n",
      "=================================================================\n",
      "Total params: 1,622,054\n",
      "Trainable params: 1,622,054\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 8):\n",
    "    model = build_2d_cnn_custom_ch_32_DO(conv_num=i)\n",
    "    model.summary()\n",
    "    del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BalanceDataGenerator(Sequence):\n",
    "    def __init__(self, x_data, y_data, batch_size, shuffle=True):\n",
    "        self.x_data = x_data\n",
    "        self.y_data = y_data\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.sample_size = int(np.sum(y_data, axis=0).min())\n",
    "        self.data_shape = x_data.shape[1:]\n",
    "        self.y_label = self.y_data.argmax(axis=1)\n",
    "        self.labels = np.unique(self.y_label)\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.y_labels) * self.sample_size / self.batch_size))\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        self.indexes = np.zeros((len(self.labels), self.sample_size))\n",
    "        for i, label in enumerate(self.labels):\n",
    "            y_index = np.argwhere(self.y_label==label).squeeze()\n",
    "            if self.shuffle == True:\n",
    "                self.indexes[i] = np.random.choice(y_index, \n",
    "                                   self.sample_size, \n",
    "                                   replace=False)\n",
    "            else:\n",
    "                self.indexes[i] = y_index[:self.sample_size]\n",
    "                \n",
    "        self.indexes = self.indexes.flatten().astype(np.int32)\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "                \n",
    "    def __getitem__(self, batch_idx):\n",
    "        indices = self.indexes[batch_idx*self.batch_size: (batch_idx+1)*self.batch_size]\n",
    "        return self.x_data[indices], self.y_data[indices]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4., 7., 8., 4., 9., 8.], dtype=float32)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 40\n",
    "data_generator = BalanceDataGenerator(x_train, y_train,\n",
    "                                      batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.7280 - acc: 0.5761WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 25s 8ms/sample - loss: 0.4682 - acc: 0.8913\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.46823, saving model to model/checkpoint/vis_imagenet_6_class_augmentation_2D_CNN_custom_ch_32_DO_075_DO_3_conv_checkpoint/001-0.4682.hdf5\n",
      "81/81 [==============================] - 34s 414ms/step - loss: 0.7268 - acc: 0.5764 - val_loss: 0.4682 - val_acc: 0.8913\n",
      "Epoch 2/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.5094 - acc: 0.7473WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.6818 - acc: 0.5778\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.46823\n",
      "81/81 [==============================] - 20s 248ms/step - loss: 0.5094 - acc: 0.7480 - val_loss: 0.6818 - val_acc: 0.5778\n",
      "Epoch 3/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.4009 - acc: 0.8307WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 14s 4ms/sample - loss: 0.4072 - acc: 0.8003\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.46823 to 0.40719, saving model to model/checkpoint/vis_imagenet_6_class_augmentation_2D_CNN_custom_ch_32_DO_075_DO_3_conv_checkpoint/003-0.4072.hdf5\n",
      "81/81 [==============================] - 25s 309ms/step - loss: 0.4001 - acc: 0.8321 - val_loss: 0.4072 - val_acc: 0.8003\n",
      "Epoch 4/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.3510 - acc: 0.8558WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.4385 - acc: 0.7800\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.40719\n",
      "81/81 [==============================] - 27s 331ms/step - loss: 0.3496 - acc: 0.8563 - val_loss: 0.4385 - val_acc: 0.7800\n",
      "Epoch 5/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.3220 - acc: 0.8708WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.2828 - acc: 0.8950\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.40719 to 0.28280, saving model to model/checkpoint/vis_imagenet_6_class_augmentation_2D_CNN_custom_ch_32_DO_075_DO_3_conv_checkpoint/005-0.2828.hdf5\n",
      "81/81 [==============================] - 20s 249ms/step - loss: 0.3223 - acc: 0.8709 - val_loss: 0.2828 - val_acc: 0.8950\n",
      "Epoch 6/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.3091 - acc: 0.8749WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.3792 - acc: 0.8472\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.28280\n",
      "81/81 [==============================] - 21s 263ms/step - loss: 0.3079 - acc: 0.8762 - val_loss: 0.3792 - val_acc: 0.8472\n",
      "Epoch 7/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.2809 - acc: 0.8815WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 23s 7ms/sample - loss: 0.3517 - acc: 0.8656\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.28280\n",
      "81/81 [==============================] - 26s 326ms/step - loss: 0.2811 - acc: 0.8818 - val_loss: 0.3517 - val_acc: 0.8656\n",
      "Epoch 8/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.2638 - acc: 0.8924WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 23s 7ms/sample - loss: 0.2133 - acc: 0.9278\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.28280 to 0.21333, saving model to model/checkpoint/vis_imagenet_6_class_augmentation_2D_CNN_custom_ch_32_DO_075_DO_3_conv_checkpoint/008-0.2133.hdf5\n",
      "81/81 [==============================] - 26s 326ms/step - loss: 0.2647 - acc: 0.8914 - val_loss: 0.2133 - val_acc: 0.9278\n",
      "Epoch 9/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.2653 - acc: 0.8969WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.1387 - acc: 0.9500\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.21333 to 0.13870, saving model to model/checkpoint/vis_imagenet_6_class_augmentation_2D_CNN_custom_ch_32_DO_075_DO_3_conv_checkpoint/009-0.1387.hdf5\n",
      "81/81 [==============================] - 24s 293ms/step - loss: 0.2666 - acc: 0.8966 - val_loss: 0.1387 - val_acc: 0.9500\n",
      "Epoch 10/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.2661 - acc: 0.8950WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 23s 7ms/sample - loss: 0.1092 - acc: 0.9638\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.13870 to 0.10923, saving model to model/checkpoint/vis_imagenet_6_class_augmentation_2D_CNN_custom_ch_32_DO_075_DO_3_conv_checkpoint/010-0.1092.hdf5\n",
      "81/81 [==============================] - 28s 340ms/step - loss: 0.2640 - acc: 0.8963 - val_loss: 0.1092 - val_acc: 0.9638\n",
      "Epoch 11/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.2443 - acc: 0.9048WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 21s 7ms/sample - loss: 0.2080 - acc: 0.9225\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.10923\n",
      "81/81 [==============================] - 25s 311ms/step - loss: 0.2441 - acc: 0.9047 - val_loss: 0.2080 - val_acc: 0.9225\n",
      "Epoch 12/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.2189 - acc: 0.9177WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.1928 - acc: 0.9375\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.10923\n",
      "81/81 [==============================] - 23s 286ms/step - loss: 0.2189 - acc: 0.9178 - val_loss: 0.1928 - val_acc: 0.9375\n",
      "Epoch 13/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.2098 - acc: 0.9246WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 23s 7ms/sample - loss: 0.2090 - acc: 0.9328\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.10923\n",
      "81/81 [==============================] - 27s 331ms/step - loss: 0.2092 - acc: 0.9246 - val_loss: 0.2090 - val_acc: 0.9328\n",
      "Epoch 14/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.2146 - acc: 0.9167WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.1888 - acc: 0.9406\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.10923\n",
      "81/81 [==============================] - 23s 286ms/step - loss: 0.2135 - acc: 0.9174 - val_loss: 0.1888 - val_acc: 0.9406\n",
      "Epoch 15/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.2057 - acc: 0.9239WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.3119 - acc: 0.8669\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.10923\n",
      "81/81 [==============================] - 22s 265ms/step - loss: 0.2046 - acc: 0.9240 - val_loss: 0.3119 - val_acc: 0.8669\n",
      "Epoch 16/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.1743 - acc: 0.9375WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 24s 8ms/sample - loss: 0.1830 - acc: 0.9450\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.10923\n",
      "81/81 [==============================] - 28s 345ms/step - loss: 0.1742 - acc: 0.9376 - val_loss: 0.1830 - val_acc: 0.9450\n",
      "Epoch 17/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.1882 - acc: 0.9344WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.1782 - acc: 0.9422\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.10923\n",
      "81/81 [==============================] - 21s 260ms/step - loss: 0.1874 - acc: 0.9345 - val_loss: 0.1782 - val_acc: 0.9422\n",
      "Epoch 18/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.1577 - acc: 0.9462WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 22s 7ms/sample - loss: 0.1240 - acc: 0.9650\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.10923\n",
      "81/81 [==============================] - 26s 317ms/step - loss: 0.1587 - acc: 0.9451 - val_loss: 0.1240 - val_acc: 0.9650\n",
      "Epoch 19/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.1775 - acc: 0.9338WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.1726 - acc: 0.9450\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.10923\n",
      "81/81 [==============================] - 21s 260ms/step - loss: 0.1772 - acc: 0.9342 - val_loss: 0.1726 - val_acc: 0.9450\n",
      "Epoch 20/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.1604 - acc: 0.9402WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.1261 - acc: 0.9628\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.10923\n",
      "81/81 [==============================] - 21s 257ms/step - loss: 0.1590 - acc: 0.9407 - val_loss: 0.1261 - val_acc: 0.9628\n",
      "Epoch 21/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.1594 - acc: 0.9414WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.1099 - acc: 0.9675\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.10923\n",
      "81/81 [==============================] - 23s 279ms/step - loss: 0.1587 - acc: 0.9420 - val_loss: 0.1099 - val_acc: 0.9675\n",
      "Epoch 22/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.1655 - acc: 0.9393WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0947 - acc: 0.9684\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.10923 to 0.09474, saving model to model/checkpoint/vis_imagenet_6_class_augmentation_2D_CNN_custom_ch_32_DO_075_DO_3_conv_checkpoint/022-0.0947.hdf5\n",
      "81/81 [==============================] - 23s 282ms/step - loss: 0.1646 - acc: 0.9398 - val_loss: 0.0947 - val_acc: 0.9684\n",
      "Epoch 23/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.1503 - acc: 0.9481WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0631 - acc: 0.9825\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.09474 to 0.06312, saving model to model/checkpoint/vis_imagenet_6_class_augmentation_2D_CNN_custom_ch_32_DO_075_DO_3_conv_checkpoint/023-0.0631.hdf5\n",
      "81/81 [==============================] - 22s 275ms/step - loss: 0.1496 - acc: 0.9485 - val_loss: 0.0631 - val_acc: 0.9825\n",
      "Epoch 24/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.1655 - acc: 0.9392WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.1003 - acc: 0.9712\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.06312\n",
      "81/81 [==============================] - 20s 247ms/step - loss: 0.1650 - acc: 0.9401 - val_loss: 0.1003 - val_acc: 0.9712\n",
      "Epoch 25/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.1510 - acc: 0.9395WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 22s 7ms/sample - loss: 0.1498 - acc: 0.9528\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.06312\n",
      "81/81 [==============================] - 26s 322ms/step - loss: 0.1516 - acc: 0.9392 - val_loss: 0.1498 - val_acc: 0.9528\n",
      "Epoch 26/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.1577 - acc: 0.9453WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 22s 7ms/sample - loss: 0.1608 - acc: 0.9325\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.06312\n",
      "81/81 [==============================] - 25s 314ms/step - loss: 0.1569 - acc: 0.9457 - val_loss: 0.1608 - val_acc: 0.9325\n",
      "Epoch 27/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.1812 - acc: 0.9327WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.1401 - acc: 0.9475\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.06312\n",
      "81/81 [==============================] - 21s 259ms/step - loss: 0.1813 - acc: 0.9323 - val_loss: 0.1401 - val_acc: 0.9475\n",
      "Epoch 28/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.1283 - acc: 0.9507WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.1822 - acc: 0.9300\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.06312\n",
      "81/81 [==============================] - 22s 272ms/step - loss: 0.1303 - acc: 0.9500 - val_loss: 0.1822 - val_acc: 0.9300\n",
      "Epoch 29/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.1729 - acc: 0.9400WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.1498 - acc: 0.9500\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.06312\n",
      "81/81 [==============================] - 20s 248ms/step - loss: 0.1725 - acc: 0.9401 - val_loss: 0.1498 - val_acc: 0.9500\n",
      "Epoch 30/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.1400 - acc: 0.9513WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.1056 - acc: 0.9616\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.06312\n",
      "81/81 [==============================] - 21s 263ms/step - loss: 0.1396 - acc: 0.9513 - val_loss: 0.1056 - val_acc: 0.9616\n",
      "Epoch 31/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.1449 - acc: 0.9497WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3190/3183 [==============================] - 22s 7ms/sample - loss: 0.0528 - acc: 0.9774\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.06312 to 0.05278, saving model to model/checkpoint/vis_imagenet_6_class_augmentation_2D_CNN_custom_ch_32_DO_075_DO_3_conv_checkpoint/031-0.0528.hdf5\n",
      "81/81 [==============================] - 26s 321ms/step - loss: 0.1439 - acc: 0.9500 - val_loss: 0.0528 - val_acc: 0.9774\n",
      "Epoch 32/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.1577 - acc: 0.9437WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 20s 6ms/sample - loss: 0.1169 - acc: 0.9584\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.05278\n",
      "81/81 [==============================] - 24s 294ms/step - loss: 0.1567 - acc: 0.9441 - val_loss: 0.1169 - val_acc: 0.9584\n",
      "Epoch 33/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.1283 - acc: 0.9548WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 15s 5ms/sample - loss: 0.1483 - acc: 0.9350\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.05278\n",
      "81/81 [==============================] - 19s 232ms/step - loss: 0.1286 - acc: 0.9550 - val_loss: 0.1483 - val_acc: 0.9350\n",
      "Epoch 34/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.1433 - acc: 0.9478WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 21s 7ms/sample - loss: 0.1117 - acc: 0.9591\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.05278\n",
      "81/81 [==============================] - 25s 308ms/step - loss: 0.1427 - acc: 0.9482 - val_loss: 0.1117 - val_acc: 0.9591\n",
      "Epoch 35/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.1164 - acc: 0.9574WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0870 - acc: 0.9741\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.05278\n",
      "81/81 [==============================] - 21s 257ms/step - loss: 0.1142 - acc: 0.9584 - val_loss: 0.0870 - val_acc: 0.9741\n",
      "Epoch 36/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.1258 - acc: 0.9544WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 20s 6ms/sample - loss: 0.0575 - acc: 0.9800\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.05278\n",
      "81/81 [==============================] - 23s 288ms/step - loss: 0.1256 - acc: 0.9547 - val_loss: 0.0575 - val_acc: 0.9800\n",
      "Epoch 37/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.1222 - acc: 0.9579WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.0504 - acc: 0.9825\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.05278 to 0.05042, saving model to model/checkpoint/vis_imagenet_6_class_augmentation_2D_CNN_custom_ch_32_DO_075_DO_3_conv_checkpoint/037-0.0504.hdf5\n",
      "81/81 [==============================] - 20s 241ms/step - loss: 0.1230 - acc: 0.9572 - val_loss: 0.0504 - val_acc: 0.9825\n",
      "Epoch 38/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.1184 - acc: 0.9596WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0652 - acc: 0.9766\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.05042\n",
      "81/81 [==============================] - 21s 258ms/step - loss: 0.1193 - acc: 0.9590 - val_loss: 0.0652 - val_acc: 0.9766\n",
      "Epoch 39/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.1330 - acc: 0.9542WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.0712 - acc: 0.9775\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.05042\n",
      "81/81 [==============================] - 20s 242ms/step - loss: 0.1336 - acc: 0.9541 - val_loss: 0.0712 - val_acc: 0.9775\n",
      "Epoch 40/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.1232 - acc: 0.9589WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.1286 - acc: 0.9556\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.05042\n",
      "81/81 [==============================] - 24s 294ms/step - loss: 0.1224 - acc: 0.9593 - val_loss: 0.1286 - val_acc: 0.9556\n",
      "Epoch 41/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.1388 - acc: 0.9519WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.1620 - acc: 0.9375\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.05042\n",
      "81/81 [==============================] - 21s 262ms/step - loss: 0.1379 - acc: 0.9519 - val_loss: 0.1620 - val_acc: 0.9375\n",
      "Epoch 42/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.1100 - acc: 0.9648WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.1264 - acc: 0.9500\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.05042\n",
      "81/81 [==============================] - 20s 246ms/step - loss: 0.1092 - acc: 0.9652 - val_loss: 0.1264 - val_acc: 0.9500\n",
      "Epoch 43/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.1162 - acc: 0.9617WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.0597 - acc: 0.9800\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.05042\n",
      "81/81 [==============================] - 19s 240ms/step - loss: 0.1154 - acc: 0.9621 - val_loss: 0.0597 - val_acc: 0.9800\n",
      "Epoch 44/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.1468 - acc: 0.9475WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3200/3183 [==============================] - 22s 7ms/sample - loss: 0.1111 - acc: 0.9638\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.05042\n",
      "81/81 [==============================] - 27s 328ms/step - loss: 0.1458 - acc: 0.9482 - val_loss: 0.1111 - val_acc: 0.9638\n",
      "Epoch 45/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.1161 - acc: 0.9589WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 23s 7ms/sample - loss: 0.0585 - acc: 0.9800\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.05042\n",
      "81/81 [==============================] - 28s 348ms/step - loss: 0.1166 - acc: 0.9584 - val_loss: 0.0585 - val_acc: 0.9800\n",
      "Epoch 46/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.1012 - acc: 0.9626WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 21s 7ms/sample - loss: 0.1101 - acc: 0.9597\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.05042\n",
      "81/81 [==============================] - 28s 351ms/step - loss: 0.1024 - acc: 0.9615 - val_loss: 0.1101 - val_acc: 0.9597\n",
      "Epoch 47/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.1255 - acc: 0.9569WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 15s 5ms/sample - loss: 0.0756 - acc: 0.9750\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.05042\n",
      "81/81 [==============================] - 20s 249ms/step - loss: 0.1254 - acc: 0.9565 - val_loss: 0.0756 - val_acc: 0.9750\n",
      "Epoch 48/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.1175 - acc: 0.9618WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.1142 - acc: 0.9609\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.05042\n",
      "81/81 [==============================] - 20s 242ms/step - loss: 0.1160 - acc: 0.9624 - val_loss: 0.1142 - val_acc: 0.9609\n",
      "Epoch 49/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.1057 - acc: 0.9645WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 21s 7ms/sample - loss: 0.1119 - acc: 0.9534\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.05042\n",
      "81/81 [==============================] - 26s 316ms/step - loss: 0.1052 - acc: 0.9649 - val_loss: 0.1119 - val_acc: 0.9534\n",
      "Epoch 50/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.1383 - acc: 0.9504WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0993 - acc: 0.9700\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.05042\n",
      "81/81 [==============================] - 21s 263ms/step - loss: 0.1386 - acc: 0.9507 - val_loss: 0.0993 - val_acc: 0.9700\n",
      "Epoch 51/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.1237 - acc: 0.9507WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0774 - acc: 0.9750\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.05042\n",
      "81/81 [==============================] - 21s 256ms/step - loss: 0.1225 - acc: 0.9513 - val_loss: 0.0774 - val_acc: 0.9750\n",
      "Epoch 52/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.1024 - acc: 0.9653WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0494 - acc: 0.9825\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.05042 to 0.04939, saving model to model/checkpoint/vis_imagenet_6_class_augmentation_2D_CNN_custom_ch_32_DO_075_DO_3_conv_checkpoint/052-0.0494.hdf5\n",
      "81/81 [==============================] - 22s 269ms/step - loss: 0.1026 - acc: 0.9652 - val_loss: 0.0494 - val_acc: 0.9825\n",
      "Epoch 53/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.1095 - acc: 0.9615WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 27s 8ms/sample - loss: 0.0558 - acc: 0.9816\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.04939\n",
      "81/81 [==============================] - 31s 378ms/step - loss: 0.1116 - acc: 0.9609 - val_loss: 0.0558 - val_acc: 0.9816\n",
      "Epoch 54/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.1073 - acc: 0.9648WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 25s 8ms/sample - loss: 0.1239 - acc: 0.9556\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.04939\n",
      "81/81 [==============================] - 29s 364ms/step - loss: 0.1068 - acc: 0.9649 - val_loss: 0.1239 - val_acc: 0.9556\n",
      "Epoch 55/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.1002 - acc: 0.9673WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 22s 7ms/sample - loss: 0.0976 - acc: 0.9578\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.04939\n",
      "81/81 [==============================] - 27s 331ms/step - loss: 0.1011 - acc: 0.9674 - val_loss: 0.0976 - val_acc: 0.9578\n",
      "Epoch 56/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0911 - acc: 0.9669WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0787 - acc: 0.9650\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.04939\n",
      "81/81 [==============================] - 21s 257ms/step - loss: 0.0912 - acc: 0.9668 - val_loss: 0.0787 - val_acc: 0.9650\n",
      "Epoch 57/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0987 - acc: 0.9642WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 27s 8ms/sample - loss: 0.0501 - acc: 0.9825\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.04939\n",
      "81/81 [==============================] - 31s 377ms/step - loss: 0.0982 - acc: 0.9646 - val_loss: 0.0501 - val_acc: 0.9825\n",
      "Epoch 58/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.1087 - acc: 0.9586WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0710 - acc: 0.9750\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.04939\n",
      "81/81 [==============================] - 23s 288ms/step - loss: 0.1080 - acc: 0.9590 - val_loss: 0.0710 - val_acc: 0.9750\n",
      "Epoch 59/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.1087 - acc: 0.9628WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0507 - acc: 0.9825\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.04939\n",
      "81/81 [==============================] - 22s 273ms/step - loss: 0.1089 - acc: 0.9634 - val_loss: 0.0507 - val_acc: 0.9825\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.1085 - acc: 0.9607WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.1681 - acc: 0.9325\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.04939\n",
      "81/81 [==============================] - 21s 264ms/step - loss: 0.1086 - acc: 0.9606 - val_loss: 0.1681 - val_acc: 0.9325\n",
      "Epoch 61/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.1024 - acc: 0.9670WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 20s 6ms/sample - loss: 0.0668 - acc: 0.9725\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.04939\n",
      "81/81 [==============================] - 24s 294ms/step - loss: 0.1023 - acc: 0.9668 - val_loss: 0.0668 - val_acc: 0.9725\n",
      "Epoch 62/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0896 - acc: 0.9707WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 20s 6ms/sample - loss: 0.0760 - acc: 0.9725\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.04939\n",
      "81/81 [==============================] - 24s 294ms/step - loss: 0.0908 - acc: 0.9696 - val_loss: 0.0760 - val_acc: 0.9725\n",
      "Epoch 63/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.1073 - acc: 0.9610WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0915 - acc: 0.9650\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.04939\n",
      "81/81 [==============================] - 22s 269ms/step - loss: 0.1071 - acc: 0.9612 - val_loss: 0.0915 - val_acc: 0.9650\n",
      "Epoch 64/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0911 - acc: 0.9707WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.0527 - acc: 0.9825\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.04939\n",
      "81/81 [==============================] - 23s 283ms/step - loss: 0.0926 - acc: 0.9696 - val_loss: 0.0527 - val_acc: 0.9825\n",
      "Epoch 65/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0862 - acc: 0.9698WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0668 - acc: 0.9800\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.04939\n",
      "81/81 [==============================] - 21s 257ms/step - loss: 0.0860 - acc: 0.9699 - val_loss: 0.0668 - val_acc: 0.9800\n",
      "Epoch 66/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0884 - acc: 0.9689WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 21s 7ms/sample - loss: 0.0512 - acc: 0.9825\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.04939\n",
      "81/81 [==============================] - 25s 307ms/step - loss: 0.0877 - acc: 0.9693 - val_loss: 0.0512 - val_acc: 0.9825\n",
      "Epoch 67/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0867 - acc: 0.9670WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 26s 8ms/sample - loss: 0.0712 - acc: 0.9750\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.04939\n",
      "81/81 [==============================] - 30s 376ms/step - loss: 0.0860 - acc: 0.9674 - val_loss: 0.0712 - val_acc: 0.9750\n",
      "Epoch 68/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0962 - acc: 0.9639WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.1738 - acc: 0.9278\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.04939\n",
      "81/81 [==============================] - 23s 282ms/step - loss: 0.0978 - acc: 0.9637 - val_loss: 0.1738 - val_acc: 0.9278\n",
      "Epoch 69/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0870 - acc: 0.9683WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0674 - acc: 0.9756\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.04939\n",
      "81/81 [==============================] - 22s 268ms/step - loss: 0.0870 - acc: 0.9683 - val_loss: 0.0674 - val_acc: 0.9756\n",
      "Epoch 70/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0845 - acc: 0.9752WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.1066 - acc: 0.9556\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.04939\n",
      "81/81 [==============================] - 23s 286ms/step - loss: 0.0846 - acc: 0.9752 - val_loss: 0.1066 - val_acc: 0.9556\n",
      "Epoch 71/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.1093 - acc: 0.9591WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 26s 8ms/sample - loss: 0.0483 - acc: 0.9850\n",
      "\n",
      "Epoch 00071: val_loss improved from 0.04939 to 0.04832, saving model to model/checkpoint/vis_imagenet_6_class_augmentation_2D_CNN_custom_ch_32_DO_075_DO_3_conv_checkpoint/071-0.0483.hdf5\n",
      "81/81 [==============================] - 30s 376ms/step - loss: 0.1097 - acc: 0.9590 - val_loss: 0.0483 - val_acc: 0.9850\n",
      "Epoch 72/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0911 - acc: 0.9694WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.0862 - acc: 0.9675\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.04832\n",
      "81/81 [==============================] - 22s 274ms/step - loss: 0.0903 - acc: 0.9699 - val_loss: 0.0862 - val_acc: 0.9675\n",
      "Epoch 73/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0724 - acc: 0.9783WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 13s 4ms/sample - loss: 0.0633 - acc: 0.9741\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.04832\n",
      "81/81 [==============================] - 19s 230ms/step - loss: 0.0768 - acc: 0.9767 - val_loss: 0.0633 - val_acc: 0.9741\n",
      "Epoch 74/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0779 - acc: 0.9733WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0662 - acc: 0.9750\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.04832\n",
      "81/81 [==============================] - 21s 259ms/step - loss: 0.0771 - acc: 0.9736 - val_loss: 0.0662 - val_acc: 0.9750\n",
      "Epoch 75/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0822 - acc: 0.9701WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.1055 - acc: 0.9600\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.04832\n",
      "81/81 [==============================] - 20s 250ms/step - loss: 0.0817 - acc: 0.9705 - val_loss: 0.1055 - val_acc: 0.9600\n",
      "Epoch 76/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0841 - acc: 0.9720WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.1236 - acc: 0.9513\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.04832\n",
      "81/81 [==============================] - 23s 282ms/step - loss: 0.0826 - acc: 0.9727 - val_loss: 0.1236 - val_acc: 0.9513\n",
      "Epoch 77/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0876 - acc: 0.9720WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0776 - acc: 0.9725\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.04832\n",
      "81/81 [==============================] - 22s 270ms/step - loss: 0.0874 - acc: 0.9721 - val_loss: 0.0776 - val_acc: 0.9725\n",
      "Epoch 78/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0801 - acc: 0.9745WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0444 - acc: 0.9850\n",
      "\n",
      "Epoch 00078: val_loss improved from 0.04832 to 0.04436, saving model to model/checkpoint/vis_imagenet_6_class_augmentation_2D_CNN_custom_ch_32_DO_075_DO_3_conv_checkpoint/078-0.0444.hdf5\n",
      "81/81 [==============================] - 20s 252ms/step - loss: 0.0805 - acc: 0.9745 - val_loss: 0.0444 - val_acc: 0.9850\n",
      "Epoch 79/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0728 - acc: 0.9752WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 23s 7ms/sample - loss: 0.0637 - acc: 0.9700\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.04436\n",
      "81/81 [==============================] - 27s 334ms/step - loss: 0.0723 - acc: 0.9755 - val_loss: 0.0637 - val_acc: 0.9700\n",
      "Epoch 80/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0964 - acc: 0.9650WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.1535 - acc: 0.9425\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.04436\n",
      "81/81 [==============================] - 24s 298ms/step - loss: 0.0947 - acc: 0.9659 - val_loss: 0.1535 - val_acc: 0.9425\n",
      "Epoch 81/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0807 - acc: 0.9723WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 23s 7ms/sample - loss: 0.0783 - acc: 0.9725\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.04436\n",
      "81/81 [==============================] - 27s 333ms/step - loss: 0.0802 - acc: 0.9727 - val_loss: 0.0783 - val_acc: 0.9725\n",
      "Epoch 82/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0846 - acc: 0.9720WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0632 - acc: 0.9688\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.04436\n",
      "81/81 [==============================] - 24s 301ms/step - loss: 0.0854 - acc: 0.9721 - val_loss: 0.0632 - val_acc: 0.9688\n",
      "Epoch 83/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0779 - acc: 0.9739WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 27s 9ms/sample - loss: 0.1035 - acc: 0.9575\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.04436\n",
      "81/81 [==============================] - 33s 410ms/step - loss: 0.0771 - acc: 0.9742 - val_loss: 0.1035 - val_acc: 0.9575\n",
      "Epoch 84/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0729 - acc: 0.9752WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0552 - acc: 0.9800\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.04436\n",
      "81/81 [==============================] - 24s 299ms/step - loss: 0.0738 - acc: 0.9752 - val_loss: 0.0552 - val_acc: 0.9800\n",
      "Epoch 85/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0829 - acc: 0.9682WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 23s 7ms/sample - loss: 0.0686 - acc: 0.9688\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.04436\n",
      "81/81 [==============================] - 27s 333ms/step - loss: 0.0823 - acc: 0.9683 - val_loss: 0.0686 - val_acc: 0.9688\n",
      "Epoch 86/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0921 - acc: 0.9704WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 23s 7ms/sample - loss: 0.0979 - acc: 0.9694\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.04436\n",
      "81/81 [==============================] - 27s 330ms/step - loss: 0.0919 - acc: 0.9705 - val_loss: 0.0979 - val_acc: 0.9694\n",
      "Epoch 87/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0702 - acc: 0.9733WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0720 - acc: 0.9644\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.04436\n",
      "81/81 [==============================] - 22s 276ms/step - loss: 0.0699 - acc: 0.9736 - val_loss: 0.0720 - val_acc: 0.9644\n",
      "Epoch 88/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0731 - acc: 0.9774WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0504 - acc: 0.9816\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.04436\n",
      "81/81 [==============================] - 21s 256ms/step - loss: 0.0722 - acc: 0.9777 - val_loss: 0.0504 - val_acc: 0.9816\n",
      "Epoch 89/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0652 - acc: 0.9783WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.0673 - acc: 0.9750\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.04436\n",
      "81/81 [==============================] - 21s 260ms/step - loss: 0.0646 - acc: 0.9786 - val_loss: 0.0673 - val_acc: 0.9750\n",
      "Epoch 90/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0751 - acc: 0.9736WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 21s 6ms/sample - loss: 0.0747 - acc: 0.9700\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.04436\n",
      "81/81 [==============================] - 24s 302ms/step - loss: 0.0757 - acc: 0.9733 - val_loss: 0.0747 - val_acc: 0.9700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0754 - acc: 0.9758WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0586 - acc: 0.9762\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.04436\n",
      "81/81 [==============================] - 24s 296ms/step - loss: 0.0748 - acc: 0.9758 - val_loss: 0.0586 - val_acc: 0.9762\n",
      "Epoch 92/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0804 - acc: 0.9755WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.0557 - acc: 0.9741\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.04436\n",
      "81/81 [==============================] - 21s 260ms/step - loss: 0.0803 - acc: 0.9755 - val_loss: 0.0557 - val_acc: 0.9741\n",
      "Epoch 93/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0841 - acc: 0.9720WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0421 - acc: 0.9875\n",
      "\n",
      "Epoch 00093: val_loss improved from 0.04436 to 0.04206, saving model to model/checkpoint/vis_imagenet_6_class_augmentation_2D_CNN_custom_ch_32_DO_075_DO_3_conv_checkpoint/093-0.0421.hdf5\n",
      "81/81 [==============================] - 23s 278ms/step - loss: 0.0835 - acc: 0.9724 - val_loss: 0.0421 - val_acc: 0.9875\n",
      "Epoch 94/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0609 - acc: 0.9786WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0685 - acc: 0.9741\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.04206\n",
      "81/81 [==============================] - 23s 289ms/step - loss: 0.0607 - acc: 0.9786 - val_loss: 0.0685 - val_acc: 0.9741\n",
      "Epoch 95/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0666 - acc: 0.9802WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 27s 8ms/sample - loss: 0.0724 - acc: 0.9700\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.04206\n",
      "81/81 [==============================] - 34s 417ms/step - loss: 0.0664 - acc: 0.9804 - val_loss: 0.0724 - val_acc: 0.9700\n",
      "Epoch 96/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0692 - acc: 0.9783WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0705 - acc: 0.9700\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.04206\n",
      "81/81 [==============================] - 24s 300ms/step - loss: 0.0687 - acc: 0.9786 - val_loss: 0.0705 - val_acc: 0.9700\n",
      "Epoch 97/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0780 - acc: 0.9755WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 28s 9ms/sample - loss: 0.0524 - acc: 0.9825\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.04206\n",
      "81/81 [==============================] - 32s 400ms/step - loss: 0.0773 - acc: 0.9758 - val_loss: 0.0524 - val_acc: 0.9825\n",
      "Epoch 98/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0655 - acc: 0.9796WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0586 - acc: 0.9800\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.04206\n",
      "81/81 [==============================] - 22s 274ms/step - loss: 0.0653 - acc: 0.9795 - val_loss: 0.0586 - val_acc: 0.9800\n",
      "Epoch 99/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0594 - acc: 0.9808WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 23s 7ms/sample - loss: 0.0675 - acc: 0.9725\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.04206\n",
      "81/81 [==============================] - 27s 334ms/step - loss: 0.0596 - acc: 0.9804 - val_loss: 0.0675 - val_acc: 0.9725\n",
      "Epoch 100/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0647 - acc: 0.9789WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0652 - acc: 0.9731\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.04206\n",
      "81/81 [==============================] - 24s 291ms/step - loss: 0.0648 - acc: 0.9789 - val_loss: 0.0652 - val_acc: 0.9731\n",
      "Epoch 101/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0660 - acc: 0.9764WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 23s 7ms/sample - loss: 0.0803 - acc: 0.9762\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 0.04206\n",
      "81/81 [==============================] - 28s 342ms/step - loss: 0.0658 - acc: 0.9767 - val_loss: 0.0803 - val_acc: 0.9762\n",
      "Epoch 102/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0742 - acc: 0.9777WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 21s 7ms/sample - loss: 0.0524 - acc: 0.9825\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 0.04206\n",
      "81/81 [==============================] - 27s 327ms/step - loss: 0.0745 - acc: 0.9777 - val_loss: 0.0524 - val_acc: 0.9825\n",
      "Epoch 103/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0799 - acc: 0.9704WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 24s 8ms/sample - loss: 0.0429 - acc: 0.9850\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 0.04206\n",
      "81/81 [==============================] - 28s 347ms/step - loss: 0.0792 - acc: 0.9708 - val_loss: 0.0429 - val_acc: 0.9850\n",
      "Epoch 104/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0795 - acc: 0.9736WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0421 - acc: 0.9841\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 0.04206\n",
      "81/81 [==============================] - 22s 270ms/step - loss: 0.0810 - acc: 0.9733 - val_loss: 0.0421 - val_acc: 0.9841\n",
      "Epoch 105/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0665 - acc: 0.9768WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0539 - acc: 0.9800\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 0.04206\n",
      "81/81 [==============================] - 22s 270ms/step - loss: 0.0654 - acc: 0.9773 - val_loss: 0.0539 - val_acc: 0.9800\n",
      "Epoch 106/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0663 - acc: 0.9802WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3200/3183 [==============================] - 24s 8ms/sample - loss: 0.0856 - acc: 0.9712\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 0.04206\n",
      "81/81 [==============================] - 29s 353ms/step - loss: 0.0664 - acc: 0.9801 - val_loss: 0.0856 - val_acc: 0.9712\n",
      "Epoch 107/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0664 - acc: 0.9767WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 22s 7ms/sample - loss: 0.0650 - acc: 0.9744\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 0.04206\n",
      "81/81 [==============================] - 26s 323ms/step - loss: 0.0661 - acc: 0.9770 - val_loss: 0.0650 - val_acc: 0.9744\n",
      "Epoch 108/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0613 - acc: 0.9780WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0426 - acc: 0.9844\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 0.04206\n",
      "81/81 [==============================] - 22s 272ms/step - loss: 0.0616 - acc: 0.9780 - val_loss: 0.0426 - val_acc: 0.9844\n",
      "Epoch 109/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0768 - acc: 0.9720WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 24s 8ms/sample - loss: 0.0763 - acc: 0.9725\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 0.04206\n",
      "81/81 [==============================] - 28s 346ms/step - loss: 0.0763 - acc: 0.9718 - val_loss: 0.0763 - val_acc: 0.9725\n",
      "Epoch 110/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0697 - acc: 0.9767WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0763 - acc: 0.972512s - loss\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 0.04206\n",
      "81/81 [==============================] - 22s 277ms/step - loss: 0.0695 - acc: 0.9767 - val_loss: 0.0763 - val_acc: 0.9725\n",
      "Epoch 111/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0659 - acc: 0.9797WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3190/3183 [==============================] - 18s 6ms/sample - loss: 0.0668 - acc: 0.9749\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 0.04206\n",
      "81/81 [==============================] - 22s 266ms/step - loss: 0.0656 - acc: 0.9798 - val_loss: 0.0668 - val_acc: 0.9749\n",
      "Epoch 112/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0569 - acc: 0.9865WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.0929 - acc: 0.9678\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 0.04206\n",
      "81/81 [==============================] - 22s 270ms/step - loss: 0.0565 - acc: 0.9867 - val_loss: 0.0929 - val_acc: 0.9678\n",
      "Epoch 113/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0601 - acc: 0.9793WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0476 - acc: 0.9825\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 0.04206\n",
      "81/81 [==============================] - 21s 260ms/step - loss: 0.0596 - acc: 0.9795 - val_loss: 0.0476 - val_acc: 0.9825\n",
      "Epoch 114/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0684 - acc: 0.9803WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0348 - acc: 0.9875\n",
      "\n",
      "Epoch 00114: val_loss improved from 0.04206 to 0.03476, saving model to model/checkpoint/vis_imagenet_6_class_augmentation_2D_CNN_custom_ch_32_DO_075_DO_3_conv_checkpoint/114-0.0348.hdf5\n",
      "81/81 [==============================] - 22s 273ms/step - loss: 0.0680 - acc: 0.9801 - val_loss: 0.0348 - val_acc: 0.9875\n",
      "Epoch 115/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0581 - acc: 0.9793WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0609 - acc: 0.9725\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 0.03476\n",
      "81/81 [==============================] - 21s 263ms/step - loss: 0.0574 - acc: 0.9795 - val_loss: 0.0609 - val_acc: 0.9725\n",
      "Epoch 116/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0548 - acc: 0.9835WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 23s 7ms/sample - loss: 0.0476 - acc: 0.9856\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 0.03476\n",
      "81/81 [==============================] - 26s 325ms/step - loss: 0.0567 - acc: 0.9829 - val_loss: 0.0476 - val_acc: 0.9856\n",
      "Epoch 117/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0597 - acc: 0.9771WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0652 - acc: 0.9812\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 0.03476\n",
      "81/81 [==============================] - 21s 262ms/step - loss: 0.0588 - acc: 0.9777 - val_loss: 0.0652 - val_acc: 0.9812\n",
      "Epoch 118/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0565 - acc: 0.9837WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0553 - acc: 0.9787\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 0.03476\n",
      "81/81 [==============================] - 23s 279ms/step - loss: 0.0562 - acc: 0.9839 - val_loss: 0.0553 - val_acc: 0.9787\n",
      "Epoch 119/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0558 - acc: 0.9808WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0409 - acc: 0.9850\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 0.03476\n",
      "81/81 [==============================] - 24s 297ms/step - loss: 0.0553 - acc: 0.9811 - val_loss: 0.0409 - val_acc: 0.9850\n",
      "Epoch 120/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0626 - acc: 0.9808WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.0666 - acc: 0.9800\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 0.03476\n",
      "81/81 [==============================] - 24s 295ms/step - loss: 0.0628 - acc: 0.9804 - val_loss: 0.0666 - val_acc: 0.9800\n",
      "Epoch 121/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0577 - acc: 0.9821WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0730 - acc: 0.9775\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 0.03476\n",
      "81/81 [==============================] - 22s 268ms/step - loss: 0.0580 - acc: 0.9820 - val_loss: 0.0730 - val_acc: 0.9775\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 122/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0659 - acc: 0.9822WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 23s 7ms/sample - loss: 0.0840 - acc: 0.9650\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 0.03476\n",
      "81/81 [==============================] - 27s 329ms/step - loss: 0.0659 - acc: 0.9820 - val_loss: 0.0840 - val_acc: 0.9650\n",
      "Epoch 123/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0691 - acc: 0.9742WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0500 - acc: 0.9875\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 0.03476\n",
      "81/81 [==============================] - 22s 273ms/step - loss: 0.0691 - acc: 0.9742 - val_loss: 0.0500 - val_acc: 0.9875\n",
      "Epoch 124/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0529 - acc: 0.9833WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0361 - acc: 0.9850\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 0.03476\n",
      "81/81 [==============================] - 23s 285ms/step - loss: 0.0536 - acc: 0.9832 - val_loss: 0.0361 - val_acc: 0.9850\n",
      "Epoch 125/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0554 - acc: 0.9838WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0519 - acc: 0.9825\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 0.03476\n",
      "81/81 [==============================] - 29s 354ms/step - loss: 0.0559 - acc: 0.9836 - val_loss: 0.0519 - val_acc: 0.9825\n",
      "Epoch 126/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0547 - acc: 0.9824WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.0372 - acc: 0.9875\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 0.03476\n",
      "81/81 [==============================] - 21s 260ms/step - loss: 0.0550 - acc: 0.9823 - val_loss: 0.0372 - val_acc: 0.9875\n",
      "Epoch 127/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0539 - acc: 0.9815WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.0615 - acc: 0.9756\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 0.03476\n",
      "81/81 [==============================] - 22s 274ms/step - loss: 0.0549 - acc: 0.9808 - val_loss: 0.0615 - val_acc: 0.9756\n",
      "Epoch 128/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0602 - acc: 0.9812WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0652 - acc: 0.9716\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 0.03476\n",
      "81/81 [==============================] - 23s 287ms/step - loss: 0.0610 - acc: 0.9808 - val_loss: 0.0652 - val_acc: 0.9716\n",
      "Epoch 129/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0504 - acc: 0.9815WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0707 - acc: 0.9728\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 0.03476\n",
      "81/81 [==============================] - 22s 267ms/step - loss: 0.0512 - acc: 0.9811 - val_loss: 0.0707 - val_acc: 0.9728\n",
      "Epoch 130/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0486 - acc: 0.9866WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.0686 - acc: 0.9700\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 0.03476\n",
      "81/81 [==============================] - 25s 304ms/step - loss: 0.0483 - acc: 0.9867 - val_loss: 0.0686 - val_acc: 0.9700\n",
      "Epoch 131/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0657 - acc: 0.9811WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 20s 6ms/sample - loss: 0.0754 - acc: 0.9712\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 0.03476\n",
      "81/81 [==============================] - 24s 296ms/step - loss: 0.0661 - acc: 0.9811 - val_loss: 0.0754 - val_acc: 0.9712\n",
      "Epoch 132/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0543 - acc: 0.9812WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0677 - acc: 0.9759\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 0.03476\n",
      "81/81 [==============================] - 23s 281ms/step - loss: 0.0545 - acc: 0.9814 - val_loss: 0.0677 - val_acc: 0.9759\n",
      "Epoch 133/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0459 - acc: 0.9847WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3190/3183 [==============================] - 17s 5ms/sample - loss: 0.0414 - acc: 0.9799\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 0.03476\n",
      "81/81 [==============================] - 22s 275ms/step - loss: 0.0465 - acc: 0.9845 - val_loss: 0.0414 - val_acc: 0.9799\n",
      "Epoch 134/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0459 - acc: 0.9847WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 5ms/sample - loss: 0.0887 - acc: 0.9675\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 0.03476\n",
      "81/81 [==============================] - 21s 263ms/step - loss: 0.0457 - acc: 0.9848 - val_loss: 0.0887 - val_acc: 0.9675\n",
      "Epoch 135/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0469 - acc: 0.9855WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0518 - acc: 0.9775\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 0.03476\n",
      "81/81 [==============================] - 21s 260ms/step - loss: 0.0464 - acc: 0.9857 - val_loss: 0.0518 - val_acc: 0.9775\n",
      "Epoch 136/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0517 - acc: 0.9841WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0341 - acc: 0.9875\n",
      "\n",
      "Epoch 00136: val_loss improved from 0.03476 to 0.03410, saving model to model/checkpoint/vis_imagenet_6_class_augmentation_2D_CNN_custom_ch_32_DO_075_DO_3_conv_checkpoint/136-0.0341.hdf5\n",
      "81/81 [==============================] - 21s 254ms/step - loss: 0.0522 - acc: 0.9836 - val_loss: 0.0341 - val_acc: 0.9875\n",
      "Epoch 137/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0404 - acc: 0.9852WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3200/3183 [==============================] - 20s 6ms/sample - loss: 0.0546 - acc: 0.9812\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 0.03410\n",
      "81/81 [==============================] - 24s 291ms/step - loss: 0.0406 - acc: 0.9848 - val_loss: 0.0546 - val_acc: 0.9812\n",
      "Epoch 138/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0409 - acc: 0.9884WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0578 - acc: 0.98067s - loss: 0.068\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 0.03410\n",
      "81/81 [==============================] - 21s 261ms/step - loss: 0.0406 - acc: 0.9885 - val_loss: 0.0578 - val_acc: 0.9806\n",
      "Epoch 139/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0468 - acc: 0.9838WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0700 - acc: 0.9725\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 0.03410\n",
      "81/81 [==============================] - 23s 283ms/step - loss: 0.0470 - acc: 0.9839 - val_loss: 0.0700 - val_acc: 0.9725\n",
      "Epoch 140/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0504 - acc: 0.9806WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0888 - acc: 0.9703\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 0.03410\n",
      "81/81 [==============================] - 23s 280ms/step - loss: 0.0510 - acc: 0.9804 - val_loss: 0.0888 - val_acc: 0.9703\n",
      "Epoch 141/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0450 - acc: 0.9877WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 24s 7ms/sample - loss: 0.0559 - acc: 0.9812\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 0.03410\n",
      "81/81 [==============================] - 28s 347ms/step - loss: 0.0448 - acc: 0.9876 - val_loss: 0.0559 - val_acc: 0.9812\n",
      "Epoch 142/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0549 - acc: 0.9811WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0461 - acc: 0.9894\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 0.03410\n",
      "81/81 [==============================] - 24s 291ms/step - loss: 0.0548 - acc: 0.9808 - val_loss: 0.0461 - val_acc: 0.9894\n",
      "Epoch 143/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0623 - acc: 0.9815WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 20s 6ms/sample - loss: 0.0481 - acc: 0.9844\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 0.03410\n",
      "81/81 [==============================] - 24s 300ms/step - loss: 0.0625 - acc: 0.9814 - val_loss: 0.0481 - val_acc: 0.9844\n",
      "Epoch 144/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0458 - acc: 0.9870WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 23s 7ms/sample - loss: 0.0374 - acc: 0.9900\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 0.03410\n",
      "81/81 [==============================] - 29s 355ms/step - loss: 0.0462 - acc: 0.9867 - val_loss: 0.0374 - val_acc: 0.9900\n",
      "Epoch 145/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0519 - acc: 0.9828WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0440 - acc: 0.9875\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 0.03410\n",
      "81/81 [==============================] - 23s 284ms/step - loss: 0.0515 - acc: 0.9829 - val_loss: 0.0440 - val_acc: 0.9875\n",
      "Epoch 146/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0531 - acc: 0.9822WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0468 - acc: 0.9831\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 0.03410\n",
      "81/81 [==============================] - 22s 265ms/step - loss: 0.0526 - acc: 0.9820 - val_loss: 0.0468 - val_acc: 0.9831\n",
      "Epoch 147/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0418 - acc: 0.9859WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 23s 7ms/sample - loss: 0.0442 - acc: 0.9856\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 0.03410\n",
      "81/81 [==============================] - 26s 322ms/step - loss: 0.0415 - acc: 0.9860 - val_loss: 0.0442 - val_acc: 0.9856\n",
      "Epoch 148/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0476 - acc: 0.9874WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0428 - acc: 0.986916s\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 0.03410\n",
      "81/81 [==============================] - 23s 282ms/step - loss: 0.0478 - acc: 0.9873 - val_loss: 0.0428 - val_acc: 0.9869\n",
      "Epoch 149/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0491 - acc: 0.9838WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0605 - acc: 0.9800\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 0.03410\n",
      "81/81 [==============================] - 23s 279ms/step - loss: 0.0493 - acc: 0.9839 - val_loss: 0.0605 - val_acc: 0.9800\n",
      "Epoch 150/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0454 - acc: 0.9860WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0629 - acc: 0.9700\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 0.03410\n",
      "81/81 [==============================] - 22s 266ms/step - loss: 0.0464 - acc: 0.9857 - val_loss: 0.0629 - val_acc: 0.9700\n",
      "Epoch 151/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0378 - acc: 0.9860WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 20s 6ms/sample - loss: 0.0562 - acc: 0.9762\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 0.03410\n",
      "81/81 [==============================] - 24s 301ms/step - loss: 0.0397 - acc: 0.9860 - val_loss: 0.0562 - val_acc: 0.9762\n",
      "Epoch 152/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0500 - acc: 0.9847WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0531 - acc: 0.9806\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 0.03410\n",
      "81/81 [==============================] - 23s 282ms/step - loss: 0.0499 - acc: 0.9845 - val_loss: 0.0531 - val_acc: 0.9806\n",
      "Epoch 153/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/81 [============================>.] - ETA: 0s - loss: 0.0399 - acc: 0.9892WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0386 - acc: 0.9900\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 0.03410\n",
      "81/81 [==============================] - 23s 281ms/step - loss: 0.0397 - acc: 0.9894 - val_loss: 0.0386 - val_acc: 0.9900\n",
      "Epoch 154/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0531 - acc: 0.9799WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0720 - acc: 0.9700\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 0.03410\n",
      "81/81 [==============================] - 21s 256ms/step - loss: 0.0522 - acc: 0.9804 - val_loss: 0.0720 - val_acc: 0.9700\n",
      "Epoch 155/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0423 - acc: 0.9860WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0455 - acc: 0.9837\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 0.03410\n",
      "81/81 [==============================] - 21s 256ms/step - loss: 0.0425 - acc: 0.9854 - val_loss: 0.0455 - val_acc: 0.9837\n",
      "Epoch 156/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0494 - acc: 0.9866WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 27s 8ms/sample - loss: 0.0462 - acc: 0.9850\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 0.03410\n",
      "81/81 [==============================] - 30s 372ms/step - loss: 0.0499 - acc: 0.9863 - val_loss: 0.0462 - val_acc: 0.9850\n",
      "Epoch 157/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0520 - acc: 0.9841WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 22s 7ms/sample - loss: 0.0447 - acc: 0.9806\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 0.03410\n",
      "81/81 [==============================] - 27s 338ms/step - loss: 0.0520 - acc: 0.9839 - val_loss: 0.0447 - val_acc: 0.9806\n",
      "Epoch 158/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0484 - acc: 0.9812WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0470 - acc: 0.9850\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 0.03410\n",
      "81/81 [==============================] - 22s 269ms/step - loss: 0.0479 - acc: 0.9817 - val_loss: 0.0470 - val_acc: 0.9850\n",
      "Epoch 159/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0496 - acc: 0.9821WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.0447 - acc: 0.9850\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 0.03410\n",
      "81/81 [==============================] - 22s 270ms/step - loss: 0.0496 - acc: 0.9823 - val_loss: 0.0447 - val_acc: 0.9850\n",
      "Epoch 160/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0599 - acc: 0.9831WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 22s 7ms/sample - loss: 0.0492 - acc: 0.9766\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 0.03410\n",
      "81/81 [==============================] - 25s 315ms/step - loss: 0.0593 - acc: 0.9832 - val_loss: 0.0492 - val_acc: 0.9766\n",
      "Epoch 161/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0420 - acc: 0.9885WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0457 - acc: 0.9800\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 0.03410\n",
      "81/81 [==============================] - 23s 281ms/step - loss: 0.0415 - acc: 0.9888 - val_loss: 0.0457 - val_acc: 0.9800\n",
      "Epoch 162/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0446 - acc: 0.9862WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0440 - acc: 0.9872\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 0.03410\n",
      "81/81 [==============================] - 21s 265ms/step - loss: 0.0448 - acc: 0.9860 - val_loss: 0.0440 - val_acc: 0.9872\n",
      "Epoch 163/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0506 - acc: 0.9859WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 22s 7ms/sample - loss: 0.0349 - acc: 0.9875\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 0.03410\n",
      "81/81 [==============================] - 25s 314ms/step - loss: 0.0506 - acc: 0.9857 - val_loss: 0.0349 - val_acc: 0.9875\n",
      "Epoch 164/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0415 - acc: 0.9896WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0359 - acc: 0.9850\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 0.03410\n",
      "81/81 [==============================] - 22s 269ms/step - loss: 0.0413 - acc: 0.9898 - val_loss: 0.0359 - val_acc: 0.9850\n",
      "Epoch 165/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0302 - acc: 0.9901WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0479 - acc: 0.9800\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 0.03410\n",
      "81/81 [==============================] - 21s 262ms/step - loss: 0.0299 - acc: 0.9904 - val_loss: 0.0479 - val_acc: 0.9800\n",
      "Epoch 166/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0480 - acc: 0.9860WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0440 - acc: 0.9841\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 0.03410\n",
      "81/81 [==============================] - 22s 266ms/step - loss: 0.0479 - acc: 0.9857 - val_loss: 0.0440 - val_acc: 0.9841\n",
      "Epoch 167/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0398 - acc: 0.9873WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0521 - acc: 0.9806\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 0.03410\n",
      "81/81 [==============================] - 22s 270ms/step - loss: 0.0395 - acc: 0.9873 - val_loss: 0.0521 - val_acc: 0.9806\n",
      "Epoch 168/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0432 - acc: 0.9862WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0579 - acc: 0.9775\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 0.03410\n",
      "81/81 [==============================] - 21s 255ms/step - loss: 0.0428 - acc: 0.9863 - val_loss: 0.0579 - val_acc: 0.9775\n",
      "Epoch 169/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0329 - acc: 0.9895WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0407 - acc: 0.9850\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 0.03410\n",
      "81/81 [==============================] - 21s 263ms/step - loss: 0.0324 - acc: 0.9898 - val_loss: 0.0407 - val_acc: 0.9850\n",
      "Epoch 170/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0459 - acc: 0.9862WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0302 - acc: 0.9937\n",
      "\n",
      "Epoch 00170: val_loss improved from 0.03410 to 0.03023, saving model to model/checkpoint/vis_imagenet_6_class_augmentation_2D_CNN_custom_ch_32_DO_075_DO_3_conv_checkpoint/170-0.0302.hdf5\n",
      "81/81 [==============================] - 25s 305ms/step - loss: 0.0464 - acc: 0.9857 - val_loss: 0.0302 - val_acc: 0.9937\n",
      "Epoch 171/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0421 - acc: 0.9870WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 5ms/sample - loss: 0.0443 - acc: 0.9825\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 0.03023\n",
      "81/81 [==============================] - 21s 259ms/step - loss: 0.0427 - acc: 0.9867 - val_loss: 0.0443 - val_acc: 0.9825\n",
      "Epoch 172/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0400 - acc: 0.9895WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0328 - acc: 0.9866\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 0.03023\n",
      "81/81 [==============================] - 21s 260ms/step - loss: 0.0401 - acc: 0.9891 - val_loss: 0.0328 - val_acc: 0.9866\n",
      "Epoch 173/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0426 - acc: 0.9871WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 15s 5ms/sample - loss: 0.0524 - acc: 0.9775\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 0.03023\n",
      "81/81 [==============================] - 19s 236ms/step - loss: 0.0424 - acc: 0.9873 - val_loss: 0.0524 - val_acc: 0.9775\n",
      "Epoch 174/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0341 - acc: 0.9896WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 23s 7ms/sample - loss: 0.0796 - acc: 0.9659\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 0.03023\n",
      "81/81 [==============================] - 27s 335ms/step - loss: 0.0338 - acc: 0.9898 - val_loss: 0.0796 - val_acc: 0.9659\n",
      "Epoch 175/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0404 - acc: 0.9899WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0417 - acc: 0.9831\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 0.03023\n",
      "81/81 [==============================] - 27s 329ms/step - loss: 0.0402 - acc: 0.9901 - val_loss: 0.0417 - val_acc: 0.9831\n",
      "Epoch 176/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0298 - acc: 0.9906WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 29s 9ms/sample - loss: 0.0633 - acc: 0.9725\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 0.03023\n",
      "81/81 [==============================] - 35s 436ms/step - loss: 0.0295 - acc: 0.9907 - val_loss: 0.0633 - val_acc: 0.9725\n",
      "Epoch 177/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0370 - acc: 0.9895WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0548 - acc: 0.9728\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 0.03023\n",
      "81/81 [==============================] - 25s 305ms/step - loss: 0.0368 - acc: 0.9898 - val_loss: 0.0548 - val_acc: 0.9728\n",
      "Epoch 178/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0373 - acc: 0.9874WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0363 - acc: 0.9887\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 0.03023\n",
      "81/81 [==============================] - 23s 282ms/step - loss: 0.0375 - acc: 0.9876 - val_loss: 0.0363 - val_acc: 0.9887\n",
      "Epoch 179/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0339 - acc: 0.9874WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 20s 6ms/sample - loss: 0.0392 - acc: 0.9837\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 0.03023\n",
      "81/81 [==============================] - 24s 302ms/step - loss: 0.0336 - acc: 0.9876 - val_loss: 0.0392 - val_acc: 0.9837\n",
      "Epoch 180/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0383 - acc: 0.9884WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0675 - acc: 0.9769\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 0.03023\n",
      "81/81 [==============================] - 23s 285ms/step - loss: 0.0380 - acc: 0.9885 - val_loss: 0.0675 - val_acc: 0.9769\n",
      "Epoch 181/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0409 - acc: 0.9873WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 20s 6ms/sample - loss: 0.0776 - acc: 0.9725\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 0.03023\n",
      "81/81 [==============================] - 23s 290ms/step - loss: 0.0418 - acc: 0.9873 - val_loss: 0.0776 - val_acc: 0.9725\n",
      "Epoch 182/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0459 - acc: 0.9835WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0351 - acc: 0.9875\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 0.03023\n",
      "81/81 [==============================] - 22s 270ms/step - loss: 0.0475 - acc: 0.9832 - val_loss: 0.0351 - val_acc: 0.9875\n",
      "Epoch 183/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0361 - acc: 0.9866WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0968 - acc: 0.9669\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 0.03023\n",
      "81/81 [==============================] - 21s 255ms/step - loss: 0.0373 - acc: 0.9863 - val_loss: 0.0968 - val_acc: 0.9669\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 184/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0413 - acc: 0.9855WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0245 - acc: 0.9900\n",
      "\n",
      "Epoch 00184: val_loss improved from 0.03023 to 0.02453, saving model to model/checkpoint/vis_imagenet_6_class_augmentation_2D_CNN_custom_ch_32_DO_075_DO_3_conv_checkpoint/184-0.0245.hdf5\n",
      "81/81 [==============================] - 22s 271ms/step - loss: 0.0411 - acc: 0.9854 - val_loss: 0.0245 - val_acc: 0.9900\n",
      "Epoch 185/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0369 - acc: 0.9884WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 21s 6ms/sample - loss: 0.0370 - acc: 0.9866\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 0.02453\n",
      "81/81 [==============================] - 24s 297ms/step - loss: 0.0375 - acc: 0.9882 - val_loss: 0.0370 - val_acc: 0.9866\n",
      "Epoch 186/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0312 - acc: 0.9899WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 5ms/sample - loss: 0.0610 - acc: 0.9750\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 0.02453\n",
      "81/81 [==============================] - 22s 274ms/step - loss: 0.0310 - acc: 0.9901 - val_loss: 0.0610 - val_acc: 0.9750\n",
      "Epoch 187/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0377 - acc: 0.9890WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0340 - acc: 0.9891\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 0.02453\n",
      "81/81 [==============================] - 27s 329ms/step - loss: 0.0373 - acc: 0.9891 - val_loss: 0.0340 - val_acc: 0.9891\n",
      "Epoch 188/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0339 - acc: 0.9892WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0535 - acc: 0.9775\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 0.02453\n",
      "81/81 [==============================] - 21s 258ms/step - loss: 0.0338 - acc: 0.9891 - val_loss: 0.0535 - val_acc: 0.9775\n",
      "Epoch 189/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0374 - acc: 0.9887WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0520 - acc: 0.9875\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 0.02453\n",
      "81/81 [==============================] - 21s 256ms/step - loss: 0.0370 - acc: 0.9888 - val_loss: 0.0520 - val_acc: 0.9875\n",
      "Epoch 190/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0342 - acc: 0.9889WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0291 - acc: 0.9850\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 0.02453\n",
      "81/81 [==============================] - 21s 258ms/step - loss: 0.0338 - acc: 0.9891 - val_loss: 0.0291 - val_acc: 0.9850\n",
      "Epoch 191/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0259 - acc: 0.9940WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0458 - acc: 0.9872\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 0.02453\n",
      "81/81 [==============================] - 22s 276ms/step - loss: 0.0256 - acc: 0.9941 - val_loss: 0.0458 - val_acc: 0.9872\n",
      "Epoch 192/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0344 - acc: 0.9895WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0412 - acc: 0.9866\n",
      "\n",
      "Epoch 00192: val_loss did not improve from 0.02453\n",
      "81/81 [==============================] - 24s 302ms/step - loss: 0.0349 - acc: 0.9888 - val_loss: 0.0412 - val_acc: 0.9866\n",
      "Epoch 193/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0361 - acc: 0.9896WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0371 - acc: 0.9856\n",
      "\n",
      "Epoch 00193: val_loss did not improve from 0.02453\n",
      "81/81 [==============================] - 23s 279ms/step - loss: 0.0366 - acc: 0.9894 - val_loss: 0.0371 - val_acc: 0.9856\n",
      "Epoch 194/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0384 - acc: 0.9862WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0407 - acc: 0.9875\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 0.02453\n",
      "81/81 [==============================] - 23s 290ms/step - loss: 0.0380 - acc: 0.9863 - val_loss: 0.0407 - val_acc: 0.9875\n",
      "Epoch 195/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0351 - acc: 0.9889WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0357 - acc: 0.9881\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 0.02453\n",
      "81/81 [==============================] - 25s 309ms/step - loss: 0.0353 - acc: 0.9888 - val_loss: 0.0357 - val_acc: 0.9881\n",
      "Epoch 196/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0400 - acc: 0.9884WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.0684 - acc: 0.9725\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 0.02453\n",
      "81/81 [==============================] - 23s 279ms/step - loss: 0.0401 - acc: 0.9882 - val_loss: 0.0684 - val_acc: 0.9725\n",
      "Epoch 197/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0457 - acc: 0.9855WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0589 - acc: 0.9812\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 0.02453\n",
      "81/81 [==============================] - 23s 279ms/step - loss: 0.0455 - acc: 0.9857 - val_loss: 0.0589 - val_acc: 0.9812\n",
      "Epoch 198/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0457 - acc: 0.9859WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 5ms/sample - loss: 0.0536 - acc: 0.98002s - loss: 0.0596 - acc: \n",
      "\n",
      "Epoch 00198: val_loss did not improve from 0.02453\n",
      "81/81 [==============================] - 23s 280ms/step - loss: 0.0454 - acc: 0.9860 - val_loss: 0.0536 - val_acc: 0.9800\n",
      "Epoch 199/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0309 - acc: 0.9901WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0409 - acc: 0.9837\n",
      "\n",
      "Epoch 00199: val_loss did not improve from 0.02453\n",
      "81/81 [==============================] - 23s 281ms/step - loss: 0.0314 - acc: 0.9901 - val_loss: 0.0409 - val_acc: 0.9837\n",
      "Epoch 200/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0324 - acc: 0.9931WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0675 - acc: 0.97502s - loss: 0.0652 - acc: \n",
      "\n",
      "Epoch 00200: val_loss did not improve from 0.02453\n",
      "81/81 [==============================] - 23s 289ms/step - loss: 0.0322 - acc: 0.9932 - val_loss: 0.0675 - val_acc: 0.9750\n",
      "Epoch 201/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0399 - acc: 0.9885WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 22s 7ms/sample - loss: 0.0564 - acc: 0.9766\n",
      "\n",
      "Epoch 00201: val_loss did not improve from 0.02453\n",
      "81/81 [==============================] - 29s 358ms/step - loss: 0.0393 - acc: 0.9885 - val_loss: 0.0564 - val_acc: 0.9766\n",
      "Epoch 202/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0424 - acc: 0.9885WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.0308 - acc: 0.9850\n",
      "\n",
      "Epoch 00202: val_loss did not improve from 0.02453\n",
      "81/81 [==============================] - 21s 255ms/step - loss: 0.0421 - acc: 0.9882 - val_loss: 0.0308 - val_acc: 0.9850\n",
      "Epoch 203/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0269 - acc: 0.9927WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.0528 - acc: 0.9775\n",
      "\n",
      "Epoch 00203: val_loss did not improve from 0.02453\n",
      "81/81 [==============================] - 23s 280ms/step - loss: 0.0264 - acc: 0.9929 - val_loss: 0.0528 - val_acc: 0.9775\n",
      "Epoch 204/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0366 - acc: 0.9873WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0535 - acc: 0.9791\n",
      "\n",
      "Epoch 00204: val_loss did not improve from 0.02453\n",
      "81/81 [==============================] - 22s 267ms/step - loss: 0.0370 - acc: 0.9867 - val_loss: 0.0535 - val_acc: 0.9791\n",
      "Epoch 205/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0293 - acc: 0.9915WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.0362 - acc: 0.9900\n",
      "\n",
      "Epoch 00205: val_loss did not improve from 0.02453\n",
      "81/81 [==============================] - 21s 261ms/step - loss: 0.0298 - acc: 0.9913 - val_loss: 0.0362 - val_acc: 0.9900\n",
      "Epoch 206/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0253 - acc: 0.9931WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0579 - acc: 0.9766\n",
      "\n",
      "Epoch 00206: val_loss did not improve from 0.02453\n",
      "81/81 [==============================] - 21s 265ms/step - loss: 0.0253 - acc: 0.9929 - val_loss: 0.0579 - val_acc: 0.9766\n",
      "Epoch 207/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0454 - acc: 0.9881WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0480 - acc: 0.9800\n",
      "\n",
      "Epoch 00207: val_loss did not improve from 0.02453\n",
      "81/81 [==============================] - 23s 282ms/step - loss: 0.0455 - acc: 0.9879 - val_loss: 0.0480 - val_acc: 0.9800\n",
      "Epoch 208/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0308 - acc: 0.9893WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0513 - acc: 0.9875\n",
      "\n",
      "Epoch 00208: val_loss did not improve from 0.02453\n",
      "81/81 [==============================] - 21s 265ms/step - loss: 0.0305 - acc: 0.9894 - val_loss: 0.0513 - val_acc: 0.9875\n",
      "Epoch 209/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0356 - acc: 0.9896WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0372 - acc: 0.9894\n",
      "\n",
      "Epoch 00209: val_loss did not improve from 0.02453\n",
      "81/81 [==============================] - 21s 265ms/step - loss: 0.0360 - acc: 0.9894 - val_loss: 0.0372 - val_acc: 0.9894\n",
      "Epoch 210/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0331 - acc: 0.9893WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0549 - acc: 0.9778\n",
      "\n",
      "Epoch 00210: val_loss did not improve from 0.02453\n",
      "81/81 [==============================] - 24s 302ms/step - loss: 0.0327 - acc: 0.9894 - val_loss: 0.0549 - val_acc: 0.9778\n",
      "Epoch 211/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0291 - acc: 0.9906WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.0523 - acc: 0.9837\n",
      "\n",
      "Epoch 00211: val_loss did not improve from 0.02453\n",
      "81/81 [==============================] - 21s 256ms/step - loss: 0.0291 - acc: 0.9907 - val_loss: 0.0523 - val_acc: 0.9837\n",
      "Epoch 212/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0437 - acc: 0.9862WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0450 - acc: 0.9856\n",
      "\n",
      "Epoch 00212: val_loss did not improve from 0.02453\n",
      "81/81 [==============================] - 24s 292ms/step - loss: 0.0433 - acc: 0.9863 - val_loss: 0.0450 - val_acc: 0.9856\n",
      "Epoch 213/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0304 - acc: 0.9925WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0400 - acc: 0.9872\n",
      "\n",
      "Epoch 00213: val_loss did not improve from 0.02453\n",
      "81/81 [==============================] - 23s 289ms/step - loss: 0.0303 - acc: 0.9926 - val_loss: 0.0400 - val_acc: 0.9872\n",
      "Epoch 214/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0335 - acc: 0.9887WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0440 - acc: 0.9897\n",
      "\n",
      "Epoch 00214: val_loss did not improve from 0.02453\n",
      "81/81 [==============================] - 23s 289ms/step - loss: 0.0351 - acc: 0.9882 - val_loss: 0.0440 - val_acc: 0.9897\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 215/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0436 - acc: 0.9846WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0435 - acc: 0.9894\n",
      "\n",
      "Epoch 00215: val_loss did not improve from 0.02453\n",
      "81/81 [==============================] - 25s 308ms/step - loss: 0.0431 - acc: 0.9848 - val_loss: 0.0435 - val_acc: 0.9894\n",
      "Epoch 216/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0282 - acc: 0.9930WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0567 - acc: 0.9737\n",
      "\n",
      "Epoch 00216: val_loss did not improve from 0.02453\n",
      "81/81 [==============================] - 23s 282ms/step - loss: 0.0286 - acc: 0.9929 - val_loss: 0.0567 - val_acc: 0.9737\n",
      "Epoch 217/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0296 - acc: 0.9911WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 20s 6ms/sample - loss: 0.0592 - acc: 0.9775\n",
      "\n",
      "Epoch 00217: val_loss did not improve from 0.02453\n",
      "81/81 [==============================] - 23s 290ms/step - loss: 0.0294 - acc: 0.9910 - val_loss: 0.0592 - val_acc: 0.9775\n",
      "Epoch 218/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0416 - acc: 0.9895WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0374 - acc: 0.9900\n",
      "\n",
      "Epoch 00218: val_loss did not improve from 0.02453\n",
      "81/81 [==============================] - 21s 256ms/step - loss: 0.0418 - acc: 0.9894 - val_loss: 0.0374 - val_acc: 0.9900\n",
      "Epoch 219/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0296 - acc: 0.9918WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0442 - acc: 0.9844\n",
      "\n",
      "Epoch 00219: val_loss did not improve from 0.02453\n",
      "81/81 [==============================] - 21s 262ms/step - loss: 0.0299 - acc: 0.9916 - val_loss: 0.0442 - val_acc: 0.9844\n",
      "Epoch 220/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0262 - acc: 0.9933WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.0415 - acc: 0.9866\n",
      "\n",
      "Epoch 00220: val_loss did not improve from 0.02453\n",
      "81/81 [==============================] - 22s 270ms/step - loss: 0.0265 - acc: 0.9932 - val_loss: 0.0415 - val_acc: 0.9866\n",
      "Epoch 221/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0308 - acc: 0.9898WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0415 - acc: 0.9919\n",
      "\n",
      "Epoch 00221: val_loss did not improve from 0.02453\n",
      "81/81 [==============================] - 21s 260ms/step - loss: 0.0307 - acc: 0.9898 - val_loss: 0.0415 - val_acc: 0.9919\n",
      "Epoch 222/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0312 - acc: 0.9912WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0392 - acc: 0.9900\n",
      "\n",
      "Epoch 00222: val_loss did not improve from 0.02453\n",
      "81/81 [==============================] - 21s 258ms/step - loss: 0.0309 - acc: 0.9913 - val_loss: 0.0392 - val_acc: 0.9900\n",
      "Epoch 223/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0273 - acc: 0.9917WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0449 - acc: 0.9806\n",
      "\n",
      "Epoch 00223: val_loss did not improve from 0.02453\n",
      "81/81 [==============================] - 23s 279ms/step - loss: 0.0276 - acc: 0.9913 - val_loss: 0.0449 - val_acc: 0.9806\n",
      "Epoch 224/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0314 - acc: 0.9921WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 21s 6ms/sample - loss: 0.0418 - acc: 0.9884\n",
      "\n",
      "Epoch 00224: val_loss did not improve from 0.02453\n",
      "81/81 [==============================] - 25s 303ms/step - loss: 0.0324 - acc: 0.9919 - val_loss: 0.0418 - val_acc: 0.9884\n",
      "Epoch 225/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0341 - acc: 0.9906WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0416 - acc: 0.9887\n",
      "\n",
      "Epoch 00225: val_loss did not improve from 0.02453\n",
      "81/81 [==============================] - 27s 331ms/step - loss: 0.0338 - acc: 0.9907 - val_loss: 0.0416 - val_acc: 0.9887\n",
      "Epoch 226/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0392 - acc: 0.9915WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0464 - acc: 0.9809\n",
      "\n",
      "Epoch 00226: val_loss did not improve from 0.02453\n",
      "81/81 [==============================] - 25s 304ms/step - loss: 0.0389 - acc: 0.9916 - val_loss: 0.0464 - val_acc: 0.9809\n",
      "Epoch 227/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0276 - acc: 0.9917WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0544 - acc: 0.9737\n",
      "\n",
      "Epoch 00227: val_loss did not improve from 0.02453\n",
      "81/81 [==============================] - 22s 274ms/step - loss: 0.0273 - acc: 0.9916 - val_loss: 0.0544 - val_acc: 0.9737\n",
      "Epoch 228/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0306 - acc: 0.9884WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0320 - acc: 0.9875\n",
      "\n",
      "Epoch 00228: val_loss did not improve from 0.02453\n",
      "81/81 [==============================] - 22s 273ms/step - loss: 0.0303 - acc: 0.9885 - val_loss: 0.0320 - val_acc: 0.9875\n",
      "Epoch 229/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0297 - acc: 0.9914WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 21s 7ms/sample - loss: 0.0390 - acc: 0.9834 8s - loss: 0.04\n",
      "\n",
      "Epoch 00229: val_loss did not improve from 0.02453\n",
      "81/81 [==============================] - 26s 316ms/step - loss: 0.0292 - acc: 0.9916 - val_loss: 0.0390 - val_acc: 0.9834\n",
      "Epoch 230/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0264 - acc: 0.9918WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0312 - acc: 0.9925\n",
      "\n",
      "Epoch 00230: val_loss did not improve from 0.02453\n",
      "81/81 [==============================] - 21s 260ms/step - loss: 0.0264 - acc: 0.9919 - val_loss: 0.0312 - val_acc: 0.9925\n",
      "Epoch 231/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0357 - acc: 0.9890WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0283 - acc: 0.9900\n",
      "\n",
      "Epoch 00231: val_loss did not improve from 0.02453\n",
      "81/81 [==============================] - 23s 283ms/step - loss: 0.0353 - acc: 0.9891 - val_loss: 0.0283 - val_acc: 0.9900\n",
      "Epoch 232/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0304 - acc: 0.9873WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0431 - acc: 0.9850\n",
      "\n",
      "Epoch 00232: val_loss did not improve from 0.02453\n",
      "81/81 [==============================] - 23s 283ms/step - loss: 0.0315 - acc: 0.9870 - val_loss: 0.0431 - val_acc: 0.9850\n",
      "Epoch 233/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0290 - acc: 0.9934WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0376 - acc: 0.9850\n",
      "\n",
      "Epoch 00233: val_loss did not improve from 0.02453\n",
      "81/81 [==============================] - 22s 277ms/step - loss: 0.0288 - acc: 0.9935 - val_loss: 0.0376 - val_acc: 0.9850\n",
      "Epoch 234/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0275 - acc: 0.9930WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 21s 7ms/sample - loss: 0.0691 - acc: 0.9737\n",
      "\n",
      "Epoch 00234: val_loss did not improve from 0.02453\n",
      "81/81 [==============================] - 27s 334ms/step - loss: 0.0269 - acc: 0.9932 - val_loss: 0.0691 - val_acc: 0.9737\n",
      "Epoch 235/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0356 - acc: 0.9908WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0463 - acc: 0.9875\n",
      "\n",
      "Epoch 00235: val_loss did not improve from 0.02453\n",
      "81/81 [==============================] - 21s 262ms/step - loss: 0.0353 - acc: 0.9907 - val_loss: 0.0463 - val_acc: 0.9875\n",
      "Epoch 236/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0292 - acc: 0.9906WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0292 - acc: 0.9925\n",
      "\n",
      "Epoch 00236: val_loss did not improve from 0.02453\n",
      "81/81 [==============================] - 25s 307ms/step - loss: 0.0291 - acc: 0.9907 - val_loss: 0.0292 - val_acc: 0.9925\n",
      "Epoch 237/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0184 - acc: 0.9943WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 21s 6ms/sample - loss: 0.0345 - acc: 0.9822\n",
      "\n",
      "Epoch 00237: val_loss did not improve from 0.02453\n",
      "81/81 [==============================] - 25s 303ms/step - loss: 0.0183 - acc: 0.9944 - val_loss: 0.0345 - val_acc: 0.9822\n",
      "Epoch 238/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0253 - acc: 0.9917WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0345 - acc: 0.9900\n",
      "\n",
      "Epoch 00238: val_loss did not improve from 0.02453\n",
      "81/81 [==============================] - 25s 305ms/step - loss: 0.0249 - acc: 0.9919 - val_loss: 0.0345 - val_acc: 0.9900\n",
      "Epoch 239/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0324 - acc: 0.9889WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0438 - acc: 0.9866\n",
      "\n",
      "Epoch 00239: val_loss did not improve from 0.02453\n",
      "81/81 [==============================] - 22s 267ms/step - loss: 0.0324 - acc: 0.9891 - val_loss: 0.0438 - val_acc: 0.9866\n",
      "Epoch 240/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0235 - acc: 0.9943WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0324 - acc: 0.9875\n",
      "\n",
      "Epoch 00240: val_loss did not improve from 0.02453\n",
      "81/81 [==============================] - 21s 261ms/step - loss: 0.0236 - acc: 0.9941 - val_loss: 0.0324 - val_acc: 0.9875\n",
      "Epoch 241/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0278 - acc: 0.9895WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0431 - acc: 0.9881\n",
      "\n",
      "Epoch 00241: val_loss did not improve from 0.02453\n",
      "81/81 [==============================] - 22s 272ms/step - loss: 0.0274 - acc: 0.9898 - val_loss: 0.0431 - val_acc: 0.9881\n",
      "Epoch 242/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0318 - acc: 0.9895WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0353 - acc: 0.9881\n",
      "\n",
      "Epoch 00242: val_loss did not improve from 0.02453\n",
      "81/81 [==============================] - 21s 265ms/step - loss: 0.0312 - acc: 0.9898 - val_loss: 0.0353 - val_acc: 0.9881\n",
      "Epoch 243/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0280 - acc: 0.9893WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0436 - acc: 0.9850\n",
      "\n",
      "Epoch 00243: val_loss did not improve from 0.02453\n",
      "81/81 [==============================] - 21s 258ms/step - loss: 0.0277 - acc: 0.9894 - val_loss: 0.0436 - val_acc: 0.9850\n",
      "Epoch 244/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0236 - acc: 0.9943WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 22s 7ms/sample - loss: 0.0457 - acc: 0.9859\n",
      "\n",
      "Epoch 00244: val_loss did not improve from 0.02453\n",
      "81/81 [==============================] - 25s 313ms/step - loss: 0.0247 - acc: 0.9938 - val_loss: 0.0457 - val_acc: 0.9859\n",
      "Epoch 245/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0207 - acc: 0.9924WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.0614 - acc: 0.9781\n",
      "\n",
      "Epoch 00245: val_loss did not improve from 0.02453\n",
      "81/81 [==============================] - 23s 289ms/step - loss: 0.0208 - acc: 0.9922 - val_loss: 0.0614 - val_acc: 0.9781\n",
      "Epoch 246/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/81 [============================>.] - ETA: 0s - loss: 0.0247 - acc: 0.9921WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0347 - acc: 0.9925\n",
      "\n",
      "Epoch 00246: val_loss did not improve from 0.02453\n",
      "81/81 [==============================] - 23s 281ms/step - loss: 0.0247 - acc: 0.9922 - val_loss: 0.0347 - val_acc: 0.9925\n",
      "Epoch 247/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0274 - acc: 0.9908WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 5ms/sample - loss: 0.0569 - acc: 0.9737\n",
      "\n",
      "Epoch 00247: val_loss did not improve from 0.02453\n",
      "81/81 [==============================] - 21s 264ms/step - loss: 0.0268 - acc: 0.9910 - val_loss: 0.0569 - val_acc: 0.9737\n",
      "Epoch 248/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0302 - acc: 0.9908WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0298 - acc: 0.9875\n",
      "\n",
      "Epoch 00248: val_loss did not improve from 0.02453\n",
      "81/81 [==============================] - 21s 261ms/step - loss: 0.0334 - acc: 0.9904 - val_loss: 0.0298 - val_acc: 0.9875\n",
      "Epoch 249/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0313 - acc: 0.9915WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0302 - acc: 0.9900\n",
      "\n",
      "Epoch 00249: val_loss did not improve from 0.02453\n",
      "81/81 [==============================] - 22s 268ms/step - loss: 0.0310 - acc: 0.9916 - val_loss: 0.0302 - val_acc: 0.9900\n",
      "Epoch 250/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0269 - acc: 0.9908WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0366 - acc: 0.9900\n",
      "\n",
      "Epoch 00250: val_loss did not improve from 0.02453\n",
      "81/81 [==============================] - 20s 248ms/step - loss: 0.0267 - acc: 0.9910 - val_loss: 0.0366 - val_acc: 0.9900\n",
      "Epoch 251/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0344 - acc: 0.9906WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0388 - acc: 0.9900\n",
      "\n",
      "Epoch 00251: val_loss did not improve from 0.02453\n",
      "81/81 [==============================] - 21s 255ms/step - loss: 0.0344 - acc: 0.9904 - val_loss: 0.0388 - val_acc: 0.9900\n",
      "Epoch 252/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0249 - acc: 0.9908WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0542 - acc: 0.9791\n",
      "\n",
      "Epoch 00252: val_loss did not improve from 0.02453\n",
      "81/81 [==============================] - 22s 268ms/step - loss: 0.0247 - acc: 0.9910 - val_loss: 0.0542 - val_acc: 0.9791\n",
      "Epoch 253/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0204 - acc: 0.9949WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 22s 7ms/sample - loss: 0.0456 - acc: 0.9875\n",
      "\n",
      "Epoch 00253: val_loss did not improve from 0.02453\n",
      "81/81 [==============================] - 25s 311ms/step - loss: 0.0201 - acc: 0.9950 - val_loss: 0.0456 - val_acc: 0.9875\n",
      "Epoch 254/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0234 - acc: 0.9927WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0368 - acc: 0.9925\n",
      "\n",
      "Epoch 00254: val_loss did not improve from 0.02453\n",
      "81/81 [==============================] - 22s 274ms/step - loss: 0.0232 - acc: 0.9926 - val_loss: 0.0368 - val_acc: 0.9925\n",
      "Epoch 255/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0211 - acc: 0.9912WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0528 - acc: 0.9775\n",
      "\n",
      "Epoch 00255: val_loss did not improve from 0.02453\n",
      "81/81 [==============================] - 22s 269ms/step - loss: 0.0224 - acc: 0.9910 - val_loss: 0.0528 - val_acc: 0.9775\n",
      "Epoch 256/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0197 - acc: 0.9943WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0591 - acc: 0.9812\n",
      "\n",
      "Epoch 00256: val_loss did not improve from 0.02453\n",
      "81/81 [==============================] - 24s 295ms/step - loss: 0.0201 - acc: 0.9941 - val_loss: 0.0591 - val_acc: 0.9812\n",
      "Epoch 257/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0214 - acc: 0.9955WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 14s 5ms/sample - loss: 0.0517 - acc: 0.9850\n",
      "\n",
      "Epoch 00257: val_loss did not improve from 0.02453\n",
      "81/81 [==============================] - 22s 267ms/step - loss: 0.0212 - acc: 0.9957 - val_loss: 0.0517 - val_acc: 0.9850\n",
      "Epoch 258/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0315 - acc: 0.9876WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0463 - acc: 0.9850\n",
      "\n",
      "Epoch 00258: val_loss did not improve from 0.02453\n",
      "81/81 [==============================] - 22s 271ms/step - loss: 0.0339 - acc: 0.9870 - val_loss: 0.0463 - val_acc: 0.9850\n",
      "Epoch 259/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0349 - acc: 0.9889WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 24s 8ms/sample - loss: 0.0359 - acc: 0.9900\n",
      "\n",
      "Epoch 00259: val_loss did not improve from 0.02453\n",
      "81/81 [==============================] - 28s 344ms/step - loss: 0.0342 - acc: 0.9891 - val_loss: 0.0359 - val_acc: 0.9900\n",
      "Epoch 260/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0179 - acc: 0.9931WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0521 - acc: 0.9800\n",
      "\n",
      "Epoch 00260: val_loss did not improve from 0.02453\n",
      "81/81 [==============================] - 26s 322ms/step - loss: 0.0177 - acc: 0.9932 - val_loss: 0.0521 - val_acc: 0.9800\n",
      "Epoch 261/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0352 - acc: 0.9909WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3200/3183 [==============================] - 23s 7ms/sample - loss: 0.0433 - acc: 0.9875\n",
      "\n",
      "Epoch 00261: val_loss did not improve from 0.02453\n",
      "81/81 [==============================] - 26s 324ms/step - loss: 0.0348 - acc: 0.9910 - val_loss: 0.0433 - val_acc: 0.9875\n",
      "Epoch 262/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0304 - acc: 0.9896WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0493 - acc: 0.9841\n",
      "\n",
      "Epoch 00262: val_loss did not improve from 0.02453\n",
      "81/81 [==============================] - 25s 314ms/step - loss: 0.0301 - acc: 0.9898 - val_loss: 0.0493 - val_acc: 0.9841\n",
      "Epoch 263/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0330 - acc: 0.9901WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0455 - acc: 0.9859\n",
      "\n",
      "Epoch 00263: val_loss did not improve from 0.02453\n",
      "81/81 [==============================] - 23s 279ms/step - loss: 0.0330 - acc: 0.9901 - val_loss: 0.0455 - val_acc: 0.9859\n",
      "Epoch 264/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0316 - acc: 0.9924WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0420 - acc: 0.9850\n",
      "\n",
      "Epoch 00264: val_loss did not improve from 0.02453\n",
      "81/81 [==============================] - 21s 259ms/step - loss: 0.0329 - acc: 0.9919 - val_loss: 0.0420 - val_acc: 0.9850\n",
      "Epoch 265/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0276 - acc: 0.9930WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0449 - acc: 0.9894\n",
      "\n",
      "Epoch 00265: val_loss did not improve from 0.02453\n",
      "81/81 [==============================] - 23s 283ms/step - loss: 0.0274 - acc: 0.9929 - val_loss: 0.0449 - val_acc: 0.9894\n",
      "Epoch 266/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0263 - acc: 0.9901WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 13s 4ms/sample - loss: 0.0337 - acc: 0.9894\n",
      "\n",
      "Epoch 00266: val_loss did not improve from 0.02453\n",
      "81/81 [==============================] - 21s 255ms/step - loss: 0.0258 - acc: 0.9904 - val_loss: 0.0337 - val_acc: 0.9894\n",
      "Epoch 267/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0258 - acc: 0.9917WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0332 - acc: 0.9900\n",
      "\n",
      "Epoch 00267: val_loss did not improve from 0.02453\n",
      "81/81 [==============================] - 22s 274ms/step - loss: 0.0257 - acc: 0.9916 - val_loss: 0.0332 - val_acc: 0.9900\n",
      "Epoch 268/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0187 - acc: 0.9947WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0373 - acc: 0.9919\n",
      "\n",
      "Epoch 00268: val_loss did not improve from 0.02453\n",
      "81/81 [==============================] - 22s 266ms/step - loss: 0.0189 - acc: 0.9947 - val_loss: 0.0373 - val_acc: 0.9919\n",
      "Epoch 269/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0235 - acc: 0.9943WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 20s 6ms/sample - loss: 0.0413 - acc: 0.9859\n",
      "\n",
      "Epoch 00269: val_loss did not improve from 0.02453\n",
      "81/81 [==============================] - 24s 295ms/step - loss: 0.0242 - acc: 0.9941 - val_loss: 0.0413 - val_acc: 0.9859\n",
      "Epoch 270/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0270 - acc: 0.9908WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0297 - acc: 0.9897\n",
      "\n",
      "Epoch 00270: val_loss did not improve from 0.02453\n",
      "81/81 [==============================] - 23s 282ms/step - loss: 0.0275 - acc: 0.9904 - val_loss: 0.0297 - val_acc: 0.9897\n",
      "Epoch 271/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0270 - acc: 0.9917WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0444 - acc: 0.9850\n",
      "\n",
      "Epoch 00271: val_loss did not improve from 0.02453\n",
      "81/81 [==============================] - 23s 286ms/step - loss: 0.0268 - acc: 0.9916 - val_loss: 0.0444 - val_acc: 0.9850\n",
      "Epoch 272/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0219 - acc: 0.9950WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0514 - acc: 0.9800\n",
      "\n",
      "Epoch 00272: val_loss did not improve from 0.02453\n",
      "81/81 [==============================] - 22s 269ms/step - loss: 0.0217 - acc: 0.9950 - val_loss: 0.0514 - val_acc: 0.9800\n",
      "Epoch 273/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0299 - acc: 0.9911WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0395 - acc: 0.9881\n",
      "\n",
      "Epoch 00273: val_loss did not improve from 0.02453\n",
      "81/81 [==============================] - 21s 264ms/step - loss: 0.0293 - acc: 0.9913 - val_loss: 0.0395 - val_acc: 0.9881\n",
      "Epoch 274/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0177 - acc: 0.9940WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0423 - acc: 0.9925\n",
      "\n",
      "Epoch 00274: val_loss did not improve from 0.02453\n",
      "81/81 [==============================] - 23s 279ms/step - loss: 0.0174 - acc: 0.9941 - val_loss: 0.0423 - val_acc: 0.9925\n",
      "Epoch 275/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0266 - acc: 0.9931WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.0378 - acc: 0.9919\n",
      "\n",
      "Epoch 00275: val_loss did not improve from 0.02453\n",
      "81/81 [==============================] - 22s 266ms/step - loss: 0.0264 - acc: 0.9932 - val_loss: 0.0378 - val_acc: 0.9919\n",
      "Epoch 276/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0273 - acc: 0.9921WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 24s 7ms/sample - loss: 0.0338 - acc: 0.9916\n",
      "\n",
      "Epoch 00276: val_loss did not improve from 0.02453\n",
      "81/81 [==============================] - 28s 346ms/step - loss: 0.0271 - acc: 0.9922 - val_loss: 0.0338 - val_acc: 0.9916\n",
      "Epoch 277/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/81 [============================>.] - ETA: 0s - loss: 0.0192 - acc: 0.9937WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.0308 - acc: 0.9925\n",
      "\n",
      "Epoch 00277: val_loss did not improve from 0.02453\n",
      "81/81 [==============================] - 21s 254ms/step - loss: 0.0190 - acc: 0.9938 - val_loss: 0.0308 - val_acc: 0.9925\n",
      "Epoch 278/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0241 - acc: 0.9917WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0453 - acc: 0.9875\n",
      "\n",
      "Epoch 00278: val_loss did not improve from 0.02453\n",
      "81/81 [==============================] - 22s 277ms/step - loss: 0.0236 - acc: 0.9919 - val_loss: 0.0453 - val_acc: 0.9875\n",
      "Epoch 279/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0322 - acc: 0.9906WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.0358 - acc: 0.9919\n",
      "\n",
      "Epoch 00279: val_loss did not improve from 0.02453\n",
      "81/81 [==============================] - 21s 263ms/step - loss: 0.0319 - acc: 0.9907 - val_loss: 0.0358 - val_acc: 0.9919\n",
      "Epoch 280/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0333 - acc: 0.9903WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 27s 9ms/sample - loss: 0.0332 - acc: 0.9909\n",
      "\n",
      "Epoch 00280: val_loss did not improve from 0.02453\n",
      "81/81 [==============================] - 31s 386ms/step - loss: 0.0330 - acc: 0.9904 - val_loss: 0.0332 - val_acc: 0.9909\n",
      "Epoch 281/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0229 - acc: 0.9934WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0339 - acc: 0.9834 8s - loss: 0.032\n",
      "\n",
      "Epoch 00281: val_loss did not improve from 0.02453\n",
      "81/81 [==============================] - 23s 284ms/step - loss: 0.0231 - acc: 0.9932 - val_loss: 0.0339 - val_acc: 0.9834\n",
      "Epoch 282/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0289 - acc: 0.9917WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0394 - acc: 0.9866\n",
      "\n",
      "Epoch 00282: val_loss did not improve from 0.02453\n",
      "81/81 [==============================] - 22s 275ms/step - loss: 0.0285 - acc: 0.9919 - val_loss: 0.0394 - val_acc: 0.9866\n",
      "Epoch 283/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0274 - acc: 0.9911WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0373 - acc: 0.9912\n",
      "\n",
      "Epoch 00283: val_loss did not improve from 0.02453\n",
      "81/81 [==============================] - 22s 277ms/step - loss: 0.0287 - acc: 0.9907 - val_loss: 0.0373 - val_acc: 0.9912\n",
      "Epoch 284/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0246 - acc: 0.9920WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0389 - acc: 0.9900\n",
      "\n",
      "Epoch 00284: val_loss did not improve from 0.02453\n",
      "81/81 [==============================] - 26s 319ms/step - loss: 0.0257 - acc: 0.9916 - val_loss: 0.0389 - val_acc: 0.9900\n",
      "\n",
      "vis_imagenet_6_class_augmentation_2D_CNN_custom_ch_32_DO_075_DO_3_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3183/3183 [==============================] - 4s 1ms/sample - loss: 10.6577 - acc: 0.3358\n",
      "Loss: 10.65774965957938 Accuracy: 0.3358467\n",
      "\n",
      "Epoch 1/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.8687 - acc: 0.4936WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.6675 - acc: 0.7225\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.66748, saving model to model/checkpoint/vis_imagenet_6_class_augmentation_2D_CNN_custom_ch_32_DO_075_DO_4_conv_checkpoint/001-0.6675.hdf5\n",
      "81/81 [==============================] - 22s 271ms/step - loss: 0.8650 - acc: 0.4947 - val_loss: 0.6675 - val_acc: 0.7225\n",
      "Epoch 2/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.6335 - acc: 0.6435WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.5309 - acc: 0.7631\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.66748 to 0.53095, saving model to model/checkpoint/vis_imagenet_6_class_augmentation_2D_CNN_custom_ch_32_DO_075_DO_4_conv_checkpoint/002-0.5309.hdf5\n",
      "81/81 [==============================] - 21s 258ms/step - loss: 0.6314 - acc: 0.6449 - val_loss: 0.5309 - val_acc: 0.7631\n",
      "Epoch 3/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.4510 - acc: 0.7963WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 21s 6ms/sample - loss: 0.4594 - acc: 0.7734\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.53095 to 0.45942, saving model to model/checkpoint/vis_imagenet_6_class_augmentation_2D_CNN_custom_ch_32_DO_075_DO_4_conv_checkpoint/003-0.4594.hdf5\n",
      "81/81 [==============================] - 25s 313ms/step - loss: 0.4500 - acc: 0.7976 - val_loss: 0.4594 - val_acc: 0.7734\n",
      "Epoch 4/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.4226 - acc: 0.8136WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 22s 7ms/sample - loss: 0.6176 - acc: 0.6434\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.45942\n",
      "81/81 [==============================] - 28s 348ms/step - loss: 0.4233 - acc: 0.8128 - val_loss: 0.6176 - val_acc: 0.6434\n",
      "Epoch 5/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.3476 - acc: 0.8596WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.3504 - acc: 0.8475\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.45942 to 0.35037, saving model to model/checkpoint/vis_imagenet_6_class_augmentation_2D_CNN_custom_ch_32_DO_075_DO_4_conv_checkpoint/005-0.3504.hdf5\n",
      "81/81 [==============================] - 22s 277ms/step - loss: 0.3495 - acc: 0.8597 - val_loss: 0.3504 - val_acc: 0.8475\n",
      "Epoch 6/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.3093 - acc: 0.8693WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.3766 - acc: 0.8388\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.35037\n",
      "81/81 [==============================] - 22s 276ms/step - loss: 0.3094 - acc: 0.8690 - val_loss: 0.3766 - val_acc: 0.8388\n",
      "Epoch 7/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.2980 - acc: 0.8768WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.4739 - acc: 0.7688\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.35037\n",
      "81/81 [==============================] - 24s 291ms/step - loss: 0.2980 - acc: 0.8771 - val_loss: 0.4739 - val_acc: 0.7688\n",
      "Epoch 8/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.2492 - acc: 0.8969WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.3684 - acc: 0.8475\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.35037\n",
      "81/81 [==============================] - 23s 287ms/step - loss: 0.2504 - acc: 0.8960 - val_loss: 0.3684 - val_acc: 0.8475\n",
      "Epoch 9/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.2474 - acc: 0.9007WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.1664 - acc: 0.9475\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.35037 to 0.16643, saving model to model/checkpoint/vis_imagenet_6_class_augmentation_2D_CNN_custom_ch_32_DO_075_DO_4_conv_checkpoint/009-0.1664.hdf5\n",
      "81/81 [==============================] - 22s 271ms/step - loss: 0.2462 - acc: 0.9013 - val_loss: 0.1664 - val_acc: 0.9475\n",
      "Epoch 10/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.2584 - acc: 0.8947WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.3623 - acc: 0.8425\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.16643\n",
      "81/81 [==============================] - 22s 273ms/step - loss: 0.2574 - acc: 0.8954 - val_loss: 0.3623 - val_acc: 0.8425\n",
      "Epoch 11/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.2263 - acc: 0.9147WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 30s 9ms/sample - loss: 0.2336 - acc: 0.9162\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.16643\n",
      "81/81 [==============================] - 36s 441ms/step - loss: 0.2271 - acc: 0.9140 - val_loss: 0.2336 - val_acc: 0.9162\n",
      "Epoch 12/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.2149 - acc: 0.9188WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.1386 - acc: 0.9525\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.16643 to 0.13863, saving model to model/checkpoint/vis_imagenet_6_class_augmentation_2D_CNN_custom_ch_32_DO_075_DO_4_conv_checkpoint/012-0.1386.hdf5\n",
      "81/81 [==============================] - 24s 292ms/step - loss: 0.2143 - acc: 0.9193 - val_loss: 0.1386 - val_acc: 0.9525\n",
      "Epoch 13/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.2174 - acc: 0.9187WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 20s 6ms/sample - loss: 0.1389 - acc: 0.9475\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.13863\n",
      "81/81 [==============================] - 28s 340ms/step - loss: 0.2151 - acc: 0.9193 - val_loss: 0.1389 - val_acc: 0.9475\n",
      "Epoch 14/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.1927 - acc: 0.9252WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3200/3183 [==============================] - 18s 5ms/sample - loss: 0.1986 - acc: 0.9300\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.13863\n",
      "81/81 [==============================] - 23s 282ms/step - loss: 0.1929 - acc: 0.9258 - val_loss: 0.1986 - val_acc: 0.9300\n",
      "Epoch 15/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.1868 - acc: 0.9303WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.2520 - acc: 0.8931\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.13863\n",
      "81/81 [==============================] - 22s 271ms/step - loss: 0.1856 - acc: 0.9311 - val_loss: 0.2520 - val_acc: 0.8931\n",
      "Epoch 16/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.1924 - acc: 0.9262WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.2428 - acc: 0.9038\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.13863\n",
      "81/81 [==============================] - 22s 269ms/step - loss: 0.1910 - acc: 0.9261 - val_loss: 0.2428 - val_acc: 0.9038\n",
      "Epoch 17/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.1588 - acc: 0.9422WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 5ms/sample - loss: 0.0702 - acc: 0.9750\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.13863 to 0.07018, saving model to model/checkpoint/vis_imagenet_6_class_augmentation_2D_CNN_custom_ch_32_DO_075_DO_4_conv_checkpoint/017-0.0702.hdf5\n",
      "81/81 [==============================] - 22s 277ms/step - loss: 0.1598 - acc: 0.9417 - val_loss: 0.0702 - val_acc: 0.9750\n",
      "Epoch 18/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.1932 - acc: 0.9284WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.2733 - acc: 0.8950\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.07018\n",
      "81/81 [==============================] - 21s 262ms/step - loss: 0.1917 - acc: 0.9289 - val_loss: 0.2733 - val_acc: 0.8950\n",
      "Epoch 19/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.1547 - acc: 0.9427WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 20s 6ms/sample - loss: 0.0711 - acc: 0.9781\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.07018\n",
      "81/81 [==============================] - 26s 318ms/step - loss: 0.1554 - acc: 0.9426 - val_loss: 0.0711 - val_acc: 0.9781\n",
      "Epoch 20/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.1643 - acc: 0.9387WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.2569 - acc: 0.9000\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.07018\n",
      "81/81 [==============================] - 22s 273ms/step - loss: 0.1635 - acc: 0.9392 - val_loss: 0.2569 - val_acc: 0.9000\n",
      "Epoch 21/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.1517 - acc: 0.9465WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0938 - acc: 0.9775\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.07018\n",
      "81/81 [==============================] - 22s 273ms/step - loss: 0.1520 - acc: 0.9466 - val_loss: 0.0938 - val_acc: 0.9775\n",
      "Epoch 22/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.1428 - acc: 0.9497WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.1072 - acc: 0.9688\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.07018\n",
      "81/81 [==============================] - 24s 302ms/step - loss: 0.1411 - acc: 0.9503 - val_loss: 0.1072 - val_acc: 0.9688\n",
      "Epoch 23/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.1636 - acc: 0.9405WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.1251 - acc: 0.9575\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.07018\n",
      "81/81 [==============================] - 23s 278ms/step - loss: 0.1628 - acc: 0.9404 - val_loss: 0.1251 - val_acc: 0.9575\n",
      "Epoch 24/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.1408 - acc: 0.9450- ETA: 1s - loss: WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.2407 - acc: 0.9000\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.07018\n",
      "81/81 [==============================] - 21s 265ms/step - loss: 0.1409 - acc: 0.9451 - val_loss: 0.2407 - val_acc: 0.9000\n",
      "Epoch 25/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.1490 - acc: 0.9463WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 23s 7ms/sample - loss: 0.1260 - acc: 0.9650\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.07018\n",
      "81/81 [==============================] - 29s 361ms/step - loss: 0.1483 - acc: 0.9469 - val_loss: 0.1260 - val_acc: 0.9650\n",
      "Epoch 26/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.1319 - acc: 0.9523WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.2197 - acc: 0.9159\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.07018\n",
      "81/81 [==============================] - 24s 296ms/step - loss: 0.1311 - acc: 0.9528 - val_loss: 0.2197 - val_acc: 0.9159\n",
      "Epoch 27/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.1304 - acc: 0.9532WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.1517 - acc: 0.9500\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.07018\n",
      "81/81 [==============================] - 22s 274ms/step - loss: 0.1293 - acc: 0.9538 - val_loss: 0.1517 - val_acc: 0.9500\n",
      "Epoch 28/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.1272 - acc: 0.9532WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.0643 - acc: 0.9762\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.07018 to 0.06430, saving model to model/checkpoint/vis_imagenet_6_class_augmentation_2D_CNN_custom_ch_32_DO_075_DO_4_conv_checkpoint/028-0.0643.hdf5\n",
      "81/81 [==============================] - 22s 273ms/step - loss: 0.1253 - acc: 0.9544 - val_loss: 0.0643 - val_acc: 0.9762\n",
      "Epoch 29/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.1248 - acc: 0.9551WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3200/3183 [==============================] - 23s 7ms/sample - loss: 0.0653 - acc: 0.9837\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.06430\n",
      "81/81 [==============================] - 27s 333ms/step - loss: 0.1250 - acc: 0.9547 - val_loss: 0.0653 - val_acc: 0.9837\n",
      "Epoch 30/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.1476 - acc: 0.9441WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 31s 10ms/sample - loss: 0.3289 - acc: 0.8625\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.06430\n",
      "81/81 [==============================] - 34s 426ms/step - loss: 0.1520 - acc: 0.9423 - val_loss: 0.3289 - val_acc: 0.8625\n",
      "Epoch 31/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.1401 - acc: 0.9419WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0768 - acc: 0.9725\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.06430\n",
      "81/81 [==============================] - 26s 327ms/step - loss: 0.1394 - acc: 0.9420 - val_loss: 0.0768 - val_acc: 0.9725\n",
      "Epoch 32/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.1188 - acc: 0.9544WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 21s 7ms/sample - loss: 0.0647 - acc: 0.9787\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.06430\n",
      "81/81 [==============================] - 25s 312ms/step - loss: 0.1185 - acc: 0.9547 - val_loss: 0.0647 - val_acc: 0.9787\n",
      "Epoch 33/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.1152 - acc: 0.9576WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 23s 7ms/sample - loss: 0.0724 - acc: 0.9737\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.06430\n",
      "81/81 [==============================] - 29s 362ms/step - loss: 0.1156 - acc: 0.9575 - val_loss: 0.0724 - val_acc: 0.9737\n",
      "Epoch 34/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.1359 - acc: 0.9510WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 14s 5ms/sample - loss: 0.1441 - acc: 0.9475\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.06430\n",
      "81/81 [==============================] - 24s 302ms/step - loss: 0.1366 - acc: 0.9510 - val_loss: 0.1441 - val_acc: 0.9475\n",
      "Epoch 35/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.1209 - acc: 0.9570WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0927 - acc: 0.9750\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.06430\n",
      "81/81 [==============================] - 29s 356ms/step - loss: 0.1231 - acc: 0.9565 - val_loss: 0.0927 - val_acc: 0.9750\n",
      "Epoch 36/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.1205 - acc: 0.9566WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0663 - acc: 0.9800\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.06430\n",
      "81/81 [==============================] - 22s 271ms/step - loss: 0.1195 - acc: 0.9572 - val_loss: 0.0663 - val_acc: 0.9800\n",
      "Epoch 37/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.1357 - acc: 0.9525WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.1013 - acc: 0.9722\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.06430\n",
      "81/81 [==============================] - 23s 283ms/step - loss: 0.1352 - acc: 0.9525 - val_loss: 0.1013 - val_acc: 0.9722\n",
      "Epoch 38/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.1377 - acc: 0.9497WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0806 - acc: 0.9772\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.06430\n",
      "81/81 [==============================] - 22s 270ms/step - loss: 0.1380 - acc: 0.9497 - val_loss: 0.0806 - val_acc: 0.9772\n",
      "Epoch 39/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.1220 - acc: 0.9542WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.1663 - acc: 0.9525\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.06430\n",
      "81/81 [==============================] - 24s 300ms/step - loss: 0.1232 - acc: 0.9538 - val_loss: 0.1663 - val_acc: 0.9525\n",
      "Epoch 40/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.1032 - acc: 0.9675WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0792 - acc: 0.9728\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.06430\n",
      "81/81 [==============================] - 22s 277ms/step - loss: 0.1056 - acc: 0.9665 - val_loss: 0.0792 - val_acc: 0.9728\n",
      "Epoch 41/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.1109 - acc: 0.9573WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.1054 - acc: 0.9575\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.06430\n",
      "81/81 [==============================] - 22s 274ms/step - loss: 0.1102 - acc: 0.9578 - val_loss: 0.1054 - val_acc: 0.9575\n",
      "Epoch 42/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.1086 - acc: 0.9647WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 20s 6ms/sample - loss: 0.1132 - acc: 0.9609\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.06430\n",
      "81/81 [==============================] - 27s 338ms/step - loss: 0.1081 - acc: 0.9646 - val_loss: 0.1132 - val_acc: 0.9609\n",
      "Epoch 43/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.1110 - acc: 0.9617WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0661 - acc: 0.9750s may duplicate your\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.06430\n",
      "81/81 [==============================] - 23s 279ms/step - loss: 0.1115 - acc: 0.9615 - val_loss: 0.0661 - val_acc: 0.9750\n",
      "Epoch 44/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.1094 - acc: 0.9602WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.1459 - acc: 0.9531\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.06430\n",
      "81/81 [==============================] - 22s 273ms/step - loss: 0.1122 - acc: 0.9590 - val_loss: 0.1459 - val_acc: 0.9531\n",
      "Epoch 45/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/81 [============================>.] - ETA: 0s - loss: 0.1176 - acc: 0.9598WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0609 - acc: 0.9725\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.06430 to 0.06094, saving model to model/checkpoint/vis_imagenet_6_class_augmentation_2D_CNN_custom_ch_32_DO_075_DO_4_conv_checkpoint/045-0.0609.hdf5\n",
      "81/81 [==============================] - 22s 275ms/step - loss: 0.1167 - acc: 0.9603 - val_loss: 0.0609 - val_acc: 0.9725\n",
      "Epoch 46/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0996 - acc: 0.9679WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 20s 6ms/sample - loss: 0.1629 - acc: 0.9400\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.06094\n",
      "81/81 [==============================] - 24s 293ms/step - loss: 0.1010 - acc: 0.9677 - val_loss: 0.1629 - val_acc: 0.9400\n",
      "Epoch 47/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0928 - acc: 0.9666WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.1036 - acc: 0.9575\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.06094\n",
      "81/81 [==============================] - 22s 275ms/step - loss: 0.0926 - acc: 0.9668 - val_loss: 0.1036 - val_acc: 0.9575\n",
      "Epoch 48/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.1031 - acc: 0.9640WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.1108 - acc: 0.9581\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.06094\n",
      "81/81 [==============================] - 21s 256ms/step - loss: 0.1038 - acc: 0.9637 - val_loss: 0.1108 - val_acc: 0.9581\n",
      "Epoch 49/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.1100 - acc: 0.9639WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0756 - acc: 0.9737\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.06094\n",
      "81/81 [==============================] - 23s 279ms/step - loss: 0.1091 - acc: 0.9643 - val_loss: 0.0756 - val_acc: 0.9737\n",
      "Epoch 50/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0917 - acc: 0.9689WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 24s 8ms/sample - loss: 0.0499 - acc: 0.9850\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.06094 to 0.04991, saving model to model/checkpoint/vis_imagenet_6_class_augmentation_2D_CNN_custom_ch_32_DO_075_DO_4_conv_checkpoint/050-0.0499.hdf5\n",
      "81/81 [==============================] - 28s 349ms/step - loss: 0.0944 - acc: 0.9677 - val_loss: 0.0499 - val_acc: 0.9850\n",
      "Epoch 51/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0996 - acc: 0.9604WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0540 - acc: 0.9781\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.04991\n",
      "81/81 [==============================] - 23s 284ms/step - loss: 0.0993 - acc: 0.9606 - val_loss: 0.0540 - val_acc: 0.9781\n",
      "Epoch 52/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0941 - acc: 0.9670WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 21s 6ms/sample - loss: 0.0813 - acc: 0.9694\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.04991\n",
      "81/81 [==============================] - 24s 302ms/step - loss: 0.0941 - acc: 0.9671 - val_loss: 0.0813 - val_acc: 0.9694\n",
      "Epoch 53/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0953 - acc: 0.9632WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0683 - acc: 0.9787\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.04991\n",
      "81/81 [==============================] - 24s 297ms/step - loss: 0.0952 - acc: 0.9634 - val_loss: 0.0683 - val_acc: 0.9787\n",
      "Epoch 54/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0997 - acc: 0.9642WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 5ms/sample - loss: 0.0635 - acc: 0.9775\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.04991\n",
      "81/81 [==============================] - 22s 268ms/step - loss: 0.0994 - acc: 0.9643 - val_loss: 0.0635 - val_acc: 0.9775\n",
      "Epoch 55/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0950 - acc: 0.9675WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 26s 8ms/sample - loss: 0.0816 - acc: 0.9675\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.04991\n",
      "81/81 [==============================] - 31s 387ms/step - loss: 0.0941 - acc: 0.9677 - val_loss: 0.0816 - val_acc: 0.9675\n",
      "Epoch 56/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0936 - acc: 0.9654WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0474 - acc: 0.9816\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.04991 to 0.04743, saving model to model/checkpoint/vis_imagenet_6_class_augmentation_2D_CNN_custom_ch_32_DO_075_DO_4_conv_checkpoint/056-0.0474.hdf5\n",
      "81/81 [==============================] - 26s 320ms/step - loss: 0.0936 - acc: 0.9652 - val_loss: 0.0474 - val_acc: 0.9816\n",
      "Epoch 57/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0876 - acc: 0.9686WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.1027 - acc: 0.9613\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.04743\n",
      "81/81 [==============================] - 23s 285ms/step - loss: 0.0870 - acc: 0.9690 - val_loss: 0.1027 - val_acc: 0.9613\n",
      "Epoch 58/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.1007 - acc: 0.9680WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 21s 6ms/sample - loss: 0.0654 - acc: 0.9775\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.04743\n",
      "81/81 [==============================] - 27s 328ms/step - loss: 0.0998 - acc: 0.9687 - val_loss: 0.0654 - val_acc: 0.9775\n",
      "Epoch 59/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0832 - acc: 0.9707WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0765 - acc: 0.9712\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.04743\n",
      "81/81 [==============================] - 22s 275ms/step - loss: 0.0819 - acc: 0.9714 - val_loss: 0.0765 - val_acc: 0.9712\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0916 - acc: 0.9686WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.0689 - acc: 0.9750\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.04743\n",
      "81/81 [==============================] - 21s 262ms/step - loss: 0.0911 - acc: 0.9687 - val_loss: 0.0689 - val_acc: 0.9750\n",
      "Epoch 61/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0990 - acc: 0.9599WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 5ms/sample - loss: 0.0455 - acc: 0.9875\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.04743 to 0.04554, saving model to model/checkpoint/vis_imagenet_6_class_augmentation_2D_CNN_custom_ch_32_DO_075_DO_4_conv_checkpoint/061-0.0455.hdf5\n",
      "81/81 [==============================] - 24s 297ms/step - loss: 0.0976 - acc: 0.9603 - val_loss: 0.0455 - val_acc: 0.9875\n",
      "Epoch 62/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.1026 - acc: 0.9612WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 15s 5ms/sample - loss: 0.0427 - acc: 0.9875\n",
      "\n",
      "Epoch 00062: val_loss improved from 0.04554 to 0.04266, saving model to model/checkpoint/vis_imagenet_6_class_augmentation_2D_CNN_custom_ch_32_DO_075_DO_4_conv_checkpoint/062-0.0427.hdf5\n",
      "81/81 [==============================] - 24s 295ms/step - loss: 0.1014 - acc: 0.9615 - val_loss: 0.0427 - val_acc: 0.9875\n",
      "Epoch 63/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0919 - acc: 0.9639WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 15s 5ms/sample - loss: 0.0655 - acc: 0.9700\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.04266\n",
      "81/81 [==============================] - 22s 277ms/step - loss: 0.0915 - acc: 0.9640 - val_loss: 0.0655 - val_acc: 0.9700\n",
      "Epoch 64/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0877 - acc: 0.9654WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 15s 5ms/sample - loss: 0.2039 - acc: 0.9250\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.04266\n",
      "81/81 [==============================] - 20s 251ms/step - loss: 0.0881 - acc: 0.9652 - val_loss: 0.2039 - val_acc: 0.9250\n",
      "Epoch 65/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0898 - acc: 0.9704WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0915 - acc: 0.9609\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.04266\n",
      "81/81 [==============================] - 29s 364ms/step - loss: 0.0904 - acc: 0.9705 - val_loss: 0.0915 - val_acc: 0.9609\n",
      "Epoch 66/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0990 - acc: 0.9673WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.1082 - acc: 0.9563\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.04266\n",
      "81/81 [==============================] - 22s 274ms/step - loss: 0.0992 - acc: 0.9668 - val_loss: 0.1082 - val_acc: 0.9563\n",
      "Epoch 67/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0837 - acc: 0.9718WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.1278 - acc: 0.9513\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.04266\n",
      "81/81 [==============================] - 23s 289ms/step - loss: 0.0827 - acc: 0.9721 - val_loss: 0.1278 - val_acc: 0.9513\n",
      "Epoch 68/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0783 - acc: 0.9707WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.0394 - acc: 0.9875\n",
      "\n",
      "Epoch 00068: val_loss improved from 0.04266 to 0.03937, saving model to model/checkpoint/vis_imagenet_6_class_augmentation_2D_CNN_custom_ch_32_DO_075_DO_4_conv_checkpoint/068-0.0394.hdf5\n",
      "81/81 [==============================] - 22s 270ms/step - loss: 0.0783 - acc: 0.9708 - val_loss: 0.0394 - val_acc: 0.9875\n",
      "Epoch 69/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0849 - acc: 0.9708WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 26s 8ms/sample - loss: 0.0623 - acc: 0.9766\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.03937\n",
      "81/81 [==============================] - 31s 389ms/step - loss: 0.0844 - acc: 0.9708 - val_loss: 0.0623 - val_acc: 0.9766\n",
      "Epoch 70/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0877 - acc: 0.9701WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0862 - acc: 0.9681\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.03937\n",
      "81/81 [==============================] - 23s 290ms/step - loss: 0.0870 - acc: 0.9702 - val_loss: 0.0862 - val_acc: 0.9681\n",
      "Epoch 71/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0864 - acc: 0.9691WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.0785 - acc: 0.9725\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.03937\n",
      "81/81 [==============================] - 26s 323ms/step - loss: 0.0850 - acc: 0.9699 - val_loss: 0.0785 - val_acc: 0.9725\n",
      "Epoch 72/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0769 - acc: 0.9749WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 22s 7ms/sample - loss: 0.1250 - acc: 0.9531\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.03937\n",
      "81/81 [==============================] - 26s 323ms/step - loss: 0.0763 - acc: 0.9752 - val_loss: 0.1250 - val_acc: 0.9531\n",
      "Epoch 73/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0915 - acc: 0.9667WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 26s 8ms/sample - loss: 0.0544 - acc: 0.9800\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.03937\n",
      "81/81 [==============================] - 31s 383ms/step - loss: 0.0908 - acc: 0.9671 - val_loss: 0.0544 - val_acc: 0.9800\n",
      "Epoch 74/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0707 - acc: 0.9758WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 20s 6ms/sample - loss: 0.0476 - acc: 0.9844\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.03937\n",
      "81/81 [==============================] - 29s 358ms/step - loss: 0.0718 - acc: 0.9755 - val_loss: 0.0476 - val_acc: 0.9844\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0652 - acc: 0.9771WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 22s 7ms/sample - loss: 0.0762 - acc: 0.9725\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.03937\n",
      "81/81 [==============================] - 28s 344ms/step - loss: 0.0654 - acc: 0.9770 - val_loss: 0.0762 - val_acc: 0.9725\n",
      "Epoch 76/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0739 - acc: 0.9749WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 21s 7ms/sample - loss: 0.0508 - acc: 0.9831\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.03937\n",
      "81/81 [==============================] - 28s 346ms/step - loss: 0.0735 - acc: 0.9749 - val_loss: 0.0508 - val_acc: 0.9831\n",
      "Epoch 77/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0843 - acc: 0.9685WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.2039 - acc: 0.9262\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.03937\n",
      "81/81 [==============================] - 26s 317ms/step - loss: 0.0836 - acc: 0.9687 - val_loss: 0.2039 - val_acc: 0.9262\n",
      "Epoch 78/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0896 - acc: 0.9654WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.1483 - acc: 0.9466\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.03937\n",
      "81/81 [==============================] - 23s 282ms/step - loss: 0.0899 - acc: 0.9652 - val_loss: 0.1483 - val_acc: 0.9466\n",
      "Epoch 79/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0680 - acc: 0.9764WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.0592 - acc: 0.9800\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.03937\n",
      "81/81 [==============================] - 24s 296ms/step - loss: 0.0695 - acc: 0.9755 - val_loss: 0.0592 - val_acc: 0.9800\n",
      "Epoch 80/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0851 - acc: 0.9705WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 28s 9ms/sample - loss: 0.0524 - acc: 0.9812\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.03937\n",
      "81/81 [==============================] - 35s 438ms/step - loss: 0.0849 - acc: 0.9705 - val_loss: 0.0524 - val_acc: 0.9812\n",
      "Epoch 81/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0786 - acc: 0.9752WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0945 - acc: 0.9625\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.03937\n",
      "81/81 [==============================] - 27s 328ms/step - loss: 0.0778 - acc: 0.9752 - val_loss: 0.0945 - val_acc: 0.9625\n",
      "Epoch 82/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0736 - acc: 0.9780WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 14s 4ms/sample - loss: 0.1093 - acc: 0.9541\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.03937\n",
      "81/81 [==============================] - 25s 303ms/step - loss: 0.0728 - acc: 0.9783 - val_loss: 0.1093 - val_acc: 0.9541\n",
      "Epoch 83/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0676 - acc: 0.9771WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 21s 7ms/sample - loss: 0.0740 - acc: 0.9716\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.03937\n",
      "81/81 [==============================] - 27s 334ms/step - loss: 0.0678 - acc: 0.9770 - val_loss: 0.0740 - val_acc: 0.9716\n",
      "Epoch 84/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0664 - acc: 0.9774WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.1324 - acc: 0.9484\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.03937\n",
      "81/81 [==============================] - 23s 279ms/step - loss: 0.0664 - acc: 0.9773 - val_loss: 0.1324 - val_acc: 0.9484\n",
      "Epoch 85/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0792 - acc: 0.9723WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.0623 - acc: 0.9741\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.03937\n",
      "81/81 [==============================] - 21s 265ms/step - loss: 0.0798 - acc: 0.9724 - val_loss: 0.0623 - val_acc: 0.9741\n",
      "Epoch 86/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0753 - acc: 0.9745WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0834 - acc: 0.9659\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.03937\n",
      "81/81 [==============================] - 21s 258ms/step - loss: 0.0752 - acc: 0.9749 - val_loss: 0.0834 - val_acc: 0.9659\n",
      "Epoch 87/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0686 - acc: 0.9749WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0496 - acc: 0.9822\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.03937\n",
      "81/81 [==============================] - 24s 297ms/step - loss: 0.0674 - acc: 0.9755 - val_loss: 0.0496 - val_acc: 0.9822\n",
      "Epoch 88/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0596 - acc: 0.9780WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 20s 6ms/sample - loss: 0.0789 - acc: 0.9750\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.03937\n",
      "81/81 [==============================] - 27s 331ms/step - loss: 0.0595 - acc: 0.9783 - val_loss: 0.0789 - val_acc: 0.9750\n",
      "Epoch 89/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0669 - acc: 0.9774WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 23s 7ms/sample - loss: 0.0448 - acc: 0.9862\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.03937\n",
      "81/81 [==============================] - 29s 357ms/step - loss: 0.0676 - acc: 0.9767 - val_loss: 0.0448 - val_acc: 0.9862\n",
      "Epoch 90/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0874 - acc: 0.9692WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.0837 - acc: 0.9725\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.03937\n",
      "81/81 [==============================] - 24s 294ms/step - loss: 0.0885 - acc: 0.9690 - val_loss: 0.0837 - val_acc: 0.9725\n",
      "Epoch 91/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0578 - acc: 0.9806WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 21s 7ms/sample - loss: 0.0967 - acc: 0.9559\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.03937\n",
      "81/81 [==============================] - 27s 336ms/step - loss: 0.0574 - acc: 0.9811 - val_loss: 0.0967 - val_acc: 0.9559\n",
      "Epoch 92/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0630 - acc: 0.9789WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0448 - acc: 0.9850\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.03937\n",
      "81/81 [==============================] - 25s 309ms/step - loss: 0.0630 - acc: 0.9789 - val_loss: 0.0448 - val_acc: 0.9850\n",
      "Epoch 93/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0696 - acc: 0.9730WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 15s 5ms/sample - loss: 0.0431 - acc: 0.9856\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.03937\n",
      "81/81 [==============================] - 27s 329ms/step - loss: 0.0693 - acc: 0.9730 - val_loss: 0.0431 - val_acc: 0.9856\n",
      "Epoch 94/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0644 - acc: 0.9780WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 22s 7ms/sample - loss: 0.0732 - acc: 0.9725\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.03937\n",
      "81/81 [==============================] - 27s 328ms/step - loss: 0.0642 - acc: 0.9783 - val_loss: 0.0732 - val_acc: 0.9725\n",
      "Epoch 95/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0633 - acc: 0.9793WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0481 - acc: 0.9900\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.03937\n",
      "81/81 [==============================] - 24s 299ms/step - loss: 0.0628 - acc: 0.9795 - val_loss: 0.0481 - val_acc: 0.9900\n",
      "Epoch 96/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0653 - acc: 0.9771WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 21s 7ms/sample - loss: 0.0545 - acc: 0.9800\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.03937\n",
      "81/81 [==============================] - 26s 325ms/step - loss: 0.0649 - acc: 0.9773 - val_loss: 0.0545 - val_acc: 0.9800\n",
      "Epoch 97/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0665 - acc: 0.9767WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 23s 7ms/sample - loss: 0.0702 - acc: 0.9731\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.03937\n",
      "81/81 [==============================] - 28s 342ms/step - loss: 0.0660 - acc: 0.9770 - val_loss: 0.0702 - val_acc: 0.9731\n",
      "Epoch 98/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0562 - acc: 0.9809WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.0467 - acc: 0.9825\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.03937\n",
      "81/81 [==============================] - 22s 272ms/step - loss: 0.0559 - acc: 0.9811 - val_loss: 0.0467 - val_acc: 0.9825\n",
      "Epoch 99/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0498 - acc: 0.9846WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 27s 8ms/sample - loss: 0.0428 - acc: 0.9869\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.03937\n",
      "81/81 [==============================] - 35s 438ms/step - loss: 0.0494 - acc: 0.9848 - val_loss: 0.0428 - val_acc: 0.9869\n",
      "Epoch 100/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0682 - acc: 0.9736WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 25s 8ms/sample - loss: 0.0442 - acc: 0.9837\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.03937\n",
      "81/81 [==============================] - 33s 406ms/step - loss: 0.0682 - acc: 0.9736 - val_loss: 0.0442 - val_acc: 0.9837\n",
      "Epoch 101/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0677 - acc: 0.9768WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 21s 6ms/sample - loss: 0.0356 - acc: 0.9878\n",
      "\n",
      "Epoch 00101: val_loss improved from 0.03937 to 0.03563, saving model to model/checkpoint/vis_imagenet_6_class_augmentation_2D_CNN_custom_ch_32_DO_075_DO_4_conv_checkpoint/101-0.0356.hdf5\n",
      "81/81 [==============================] - 29s 356ms/step - loss: 0.0668 - acc: 0.9773 - val_loss: 0.0356 - val_acc: 0.9878\n",
      "Epoch 102/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0711 - acc: 0.9758WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 23s 7ms/sample - loss: 0.0553 - acc: 0.9775\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 0.03563\n",
      "81/81 [==============================] - 28s 341ms/step - loss: 0.0708 - acc: 0.9761 - val_loss: 0.0553 - val_acc: 0.9775\n",
      "Epoch 103/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0631 - acc: 0.9815WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0482 - acc: 0.9850\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 0.03563\n",
      "81/81 [==============================] - 26s 324ms/step - loss: 0.0629 - acc: 0.9814 - val_loss: 0.0482 - val_acc: 0.9850\n",
      "Epoch 104/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0661 - acc: 0.9767WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0734 - acc: 0.9791\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 0.03563\n",
      "81/81 [==============================] - 24s 293ms/step - loss: 0.0662 - acc: 0.9767 - val_loss: 0.0734 - val_acc: 0.9791\n",
      "Epoch 105/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0591 - acc: 0.9777WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0730 - acc: 0.9700\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 0.03563\n",
      "81/81 [==============================] - 22s 267ms/step - loss: 0.0579 - acc: 0.9783 - val_loss: 0.0730 - val_acc: 0.9700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 106/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0640 - acc: 0.9787WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.0548 - acc: 0.9766\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 0.03563\n",
      "81/81 [==============================] - 31s 384ms/step - loss: 0.0629 - acc: 0.9792 - val_loss: 0.0548 - val_acc: 0.9766\n",
      "Epoch 107/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0568 - acc: 0.9808WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.0771 - acc: 0.9709\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 0.03563\n",
      "81/81 [==============================] - 22s 271ms/step - loss: 0.0568 - acc: 0.9808 - val_loss: 0.0771 - val_acc: 0.9709\n",
      "Epoch 108/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0527 - acc: 0.9819WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0402 - acc: 0.9875\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 0.03563\n",
      "81/81 [==============================] - 22s 271ms/step - loss: 0.0532 - acc: 0.9817 - val_loss: 0.0402 - val_acc: 0.9875\n",
      "Epoch 109/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0542 - acc: 0.9812WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.0538 - acc: 0.9819\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 0.03563\n",
      "81/81 [==============================] - 21s 254ms/step - loss: 0.0533 - acc: 0.9817 - val_loss: 0.0538 - val_acc: 0.9819\n",
      "Epoch 110/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0508 - acc: 0.9827WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.1146 - acc: 0.9641\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 0.03563\n",
      "81/81 [==============================] - 21s 264ms/step - loss: 0.0513 - acc: 0.9823 - val_loss: 0.1146 - val_acc: 0.9641\n",
      "Epoch 111/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0475 - acc: 0.9828WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 20s 6ms/sample - loss: 0.0551 - acc: 0.9856\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 0.03563\n",
      "81/81 [==============================] - 26s 319ms/step - loss: 0.0480 - acc: 0.9826 - val_loss: 0.0551 - val_acc: 0.9856\n",
      "Epoch 112/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0540 - acc: 0.9815WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 15s 5ms/sample - loss: 0.2223 - acc: 0.9094\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 0.03563\n",
      "81/81 [==============================] - 22s 268ms/step - loss: 0.0558 - acc: 0.9811 - val_loss: 0.2223 - val_acc: 0.9094\n",
      "Epoch 113/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0515 - acc: 0.9862WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0527 - acc: 0.9825\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 0.03563\n",
      "81/81 [==============================] - 22s 277ms/step - loss: 0.0518 - acc: 0.9860 - val_loss: 0.0527 - val_acc: 0.9825\n",
      "Epoch 114/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0524 - acc: 0.9846WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.0607 - acc: 0.9756\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 0.03563\n",
      "81/81 [==============================] - 23s 278ms/step - loss: 0.0519 - acc: 0.9848 - val_loss: 0.0607 - val_acc: 0.9756\n",
      "Epoch 115/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0410 - acc: 0.9865WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 20s 6ms/sample - loss: 0.0482 - acc: 0.9850\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 0.03563\n",
      "81/81 [==============================] - 25s 307ms/step - loss: 0.0412 - acc: 0.9863 - val_loss: 0.0482 - val_acc: 0.9850\n",
      "Epoch 116/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0606 - acc: 0.9808WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.0425 - acc: 0.9831\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 0.03563\n",
      "81/81 [==============================] - 27s 334ms/step - loss: 0.0602 - acc: 0.9811 - val_loss: 0.0425 - val_acc: 0.9831\n",
      "Epoch 117/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0570 - acc: 0.9815WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.0463 - acc: 0.9800\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 0.03563\n",
      "81/81 [==============================] - 26s 323ms/step - loss: 0.0573 - acc: 0.9814 - val_loss: 0.0463 - val_acc: 0.9800\n",
      "Epoch 118/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0486 - acc: 0.9821WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 21s 7ms/sample - loss: 0.0378 - acc: 0.9872\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 0.03563\n",
      "81/81 [==============================] - 29s 353ms/step - loss: 0.0493 - acc: 0.9817 - val_loss: 0.0378 - val_acc: 0.9872\n",
      "Epoch 119/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0540 - acc: 0.9809WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0512 - acc: 0.9800\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 0.03563\n",
      "81/81 [==============================] - 27s 327ms/step - loss: 0.0530 - acc: 0.9814 - val_loss: 0.0512 - val_acc: 0.9800\n",
      "Epoch 120/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0471 - acc: 0.9833WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.0443 - acc: 0.9825\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 0.03563\n",
      "81/81 [==============================] - 22s 273ms/step - loss: 0.0477 - acc: 0.9832 - val_loss: 0.0443 - val_acc: 0.9825\n",
      "Epoch 121/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0449 - acc: 0.9844WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3200/3183 [==============================] - 21s 6ms/sample - loss: 0.0519 - acc: 0.9825\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 0.03563\n",
      "81/81 [==============================] - 25s 305ms/step - loss: 0.0447 - acc: 0.9848 - val_loss: 0.0519 - val_acc: 0.9825\n",
      "Epoch 122/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0425 - acc: 0.9862WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0472 - acc: 0.9819\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 0.03563\n",
      "81/81 [==============================] - 22s 272ms/step - loss: 0.0433 - acc: 0.9857 - val_loss: 0.0472 - val_acc: 0.9819\n",
      "Epoch 123/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0507 - acc: 0.9802WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.0476 - acc: 0.9872\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 0.03563\n",
      "81/81 [==============================] - 25s 305ms/step - loss: 0.0515 - acc: 0.9798 - val_loss: 0.0476 - val_acc: 0.9872\n",
      "Epoch 124/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0409 - acc: 0.9860WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0391 - acc: 0.9844\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 0.03563\n",
      "81/81 [==============================] - 22s 272ms/step - loss: 0.0403 - acc: 0.9863 - val_loss: 0.0391 - val_acc: 0.9844\n",
      "Epoch 125/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0489 - acc: 0.9835WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 20s 6ms/sample - loss: 0.0465 - acc: 0.9862\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 0.03563\n",
      "81/81 [==============================] - 31s 382ms/step - loss: 0.0490 - acc: 0.9832 - val_loss: 0.0465 - val_acc: 0.9862\n",
      "Epoch 126/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0501 - acc: 0.9838WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0385 - acc: 0.9894\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 0.03563\n",
      "81/81 [==============================] - 22s 268ms/step - loss: 0.0503 - acc: 0.9836 - val_loss: 0.0385 - val_acc: 0.9894\n",
      "Epoch 127/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0512 - acc: 0.9835WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 25s 8ms/sample - loss: 0.0623 - acc: 0.9825\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 0.03563\n",
      "81/81 [==============================] - 30s 366ms/step - loss: 0.0505 - acc: 0.9836 - val_loss: 0.0623 - val_acc: 0.9825\n",
      "Epoch 128/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0413 - acc: 0.9876WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0461 - acc: 0.9844\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 0.03563\n",
      "81/81 [==============================] - 29s 361ms/step - loss: 0.0413 - acc: 0.9873 - val_loss: 0.0461 - val_acc: 0.9844\n",
      "Epoch 129/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0556 - acc: 0.9796WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 22s 7ms/sample - loss: 0.0694 - acc: 0.9719\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 0.03563\n",
      "81/81 [==============================] - 27s 337ms/step - loss: 0.0565 - acc: 0.9792 - val_loss: 0.0694 - val_acc: 0.9719\n",
      "Epoch 130/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0383 - acc: 0.9887WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0881 - acc: 0.975610s - loss: \n",
      "\n",
      "Epoch 00130: val_loss did not improve from 0.03563\n",
      "81/81 [==============================] - 22s 273ms/step - loss: 0.0390 - acc: 0.9885 - val_loss: 0.0881 - val_acc: 0.9756\n",
      "Epoch 131/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0352 - acc: 0.9876WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 26s 8ms/sample - loss: 0.0535 - acc: 0.9831\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 0.03563\n",
      "81/81 [==============================] - 30s 376ms/step - loss: 0.0384 - acc: 0.9863 - val_loss: 0.0535 - val_acc: 0.9831\n",
      "Epoch 132/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0438 - acc: 0.9862WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0444 - acc: 0.9844\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 0.03563\n",
      "81/81 [==============================] - 24s 301ms/step - loss: 0.0435 - acc: 0.9863 - val_loss: 0.0444 - val_acc: 0.9844\n",
      "Epoch 133/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0363 - acc: 0.9885WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0455 - acc: 0.9841\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 0.03563\n",
      "81/81 [==============================] - 24s 302ms/step - loss: 0.0366 - acc: 0.9885 - val_loss: 0.0455 - val_acc: 0.9841\n",
      "Epoch 134/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0521 - acc: 0.9859WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0527 - acc: 0.9809\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 0.03563\n",
      "81/81 [==============================] - 26s 327ms/step - loss: 0.0516 - acc: 0.9860 - val_loss: 0.0527 - val_acc: 0.9809\n",
      "Epoch 135/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0473 - acc: 0.9860WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0647 - acc: 0.9856\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 0.03563\n",
      "81/81 [==============================] - 25s 305ms/step - loss: 0.0465 - acc: 0.9863 - val_loss: 0.0647 - val_acc: 0.9856\n",
      "Epoch 136/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0438 - acc: 0.9844WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.0369 - acc: 0.9850\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 0.03563\n",
      "81/81 [==============================] - 22s 271ms/step - loss: 0.0448 - acc: 0.9845 - val_loss: 0.0369 - val_acc: 0.9850\n",
      "Epoch 137/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/81 [============================>.] - ETA: 0s - loss: 0.0454 - acc: 0.9860WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0652 - acc: 0.9784\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 0.03563\n",
      "81/81 [==============================] - 24s 295ms/step - loss: 0.0470 - acc: 0.9857 - val_loss: 0.0652 - val_acc: 0.9784\n",
      "Epoch 138/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0469 - acc: 0.9868WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0527 - acc: 0.9850\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 0.03563\n",
      "81/81 [==============================] - 25s 304ms/step - loss: 0.0464 - acc: 0.9870 - val_loss: 0.0527 - val_acc: 0.9850\n",
      "Epoch 139/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0357 - acc: 0.9896WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0443 - acc: 0.9900\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 0.03563\n",
      "81/81 [==============================] - 23s 289ms/step - loss: 0.0355 - acc: 0.9898 - val_loss: 0.0443 - val_acc: 0.9900\n",
      "Epoch 140/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0440 - acc: 0.9859WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0515 - acc: 0.9800\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 0.03563\n",
      "81/81 [==============================] - 23s 278ms/step - loss: 0.0436 - acc: 0.9860 - val_loss: 0.0515 - val_acc: 0.9800\n",
      "Epoch 141/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0488 - acc: 0.9864WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0531 - acc: 0.9831\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 0.03563\n",
      "81/81 [==============================] - 23s 285ms/step - loss: 0.0484 - acc: 0.9867 - val_loss: 0.0531 - val_acc: 0.9831\n",
      "Epoch 142/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0488 - acc: 0.9824WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 20s 6ms/sample - loss: 0.0444 - acc: 0.9862\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 0.03563\n",
      "81/81 [==============================] - 25s 305ms/step - loss: 0.0493 - acc: 0.9823 - val_loss: 0.0444 - val_acc: 0.9862\n",
      "Epoch 143/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0439 - acc: 0.9871WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0399 - acc: 0.9900\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 0.03563\n",
      "81/81 [==============================] - 24s 290ms/step - loss: 0.0441 - acc: 0.9867 - val_loss: 0.0399 - val_acc: 0.9900\n",
      "Epoch 144/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0371 - acc: 0.9884WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 15s 5ms/sample - loss: 0.0374 - acc: 0.9894\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 0.03563\n",
      "81/81 [==============================] - 22s 270ms/step - loss: 0.0377 - acc: 0.9882 - val_loss: 0.0374 - val_acc: 0.9894\n",
      "Epoch 145/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0360 - acc: 0.9874WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 26s 8ms/sample - loss: 0.0640 - acc: 0.9825\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 0.03563\n",
      "81/81 [==============================] - 31s 379ms/step - loss: 0.0356 - acc: 0.9876 - val_loss: 0.0640 - val_acc: 0.9825\n",
      "Epoch 146/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0366 - acc: 0.9895WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0474 - acc: 0.9875\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 0.03563\n",
      "81/81 [==============================] - 26s 316ms/step - loss: 0.0362 - acc: 0.9898 - val_loss: 0.0474 - val_acc: 0.9875\n",
      "Epoch 147/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0322 - acc: 0.9884WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0557 - acc: 0.9803\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 0.03563\n",
      "81/81 [==============================] - 23s 279ms/step - loss: 0.0320 - acc: 0.9885 - val_loss: 0.0557 - val_acc: 0.9803\n",
      "Epoch 148/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0410 - acc: 0.9847WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0485 - acc: 0.9850\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 0.03563\n",
      "81/81 [==============================] - 23s 279ms/step - loss: 0.0401 - acc: 0.9851 - val_loss: 0.0485 - val_acc: 0.9850\n",
      "Epoch 149/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0374 - acc: 0.9877WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0535 - acc: 0.9850\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 0.03563\n",
      "81/81 [==============================] - 22s 267ms/step - loss: 0.0369 - acc: 0.9879 - val_loss: 0.0535 - val_acc: 0.9850\n",
      "Epoch 150/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0388 - acc: 0.9859WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 22s 7ms/sample - loss: 0.0599 - acc: 0.9809\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 0.03563\n",
      "81/81 [==============================] - 27s 336ms/step - loss: 0.0386 - acc: 0.9860 - val_loss: 0.0599 - val_acc: 0.9809\n",
      "Epoch 151/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0429 - acc: 0.9840WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0527 - acc: 0.9891\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 0.03563\n",
      "81/81 [==============================] - 25s 304ms/step - loss: 0.0433 - acc: 0.9839 - val_loss: 0.0527 - val_acc: 0.9891\n",
      "Epoch 152/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0423 - acc: 0.9863WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3200/3183 [==============================] - 24s 7ms/sample - loss: 0.0624 - acc: 0.9775\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 0.03563\n",
      "81/81 [==============================] - 28s 342ms/step - loss: 0.0431 - acc: 0.9860 - val_loss: 0.0624 - val_acc: 0.9775\n",
      "Epoch 153/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0346 - acc: 0.9903WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 20s 6ms/sample - loss: 0.0644 - acc: 0.9719\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 0.03563\n",
      "81/81 [==============================] - 25s 310ms/step - loss: 0.0359 - acc: 0.9898 - val_loss: 0.0644 - val_acc: 0.9719\n",
      "Epoch 154/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0357 - acc: 0.9881WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 21s 7ms/sample - loss: 0.0491 - acc: 0.9878\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 0.03563\n",
      "81/81 [==============================] - 26s 319ms/step - loss: 0.0357 - acc: 0.9882 - val_loss: 0.0491 - val_acc: 0.9878\n",
      "Epoch 155/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0348 - acc: 0.9887WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 20s 6ms/sample - loss: 0.0550 - acc: 0.9831\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 0.03563\n",
      "81/81 [==============================] - 27s 328ms/step - loss: 0.0345 - acc: 0.9888 - val_loss: 0.0550 - val_acc: 0.9831\n",
      "Epoch 156/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0425 - acc: 0.9840WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0482 - acc: 0.9831\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 0.03563\n",
      "81/81 [==============================] - 22s 277ms/step - loss: 0.0425 - acc: 0.9839 - val_loss: 0.0482 - val_acc: 0.9831\n",
      "Epoch 157/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0357 - acc: 0.9898WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 20s 6ms/sample - loss: 0.0427 - acc: 0.9869\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 0.03563\n",
      "81/81 [==============================] - 26s 317ms/step - loss: 0.0357 - acc: 0.9898 - val_loss: 0.0427 - val_acc: 0.9869\n",
      "Epoch 158/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0360 - acc: 0.9911WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0386 - acc: 0.9841\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 0.03563\n",
      "81/81 [==============================] - 23s 287ms/step - loss: 0.0355 - acc: 0.9913 - val_loss: 0.0386 - val_acc: 0.9841\n",
      "Epoch 159/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0416 - acc: 0.9873WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 21s 7ms/sample - loss: 0.0365 - acc: 0.9869\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 0.03563\n",
      "81/81 [==============================] - 27s 336ms/step - loss: 0.0414 - acc: 0.9873 - val_loss: 0.0365 - val_acc: 0.9869\n",
      "Epoch 160/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0323 - acc: 0.9915WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0468 - acc: 0.9862\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 0.03563\n",
      "81/81 [==============================] - 24s 298ms/step - loss: 0.0320 - acc: 0.9916 - val_loss: 0.0468 - val_acc: 0.9862\n",
      "Epoch 161/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0334 - acc: 0.9885WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0345 - acc: 0.9869\n",
      "\n",
      "Epoch 00161: val_loss improved from 0.03563 to 0.03454, saving model to model/checkpoint/vis_imagenet_6_class_augmentation_2D_CNN_custom_ch_32_DO_075_DO_4_conv_checkpoint/161-0.0345.hdf5\n",
      "81/81 [==============================] - 24s 292ms/step - loss: 0.0331 - acc: 0.9888 - val_loss: 0.0345 - val_acc: 0.9869\n",
      "Epoch 162/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0381 - acc: 0.9877WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 27s 8ms/sample - loss: 0.0326 - acc: 0.9894\n",
      "\n",
      "Epoch 00162: val_loss improved from 0.03454 to 0.03263, saving model to model/checkpoint/vis_imagenet_6_class_augmentation_2D_CNN_custom_ch_32_DO_075_DO_4_conv_checkpoint/162-0.0326.hdf5\n",
      "81/81 [==============================] - 34s 425ms/step - loss: 0.0378 - acc: 0.9879 - val_loss: 0.0326 - val_acc: 0.9894\n",
      "Epoch 163/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0251 - acc: 0.9908WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0353 - acc: 0.9925\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 0.03263\n",
      "81/81 [==============================] - 23s 280ms/step - loss: 0.0251 - acc: 0.9907 - val_loss: 0.0353 - val_acc: 0.9925\n",
      "Epoch 164/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0247 - acc: 0.9918- ETA: 0s - loss: 0.0239 - acc: WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0336 - acc: 0.9900\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 0.03263\n",
      "81/81 [==============================] - 23s 284ms/step - loss: 0.0249 - acc: 0.9916 - val_loss: 0.0336 - val_acc: 0.9900\n",
      "Epoch 165/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0288 - acc: 0.9901WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 21s 7ms/sample - loss: 0.0436 - acc: 0.9925\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 0.03263\n",
      "81/81 [==============================] - 26s 319ms/step - loss: 0.0302 - acc: 0.9901 - val_loss: 0.0436 - val_acc: 0.9925\n",
      "Epoch 166/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0435 - acc: 0.9843WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 21s 7ms/sample - loss: 0.0417 - acc: 0.9850\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 0.03263\n",
      "81/81 [==============================] - 27s 335ms/step - loss: 0.0433 - acc: 0.9842 - val_loss: 0.0417 - val_acc: 0.9850\n",
      "Epoch 167/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0408 - acc: 0.9870WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3200/3183 [==============================] - 21s 6ms/sample - loss: 0.0394 - acc: 0.9878\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 0.03263\n",
      "81/81 [==============================] - 25s 306ms/step - loss: 0.0405 - acc: 0.9870 - val_loss: 0.0394 - val_acc: 0.9878\n",
      "Epoch 168/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0265 - acc: 0.9909WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 27s 9ms/sample - loss: 0.0336 - acc: 0.9919\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 0.03263\n",
      "81/81 [==============================] - 34s 418ms/step - loss: 0.0266 - acc: 0.9907 - val_loss: 0.0336 - val_acc: 0.9919\n",
      "Epoch 169/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0330 - acc: 0.9881WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 25s 8ms/sample - loss: 0.0412 - acc: 0.9875\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 0.03263\n",
      "81/81 [==============================] - 33s 410ms/step - loss: 0.0328 - acc: 0.9882 - val_loss: 0.0412 - val_acc: 0.9875\n",
      "Epoch 170/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0232 - acc: 0.9933WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0304 - acc: 0.9925\n",
      "\n",
      "Epoch 00170: val_loss improved from 0.03263 to 0.03040, saving model to model/checkpoint/vis_imagenet_6_class_augmentation_2D_CNN_custom_ch_32_DO_075_DO_4_conv_checkpoint/170-0.0304.hdf5\n",
      "81/81 [==============================] - 23s 283ms/step - loss: 0.0230 - acc: 0.9935 - val_loss: 0.0304 - val_acc: 0.9925\n",
      "Epoch 171/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0376 - acc: 0.9885- ETA: 1s - loss: 0.0352 -WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 20s 6ms/sample - loss: 0.0415 - acc: 0.9837\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 0.03040\n",
      "81/81 [==============================] - 27s 335ms/step - loss: 0.0369 - acc: 0.9888 - val_loss: 0.0415 - val_acc: 0.9837\n",
      "Epoch 172/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0347 - acc: 0.9911WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.0372 - acc: 0.9900\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 0.03040\n",
      "81/81 [==============================] - 22s 272ms/step - loss: 0.0344 - acc: 0.9913 - val_loss: 0.0372 - val_acc: 0.9900\n",
      "Epoch 173/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0285 - acc: 0.9914WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0453 - acc: 0.9825\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 0.03040\n",
      "81/81 [==============================] - 23s 279ms/step - loss: 0.0283 - acc: 0.9913 - val_loss: 0.0453 - val_acc: 0.9825\n",
      "Epoch 174/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0278 - acc: 0.9911WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 24s 7ms/sample - loss: 0.0412 - acc: 0.9916\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 0.03040\n",
      "81/81 [==============================] - 28s 342ms/step - loss: 0.0273 - acc: 0.9913 - val_loss: 0.0412 - val_acc: 0.9916\n",
      "Epoch 175/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0332 - acc: 0.9899WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0762 - acc: 0.9784\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 0.03040\n",
      "81/81 [==============================] - 24s 291ms/step - loss: 0.0336 - acc: 0.9898 - val_loss: 0.0762 - val_acc: 0.9784\n",
      "Epoch 176/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0269 - acc: 0.9920WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 20s 6ms/sample - loss: 0.0356 - acc: 0.9887\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 0.03040\n",
      "81/81 [==============================] - 25s 310ms/step - loss: 0.0264 - acc: 0.9922 - val_loss: 0.0356 - val_acc: 0.9887\n",
      "Epoch 177/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0354 - acc: 0.9882WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 20s 6ms/sample - loss: 0.0383 - acc: 0.9884\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 0.03040\n",
      "81/81 [==============================] - 28s 351ms/step - loss: 0.0349 - acc: 0.9885 - val_loss: 0.0383 - val_acc: 0.9884\n",
      "Epoch 178/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0368 - acc: 0.9866WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 28s 9ms/sample - loss: 0.0340 - acc: 0.9875\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 0.03040\n",
      "81/81 [==============================] - 33s 402ms/step - loss: 0.0363 - acc: 0.9870 - val_loss: 0.0340 - val_acc: 0.9875\n",
      "Epoch 179/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0389 - acc: 0.9879WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0638 - acc: 0.9725\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 0.03040\n",
      "81/81 [==============================] - 25s 309ms/step - loss: 0.0387 - acc: 0.9879 - val_loss: 0.0638 - val_acc: 0.9725\n",
      "Epoch 180/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0330 - acc: 0.9899WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0337 - acc: 0.9947\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 0.03040\n",
      "81/81 [==============================] - 23s 281ms/step - loss: 0.0332 - acc: 0.9898 - val_loss: 0.0337 - val_acc: 0.9947\n",
      "Epoch 181/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0257 - acc: 0.9920WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 15s 5ms/sample - loss: 0.0320 - acc: 0.9894\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 0.03040\n",
      "81/81 [==============================] - 23s 281ms/step - loss: 0.0265 - acc: 0.9919 - val_loss: 0.0320 - val_acc: 0.9894\n",
      "Epoch 182/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0280 - acc: 0.9903WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0571 - acc: 0.9856\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 0.03040\n",
      "81/81 [==============================] - 22s 276ms/step - loss: 0.0278 - acc: 0.9904 - val_loss: 0.0571 - val_acc: 0.9856\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 183/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0368 - acc: 0.9887WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 22s 7ms/sample - loss: 0.0419 - acc: 0.9862\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 0.03040\n",
      "81/81 [==============================] - 27s 327ms/step - loss: 0.0365 - acc: 0.9888 - val_loss: 0.0419 - val_acc: 0.9862\n",
      "Epoch 184/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0270 - acc: 0.9911WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0406 - acc: 0.9869\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 0.03040\n",
      "81/81 [==============================] - 23s 284ms/step - loss: 0.0273 - acc: 0.9904 - val_loss: 0.0406 - val_acc: 0.9869\n",
      "Epoch 185/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0307 - acc: 0.9899WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 14s 5ms/sample - loss: 0.0344 - acc: 0.9872\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 0.03040\n",
      "81/81 [==============================] - 20s 250ms/step - loss: 0.0304 - acc: 0.9901 - val_loss: 0.0344 - val_acc: 0.9872\n",
      "Epoch 186/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0304 - acc: 0.9903WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0792 - acc: 0.9731\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 0.03040\n",
      "81/81 [==============================] - 23s 287ms/step - loss: 0.0302 - acc: 0.9904 - val_loss: 0.0792 - val_acc: 0.9731\n",
      "Epoch 187/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0347 - acc: 0.9868WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0641 - acc: 0.9791\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 0.03040\n",
      "81/81 [==============================] - 22s 274ms/step - loss: 0.0347 - acc: 0.9870 - val_loss: 0.0641 - val_acc: 0.9791\n",
      "Epoch 188/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0224 - acc: 0.9931WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 22s 7ms/sample - loss: 0.0421 - acc: 0.9891\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 0.03040\n",
      "81/81 [==============================] - 26s 316ms/step - loss: 0.0225 - acc: 0.9932 - val_loss: 0.0421 - val_acc: 0.9891\n",
      "Epoch 189/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0347 - acc: 0.9857WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0448 - acc: 0.9825\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 0.03040\n",
      "81/81 [==============================] - 22s 268ms/step - loss: 0.0341 - acc: 0.9860 - val_loss: 0.0448 - val_acc: 0.9825\n",
      "Epoch 190/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0406 - acc: 0.9852WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0498 - acc: 0.9862\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 0.03040\n",
      "81/81 [==============================] - 24s 298ms/step - loss: 0.0402 - acc: 0.9854 - val_loss: 0.0498 - val_acc: 0.9862\n",
      "Epoch 191/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0256 - acc: 0.9921WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0499 - acc: 0.9800\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 0.03040\n",
      "81/81 [==============================] - 23s 287ms/step - loss: 0.0253 - acc: 0.9922 - val_loss: 0.0499 - val_acc: 0.9800\n",
      "Epoch 192/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0196 - acc: 0.9953WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0423 - acc: 0.9900\n",
      "\n",
      "Epoch 00192: val_loss did not improve from 0.03040\n",
      "81/81 [==============================] - 22s 267ms/step - loss: 0.0195 - acc: 0.9953 - val_loss: 0.0423 - val_acc: 0.9900\n",
      "Epoch 193/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0176 - acc: 0.9946WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0487 - acc: 0.9847\n",
      "\n",
      "Epoch 00193: val_loss did not improve from 0.03040\n",
      "81/81 [==============================] - 23s 287ms/step - loss: 0.0174 - acc: 0.9947 - val_loss: 0.0487 - val_acc: 0.9847\n",
      "Epoch 194/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0349 - acc: 0.9871WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0469 - acc: 0.9847\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 0.03040\n",
      "81/81 [==============================] - 23s 280ms/step - loss: 0.0346 - acc: 0.9873 - val_loss: 0.0469 - val_acc: 0.9847\n",
      "Epoch 195/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0219 - acc: 0.9928WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 26s 8ms/sample - loss: 0.1180 - acc: 0.9563\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 0.03040\n",
      "81/81 [==============================] - 31s 383ms/step - loss: 0.0219 - acc: 0.9929 - val_loss: 0.1180 - val_acc: 0.9563\n",
      "Epoch 196/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0270 - acc: 0.9909WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 5ms/sample - loss: 0.0593 - acc: 0.9800\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 0.03040\n",
      "81/81 [==============================] - 24s 295ms/step - loss: 0.0269 - acc: 0.9910 - val_loss: 0.0593 - val_acc: 0.9800\n",
      "Epoch 197/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0221 - acc: 0.9927WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 20s 6ms/sample - loss: 0.0665 - acc: 0.9781\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 0.03040\n",
      "81/81 [==============================] - 27s 330ms/step - loss: 0.0226 - acc: 0.9922 - val_loss: 0.0665 - val_acc: 0.9781\n",
      "Epoch 198/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0217 - acc: 0.9930WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3200/3183 [==============================] - 23s 7ms/sample - loss: 0.0490 - acc: 0.9819\n",
      "\n",
      "Epoch 00198: val_loss did not improve from 0.03040\n",
      "81/81 [==============================] - 27s 335ms/step - loss: 0.0215 - acc: 0.9932 - val_loss: 0.0490 - val_acc: 0.9819\n",
      "Epoch 199/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0321 - acc: 0.9890WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 21s 6ms/sample - loss: 0.0427 - acc: 0.9856\n",
      "\n",
      "Epoch 00199: val_loss did not improve from 0.03040\n",
      "81/81 [==============================] - 24s 302ms/step - loss: 0.0317 - acc: 0.9891 - val_loss: 0.0427 - val_acc: 0.9856\n",
      "Epoch 200/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0292 - acc: 0.9887WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 25s 8ms/sample - loss: 0.0406 - acc: 0.9850\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 0.03040\n",
      "81/81 [==============================] - 30s 364ms/step - loss: 0.0289 - acc: 0.9888 - val_loss: 0.0406 - val_acc: 0.9850\n",
      "Epoch 201/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0337 - acc: 0.9905WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 23s 7ms/sample - loss: 0.0419 - acc: 0.9925\n",
      "\n",
      "Epoch 00201: val_loss did not improve from 0.03040\n",
      "81/81 [==============================] - 27s 339ms/step - loss: 0.0331 - acc: 0.9907 - val_loss: 0.0419 - val_acc: 0.9925\n",
      "Epoch 202/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0195 - acc: 0.9928WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 22s 7ms/sample - loss: 0.0419 - acc: 0.987213s - loss: 0.0692 - acc:  - ETA: 10s - loss: 0\n",
      "\n",
      "Epoch 00202: val_loss did not improve from 0.03040\n",
      "81/81 [==============================] - 27s 338ms/step - loss: 0.0193 - acc: 0.9929 - val_loss: 0.0419 - val_acc: 0.9872\n",
      "Epoch 203/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0295 - acc: 0.9895WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 21s 7ms/sample - loss: 0.0468 - acc: 0.9850\n",
      "\n",
      "Epoch 00203: val_loss did not improve from 0.03040\n",
      "81/81 [==============================] - 28s 344ms/step - loss: 0.0293 - acc: 0.9894 - val_loss: 0.0468 - val_acc: 0.9850\n",
      "Epoch 204/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0186 - acc: 0.9936WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.0458 - acc: 0.9875\n",
      "\n",
      "Epoch 00204: val_loss did not improve from 0.03040\n",
      "81/81 [==============================] - 22s 266ms/step - loss: 0.0184 - acc: 0.9938 - val_loss: 0.0458 - val_acc: 0.9875\n",
      "Epoch 205/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0234 - acc: 0.9918WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 22s 7ms/sample - loss: 0.0390 - acc: 0.9875\n",
      "\n",
      "Epoch 00205: val_loss did not improve from 0.03040\n",
      "81/81 [==============================] - 26s 320ms/step - loss: 0.0232 - acc: 0.9919 - val_loss: 0.0390 - val_acc: 0.9875\n",
      "Epoch 206/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0194 - acc: 0.9936WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0411 - acc: 0.9862\n",
      "\n",
      "Epoch 00206: val_loss did not improve from 0.03040\n",
      "81/81 [==============================] - 25s 312ms/step - loss: 0.0190 - acc: 0.9938 - val_loss: 0.0411 - val_acc: 0.9862\n",
      "Epoch 207/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0290 - acc: 0.9915WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0336 - acc: 0.9825\n",
      "\n",
      "Epoch 00207: val_loss did not improve from 0.03040\n",
      "81/81 [==============================] - 27s 331ms/step - loss: 0.0306 - acc: 0.9913 - val_loss: 0.0336 - val_acc: 0.9825\n",
      "Epoch 208/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0182 - acc: 0.9956WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 20s 6ms/sample - loss: 0.0375 - acc: 0.9916\n",
      "\n",
      "Epoch 00208: val_loss did not improve from 0.03040\n",
      "81/81 [==============================] - 24s 298ms/step - loss: 0.0191 - acc: 0.9953 - val_loss: 0.0375 - val_acc: 0.9916\n",
      "Epoch 209/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0257 - acc: 0.9918WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 23s 7ms/sample - loss: 0.0251 - acc: 0.9900\n",
      "\n",
      "Epoch 00209: val_loss improved from 0.03040 to 0.02508, saving model to model/checkpoint/vis_imagenet_6_class_augmentation_2D_CNN_custom_ch_32_DO_075_DO_4_conv_checkpoint/209-0.0251.hdf5\n",
      "81/81 [==============================] - 31s 381ms/step - loss: 0.0256 - acc: 0.9919 - val_loss: 0.0251 - val_acc: 0.9900\n",
      "Epoch 210/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0237 - acc: 0.9930WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 21s 6ms/sample - loss: 0.0612 - acc: 0.97695s - loss: 0.0579 \n",
      "\n",
      "Epoch 00210: val_loss did not improve from 0.02508\n",
      "81/81 [==============================] - 29s 355ms/step - loss: 0.0236 - acc: 0.9932 - val_loss: 0.0612 - val_acc: 0.9769\n",
      "Epoch 211/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0351 - acc: 0.9915WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0367 - acc: 0.9847\n",
      "\n",
      "Epoch 00211: val_loss did not improve from 0.02508\n",
      "81/81 [==============================] - 22s 275ms/step - loss: 0.0348 - acc: 0.9916 - val_loss: 0.0367 - val_acc: 0.9847\n",
      "Epoch 212/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0356 - acc: 0.9908WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0286 - acc: 0.9906\n",
      "\n",
      "Epoch 00212: val_loss did not improve from 0.02508\n",
      "81/81 [==============================] - 32s 394ms/step - loss: 0.0353 - acc: 0.9907 - val_loss: 0.0286 - val_acc: 0.9906\n",
      "Epoch 213/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0256 - acc: 0.9911WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 22s 7ms/sample - loss: 0.0314 - acc: 0.9891\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00213: val_loss did not improve from 0.02508\n",
      "81/81 [==============================] - 32s 394ms/step - loss: 0.0251 - acc: 0.9913 - val_loss: 0.0314 - val_acc: 0.9891\n",
      "Epoch 214/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0194 - acc: 0.9931WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 14s 4ms/sample - loss: 0.0580 - acc: 0.9822\n",
      "\n",
      "Epoch 00214: val_loss did not improve from 0.02508\n",
      "81/81 [==============================] - 22s 266ms/step - loss: 0.0210 - acc: 0.9929 - val_loss: 0.0580 - val_acc: 0.9822\n",
      "Epoch 215/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0325 - acc: 0.9911WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 23s 7ms/sample - loss: 0.0315 - acc: 0.9872\n",
      "\n",
      "Epoch 00215: val_loss did not improve from 0.02508\n",
      "81/81 [==============================] - 29s 357ms/step - loss: 0.0329 - acc: 0.9907 - val_loss: 0.0315 - val_acc: 0.9872\n",
      "Epoch 216/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0269 - acc: 0.9914WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 20s 6ms/sample - loss: 0.0699 - acc: 0.9803\n",
      "\n",
      "Epoch 00216: val_loss did not improve from 0.02508\n",
      "81/81 [==============================] - 27s 339ms/step - loss: 0.0267 - acc: 0.9913 - val_loss: 0.0699 - val_acc: 0.9803\n",
      "Epoch 217/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0325 - acc: 0.9892WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0427 - acc: 0.9916\n",
      "\n",
      "Epoch 00217: val_loss did not improve from 0.02508\n",
      "81/81 [==============================] - 24s 299ms/step - loss: 0.0335 - acc: 0.9888 - val_loss: 0.0427 - val_acc: 0.9916\n",
      "Epoch 218/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0273 - acc: 0.9931WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 21s 6ms/sample - loss: 0.0443 - acc: 0.9894\n",
      "\n",
      "Epoch 00218: val_loss did not improve from 0.02508\n",
      "81/81 [==============================] - 30s 369ms/step - loss: 0.0272 - acc: 0.9932 - val_loss: 0.0443 - val_acc: 0.9894\n",
      "Epoch 219/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0270 - acc: 0.9925WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0350 - acc: 0.9887\n",
      "\n",
      "Epoch 00219: val_loss did not improve from 0.02508\n",
      "81/81 [==============================] - 26s 323ms/step - loss: 0.0273 - acc: 0.9922 - val_loss: 0.0350 - val_acc: 0.9887\n",
      "Epoch 220/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0241 - acc: 0.9943WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 24s 7ms/sample - loss: 0.0498 - acc: 0.9816\n",
      "\n",
      "Epoch 00220: val_loss did not improve from 0.02508\n",
      "81/81 [==============================] - 32s 392ms/step - loss: 0.0240 - acc: 0.9944 - val_loss: 0.0498 - val_acc: 0.9816\n",
      "Epoch 221/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0206 - acc: 0.9937WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.0575 - acc: 0.9841\n",
      "\n",
      "Epoch 00221: val_loss did not improve from 0.02508\n",
      "81/81 [==============================] - 22s 278ms/step - loss: 0.0204 - acc: 0.9938 - val_loss: 0.0575 - val_acc: 0.9841\n",
      "Epoch 222/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0211 - acc: 0.9933WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 15s 5ms/sample - loss: 0.0325 - acc: 0.9872\n",
      "\n",
      "Epoch 00222: val_loss did not improve from 0.02508\n",
      "81/81 [==============================] - 24s 294ms/step - loss: 0.0206 - acc: 0.9935 - val_loss: 0.0325 - val_acc: 0.9872\n",
      "Epoch 223/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0164 - acc: 0.9953WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 23s 7ms/sample - loss: 0.0377 - acc: 0.9850\n",
      "\n",
      "Epoch 00223: val_loss did not improve from 0.02508\n",
      "81/81 [==============================] - 30s 368ms/step - loss: 0.0182 - acc: 0.9950 - val_loss: 0.0377 - val_acc: 0.9850\n",
      "Epoch 224/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0224 - acc: 0.9937WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0363 - acc: 0.9937\n",
      "\n",
      "Epoch 00224: val_loss did not improve from 0.02508\n",
      "81/81 [==============================] - 28s 343ms/step - loss: 0.0226 - acc: 0.9935 - val_loss: 0.0363 - val_acc: 0.9937\n",
      "Epoch 225/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0270 - acc: 0.9917WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 22s 7ms/sample - loss: 0.0378 - acc: 0.9900\n",
      "\n",
      "Epoch 00225: val_loss did not improve from 0.02508\n",
      "81/81 [==============================] - 26s 323ms/step - loss: 0.0265 - acc: 0.9919 - val_loss: 0.0378 - val_acc: 0.9900\n",
      "Epoch 226/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0268 - acc: 0.9937WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 23s 7ms/sample - loss: 0.0321 - acc: 0.9900\n",
      "\n",
      "Epoch 00226: val_loss did not improve from 0.02508\n",
      "81/81 [==============================] - 32s 390ms/step - loss: 0.0265 - acc: 0.9938 - val_loss: 0.0321 - val_acc: 0.9900\n",
      "Epoch 227/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0218 - acc: 0.9933WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.0505 - acc: 0.9853\n",
      "\n",
      "Epoch 00227: val_loss did not improve from 0.02508\n",
      "81/81 [==============================] - 24s 297ms/step - loss: 0.0221 - acc: 0.9932 - val_loss: 0.0505 - val_acc: 0.9853\n",
      "Epoch 228/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0296 - acc: 0.9896WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 22s 7ms/sample - loss: 0.0275 - acc: 0.9900\n",
      "\n",
      "Epoch 00228: val_loss did not improve from 0.02508\n",
      "81/81 [==============================] - 28s 345ms/step - loss: 0.0295 - acc: 0.9898 - val_loss: 0.0275 - val_acc: 0.9900\n",
      "Epoch 229/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0206 - acc: 0.9962WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0503 - acc: 0.9825\n",
      "\n",
      "Epoch 00229: val_loss did not improve from 0.02508\n",
      "81/81 [==============================] - 26s 326ms/step - loss: 0.0208 - acc: 0.9957 - val_loss: 0.0503 - val_acc: 0.9825\n",
      "Epoch 230/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0238 - acc: 0.9943WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 15s 5ms/sample - loss: 0.0336 - acc: 0.9850\n",
      "\n",
      "Epoch 00230: val_loss did not improve from 0.02508\n",
      "81/81 [==============================] - 22s 275ms/step - loss: 0.0234 - acc: 0.9944 - val_loss: 0.0336 - val_acc: 0.9850\n",
      "Epoch 231/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0281 - acc: 0.9931WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3190/3183 [==============================] - 19s 6ms/sample - loss: 0.0318 - acc: 0.9875\n",
      "\n",
      "Epoch 00231: val_loss did not improve from 0.02508\n",
      "81/81 [==============================] - 26s 318ms/step - loss: 0.0280 - acc: 0.9932 - val_loss: 0.0318 - val_acc: 0.9875\n",
      "Epoch 232/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0176 - acc: 0.9955WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.0456 - acc: 0.9841\n",
      "\n",
      "Epoch 00232: val_loss did not improve from 0.02508\n",
      "81/81 [==============================] - 20s 245ms/step - loss: 0.0172 - acc: 0.9957 - val_loss: 0.0456 - val_acc: 0.9841\n",
      "Epoch 233/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0131 - acc: 0.9981WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 23s 7ms/sample - loss: 0.0267 - acc: 0.9897\n",
      "\n",
      "Epoch 00233: val_loss did not improve from 0.02508\n",
      "81/81 [==============================] - 29s 358ms/step - loss: 0.0129 - acc: 0.9981 - val_loss: 0.0267 - val_acc: 0.9897\n",
      "Epoch 234/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0231 - acc: 0.9925WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0315 - acc: 0.9841\n",
      "\n",
      "Epoch 00234: val_loss did not improve from 0.02508\n",
      "81/81 [==============================] - 26s 318ms/step - loss: 0.0233 - acc: 0.9926 - val_loss: 0.0315 - val_acc: 0.9841\n",
      "Epoch 235/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0182 - acc: 0.9955WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 20s 6ms/sample - loss: 0.0308 - acc: 0.9875\n",
      "\n",
      "Epoch 00235: val_loss did not improve from 0.02508\n",
      "81/81 [==============================] - 24s 292ms/step - loss: 0.0180 - acc: 0.9957 - val_loss: 0.0308 - val_acc: 0.9875\n",
      "Epoch 236/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0193 - acc: 0.9943WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 22s 7ms/sample - loss: 0.0408 - acc: 0.9862\n",
      "\n",
      "Epoch 00236: val_loss did not improve from 0.02508\n",
      "81/81 [==============================] - 26s 320ms/step - loss: 0.0192 - acc: 0.9941 - val_loss: 0.0408 - val_acc: 0.9862\n",
      "Epoch 237/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0198 - acc: 0.9933WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 29s 9ms/sample - loss: 0.0309 - acc: 0.9900\n",
      "\n",
      "Epoch 00237: val_loss did not improve from 0.02508\n",
      "81/81 [==============================] - 33s 407ms/step - loss: 0.0198 - acc: 0.9932 - val_loss: 0.0309 - val_acc: 0.9900\n",
      "Epoch 238/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0202 - acc: 0.9947WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0303 - acc: 0.9875\n",
      "\n",
      "Epoch 00238: val_loss did not improve from 0.02508\n",
      "81/81 [==============================] - 24s 300ms/step - loss: 0.0201 - acc: 0.9947 - val_loss: 0.0303 - val_acc: 0.9875\n",
      "Epoch 239/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0222 - acc: 0.9918WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3190/3183 [==============================] - 16s 5ms/sample - loss: 0.0218 - acc: 0.9918\n",
      "\n",
      "Epoch 00239: val_loss improved from 0.02508 to 0.02184, saving model to model/checkpoint/vis_imagenet_6_class_augmentation_2D_CNN_custom_ch_32_DO_075_DO_4_conv_checkpoint/239-0.0218.hdf5\n",
      "81/81 [==============================] - 22s 273ms/step - loss: 0.0242 - acc: 0.9916 - val_loss: 0.0218 - val_acc: 0.9918\n",
      "Epoch 240/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0232 - acc: 0.9931WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0377 - acc: 0.9881\n",
      "\n",
      "Epoch 00240: val_loss did not improve from 0.02184\n",
      "81/81 [==============================] - 24s 300ms/step - loss: 0.0232 - acc: 0.9929 - val_loss: 0.0377 - val_acc: 0.9881\n",
      "Epoch 241/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0196 - acc: 0.9937WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0694 - acc: 0.9806\n",
      "\n",
      "Epoch 00241: val_loss did not improve from 0.02184\n",
      "81/81 [==============================] - 23s 285ms/step - loss: 0.0194 - acc: 0.9938 - val_loss: 0.0694 - val_acc: 0.9806\n",
      "Epoch 242/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0254 - acc: 0.9930WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0191 - acc: 0.9900\n",
      "\n",
      "Epoch 00242: val_loss improved from 0.02184 to 0.01906, saving model to model/checkpoint/vis_imagenet_6_class_augmentation_2D_CNN_custom_ch_32_DO_075_DO_4_conv_checkpoint/242-0.0191.hdf5\n",
      "81/81 [==============================] - 21s 261ms/step - loss: 0.0256 - acc: 0.9926 - val_loss: 0.0191 - val_acc: 0.9900\n",
      "Epoch 243/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0242 - acc: 0.9914WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0373 - acc: 0.9837\n",
      "\n",
      "Epoch 00243: val_loss did not improve from 0.01906\n",
      "81/81 [==============================] - 23s 282ms/step - loss: 0.0237 - acc: 0.9916 - val_loss: 0.0373 - val_acc: 0.9837\n",
      "Epoch 244/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0170 - acc: 0.9933WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3200/3183 [==============================] - 23s 7ms/sample - loss: 0.0277 - acc: 0.9950\n",
      "\n",
      "Epoch 00244: val_loss did not improve from 0.01906\n",
      "81/81 [==============================] - 31s 380ms/step - loss: 0.0169 - acc: 0.9935 - val_loss: 0.0277 - val_acc: 0.9950\n",
      "Epoch 245/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0268 - acc: 0.9915WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.0324 - acc: 0.9850\n",
      "\n",
      "Epoch 00245: val_loss did not improve from 0.01906\n",
      "81/81 [==============================] - 22s 271ms/step - loss: 0.0265 - acc: 0.9916 - val_loss: 0.0324 - val_acc: 0.9850\n",
      "Epoch 246/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0209 - acc: 0.9953WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 28s 9ms/sample - loss: 0.0453 - acc: 0.9887\n",
      "\n",
      "Epoch 00246: val_loss did not improve from 0.01906\n",
      "81/81 [==============================] - 32s 395ms/step - loss: 0.0207 - acc: 0.9953 - val_loss: 0.0453 - val_acc: 0.9887\n",
      "Epoch 247/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0242 - acc: 0.9905WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0296 - acc: 0.9919\n",
      "\n",
      "Epoch 00247: val_loss did not improve from 0.01906\n",
      "81/81 [==============================] - 24s 296ms/step - loss: 0.0243 - acc: 0.9904 - val_loss: 0.0296 - val_acc: 0.9919\n",
      "Epoch 248/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0268 - acc: 0.9918WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0391 - acc: 0.9900\n",
      "\n",
      "Epoch 00248: val_loss did not improve from 0.01906\n",
      "81/81 [==============================] - 22s 266ms/step - loss: 0.0267 - acc: 0.9919 - val_loss: 0.0391 - val_acc: 0.9900\n",
      "Epoch 249/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0242 - acc: 0.9933WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 5ms/sample - loss: 0.0355 - acc: 0.9872\n",
      "\n",
      "Epoch 00249: val_loss did not improve from 0.01906\n",
      "81/81 [==============================] - 22s 268ms/step - loss: 0.0238 - acc: 0.9935 - val_loss: 0.0355 - val_acc: 0.9872\n",
      "Epoch 250/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0183 - acc: 0.9956WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0398 - acc: 0.9831\n",
      "\n",
      "Epoch 00250: val_loss did not improve from 0.01906\n",
      "81/81 [==============================] - 23s 282ms/step - loss: 0.0181 - acc: 0.9957 - val_loss: 0.0398 - val_acc: 0.9831\n",
      "Epoch 251/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0238 - acc: 0.9943WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.0377 - acc: 0.9916\n",
      "\n",
      "Epoch 00251: val_loss did not improve from 0.01906\n",
      "81/81 [==============================] - 22s 275ms/step - loss: 0.0236 - acc: 0.9944 - val_loss: 0.0377 - val_acc: 0.9916\n",
      "Epoch 252/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0296 - acc: 0.9905WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0413 - acc: 0.9894\n",
      "\n",
      "Epoch 00252: val_loss did not improve from 0.01906\n",
      "81/81 [==============================] - 23s 278ms/step - loss: 0.0296 - acc: 0.9904 - val_loss: 0.0413 - val_acc: 0.9894\n",
      "Epoch 253/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0152 - acc: 0.9965WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0324 - acc: 0.9900\n",
      "\n",
      "Epoch 00253: val_loss did not improve from 0.01906\n",
      "81/81 [==============================] - 22s 275ms/step - loss: 0.0150 - acc: 0.9966 - val_loss: 0.0324 - val_acc: 0.9900\n",
      "Epoch 254/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0210 - acc: 0.9924WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0271 - acc: 0.9900\n",
      "\n",
      "Epoch 00254: val_loss did not improve from 0.01906\n",
      "81/81 [==============================] - 23s 287ms/step - loss: 0.0206 - acc: 0.9926 - val_loss: 0.0271 - val_acc: 0.9900\n",
      "Epoch 255/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0202 - acc: 0.9943WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 23s 7ms/sample - loss: 0.0413 - acc: 0.9837\n",
      "\n",
      "Epoch 00255: val_loss did not improve from 0.01906\n",
      "81/81 [==============================] - 29s 359ms/step - loss: 0.0198 - acc: 0.9944 - val_loss: 0.0413 - val_acc: 0.9837\n",
      "Epoch 256/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0113 - acc: 0.9969WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 22s 7ms/sample - loss: 0.0334 - acc: 0.9950\n",
      "\n",
      "Epoch 00256: val_loss did not improve from 0.01906\n",
      "81/81 [==============================] - 27s 333ms/step - loss: 0.0112 - acc: 0.9969 - val_loss: 0.0334 - val_acc: 0.9950\n",
      "Epoch 257/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0128 - acc: 0.9959WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0317 - acc: 0.9919\n",
      "\n",
      "Epoch 00257: val_loss did not improve from 0.01906\n",
      "81/81 [==============================] - 25s 306ms/step - loss: 0.0128 - acc: 0.9960 - val_loss: 0.0317 - val_acc: 0.9919\n",
      "Epoch 258/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0253 - acc: 0.9943WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 20s 6ms/sample - loss: 0.0477 - acc: 0.9819\n",
      "\n",
      "Epoch 00258: val_loss did not improve from 0.01906\n",
      "81/81 [==============================] - 24s 292ms/step - loss: 0.0249 - acc: 0.9944 - val_loss: 0.0477 - val_acc: 0.9819\n",
      "Epoch 259/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0170 - acc: 0.9943WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 20s 6ms/sample - loss: 0.0501 - acc: 0.9812\n",
      "\n",
      "Epoch 00259: val_loss did not improve from 0.01906\n",
      "81/81 [==============================] - 26s 318ms/step - loss: 0.0168 - acc: 0.9944 - val_loss: 0.0501 - val_acc: 0.9812\n",
      "Epoch 260/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/81 [============================>.] - ETA: 0s - loss: 0.0140 - acc: 0.9965WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.0339 - acc: 0.9872\n",
      "\n",
      "Epoch 00260: val_loss did not improve from 0.01906\n",
      "81/81 [==============================] - 21s 264ms/step - loss: 0.0139 - acc: 0.9966 - val_loss: 0.0339 - val_acc: 0.9872\n",
      "Epoch 261/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0181 - acc: 0.9936WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0358 - acc: 0.9900\n",
      "\n",
      "Epoch 00261: val_loss did not improve from 0.01906\n",
      "81/81 [==============================] - 23s 279ms/step - loss: 0.0181 - acc: 0.9938 - val_loss: 0.0358 - val_acc: 0.9900\n",
      "Epoch 262/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0207 - acc: 0.9940WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0367 - acc: 0.9897\n",
      "\n",
      "Epoch 00262: val_loss did not improve from 0.01906\n",
      "81/81 [==============================] - 23s 283ms/step - loss: 0.0202 - acc: 0.9941 - val_loss: 0.0367 - val_acc: 0.9897\n",
      "Epoch 263/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0152 - acc: 0.9959WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.0494 - acc: 0.9756\n",
      "\n",
      "Epoch 00263: val_loss did not improve from 0.01906\n",
      "81/81 [==============================] - 21s 264ms/step - loss: 0.0150 - acc: 0.9960 - val_loss: 0.0494 - val_acc: 0.9756\n",
      "Epoch 264/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0220 - acc: 0.9943WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0324 - acc: 0.9900\n",
      "\n",
      "Epoch 00264: val_loss did not improve from 0.01906\n",
      "81/81 [==============================] - 21s 263ms/step - loss: 0.0221 - acc: 0.9941 - val_loss: 0.0324 - val_acc: 0.9900\n",
      "Epoch 265/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0169 - acc: 0.9928WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0331 - acc: 0.9900\n",
      "\n",
      "Epoch 00265: val_loss did not improve from 0.01906\n",
      "81/81 [==============================] - 23s 281ms/step - loss: 0.0171 - acc: 0.9926 - val_loss: 0.0331 - val_acc: 0.9900\n",
      "Epoch 266/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0293 - acc: 0.9899WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 15s 5ms/sample - loss: 0.0252 - acc: 0.9947\n",
      "\n",
      "Epoch 00266: val_loss did not improve from 0.01906\n",
      "81/81 [==============================] - 23s 286ms/step - loss: 0.0290 - acc: 0.9901 - val_loss: 0.0252 - val_acc: 0.9947\n",
      "Epoch 267/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0185 - acc: 0.9943WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0316 - acc: 0.9944\n",
      "\n",
      "Epoch 00267: val_loss did not improve from 0.01906\n",
      "81/81 [==============================] - 25s 310ms/step - loss: 0.0189 - acc: 0.9941 - val_loss: 0.0316 - val_acc: 0.9944\n",
      "Epoch 268/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0149 - acc: 0.9947WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 20s 6ms/sample - loss: 0.0474 - acc: 0.9894\n",
      "\n",
      "Epoch 00268: val_loss did not improve from 0.01906\n",
      "81/81 [==============================] - 25s 309ms/step - loss: 0.0153 - acc: 0.9944 - val_loss: 0.0474 - val_acc: 0.9894\n",
      "Epoch 269/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0216 - acc: 0.9937WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 20s 6ms/sample - loss: 0.0337 - acc: 0.9875\n",
      "\n",
      "Epoch 00269: val_loss did not improve from 0.01906\n",
      "81/81 [==============================] - 23s 290ms/step - loss: 0.0215 - acc: 0.9938 - val_loss: 0.0337 - val_acc: 0.9875\n",
      "Epoch 270/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0240 - acc: 0.9917WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 14s 4ms/sample - loss: 0.0343 - acc: 0.9881\n",
      "\n",
      "Epoch 00270: val_loss did not improve from 0.01906\n",
      "81/81 [==============================] - 21s 257ms/step - loss: 0.0236 - acc: 0.9919 - val_loss: 0.0343 - val_acc: 0.9881\n",
      "Epoch 271/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0112 - acc: 0.9971WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 14s 5ms/sample - loss: 0.0442 - acc: 0.9862\n",
      "\n",
      "Epoch 00271: val_loss did not improve from 0.01906\n",
      "81/81 [==============================] - 23s 279ms/step - loss: 0.0112 - acc: 0.9972 - val_loss: 0.0442 - val_acc: 0.9862\n",
      "Epoch 272/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0156 - acc: 0.9959WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 20s 6ms/sample - loss: 0.0293 - acc: 0.9919\n",
      "\n",
      "Epoch 00272: val_loss did not improve from 0.01906\n",
      "81/81 [==============================] - 23s 289ms/step - loss: 0.0156 - acc: 0.9960 - val_loss: 0.0293 - val_acc: 0.9919\n",
      "Epoch 273/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0249 - acc: 0.9914WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 14s 4ms/sample - loss: 0.0482 - acc: 0.9841\n",
      "\n",
      "Epoch 00273: val_loss did not improve from 0.01906\n",
      "81/81 [==============================] - 20s 250ms/step - loss: 0.0244 - acc: 0.9916 - val_loss: 0.0482 - val_acc: 0.9841\n",
      "Epoch 274/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0204 - acc: 0.9947WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.0353 - acc: 0.9891\n",
      "\n",
      "Epoch 00274: val_loss did not improve from 0.01906\n",
      "81/81 [==============================] - 21s 259ms/step - loss: 0.0202 - acc: 0.9947 - val_loss: 0.0353 - val_acc: 0.9891\n",
      "Epoch 275/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0277 - acc: 0.9912WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0461 - acc: 0.9916\n",
      "\n",
      "Epoch 00275: val_loss did not improve from 0.01906\n",
      "81/81 [==============================] - 22s 274ms/step - loss: 0.0276 - acc: 0.9913 - val_loss: 0.0461 - val_acc: 0.9916\n",
      "Epoch 276/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0226 - acc: 0.9928WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 5ms/sample - loss: 0.0719 - acc: 0.9794\n",
      "\n",
      "Epoch 00276: val_loss did not improve from 0.01906\n",
      "81/81 [==============================] - 22s 268ms/step - loss: 0.0223 - acc: 0.9929 - val_loss: 0.0719 - val_acc: 0.9794\n",
      "Epoch 277/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0184 - acc: 0.9943WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0373 - acc: 0.9947\n",
      "\n",
      "Epoch 00277: val_loss did not improve from 0.01906\n",
      "81/81 [==============================] - 24s 297ms/step - loss: 0.0192 - acc: 0.9938 - val_loss: 0.0373 - val_acc: 0.9947\n",
      "Epoch 278/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0203 - acc: 0.9937WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0425 - acc: 0.9866\n",
      "\n",
      "Epoch 00278: val_loss did not improve from 0.01906\n",
      "81/81 [==============================] - 24s 292ms/step - loss: 0.0201 - acc: 0.9938 - val_loss: 0.0425 - val_acc: 0.9866\n",
      "Epoch 279/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0220 - acc: 0.9940WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0249 - acc: 0.9900\n",
      "\n",
      "Epoch 00279: val_loss did not improve from 0.01906\n",
      "81/81 [==============================] - 22s 270ms/step - loss: 0.0216 - acc: 0.9941 - val_loss: 0.0249 - val_acc: 0.9900\n",
      "Epoch 280/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0171 - acc: 0.9953WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 21s 6ms/sample - loss: 0.0516 - acc: 0.9941\n",
      "\n",
      "Epoch 00280: val_loss did not improve from 0.01906\n",
      "81/81 [==============================] - 25s 308ms/step - loss: 0.0174 - acc: 0.9950 - val_loss: 0.0516 - val_acc: 0.9941\n",
      "Epoch 281/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0192 - acc: 0.9950WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0204 - acc: 0.9900\n",
      "\n",
      "Epoch 00281: val_loss did not improve from 0.01906\n",
      "81/81 [==============================] - 22s 266ms/step - loss: 0.0191 - acc: 0.9950 - val_loss: 0.0204 - val_acc: 0.9900\n",
      "Epoch 282/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0144 - acc: 0.9956WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0444 - acc: 0.9850\n",
      "\n",
      "Epoch 00282: val_loss did not improve from 0.01906\n",
      "81/81 [==============================] - 22s 275ms/step - loss: 0.0169 - acc: 0.9953 - val_loss: 0.0444 - val_acc: 0.9850\n",
      "Epoch 283/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0285 - acc: 0.9914WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0515 - acc: 0.9900\n",
      "\n",
      "Epoch 00283: val_loss did not improve from 0.01906\n",
      "81/81 [==============================] - 22s 268ms/step - loss: 0.0303 - acc: 0.9913 - val_loss: 0.0515 - val_acc: 0.9900\n",
      "Epoch 284/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0152 - acc: 0.9962WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0411 - acc: 0.9919\n",
      "\n",
      "Epoch 00284: val_loss did not improve from 0.01906\n",
      "81/81 [==============================] - 22s 277ms/step - loss: 0.0149 - acc: 0.9963 - val_loss: 0.0411 - val_acc: 0.9919\n",
      "Epoch 285/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0187 - acc: 0.9947WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.0367 - acc: 0.9869\n",
      "\n",
      "Epoch 00285: val_loss did not improve from 0.01906\n",
      "81/81 [==============================] - 22s 273ms/step - loss: 0.0186 - acc: 0.9947 - val_loss: 0.0367 - val_acc: 0.9869\n",
      "Epoch 286/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0166 - acc: 0.9949WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0312 - acc: 0.9950\n",
      "\n",
      "Epoch 00286: val_loss did not improve from 0.01906\n",
      "81/81 [==============================] - 24s 291ms/step - loss: 0.0164 - acc: 0.9950 - val_loss: 0.0312 - val_acc: 0.9950\n",
      "Epoch 287/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0183 - acc: 0.9946WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0313 - acc: 0.9875\n",
      "\n",
      "Epoch 00287: val_loss did not improve from 0.01906\n",
      "81/81 [==============================] - 22s 268ms/step - loss: 0.0181 - acc: 0.9947 - val_loss: 0.0313 - val_acc: 0.9875\n",
      "Epoch 288/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0086 - acc: 0.9978WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0346 - acc: 0.9897\n",
      "\n",
      "Epoch 00288: val_loss did not improve from 0.01906\n",
      "81/81 [==============================] - 21s 259ms/step - loss: 0.0096 - acc: 0.9975 - val_loss: 0.0346 - val_acc: 0.9897\n",
      "Epoch 289/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0206 - acc: 0.9931WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0325 - acc: 0.9906\n",
      "\n",
      "Epoch 00289: val_loss did not improve from 0.01906\n",
      "81/81 [==============================] - 21s 264ms/step - loss: 0.0209 - acc: 0.9929 - val_loss: 0.0325 - val_acc: 0.9906\n",
      "Epoch 290/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0126 - acc: 0.9959WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0361 - acc: 0.9869\n",
      "\n",
      "Epoch 00290: val_loss did not improve from 0.01906\n",
      "81/81 [==============================] - 23s 282ms/step - loss: 0.0123 - acc: 0.9960 - val_loss: 0.0361 - val_acc: 0.9869\n",
      "Epoch 291/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/81 [============================>.] - ETA: 0s - loss: 0.0145 - acc: 0.9952WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0543 - acc: 0.9837\n",
      "\n",
      "Epoch 00291: val_loss did not improve from 0.01906\n",
      "81/81 [==============================] - 21s 263ms/step - loss: 0.0142 - acc: 0.9953 - val_loss: 0.0543 - val_acc: 0.9837\n",
      "Epoch 292/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0160 - acc: 0.9959WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0416 - acc: 0.9897\n",
      "\n",
      "Epoch 00292: val_loss did not improve from 0.01906\n",
      "81/81 [==============================] - 22s 276ms/step - loss: 0.0159 - acc: 0.9960 - val_loss: 0.0416 - val_acc: 0.9897\n",
      "Epoch 293/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0174 - acc: 0.9946WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0821 - acc: 0.9684\n",
      "\n",
      "Epoch 00293: val_loss did not improve from 0.01906\n",
      "81/81 [==============================] - 23s 283ms/step - loss: 0.0171 - acc: 0.9947 - val_loss: 0.0821 - val_acc: 0.9684\n",
      "Epoch 294/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0146 - acc: 0.9949WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0379 - acc: 0.9812\n",
      "\n",
      "Epoch 00294: val_loss did not improve from 0.01906\n",
      "81/81 [==============================] - 22s 272ms/step - loss: 0.0147 - acc: 0.9950 - val_loss: 0.0379 - val_acc: 0.9812\n",
      "Epoch 295/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0178 - acc: 0.9919WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3190/3183 [==============================] - 18s 6ms/sample - loss: 0.0330 - acc: 0.9918\n",
      "\n",
      "Epoch 00295: val_loss did not improve from 0.01906\n",
      "81/81 [==============================] - 22s 271ms/step - loss: 0.0180 - acc: 0.9916 - val_loss: 0.0330 - val_acc: 0.9918\n",
      "Epoch 296/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0164 - acc: 0.9949WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0440 - acc: 0.9894\n",
      "\n",
      "Epoch 00296: val_loss did not improve from 0.01906\n",
      "81/81 [==============================] - 22s 267ms/step - loss: 0.0161 - acc: 0.9950 - val_loss: 0.0440 - val_acc: 0.9894\n",
      "Epoch 297/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0209 - acc: 0.9930WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 21s 7ms/sample - loss: 0.0478 - acc: 0.9887\n",
      "\n",
      "Epoch 00297: val_loss did not improve from 0.01906\n",
      "81/81 [==============================] - 26s 324ms/step - loss: 0.0212 - acc: 0.9926 - val_loss: 0.0478 - val_acc: 0.9887\n",
      "Epoch 298/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0229 - acc: 0.9928WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 21s 7ms/sample - loss: 0.0373 - acc: 0.9872\n",
      "\n",
      "Epoch 00298: val_loss did not improve from 0.01906\n",
      "81/81 [==============================] - 28s 343ms/step - loss: 0.0227 - acc: 0.9929 - val_loss: 0.0373 - val_acc: 0.9872\n",
      "Epoch 299/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0177 - acc: 0.9940WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.0311 - acc: 0.9894\n",
      "\n",
      "Epoch 00299: val_loss did not improve from 0.01906\n",
      "81/81 [==============================] - 23s 283ms/step - loss: 0.0176 - acc: 0.9941 - val_loss: 0.0311 - val_acc: 0.9894\n",
      "Epoch 300/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0207 - acc: 0.9947WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0449 - acc: 0.9875\n",
      "\n",
      "Epoch 00300: val_loss did not improve from 0.01906\n",
      "81/81 [==============================] - 22s 273ms/step - loss: 0.0204 - acc: 0.9947 - val_loss: 0.0449 - val_acc: 0.9875\n",
      "Epoch 301/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0118 - acc: 0.9969WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 22s 7ms/sample - loss: 0.0334 - acc: 0.9922\n",
      "\n",
      "Epoch 00301: val_loss did not improve from 0.01906\n",
      "81/81 [==============================] - 26s 321ms/step - loss: 0.0117 - acc: 0.9969 - val_loss: 0.0334 - val_acc: 0.9922\n",
      "Epoch 302/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0157 - acc: 0.9969WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 20s 6ms/sample - loss: 0.0417 - acc: 0.9812\n",
      "\n",
      "Epoch 00302: val_loss did not improve from 0.01906\n",
      "81/81 [==============================] - 25s 307ms/step - loss: 0.0155 - acc: 0.9969 - val_loss: 0.0417 - val_acc: 0.9812\n",
      "Epoch 303/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0120 - acc: 0.9969WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0444 - acc: 0.9922\n",
      "\n",
      "Epoch 00303: val_loss did not improve from 0.01906\n",
      "81/81 [==============================] - 24s 295ms/step - loss: 0.0126 - acc: 0.9966 - val_loss: 0.0444 - val_acc: 0.9922\n",
      "Epoch 304/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0151 - acc: 0.9959WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0322 - acc: 0.9900\n",
      "\n",
      "Epoch 00304: val_loss did not improve from 0.01906\n",
      "81/81 [==============================] - 21s 260ms/step - loss: 0.0150 - acc: 0.9960 - val_loss: 0.0322 - val_acc: 0.9900\n",
      "Epoch 305/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0185 - acc: 0.9947WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.0396 - acc: 0.9900\n",
      "\n",
      "Epoch 00305: val_loss did not improve from 0.01906\n",
      "81/81 [==============================] - 22s 274ms/step - loss: 0.0183 - acc: 0.9947 - val_loss: 0.0396 - val_acc: 0.9900\n",
      "Epoch 306/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0227 - acc: 0.9924WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0410 - acc: 0.9900\n",
      "\n",
      "Epoch 00306: val_loss did not improve from 0.01906\n",
      "81/81 [==============================] - 22s 272ms/step - loss: 0.0223 - acc: 0.9926 - val_loss: 0.0410 - val_acc: 0.9900\n",
      "Epoch 307/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0102 - acc: 0.9975WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.0412 - acc: 0.9919\n",
      "\n",
      "Epoch 00307: val_loss did not improve from 0.01906\n",
      "81/81 [==============================] - 21s 265ms/step - loss: 0.0100 - acc: 0.9975 - val_loss: 0.0412 - val_acc: 0.9919\n",
      "Epoch 308/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0153 - acc: 0.9962WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0331 - acc: 0.9894\n",
      "\n",
      "Epoch 00308: val_loss did not improve from 0.01906\n",
      "81/81 [==============================] - 25s 305ms/step - loss: 0.0154 - acc: 0.9960 - val_loss: 0.0331 - val_acc: 0.9894\n",
      "Epoch 309/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0198 - acc: 0.9940WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0206 - acc: 0.9897\n",
      "\n",
      "Epoch 00309: val_loss did not improve from 0.01906\n",
      "81/81 [==============================] - 23s 285ms/step - loss: 0.0196 - acc: 0.9941 - val_loss: 0.0206 - val_acc: 0.9897\n",
      "Epoch 310/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0153 - acc: 0.9946WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0282 - acc: 0.9916\n",
      "\n",
      "Epoch 00310: val_loss did not improve from 0.01906\n",
      "81/81 [==============================] - 21s 262ms/step - loss: 0.0150 - acc: 0.9947 - val_loss: 0.0282 - val_acc: 0.9916\n",
      "Epoch 311/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0275 - acc: 0.9901WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0347 - acc: 0.9906\n",
      "\n",
      "Epoch 00311: val_loss did not improve from 0.01906\n",
      "81/81 [==============================] - 22s 270ms/step - loss: 0.0281 - acc: 0.9901 - val_loss: 0.0347 - val_acc: 0.9906\n",
      "Epoch 312/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0108 - acc: 0.9972WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 5ms/sample - loss: 0.0298 - acc: 0.9897\n",
      "\n",
      "Epoch 00312: val_loss did not improve from 0.01906\n",
      "81/81 [==============================] - 23s 290ms/step - loss: 0.0107 - acc: 0.9972 - val_loss: 0.0298 - val_acc: 0.9897\n",
      "Epoch 313/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0177 - acc: 0.9950WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 22s 7ms/sample - loss: 0.0286 - acc: 0.9925\n",
      "\n",
      "Epoch 00313: val_loss did not improve from 0.01906\n",
      "81/81 [==============================] - 27s 335ms/step - loss: 0.0175 - acc: 0.9950 - val_loss: 0.0286 - val_acc: 0.9925\n",
      "Epoch 314/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0177 - acc: 0.9959WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0298 - acc: 0.9872\n",
      "\n",
      "Epoch 00314: val_loss did not improve from 0.01906\n",
      "81/81 [==============================] - 22s 273ms/step - loss: 0.0175 - acc: 0.9960 - val_loss: 0.0298 - val_acc: 0.9872\n",
      "Epoch 315/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0143 - acc: 0.9952WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0287 - acc: 0.9925\n",
      "\n",
      "Epoch 00315: val_loss did not improve from 0.01906\n",
      "81/81 [==============================] - 23s 280ms/step - loss: 0.0143 - acc: 0.9950 - val_loss: 0.0287 - val_acc: 0.9925\n",
      "Epoch 316/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0140 - acc: 0.9965WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0351 - acc: 0.9862\n",
      "\n",
      "Epoch 00316: val_loss did not improve from 0.01906\n",
      "81/81 [==============================] - 24s 298ms/step - loss: 0.0137 - acc: 0.9966 - val_loss: 0.0351 - val_acc: 0.9862\n",
      "Epoch 317/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0135 - acc: 0.9962WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.0278 - acc: 0.9894\n",
      "\n",
      "Epoch 00317: val_loss did not improve from 0.01906\n",
      "81/81 [==============================] - 22s 275ms/step - loss: 0.0135 - acc: 0.9960 - val_loss: 0.0278 - val_acc: 0.9894\n",
      "Epoch 318/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0125 - acc: 0.9962WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.0323 - acc: 0.9900\n",
      "\n",
      "Epoch 00318: val_loss did not improve from 0.01906\n",
      "81/81 [==============================] - 22s 270ms/step - loss: 0.0124 - acc: 0.9963 - val_loss: 0.0323 - val_acc: 0.9900\n",
      "Epoch 319/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0189 - acc: 0.9928WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.0299 - acc: 0.9887\n",
      "\n",
      "Epoch 00319: val_loss did not improve from 0.01906\n",
      "81/81 [==============================] - 23s 289ms/step - loss: 0.0186 - acc: 0.9929 - val_loss: 0.0299 - val_acc: 0.9887\n",
      "Epoch 320/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0075 - acc: 0.9984WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.0268 - acc: 0.9875\n",
      "\n",
      "Epoch 00320: val_loss did not improve from 0.01906\n",
      "81/81 [==============================] - 21s 265ms/step - loss: 0.0074 - acc: 0.9984 - val_loss: 0.0268 - val_acc: 0.9875\n",
      "Epoch 321/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0134 - acc: 0.9978WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0424 - acc: 0.9847\n",
      "\n",
      "Epoch 00321: val_loss did not improve from 0.01906\n",
      "81/81 [==============================] - 22s 278ms/step - loss: 0.0133 - acc: 0.9978 - val_loss: 0.0424 - val_acc: 0.9847\n",
      "Epoch 322/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/81 [============================>.] - ETA: 0s - loss: 0.0153 - acc: 0.9952WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0247 - acc: 0.9897\n",
      "\n",
      "Epoch 00322: val_loss did not improve from 0.01906\n",
      "81/81 [==============================] - 23s 279ms/step - loss: 0.0167 - acc: 0.9944 - val_loss: 0.0247 - val_acc: 0.9897\n",
      "Epoch 323/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0109 - acc: 0.9956WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 15s 5ms/sample - loss: 0.0431 - acc: 0.9900\n",
      "\n",
      "Epoch 00323: val_loss did not improve from 0.01906\n",
      "81/81 [==============================] - 22s 276ms/step - loss: 0.0107 - acc: 0.9957 - val_loss: 0.0431 - val_acc: 0.9900\n",
      "Epoch 324/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0189 - acc: 0.9959WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 21s 6ms/sample - loss: 0.0407 - acc: 0.9897\n",
      "\n",
      "Epoch 00324: val_loss did not improve from 0.01906\n",
      "81/81 [==============================] - 25s 303ms/step - loss: 0.0187 - acc: 0.9960 - val_loss: 0.0407 - val_acc: 0.9897\n",
      "Epoch 325/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0117 - acc: 0.9972WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.0304 - acc: 0.9875\n",
      "\n",
      "Epoch 00325: val_loss did not improve from 0.01906\n",
      "81/81 [==============================] - 22s 272ms/step - loss: 0.0119 - acc: 0.9969 - val_loss: 0.0304 - val_acc: 0.9875\n",
      "Epoch 326/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0169 - acc: 0.9946WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 22s 7ms/sample - loss: 0.0468 - acc: 0.9875\n",
      "\n",
      "Epoch 00326: val_loss did not improve from 0.01906\n",
      "81/81 [==============================] - 26s 327ms/step - loss: 0.0169 - acc: 0.9944 - val_loss: 0.0468 - val_acc: 0.9875\n",
      "Epoch 327/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0117 - acc: 0.9971WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.0437 - acc: 0.9844\n",
      "\n",
      "Epoch 00327: val_loss did not improve from 0.01906\n",
      "81/81 [==============================] - 23s 278ms/step - loss: 0.0120 - acc: 0.9969 - val_loss: 0.0437 - val_acc: 0.9844\n",
      "Epoch 328/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0077 - acc: 0.9984WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 15s 5ms/sample - loss: 0.0429 - acc: 0.9869\n",
      "\n",
      "Epoch 00328: val_loss did not improve from 0.01906\n",
      "81/81 [==============================] - 22s 275ms/step - loss: 0.0079 - acc: 0.9981 - val_loss: 0.0429 - val_acc: 0.9869\n",
      "Epoch 329/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0134 - acc: 0.9959WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.0251 - acc: 0.9875\n",
      "\n",
      "Epoch 00329: val_loss did not improve from 0.01906\n",
      "81/81 [==============================] - 22s 272ms/step - loss: 0.0135 - acc: 0.9957 - val_loss: 0.0251 - val_acc: 0.9875\n",
      "Epoch 330/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0156 - acc: 0.9962WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 21s 6ms/sample - loss: 0.0380 - acc: 0.9884s may du\n",
      "\n",
      "Epoch 00330: val_loss did not improve from 0.01906\n",
      "81/81 [==============================] - 26s 327ms/step - loss: 0.0160 - acc: 0.9960 - val_loss: 0.0380 - val_acc: 0.9884\n",
      "Epoch 331/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0165 - acc: 0.9965WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.0274 - acc: 0.9922\n",
      "\n",
      "Epoch 00331: val_loss did not improve from 0.01906\n",
      "81/81 [==============================] - 22s 269ms/step - loss: 0.0171 - acc: 0.9963 - val_loss: 0.0274 - val_acc: 0.9922\n",
      "Epoch 332/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0101 - acc: 0.9975WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0387 - acc: 0.9947\n",
      "\n",
      "Epoch 00332: val_loss did not improve from 0.01906\n",
      "81/81 [==============================] - 22s 267ms/step - loss: 0.0100 - acc: 0.9975 - val_loss: 0.0387 - val_acc: 0.9947\n",
      "Epoch 333/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0184 - acc: 0.9953WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0284 - acc: 0.9950\n",
      "\n",
      "Epoch 00333: val_loss did not improve from 0.01906\n",
      "81/81 [==============================] - 24s 301ms/step - loss: 0.0182 - acc: 0.9953 - val_loss: 0.0284 - val_acc: 0.9950\n",
      "Epoch 334/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0136 - acc: 0.9975WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0303 - acc: 0.9856\n",
      "\n",
      "Epoch 00334: val_loss did not improve from 0.01906\n",
      "81/81 [==============================] - 23s 287ms/step - loss: 0.0135 - acc: 0.9975 - val_loss: 0.0303 - val_acc: 0.9856\n",
      "Epoch 335/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0106 - acc: 0.9975WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 13s 4ms/sample - loss: 0.0574 - acc: 0.9950\n",
      "\n",
      "Epoch 00335: val_loss did not improve from 0.01906\n",
      "81/81 [==============================] - 24s 293ms/step - loss: 0.0105 - acc: 0.9975 - val_loss: 0.0574 - val_acc: 0.9950\n",
      "Epoch 336/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0178 - acc: 0.9937WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0293 - acc: 0.9900\n",
      "\n",
      "Epoch 00336: val_loss did not improve from 0.01906\n",
      "81/81 [==============================] - 21s 265ms/step - loss: 0.0175 - acc: 0.9938 - val_loss: 0.0293 - val_acc: 0.9900\n",
      "Epoch 337/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0223 - acc: 0.9918WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3200/3183 [==============================] - 14s 4ms/sample - loss: 0.0356 - acc: 0.9875\n",
      "\n",
      "Epoch 00337: val_loss did not improve from 0.01906\n",
      "81/81 [==============================] - 20s 246ms/step - loss: 0.0222 - acc: 0.9919 - val_loss: 0.0356 - val_acc: 0.9875\n",
      "Epoch 338/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0139 - acc: 0.9956WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 22s 7ms/sample - loss: 0.1103 - acc: 0.9663s may dup\n",
      "\n",
      "Epoch 00338: val_loss did not improve from 0.01906\n",
      "81/81 [==============================] - 26s 319ms/step - loss: 0.0145 - acc: 0.9953 - val_loss: 0.1103 - val_acc: 0.9663\n",
      "Epoch 339/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0149 - acc: 0.9953WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0290 - acc: 0.9869\n",
      "\n",
      "Epoch 00339: val_loss did not improve from 0.01906\n",
      "81/81 [==============================] - 24s 300ms/step - loss: 0.0147 - acc: 0.9953 - val_loss: 0.0290 - val_acc: 0.9869\n",
      "Epoch 340/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0115 - acc: 0.9969WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0327 - acc: 0.9937\n",
      "\n",
      "Epoch 00340: val_loss did not improve from 0.01906\n",
      "81/81 [==============================] - 22s 276ms/step - loss: 0.0115 - acc: 0.9969 - val_loss: 0.0327 - val_acc: 0.9937\n",
      "Epoch 341/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0119 - acc: 0.9978WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 14s 4ms/sample - loss: 0.0167 - acc: 0.9919\n",
      "\n",
      "Epoch 00341: val_loss improved from 0.01906 to 0.01669, saving model to model/checkpoint/vis_imagenet_6_class_augmentation_2D_CNN_custom_ch_32_DO_075_DO_4_conv_checkpoint/341-0.0167.hdf5\n",
      "81/81 [==============================] - 20s 247ms/step - loss: 0.0118 - acc: 0.9978 - val_loss: 0.0167 - val_acc: 0.9919\n",
      "Epoch 342/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0106 - acc: 0.9972WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0423 - acc: 0.9950\n",
      "\n",
      "Epoch 00342: val_loss did not improve from 0.01669\n",
      "81/81 [==============================] - 22s 274ms/step - loss: 0.0105 - acc: 0.9972 - val_loss: 0.0423 - val_acc: 0.9950\n",
      "Epoch 343/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0240 - acc: 0.9917WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0364 - acc: 0.9947\n",
      "\n",
      "Epoch 00343: val_loss did not improve from 0.01669\n",
      "81/81 [==============================] - 22s 268ms/step - loss: 0.0235 - acc: 0.9919 - val_loss: 0.0364 - val_acc: 0.9947\n",
      "Epoch 344/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0143 - acc: 0.9981WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0298 - acc: 0.9859\n",
      "\n",
      "Epoch 00344: val_loss did not improve from 0.01669\n",
      "81/81 [==============================] - 23s 287ms/step - loss: 0.0140 - acc: 0.9981 - val_loss: 0.0298 - val_acc: 0.9859\n",
      "Epoch 345/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0145 - acc: 0.9943WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 21s 7ms/sample - loss: 0.0369 - acc: 0.9919\n",
      "\n",
      "Epoch 00345: val_loss did not improve from 0.01669\n",
      "81/81 [==============================] - 29s 352ms/step - loss: 0.0144 - acc: 0.9944 - val_loss: 0.0369 - val_acc: 0.9919\n",
      "Epoch 346/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0115 - acc: 0.9959WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0344 - acc: 0.9950\n",
      "\n",
      "Epoch 00346: val_loss did not improve from 0.01669\n",
      "81/81 [==============================] - 22s 269ms/step - loss: 0.0119 - acc: 0.9957 - val_loss: 0.0344 - val_acc: 0.9950\n",
      "Epoch 347/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0131 - acc: 0.9953WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.0324 - acc: 0.9944\n",
      "\n",
      "Epoch 00347: val_loss did not improve from 0.01669\n",
      "81/81 [==============================] - 22s 271ms/step - loss: 0.0129 - acc: 0.9953 - val_loss: 0.0324 - val_acc: 0.9944\n",
      "Epoch 348/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0156 - acc: 0.9943WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0428 - acc: 0.9891\n",
      "\n",
      "Epoch 00348: val_loss did not improve from 0.01669\n",
      "81/81 [==============================] - 22s 277ms/step - loss: 0.0159 - acc: 0.9941 - val_loss: 0.0428 - val_acc: 0.9891\n",
      "Epoch 349/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0180 - acc: 0.9931WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 5ms/sample - loss: 0.0227 - acc: 0.9875\n",
      "\n",
      "Epoch 00349: val_loss did not improve from 0.01669\n",
      "81/81 [==============================] - 27s 330ms/step - loss: 0.0178 - acc: 0.9932 - val_loss: 0.0227 - val_acc: 0.9875\n",
      "Epoch 350/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0160 - acc: 0.9949WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 13s 4ms/sample - loss: 0.0360 - acc: 0.9831\n",
      "\n",
      "Epoch 00350: val_loss did not improve from 0.01669\n",
      "81/81 [==============================] - 22s 275ms/step - loss: 0.0159 - acc: 0.9947 - val_loss: 0.0360 - val_acc: 0.9831\n",
      "Epoch 351/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0164 - acc: 0.9959WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0248 - acc: 0.9947\n",
      "\n",
      "Epoch 00351: val_loss did not improve from 0.01669\n",
      "81/81 [==============================] - 22s 275ms/step - loss: 0.0161 - acc: 0.9960 - val_loss: 0.0248 - val_acc: 0.9947\n",
      "Epoch 352/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0135 - acc: 0.9975WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0228 - acc: 0.9919\n",
      "\n",
      "Epoch 00352: val_loss did not improve from 0.01669\n",
      "81/81 [==============================] - 26s 318ms/step - loss: 0.0133 - acc: 0.9975 - val_loss: 0.0228 - val_acc: 0.9919\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 353/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0115 - acc: 0.9965WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0226 - acc: 0.9950\n",
      "\n",
      "Epoch 00353: val_loss did not improve from 0.01669\n",
      "81/81 [==============================] - 24s 300ms/step - loss: 0.0120 - acc: 0.9960 - val_loss: 0.0226 - val_acc: 0.9950\n",
      "Epoch 354/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0113 - acc: 0.9959WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0211 - acc: 0.9950\n",
      "\n",
      "Epoch 00354: val_loss did not improve from 0.01669\n",
      "81/81 [==============================] - 22s 269ms/step - loss: 0.0121 - acc: 0.9957 - val_loss: 0.0211 - val_acc: 0.9950\n",
      "Epoch 355/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0129 - acc: 0.9949WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 21s 7ms/sample - loss: 0.0154 - acc: 0.9944\n",
      "\n",
      "Epoch 00355: val_loss improved from 0.01669 to 0.01543, saving model to model/checkpoint/vis_imagenet_6_class_augmentation_2D_CNN_custom_ch_32_DO_075_DO_4_conv_checkpoint/355-0.0154.hdf5\n",
      "81/81 [==============================] - 25s 312ms/step - loss: 0.0127 - acc: 0.9950 - val_loss: 0.0154 - val_acc: 0.9944\n",
      "Epoch 356/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0154 - acc: 0.9946WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0259 - acc: 0.9950\n",
      "\n",
      "Epoch 00356: val_loss did not improve from 0.01543\n",
      "81/81 [==============================] - 22s 271ms/step - loss: 0.0150 - acc: 0.9947 - val_loss: 0.0259 - val_acc: 0.9950\n",
      "Epoch 357/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0142 - acc: 0.9965WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.0356 - acc: 0.9900\n",
      "\n",
      "Epoch 00357: val_loss did not improve from 0.01543\n",
      "81/81 [==============================] - 22s 266ms/step - loss: 0.0140 - acc: 0.9966 - val_loss: 0.0356 - val_acc: 0.9900\n",
      "Epoch 358/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0172 - acc: 0.9946WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0362 - acc: 0.9947\n",
      "\n",
      "Epoch 00358: val_loss did not improve from 0.01543\n",
      "81/81 [==============================] - 22s 267ms/step - loss: 0.0170 - acc: 0.9947 - val_loss: 0.0362 - val_acc: 0.9947\n",
      "Epoch 359/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0129 - acc: 0.9965WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 5ms/sample - loss: 0.0197 - acc: 0.9925\n",
      "\n",
      "Epoch 00359: val_loss did not improve from 0.01543\n",
      "81/81 [==============================] - 22s 270ms/step - loss: 0.0126 - acc: 0.9966 - val_loss: 0.0197 - val_acc: 0.9925\n",
      "Epoch 360/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0169 - acc: 0.9943WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 15s 5ms/sample - loss: 0.0134 - acc: 0.9950\n",
      "\n",
      "Epoch 00360: val_loss improved from 0.01543 to 0.01340, saving model to model/checkpoint/vis_imagenet_6_class_augmentation_2D_CNN_custom_ch_32_DO_075_DO_4_conv_checkpoint/360-0.0134.hdf5\n",
      "81/81 [==============================] - 21s 265ms/step - loss: 0.0165 - acc: 0.9944 - val_loss: 0.0134 - val_acc: 0.9950\n",
      "Epoch 361/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0094 - acc: 0.9975WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0227 - acc: 0.9950\n",
      "\n",
      "Epoch 00361: val_loss did not improve from 0.01340\n",
      "81/81 [==============================] - 22s 266ms/step - loss: 0.0093 - acc: 0.9975 - val_loss: 0.0227 - val_acc: 0.9950\n",
      "Epoch 362/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0098 - acc: 0.9962WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.0376 - acc: 0.9950\n",
      "\n",
      "Epoch 00362: val_loss did not improve from 0.01340\n",
      "81/81 [==============================] - 21s 260ms/step - loss: 0.0098 - acc: 0.9963 - val_loss: 0.0376 - val_acc: 0.9950\n",
      "Epoch 363/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0126 - acc: 0.9968WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0291 - acc: 0.9894\n",
      "\n",
      "Epoch 00363: val_loss did not improve from 0.01340\n",
      "81/81 [==============================] - 22s 272ms/step - loss: 0.0125 - acc: 0.9969 - val_loss: 0.0291 - val_acc: 0.9894\n",
      "Epoch 364/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0075 - acc: 0.9990WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0275 - acc: 0.9944\n",
      "\n",
      "Epoch 00364: val_loss did not improve from 0.01340\n",
      "81/81 [==============================] - 22s 277ms/step - loss: 0.0075 - acc: 0.9991 - val_loss: 0.0275 - val_acc: 0.9944\n",
      "Epoch 365/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0078 - acc: 0.9971WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 15s 5ms/sample - loss: 0.0284 - acc: 0.9950\n",
      "\n",
      "Epoch 00365: val_loss did not improve from 0.01340\n",
      "81/81 [==============================] - 21s 260ms/step - loss: 0.0077 - acc: 0.9972 - val_loss: 0.0284 - val_acc: 0.9950\n",
      "Epoch 366/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0201 - acc: 0.9956WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.0187 - acc: 0.9950\n",
      "\n",
      "Epoch 00366: val_loss did not improve from 0.01340\n",
      "81/81 [==============================] - 22s 267ms/step - loss: 0.0199 - acc: 0.9957 - val_loss: 0.0187 - val_acc: 0.9950\n",
      "Epoch 367/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0109 - acc: 0.9972WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0126 - acc: 0.9950\n",
      "\n",
      "Epoch 00367: val_loss improved from 0.01340 to 0.01256, saving model to model/checkpoint/vis_imagenet_6_class_augmentation_2D_CNN_custom_ch_32_DO_075_DO_4_conv_checkpoint/367-0.0126.hdf5\n",
      "81/81 [==============================] - 22s 266ms/step - loss: 0.0109 - acc: 0.9972 - val_loss: 0.0126 - val_acc: 0.9950\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 368/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0074 - acc: 0.9978WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0307 - acc: 0.9925\n",
      "\n",
      "Epoch 00368: val_loss did not improve from 0.01256\n",
      "81/81 [==============================] - 23s 282ms/step - loss: 0.0074 - acc: 0.9978 - val_loss: 0.0307 - val_acc: 0.9925\n",
      "Epoch 369/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0077 - acc: 0.9978WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0401 - acc: 0.9875\n",
      "\n",
      "Epoch 00369: val_loss did not improve from 0.01256\n",
      "81/81 [==============================] - 23s 278ms/step - loss: 0.0076 - acc: 0.9978 - val_loss: 0.0401 - val_acc: 0.9875\n",
      "Epoch 370/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0093 - acc: 0.9981WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0327 - acc: 0.9925\n",
      "\n",
      "Epoch 00370: val_loss did not improve from 0.01256\n",
      "81/81 [==============================] - 24s 292ms/step - loss: 0.0098 - acc: 0.9978 - val_loss: 0.0327 - val_acc: 0.9925\n",
      "Epoch 371/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0097 - acc: 0.9975WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.0184 - acc: 0.9925\n",
      "\n",
      "Epoch 00371: val_loss did not improve from 0.01256\n",
      "81/81 [==============================] - 23s 286ms/step - loss: 0.0096 - acc: 0.9975 - val_loss: 0.0184 - val_acc: 0.9925\n",
      "Epoch 372/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0056 - acc: 0.9978WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0268 - acc: 0.9950\n",
      "\n",
      "Epoch 00372: val_loss did not improve from 0.01256\n",
      "81/81 [==============================] - 22s 268ms/step - loss: 0.0055 - acc: 0.9978 - val_loss: 0.0268 - val_acc: 0.9950\n",
      "Epoch 373/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0102 - acc: 0.9972WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0249 - acc: 0.9869\n",
      "\n",
      "Epoch 00373: val_loss did not improve from 0.01256\n",
      "81/81 [==============================] - 24s 292ms/step - loss: 0.0102 - acc: 0.9972 - val_loss: 0.0249 - val_acc: 0.9869\n",
      "Epoch 374/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0093 - acc: 0.9978WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 21s 6ms/sample - loss: 0.0479 - acc: 0.9944\n",
      "\n",
      "Epoch 00374: val_loss did not improve from 0.01256\n",
      "81/81 [==============================] - 25s 304ms/step - loss: 0.0095 - acc: 0.9978 - val_loss: 0.0479 - val_acc: 0.9944\n",
      "Epoch 375/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0096 - acc: 0.9962WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0308 - acc: 0.9922\n",
      "\n",
      "Epoch 00375: val_loss did not improve from 0.01256\n",
      "81/81 [==============================] - 22s 273ms/step - loss: 0.0095 - acc: 0.9963 - val_loss: 0.0308 - val_acc: 0.9922\n",
      "Epoch 376/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0100 - acc: 0.9971WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0301 - acc: 0.9875\n",
      "\n",
      "Epoch 00376: val_loss did not improve from 0.01256\n",
      "81/81 [==============================] - 26s 316ms/step - loss: 0.0098 - acc: 0.9972 - val_loss: 0.0301 - val_acc: 0.9875\n",
      "Epoch 377/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0085 - acc: 0.9981WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.0117 - acc: 0.9925\n",
      "\n",
      "Epoch 00377: val_loss improved from 0.01256 to 0.01170, saving model to model/checkpoint/vis_imagenet_6_class_augmentation_2D_CNN_custom_ch_32_DO_075_DO_4_conv_checkpoint/377-0.0117.hdf5\n",
      "81/81 [==============================] - 22s 276ms/step - loss: 0.0084 - acc: 0.9981 - val_loss: 0.0117 - val_acc: 0.9925\n",
      "Epoch 378/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0140 - acc: 0.9965WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 5ms/sample - loss: 0.0236 - acc: 0.9925\n",
      "\n",
      "Epoch 00378: val_loss did not improve from 0.01170\n",
      "81/81 [==============================] - 23s 281ms/step - loss: 0.0138 - acc: 0.9966 - val_loss: 0.0236 - val_acc: 0.9925\n",
      "Epoch 379/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0137 - acc: 0.9965WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.0181 - acc: 0.9950\n",
      "\n",
      "Epoch 00379: val_loss did not improve from 0.01170\n",
      "81/81 [==============================] - 21s 261ms/step - loss: 0.0135 - acc: 0.9966 - val_loss: 0.0181 - val_acc: 0.9950\n",
      "Epoch 380/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0074 - acc: 0.9984WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 26s 8ms/sample - loss: 0.0261 - acc: 0.9919\n",
      "\n",
      "Epoch 00380: val_loss did not improve from 0.01170\n",
      "81/81 [==============================] - 33s 406ms/step - loss: 0.0075 - acc: 0.9984 - val_loss: 0.0261 - val_acc: 0.9919\n",
      "Epoch 381/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0116 - acc: 0.9962WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0330 - acc: 0.9950\n",
      "\n",
      "Epoch 00381: val_loss did not improve from 0.01170\n",
      "81/81 [==============================] - 22s 275ms/step - loss: 0.0123 - acc: 0.9960 - val_loss: 0.0330 - val_acc: 0.9950\n",
      "Epoch 382/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0142 - acc: 0.9959WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.0332 - acc: 0.9897\n",
      "\n",
      "Epoch 00382: val_loss did not improve from 0.01170\n",
      "81/81 [==============================] - 22s 272ms/step - loss: 0.0141 - acc: 0.9960 - val_loss: 0.0332 - val_acc: 0.9897\n",
      "Epoch 383/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0066 - acc: 0.9981WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0331 - acc: 0.9897\n",
      "\n",
      "Epoch 00383: val_loss did not improve from 0.01170\n",
      "81/81 [==============================] - 22s 275ms/step - loss: 0.0065 - acc: 0.9981 - val_loss: 0.0331 - val_acc: 0.9897\n",
      "Epoch 384/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0127 - acc: 0.9956WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0245 - acc: 0.9950\n",
      "\n",
      "Epoch 00384: val_loss did not improve from 0.01170\n",
      "81/81 [==============================] - 21s 264ms/step - loss: 0.0125 - acc: 0.9957 - val_loss: 0.0245 - val_acc: 0.9950\n",
      "Epoch 385/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0215 - acc: 0.9925WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 20s 6ms/sample - loss: 0.0324 - acc: 0.9897\n",
      "\n",
      "Epoch 00385: val_loss did not improve from 0.01170\n",
      "81/81 [==============================] - 24s 294ms/step - loss: 0.0213 - acc: 0.9926 - val_loss: 0.0324 - val_acc: 0.9897\n",
      "Epoch 386/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0091 - acc: 0.9972WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3190/3183 [==============================] - 18s 6ms/sample - loss: 0.0331 - acc: 0.9925\n",
      "\n",
      "Epoch 00386: val_loss did not improve from 0.01170\n",
      "81/81 [==============================] - 22s 275ms/step - loss: 0.0090 - acc: 0.9972 - val_loss: 0.0331 - val_acc: 0.9925\n",
      "Epoch 387/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0080 - acc: 0.9965WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.0366 - acc: 0.9922\n",
      "\n",
      "Epoch 00387: val_loss did not improve from 0.01170\n",
      "81/81 [==============================] - 22s 269ms/step - loss: 0.0079 - acc: 0.9966 - val_loss: 0.0366 - val_acc: 0.9922\n",
      "Epoch 388/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0046 - acc: 0.9981WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0376 - acc: 0.9925\n",
      "\n",
      "Epoch 00388: val_loss did not improve from 0.01170\n",
      "81/81 [==============================] - 22s 275ms/step - loss: 0.0047 - acc: 0.9981 - val_loss: 0.0376 - val_acc: 0.9925\n",
      "Epoch 389/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0101 - acc: 0.9968WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 24s 8ms/sample - loss: 0.0508 - acc: 0.9831\n",
      "\n",
      "Epoch 00389: val_loss did not improve from 0.01170\n",
      "81/81 [==============================] - 28s 346ms/step - loss: 0.0099 - acc: 0.9969 - val_loss: 0.0508 - val_acc: 0.9831\n",
      "Epoch 390/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0252 - acc: 0.9915WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0425 - acc: 0.9850\n",
      "\n",
      "Epoch 00390: val_loss did not improve from 0.01170\n",
      "81/81 [==============================] - 24s 295ms/step - loss: 0.0272 - acc: 0.9910 - val_loss: 0.0425 - val_acc: 0.9850\n",
      "Epoch 391/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0159 - acc: 0.9928WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 23s 7ms/sample - loss: 0.0287 - acc: 0.9916\n",
      "\n",
      "Epoch 00391: val_loss did not improve from 0.01170\n",
      "81/81 [==============================] - 30s 371ms/step - loss: 0.0158 - acc: 0.9929 - val_loss: 0.0287 - val_acc: 0.9916\n",
      "Epoch 392/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0173 - acc: 0.9936WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 20s 6ms/sample - loss: 0.0316 - acc: 0.9922\n",
      "\n",
      "Epoch 00392: val_loss did not improve from 0.01170\n",
      "81/81 [==============================] - 25s 312ms/step - loss: 0.0169 - acc: 0.9938 - val_loss: 0.0316 - val_acc: 0.9922\n",
      "Epoch 393/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0134 - acc: 0.9959WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0411 - acc: 0.9919\n",
      "\n",
      "Epoch 00393: val_loss did not improve from 0.01170\n",
      "81/81 [==============================] - 23s 284ms/step - loss: 0.0133 - acc: 0.9960 - val_loss: 0.0411 - val_acc: 0.9919\n",
      "Epoch 394/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0153 - acc: 0.9956WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 23s 7ms/sample - loss: 0.0353 - acc: 0.9875\n",
      "\n",
      "Epoch 00394: val_loss did not improve from 0.01170\n",
      "81/81 [==============================] - 38s 463ms/step - loss: 0.0151 - acc: 0.9957 - val_loss: 0.0353 - val_acc: 0.9875\n",
      "Epoch 395/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0149 - acc: 0.9955WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 24s 7ms/sample - loss: 0.0244 - acc: 0.9944\n",
      "\n",
      "Epoch 00395: val_loss did not improve from 0.01170\n",
      "81/81 [==============================] - 29s 353ms/step - loss: 0.0146 - acc: 0.9957 - val_loss: 0.0244 - val_acc: 0.9944\n",
      "Epoch 396/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0093 - acc: 0.9981WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 23s 7ms/sample - loss: 0.0290 - acc: 0.9922\n",
      "\n",
      "Epoch 00396: val_loss did not improve from 0.01170\n",
      "81/81 [==============================] - 27s 333ms/step - loss: 0.0092 - acc: 0.9981 - val_loss: 0.0290 - val_acc: 0.9922\n",
      "Epoch 397/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0067 - acc: 0.9978WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0226 - acc: 0.9925\n",
      "\n",
      "Epoch 00397: val_loss did not improve from 0.01170\n",
      "81/81 [==============================] - 23s 285ms/step - loss: 0.0068 - acc: 0.9975 - val_loss: 0.0226 - val_acc: 0.9925\n",
      "Epoch 398/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0032 - acc: 0.9994WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 22s 7ms/sample - loss: 0.0299 - acc: 0.9925\n",
      "\n",
      "Epoch 00398: val_loss did not improve from 0.01170\n",
      "81/81 [==============================] - 27s 338ms/step - loss: 0.0031 - acc: 0.9994 - val_loss: 0.0299 - val_acc: 0.9925\n",
      "Epoch 399/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/81 [============================>.] - ETA: 0s - loss: 0.0069 - acc: 0.9981WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 26s 8ms/sample - loss: 0.0349 - acc: 0.9891\n",
      "\n",
      "Epoch 00399: val_loss did not improve from 0.01170\n",
      "81/81 [==============================] - 31s 384ms/step - loss: 0.0070 - acc: 0.9978 - val_loss: 0.0349 - val_acc: 0.9891\n",
      "Epoch 400/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0123 - acc: 0.9968WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0226 - acc: 0.9925\n",
      "\n",
      "Epoch 00400: val_loss did not improve from 0.01170\n",
      "81/81 [==============================] - 23s 290ms/step - loss: 0.0126 - acc: 0.9966 - val_loss: 0.0226 - val_acc: 0.9925\n",
      "Epoch 401/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0046 - acc: 0.9987WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0168 - acc: 0.9950\n",
      "\n",
      "Epoch 00401: val_loss did not improve from 0.01170\n",
      "81/81 [==============================] - 23s 280ms/step - loss: 0.0056 - acc: 0.9984 - val_loss: 0.0168 - val_acc: 0.9950\n",
      "Epoch 402/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0223 - acc: 0.9917WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.0339 - acc: 0.9944\n",
      "\n",
      "Epoch 00402: val_loss did not improve from 0.01170\n",
      "81/81 [==============================] - 23s 279ms/step - loss: 0.0236 - acc: 0.9910 - val_loss: 0.0339 - val_acc: 0.9944\n",
      "Epoch 403/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0129 - acc: 0.9965WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 5ms/sample - loss: 0.0362 - acc: 0.9912\n",
      "\n",
      "Epoch 00403: val_loss did not improve from 0.01170\n",
      "81/81 [==============================] - 22s 275ms/step - loss: 0.0128 - acc: 0.9966 - val_loss: 0.0362 - val_acc: 0.9912\n",
      "Epoch 404/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0095 - acc: 0.9965WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0431 - acc: 0.9872\n",
      "\n",
      "Epoch 00404: val_loss did not improve from 0.01170\n",
      "81/81 [==============================] - 23s 288ms/step - loss: 0.0094 - acc: 0.9966 - val_loss: 0.0431 - val_acc: 0.9872\n",
      "Epoch 405/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0139 - acc: 0.9956WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 24s 7ms/sample - loss: 0.0321 - acc: 0.9950\n",
      "\n",
      "Epoch 00405: val_loss did not improve from 0.01170\n",
      "81/81 [==============================] - 28s 351ms/step - loss: 0.0139 - acc: 0.9957 - val_loss: 0.0321 - val_acc: 0.9950\n",
      "Epoch 406/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0112 - acc: 0.9972WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 5ms/sample - loss: 0.0340 - acc: 0.9950\n",
      "\n",
      "Epoch 00406: val_loss did not improve from 0.01170\n",
      "81/81 [==============================] - 23s 288ms/step - loss: 0.0112 - acc: 0.9972 - val_loss: 0.0340 - val_acc: 0.9950\n",
      "Epoch 407/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0079 - acc: 0.9972WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 20s 6ms/sample - loss: 0.0200 - acc: 0.995011s - loss:\n",
      "\n",
      "Epoch 00407: val_loss did not improve from 0.01170\n",
      "81/81 [==============================] - 24s 296ms/step - loss: 0.0078 - acc: 0.9972 - val_loss: 0.0200 - val_acc: 0.9950\n",
      "Epoch 408/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0062 - acc: 0.9991WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0255 - acc: 0.9950\n",
      "\n",
      "Epoch 00408: val_loss did not improve from 0.01170\n",
      "81/81 [==============================] - 25s 313ms/step - loss: 0.0062 - acc: 0.9991 - val_loss: 0.0255 - val_acc: 0.9950\n",
      "Epoch 409/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0090 - acc: 0.9962WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 14s 4ms/sample - loss: 0.0286 - acc: 0.9866\n",
      "\n",
      "Epoch 00409: val_loss did not improve from 0.01170\n",
      "81/81 [==============================] - 23s 280ms/step - loss: 0.0107 - acc: 0.9953 - val_loss: 0.0286 - val_acc: 0.9866\n",
      "Epoch 410/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0142 - acc: 0.9952WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0319 - acc: 0.9897\n",
      "\n",
      "Epoch 00410: val_loss did not improve from 0.01170\n",
      "81/81 [==============================] - 22s 269ms/step - loss: 0.0140 - acc: 0.9953 - val_loss: 0.0319 - val_acc: 0.9897\n",
      "Epoch 411/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0095 - acc: 0.9975WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 21s 7ms/sample - loss: 0.0485 - acc: 0.9825\n",
      "\n",
      "Epoch 00411: val_loss did not improve from 0.01170\n",
      "81/81 [==============================] - 26s 318ms/step - loss: 0.0093 - acc: 0.9975 - val_loss: 0.0485 - val_acc: 0.9825\n",
      "Epoch 412/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0170 - acc: 0.9972WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 27s 8ms/sample - loss: 0.0320 - acc: 0.9837\n",
      "\n",
      "Epoch 00412: val_loss did not improve from 0.01170\n",
      "81/81 [==============================] - 32s 400ms/step - loss: 0.0177 - acc: 0.9969 - val_loss: 0.0320 - val_acc: 0.9837\n",
      "Epoch 413/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0134 - acc: 0.9955WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 23s 7ms/sample - loss: 0.0391 - acc: 0.9900\n",
      "\n",
      "Epoch 00413: val_loss did not improve from 0.01170\n",
      "81/81 [==============================] - 29s 359ms/step - loss: 0.0134 - acc: 0.9953 - val_loss: 0.0391 - val_acc: 0.9900\n",
      "Epoch 414/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0071 - acc: 0.9972WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3200/3183 [==============================] - 14s 4ms/sample - loss: 0.0447 - acc: 0.9947\n",
      "\n",
      "Epoch 00414: val_loss did not improve from 0.01170\n",
      "81/81 [==============================] - 21s 254ms/step - loss: 0.0070 - acc: 0.9972 - val_loss: 0.0447 - val_acc: 0.9947\n",
      "Epoch 415/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0078 - acc: 0.9975WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 14s 4ms/sample - loss: 0.0337 - acc: 0.9872\n",
      "\n",
      "Epoch 00415: val_loss did not improve from 0.01170\n",
      "81/81 [==============================] - 21s 263ms/step - loss: 0.0077 - acc: 0.9975 - val_loss: 0.0337 - val_acc: 0.9872\n",
      "Epoch 416/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0059 - acc: 0.9987WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0276 - acc: 0.9869\n",
      "\n",
      "Epoch 00416: val_loss did not improve from 0.01170\n",
      "81/81 [==============================] - 22s 273ms/step - loss: 0.0058 - acc: 0.9988 - val_loss: 0.0276 - val_acc: 0.9869\n",
      "Epoch 417/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0090 - acc: 0.9969WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 21s 7ms/sample - loss: 0.0304 - acc: 0.9869\n",
      "\n",
      "Epoch 00417: val_loss did not improve from 0.01170\n",
      "81/81 [==============================] - 25s 307ms/step - loss: 0.0089 - acc: 0.9969 - val_loss: 0.0304 - val_acc: 0.9869\n",
      "Epoch 418/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0105 - acc: 0.9971WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 20s 6ms/sample - loss: 0.0346 - acc: 0.9950\n",
      "\n",
      "Epoch 00418: val_loss did not improve from 0.01170\n",
      "81/81 [==============================] - 27s 330ms/step - loss: 0.0103 - acc: 0.9972 - val_loss: 0.0346 - val_acc: 0.9950\n",
      "Epoch 419/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0091 - acc: 0.9962WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0347 - acc: 0.9950\n",
      "\n",
      "Epoch 00419: val_loss did not improve from 0.01170\n",
      "81/81 [==============================] - 24s 300ms/step - loss: 0.0090 - acc: 0.9963 - val_loss: 0.0347 - val_acc: 0.9950\n",
      "Epoch 420/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0091 - acc: 0.9975WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0460 - acc: 0.9925\n",
      "\n",
      "Epoch 00420: val_loss did not improve from 0.01170\n",
      "81/81 [==============================] - 24s 296ms/step - loss: 0.0096 - acc: 0.9972 - val_loss: 0.0460 - val_acc: 0.9925\n",
      "Epoch 421/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0047 - acc: 0.9987WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0304 - acc: 0.9897\n",
      "\n",
      "Epoch 00421: val_loss did not improve from 0.01170\n",
      "81/81 [==============================] - 26s 325ms/step - loss: 0.0047 - acc: 0.9988 - val_loss: 0.0304 - val_acc: 0.9897\n",
      "Epoch 422/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0118 - acc: 0.9965WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0179 - acc: 0.9925\n",
      "\n",
      "Epoch 00422: val_loss did not improve from 0.01170\n",
      "81/81 [==============================] - 26s 324ms/step - loss: 0.0117 - acc: 0.9966 - val_loss: 0.0179 - val_acc: 0.9925\n",
      "Epoch 423/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0108 - acc: 0.9968WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0083 - acc: 0.9975\n",
      "\n",
      "Epoch 00423: val_loss improved from 0.01170 to 0.00826, saving model to model/checkpoint/vis_imagenet_6_class_augmentation_2D_CNN_custom_ch_32_DO_075_DO_4_conv_checkpoint/423-0.0083.hdf5\n",
      "81/81 [==============================] - 23s 288ms/step - loss: 0.0107 - acc: 0.9969 - val_loss: 0.0083 - val_acc: 0.9975\n",
      "Epoch 424/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0062 - acc: 0.9991WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.0457 - acc: 0.9950\n",
      "\n",
      "Epoch 00424: val_loss did not improve from 0.00826\n",
      "81/81 [==============================] - 22s 275ms/step - loss: 0.0062 - acc: 0.9991 - val_loss: 0.0457 - val_acc: 0.9950\n",
      "Epoch 425/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0102 - acc: 0.9975WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 5ms/sample - loss: 0.0302 - acc: 0.9950\n",
      "\n",
      "Epoch 00425: val_loss did not improve from 0.00826\n",
      "81/81 [==============================] - 22s 267ms/step - loss: 0.0101 - acc: 0.9975 - val_loss: 0.0302 - val_acc: 0.9950\n",
      "Epoch 426/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0026 - acc: 0.9997WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0365 - acc: 0.9947\n",
      "\n",
      "Epoch 00426: val_loss did not improve from 0.00826\n",
      "81/81 [==============================] - 23s 283ms/step - loss: 0.0026 - acc: 0.9997 - val_loss: 0.0365 - val_acc: 0.9947\n",
      "Epoch 427/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0122 - acc: 0.9978WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0363 - acc: 0.9925\n",
      "\n",
      "Epoch 00427: val_loss did not improve from 0.00826\n",
      "81/81 [==============================] - 23s 281ms/step - loss: 0.0122 - acc: 0.9978 - val_loss: 0.0363 - val_acc: 0.9925\n",
      "Epoch 428/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0073 - acc: 0.9971WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 15s 5ms/sample - loss: 0.0304 - acc: 0.9887\n",
      "\n",
      "Epoch 00428: val_loss did not improve from 0.00826\n",
      "81/81 [==============================] - 21s 264ms/step - loss: 0.0071 - acc: 0.9972 - val_loss: 0.0304 - val_acc: 0.9887\n",
      "Epoch 429/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0112 - acc: 0.9971WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.0210 - acc: 0.9944\n",
      "\n",
      "Epoch 00429: val_loss did not improve from 0.00826\n",
      "81/81 [==============================] - 22s 273ms/step - loss: 0.0113 - acc: 0.9969 - val_loss: 0.0210 - val_acc: 0.9944\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 430/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0082 - acc: 0.9975WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0259 - acc: 0.9925\n",
      "\n",
      "Epoch 00430: val_loss did not improve from 0.00826\n",
      "81/81 [==============================] - 22s 269ms/step - loss: 0.0080 - acc: 0.9975 - val_loss: 0.0259 - val_acc: 0.9925\n",
      "Epoch 431/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0084 - acc: 0.9991WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3190/3183 [==============================] - 17s 5ms/sample - loss: 0.0361 - acc: 0.9950\n",
      "\n",
      "Epoch 00431: val_loss did not improve from 0.00826\n",
      "81/81 [==============================] - 21s 264ms/step - loss: 0.0083 - acc: 0.9991 - val_loss: 0.0361 - val_acc: 0.9950\n",
      "Epoch 432/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0126 - acc: 0.9962WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0333 - acc: 0.9866\n",
      "\n",
      "Epoch 00432: val_loss did not improve from 0.00826\n",
      "81/81 [==============================] - 22s 275ms/step - loss: 0.0132 - acc: 0.9957 - val_loss: 0.0333 - val_acc: 0.9866\n",
      "Epoch 433/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0095 - acc: 0.9971WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0256 - acc: 0.9891\n",
      "\n",
      "Epoch 00433: val_loss did not improve from 0.00826\n",
      "81/81 [==============================] - 24s 300ms/step - loss: 0.0093 - acc: 0.9972 - val_loss: 0.0256 - val_acc: 0.9891\n",
      "Epoch 434/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0087 - acc: 0.9968WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0187 - acc: 0.9925\n",
      "\n",
      "Epoch 00434: val_loss did not improve from 0.00826\n",
      "81/81 [==============================] - 24s 301ms/step - loss: 0.0085 - acc: 0.9969 - val_loss: 0.0187 - val_acc: 0.9925\n",
      "Epoch 435/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0057 - acc: 0.9978WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0286 - acc: 0.9947\n",
      "\n",
      "Epoch 00435: val_loss did not improve from 0.00826\n",
      "81/81 [==============================] - 21s 264ms/step - loss: 0.0056 - acc: 0.9978 - val_loss: 0.0286 - val_acc: 0.9947\n",
      "Epoch 436/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0044 - acc: 0.9984WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.0189 - acc: 0.9950\n",
      "\n",
      "Epoch 00436: val_loss did not improve from 0.00826\n",
      "81/81 [==============================] - 22s 275ms/step - loss: 0.0043 - acc: 0.9984 - val_loss: 0.0189 - val_acc: 0.9950\n",
      "Epoch 437/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0076 - acc: 0.9984WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0270 - acc: 0.9950\n",
      "\n",
      "Epoch 00437: val_loss did not improve from 0.00826\n",
      "81/81 [==============================] - 22s 275ms/step - loss: 0.0075 - acc: 0.9984 - val_loss: 0.0270 - val_acc: 0.9950\n",
      "Epoch 438/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0086 - acc: 0.9968WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0305 - acc: 0.9925\n",
      "\n",
      "Epoch 00438: val_loss did not improve from 0.00826\n",
      "81/81 [==============================] - 25s 304ms/step - loss: 0.0084 - acc: 0.9969 - val_loss: 0.0305 - val_acc: 0.9925\n",
      "Epoch 439/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0103 - acc: 0.9965WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0358 - acc: 0.9950\n",
      "\n",
      "Epoch 00439: val_loss did not improve from 0.00826\n",
      "81/81 [==============================] - 23s 289ms/step - loss: 0.0108 - acc: 0.9963 - val_loss: 0.0358 - val_acc: 0.9950\n",
      "Epoch 440/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0136 - acc: 0.9946WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0238 - acc: 0.9944\n",
      "\n",
      "Epoch 00440: val_loss did not improve from 0.00826\n",
      "81/81 [==============================] - 23s 281ms/step - loss: 0.0139 - acc: 0.9944 - val_loss: 0.0238 - val_acc: 0.9944\n",
      "Epoch 441/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0071 - acc: 0.9978WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 5ms/sample - loss: 0.0424 - acc: 0.9894\n",
      "\n",
      "Epoch 00441: val_loss did not improve from 0.00826\n",
      "81/81 [==============================] - 21s 264ms/step - loss: 0.0070 - acc: 0.9978 - val_loss: 0.0424 - val_acc: 0.9894\n",
      "Epoch 442/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0100 - acc: 0.9965WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0280 - acc: 0.9891\n",
      "\n",
      "Epoch 00442: val_loss did not improve from 0.00826\n",
      "81/81 [==============================] - 21s 254ms/step - loss: 0.0104 - acc: 0.9963 - val_loss: 0.0280 - val_acc: 0.9891\n",
      "Epoch 443/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0073 - acc: 0.9978WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0320 - acc: 0.9922\n",
      "\n",
      "Epoch 00443: val_loss did not improve from 0.00826\n",
      "81/81 [==============================] - 25s 306ms/step - loss: 0.0071 - acc: 0.9978 - val_loss: 0.0320 - val_acc: 0.9922\n",
      "Epoch 444/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0087 - acc: 0.9968WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 5ms/sample - loss: 0.0374 - acc: 0.9950\n",
      "\n",
      "Epoch 00444: val_loss did not improve from 0.00826\n",
      "81/81 [==============================] - 21s 265ms/step - loss: 0.0089 - acc: 0.9966 - val_loss: 0.0374 - val_acc: 0.9950\n",
      "Epoch 445/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0065 - acc: 0.9978WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3200/3183 [==============================] - 28s 9ms/sample - loss: 0.0414 - acc: 0.9950\n",
      "\n",
      "Epoch 00445: val_loss did not improve from 0.00826\n",
      "81/81 [==============================] - 32s 391ms/step - loss: 0.0064 - acc: 0.9978 - val_loss: 0.0414 - val_acc: 0.9950\n",
      "Epoch 446/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0105 - acc: 0.9971WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 21s 7ms/sample - loss: 0.0289 - acc: 0.9944\n",
      "\n",
      "Epoch 00446: val_loss did not improve from 0.00826\n",
      "81/81 [==============================] - 26s 322ms/step - loss: 0.0103 - acc: 0.9972 - val_loss: 0.0289 - val_acc: 0.9944\n",
      "Epoch 447/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0107 - acc: 0.9965WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0503 - acc: 0.9891\n",
      "\n",
      "Epoch 00447: val_loss did not improve from 0.00826\n",
      "81/81 [==============================] - 21s 264ms/step - loss: 0.0105 - acc: 0.9966 - val_loss: 0.0503 - val_acc: 0.9891\n",
      "Epoch 448/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0107 - acc: 0.9955WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0244 - acc: 0.9944\n",
      "\n",
      "Epoch 00448: val_loss did not improve from 0.00826\n",
      "81/81 [==============================] - 24s 292ms/step - loss: 0.0106 - acc: 0.9957 - val_loss: 0.0244 - val_acc: 0.9944\n",
      "Epoch 449/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0075 - acc: 0.9975WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0339 - acc: 0.9894\n",
      "\n",
      "Epoch 00449: val_loss did not improve from 0.00826\n",
      "81/81 [==============================] - 23s 286ms/step - loss: 0.0074 - acc: 0.9975 - val_loss: 0.0339 - val_acc: 0.9894\n",
      "Epoch 450/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0108 - acc: 0.9969WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0407 - acc: 0.9941\n",
      "\n",
      "Epoch 00450: val_loss did not improve from 0.00826\n",
      "81/81 [==============================] - 23s 287ms/step - loss: 0.0107 - acc: 0.9969 - val_loss: 0.0407 - val_acc: 0.9941\n",
      "Epoch 451/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0177 - acc: 0.9953WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0264 - acc: 0.9950\n",
      "\n",
      "Epoch 00451: val_loss did not improve from 0.00826\n",
      "81/81 [==============================] - 23s 288ms/step - loss: 0.0175 - acc: 0.9953 - val_loss: 0.0264 - val_acc: 0.9950\n",
      "Epoch 452/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0046 - acc: 0.9987WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0497 - acc: 0.9950\n",
      "\n",
      "Epoch 00452: val_loss did not improve from 0.00826\n",
      "81/81 [==============================] - 25s 303ms/step - loss: 0.0045 - acc: 0.9988 - val_loss: 0.0497 - val_acc: 0.9950\n",
      "Epoch 453/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0099 - acc: 0.9971WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0166 - acc: 0.9925\n",
      "\n",
      "Epoch 00453: val_loss did not improve from 0.00826\n",
      "81/81 [==============================] - 22s 272ms/step - loss: 0.0098 - acc: 0.9972 - val_loss: 0.0166 - val_acc: 0.9925\n",
      "Epoch 454/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0114 - acc: 0.9975WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.0242 - acc: 0.9950\n",
      "\n",
      "Epoch 00454: val_loss did not improve from 0.00826\n",
      "81/81 [==============================] - 22s 276ms/step - loss: 0.0112 - acc: 0.9975 - val_loss: 0.0242 - val_acc: 0.9950\n",
      "Epoch 455/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0147 - acc: 0.9953WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0303 - acc: 0.9900\n",
      "\n",
      "Epoch 00455: val_loss did not improve from 0.00826\n",
      "81/81 [==============================] - 24s 293ms/step - loss: 0.0146 - acc: 0.9953 - val_loss: 0.0303 - val_acc: 0.9900\n",
      "Epoch 456/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0149 - acc: 0.9946WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 20s 6ms/sample - loss: 0.0167 - acc: 0.9919\n",
      "\n",
      "Epoch 00456: val_loss did not improve from 0.00826\n",
      "81/81 [==============================] - 24s 300ms/step - loss: 0.0145 - acc: 0.9947 - val_loss: 0.0167 - val_acc: 0.9919\n",
      "Epoch 457/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0046 - acc: 0.9984WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.0190 - acc: 0.9950\n",
      "\n",
      "Epoch 00457: val_loss did not improve from 0.00826\n",
      "81/81 [==============================] - 23s 281ms/step - loss: 0.0045 - acc: 0.9984 - val_loss: 0.0190 - val_acc: 0.9950\n",
      "Epoch 458/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0098 - acc: 0.9972WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0231 - acc: 0.9925\n",
      "\n",
      "Epoch 00458: val_loss did not improve from 0.00826\n",
      "81/81 [==============================] - 22s 277ms/step - loss: 0.0107 - acc: 0.9969 - val_loss: 0.0231 - val_acc: 0.9925\n",
      "Epoch 459/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0050 - acc: 0.9987WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 21s 7ms/sample - loss: 0.0317 - acc: 0.9925\n",
      "\n",
      "Epoch 00459: val_loss did not improve from 0.00826\n",
      "81/81 [==============================] - 25s 308ms/step - loss: 0.0049 - acc: 0.9988 - val_loss: 0.0317 - val_acc: 0.9925\n",
      "Epoch 460/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0104 - acc: 0.9962WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 27s 8ms/sample - loss: 0.0311 - acc: 0.9925\n",
      "\n",
      "Epoch 00460: val_loss did not improve from 0.00826\n",
      "81/81 [==============================] - 31s 379ms/step - loss: 0.0102 - acc: 0.9963 - val_loss: 0.0311 - val_acc: 0.9925\n",
      "Epoch 461/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/81 [============================>.] - ETA: 0s - loss: 0.0137 - acc: 0.9959WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 25s 8ms/sample - loss: 0.0263 - acc: 0.9912\n",
      "\n",
      "Epoch 00461: val_loss did not improve from 0.00826\n",
      "81/81 [==============================] - 30s 367ms/step - loss: 0.0136 - acc: 0.9960 - val_loss: 0.0263 - val_acc: 0.9912\n",
      "Epoch 462/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0058 - acc: 0.9984WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.0420 - acc: 0.9922\n",
      "\n",
      "Epoch 00462: val_loss did not improve from 0.00826\n",
      "81/81 [==============================] - 22s 274ms/step - loss: 0.0058 - acc: 0.9984 - val_loss: 0.0420 - val_acc: 0.9922\n",
      "Epoch 463/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0050 - acc: 0.9978WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0353 - acc: 0.9925\n",
      "\n",
      "Epoch 00463: val_loss did not improve from 0.00826\n",
      "81/81 [==============================] - 24s 291ms/step - loss: 0.0063 - acc: 0.9972 - val_loss: 0.0353 - val_acc: 0.9925\n",
      "Epoch 464/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0070 - acc: 0.9984WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.0491 - acc: 0.9925\n",
      "\n",
      "Epoch 00464: val_loss did not improve from 0.00826\n",
      "81/81 [==============================] - 24s 295ms/step - loss: 0.0081 - acc: 0.9981 - val_loss: 0.0491 - val_acc: 0.9925\n",
      "Epoch 465/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0169 - acc: 0.9930WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.0325 - acc: 0.9950\n",
      "\n",
      "Epoch 00465: val_loss did not improve from 0.00826\n",
      "81/81 [==============================] - 22s 269ms/step - loss: 0.0165 - acc: 0.9932 - val_loss: 0.0325 - val_acc: 0.9950\n",
      "Epoch 466/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0027 - acc: 0.9987WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 21s 6ms/sample - loss: 0.0308 - acc: 0.9919\n",
      "\n",
      "Epoch 00466: val_loss did not improve from 0.00826\n",
      "81/81 [==============================] - 25s 305ms/step - loss: 0.0026 - acc: 0.9988 - val_loss: 0.0308 - val_acc: 0.9919\n",
      "Epoch 467/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0115 - acc: 0.9971WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 5ms/sample - loss: 0.0313 - acc: 0.99251s - loss: 0.0334 - acc: 0.9\n",
      "\n",
      "Epoch 00467: val_loss did not improve from 0.00826\n",
      "81/81 [==============================] - 22s 266ms/step - loss: 0.0115 - acc: 0.9972 - val_loss: 0.0313 - val_acc: 0.9925\n",
      "Epoch 468/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0045 - acc: 0.9987WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0355 - acc: 0.9950\n",
      "\n",
      "Epoch 00468: val_loss did not improve from 0.00826\n",
      "81/81 [==============================] - 24s 294ms/step - loss: 0.0054 - acc: 0.9981 - val_loss: 0.0355 - val_acc: 0.9950\n",
      "Epoch 469/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0072 - acc: 0.9975WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 27s 8ms/sample - loss: 0.0230 - acc: 0.9900\n",
      "\n",
      "Epoch 00469: val_loss did not improve from 0.00826\n",
      "81/81 [==============================] - 31s 384ms/step - loss: 0.0071 - acc: 0.9975 - val_loss: 0.0230 - val_acc: 0.9900\n",
      "Epoch 470/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0054 - acc: 0.9981WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.0600 - acc: 0.9900\n",
      "\n",
      "Epoch 00470: val_loss did not improve from 0.00826\n",
      "81/81 [==============================] - 24s 295ms/step - loss: 0.0053 - acc: 0.9981 - val_loss: 0.0600 - val_acc: 0.9900\n",
      "Epoch 471/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0119 - acc: 0.9950WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 22s 7ms/sample - loss: 0.0299 - acc: 0.9947\n",
      "\n",
      "Epoch 00471: val_loss did not improve from 0.00826\n",
      "81/81 [==============================] - 25s 312ms/step - loss: 0.0117 - acc: 0.9950 - val_loss: 0.0299 - val_acc: 0.9947\n",
      "Epoch 472/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0056 - acc: 0.9981WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0268 - acc: 0.9950\n",
      "\n",
      "Epoch 00472: val_loss did not improve from 0.00826\n",
      "81/81 [==============================] - 23s 289ms/step - loss: 0.0055 - acc: 0.9981 - val_loss: 0.0268 - val_acc: 0.9950\n",
      "Epoch 473/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0045 - acc: 0.9987WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 15s 5ms/sample - loss: 0.0342 - acc: 0.9925\n",
      "\n",
      "Epoch 00473: val_loss did not improve from 0.00826\n",
      "81/81 [==============================] - 23s 289ms/step - loss: 0.0044 - acc: 0.9988 - val_loss: 0.0342 - val_acc: 0.9925\n",
      "Epoch 474/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0098 - acc: 0.9981WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 20s 6ms/sample - loss: 0.0472 - acc: 0.9950\n",
      "\n",
      "Epoch 00474: val_loss did not improve from 0.00826\n",
      "81/81 [==============================] - 24s 296ms/step - loss: 0.0095 - acc: 0.9981 - val_loss: 0.0472 - val_acc: 0.9950\n",
      "Epoch 475/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0051 - acc: 0.9987WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0274 - acc: 0.9950\n",
      "\n",
      "Epoch 00475: val_loss did not improve from 0.00826\n",
      "81/81 [==============================] - 22s 267ms/step - loss: 0.0050 - acc: 0.9988 - val_loss: 0.0274 - val_acc: 0.9950\n",
      "Epoch 476/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0047 - acc: 0.9987WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0401 - acc: 0.9950\n",
      "\n",
      "Epoch 00476: val_loss did not improve from 0.00826\n",
      "81/81 [==============================] - 21s 264ms/step - loss: 0.0046 - acc: 0.9988 - val_loss: 0.0401 - val_acc: 0.9950\n",
      "Epoch 477/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0035 - acc: 0.9987WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0310 - acc: 0.9891\n",
      "\n",
      "Epoch 00477: val_loss did not improve from 0.00826\n",
      "81/81 [==============================] - 22s 270ms/step - loss: 0.0037 - acc: 0.9988 - val_loss: 0.0310 - val_acc: 0.9891\n",
      "Epoch 478/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0050 - acc: 0.9987WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0254 - acc: 0.9950\n",
      "\n",
      "Epoch 00478: val_loss did not improve from 0.00826\n",
      "81/81 [==============================] - 22s 269ms/step - loss: 0.0050 - acc: 0.9988 - val_loss: 0.0254 - val_acc: 0.9950\n",
      "Epoch 479/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0108 - acc: 0.9969WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0348 - acc: 0.9925\n",
      "\n",
      "Epoch 00479: val_loss did not improve from 0.00826\n",
      "81/81 [==============================] - 25s 311ms/step - loss: 0.0108 - acc: 0.9969 - val_loss: 0.0348 - val_acc: 0.9925\n",
      "Epoch 480/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0109 - acc: 0.9972WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 20s 6ms/sample - loss: 0.0286 - acc: 0.9925\n",
      "\n",
      "Epoch 00480: val_loss did not improve from 0.00826\n",
      "81/81 [==============================] - 24s 294ms/step - loss: 0.0108 - acc: 0.9972 - val_loss: 0.0286 - val_acc: 0.9925\n",
      "Epoch 481/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0115 - acc: 0.9965WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 22s 7ms/sample - loss: 0.0320 - acc: 0.9875\n",
      "\n",
      "Epoch 00481: val_loss did not improve from 0.00826\n",
      "81/81 [==============================] - 28s 346ms/step - loss: 0.0113 - acc: 0.9966 - val_loss: 0.0320 - val_acc: 0.9875\n",
      "Epoch 482/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0068 - acc: 0.9981WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3190/3183 [==============================] - 21s 7ms/sample - loss: 0.0380 - acc: 0.9900\n",
      "\n",
      "Epoch 00482: val_loss did not improve from 0.00826\n",
      "81/81 [==============================] - 26s 319ms/step - loss: 0.0067 - acc: 0.9981 - val_loss: 0.0380 - val_acc: 0.9900\n",
      "Epoch 483/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0086 - acc: 0.9962WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0253 - acc: 0.9925\n",
      "\n",
      "Epoch 00483: val_loss did not improve from 0.00826\n",
      "81/81 [==============================] - 26s 317ms/step - loss: 0.0085 - acc: 0.9963 - val_loss: 0.0253 - val_acc: 0.9925\n",
      "Epoch 484/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0066 - acc: 0.9975WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0403 - acc: 0.9944\n",
      "\n",
      "Epoch 00484: val_loss did not improve from 0.00826\n",
      "81/81 [==============================] - 23s 284ms/step - loss: 0.0065 - acc: 0.9975 - val_loss: 0.0403 - val_acc: 0.9944\n",
      "Epoch 485/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0068 - acc: 0.9978WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0323 - acc: 0.9897\n",
      "\n",
      "Epoch 00485: val_loss did not improve from 0.00826\n",
      "81/81 [==============================] - 21s 262ms/step - loss: 0.0066 - acc: 0.9978 - val_loss: 0.0323 - val_acc: 0.9897\n",
      "Epoch 486/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0045 - acc: 0.9984WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0336 - acc: 0.992510s - loss: 0.\n",
      "\n",
      "Epoch 00486: val_loss did not improve from 0.00826\n",
      "81/81 [==============================] - 22s 269ms/step - loss: 0.0045 - acc: 0.9984 - val_loss: 0.0336 - val_acc: 0.9925\n",
      "Epoch 487/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0043 - acc: 0.9984WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.0382 - acc: 0.9950\n",
      "\n",
      "Epoch 00487: val_loss did not improve from 0.00826\n",
      "81/81 [==============================] - 23s 280ms/step - loss: 0.0043 - acc: 0.9984 - val_loss: 0.0382 - val_acc: 0.9950\n",
      "Epoch 488/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0081 - acc: 0.9978WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.0299 - acc: 0.9944\n",
      "\n",
      "Epoch 00488: val_loss did not improve from 0.00826\n",
      "81/81 [==============================] - 21s 264ms/step - loss: 0.0079 - acc: 0.9978 - val_loss: 0.0299 - val_acc: 0.9944\n",
      "Epoch 489/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0072 - acc: 0.9981WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0392 - acc: 0.9900\n",
      "\n",
      "Epoch 00489: val_loss did not improve from 0.00826\n",
      "81/81 [==============================] - 23s 282ms/step - loss: 0.0070 - acc: 0.9981 - val_loss: 0.0392 - val_acc: 0.9900\n",
      "Epoch 490/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0149 - acc: 0.9955WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0279 - acc: 0.9900\n",
      "\n",
      "Epoch 00490: val_loss did not improve from 0.00826\n",
      "81/81 [==============================] - 22s 268ms/step - loss: 0.0145 - acc: 0.9957 - val_loss: 0.0279 - val_acc: 0.9900\n",
      "Epoch 491/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0071 - acc: 0.9968WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 5ms/sample - loss: 0.0227 - acc: 0.9912\n",
      "\n",
      "Epoch 00491: val_loss did not improve from 0.00826\n",
      "81/81 [==============================] - 22s 276ms/step - loss: 0.0069 - acc: 0.9969 - val_loss: 0.0227 - val_acc: 0.9912\n",
      "Epoch 492/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/81 [============================>.] - ETA: 0s - loss: 0.0039 - acc: 0.9990WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.0312 - acc: 0.9922\n",
      "\n",
      "Epoch 00492: val_loss did not improve from 0.00826\n",
      "81/81 [==============================] - 23s 284ms/step - loss: 0.0039 - acc: 0.9991 - val_loss: 0.0312 - val_acc: 0.9922\n",
      "Epoch 493/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0074 - acc: 0.9981WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0217 - acc: 0.9919\n",
      "\n",
      "Epoch 00493: val_loss did not improve from 0.00826\n",
      "81/81 [==============================] - 22s 277ms/step - loss: 0.0074 - acc: 0.9981 - val_loss: 0.0217 - val_acc: 0.9919\n",
      "Epoch 494/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0053 - acc: 0.9984WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0371 - acc: 0.9916\n",
      "\n",
      "Epoch 00494: val_loss did not improve from 0.00826\n",
      "81/81 [==============================] - 23s 285ms/step - loss: 0.0053 - acc: 0.9984 - val_loss: 0.0371 - val_acc: 0.9916\n",
      "Epoch 495/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0072 - acc: 0.9984WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0300 - acc: 0.9900\n",
      "\n",
      "Epoch 00495: val_loss did not improve from 0.00826\n",
      "81/81 [==============================] - 22s 267ms/step - loss: 0.0071 - acc: 0.9984 - val_loss: 0.0300 - val_acc: 0.9900\n",
      "Epoch 496/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0035 - acc: 0.9994WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0407 - acc: 0.9831\n",
      "\n",
      "Epoch 00496: val_loss did not improve from 0.00826\n",
      "81/81 [==============================] - 23s 278ms/step - loss: 0.0034 - acc: 0.9994 - val_loss: 0.0407 - val_acc: 0.9831\n",
      "Epoch 497/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0098 - acc: 0.9971WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0225 - acc: 0.9925\n",
      "\n",
      "Epoch 00497: val_loss did not improve from 0.00826\n",
      "81/81 [==============================] - 22s 267ms/step - loss: 0.0096 - acc: 0.9972 - val_loss: 0.0225 - val_acc: 0.9925\n",
      "Epoch 498/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0067 - acc: 0.9981WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.0247 - acc: 0.9947\n",
      "\n",
      "Epoch 00498: val_loss did not improve from 0.00826\n",
      "81/81 [==============================] - 21s 264ms/step - loss: 0.0066 - acc: 0.9981 - val_loss: 0.0247 - val_acc: 0.9947\n",
      "Epoch 499/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0092 - acc: 0.9984WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 23s 7ms/sample - loss: 0.0425 - acc: 0.9950\n",
      "\n",
      "Epoch 00499: val_loss did not improve from 0.00826\n",
      "81/81 [==============================] - 27s 339ms/step - loss: 0.0091 - acc: 0.9984 - val_loss: 0.0425 - val_acc: 0.9950\n",
      "Epoch 500/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0110 - acc: 0.9953WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0499 - acc: 0.9900\n",
      "\n",
      "Epoch 00500: val_loss did not improve from 0.00826\n",
      "81/81 [==============================] - 22s 269ms/step - loss: 0.0109 - acc: 0.9953 - val_loss: 0.0499 - val_acc: 0.9900\n",
      "Epoch 501/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0056 - acc: 0.9984WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.0345 - acc: 0.9875\n",
      "\n",
      "Epoch 00501: val_loss did not improve from 0.00826\n",
      "81/81 [==============================] - 22s 265ms/step - loss: 0.0055 - acc: 0.9984 - val_loss: 0.0345 - val_acc: 0.9875\n",
      "Epoch 502/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0076 - acc: 0.9978WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0259 - acc: 0.9891\n",
      "\n",
      "Epoch 00502: val_loss did not improve from 0.00826\n",
      "81/81 [==============================] - 23s 285ms/step - loss: 0.0074 - acc: 0.9978 - val_loss: 0.0259 - val_acc: 0.9891\n",
      "Epoch 503/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0090 - acc: 0.9975WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 21s 6ms/sample - loss: 0.0256 - acc: 0.9900\n",
      "\n",
      "Epoch 00503: val_loss did not improve from 0.00826\n",
      "81/81 [==============================] - 25s 306ms/step - loss: 0.0089 - acc: 0.9975 - val_loss: 0.0256 - val_acc: 0.9900\n",
      "Epoch 504/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0106 - acc: 0.9968WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0215 - acc: 0.9950\n",
      "\n",
      "Epoch 00504: val_loss did not improve from 0.00826\n",
      "81/81 [==============================] - 29s 363ms/step - loss: 0.0105 - acc: 0.9969 - val_loss: 0.0215 - val_acc: 0.9950\n",
      "Epoch 505/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0057 - acc: 0.9972WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 14s 4ms/sample - loss: 0.0278 - acc: 0.9900\n",
      "\n",
      "Epoch 00505: val_loss did not improve from 0.00826\n",
      "81/81 [==============================] - 21s 262ms/step - loss: 0.0057 - acc: 0.9972 - val_loss: 0.0278 - val_acc: 0.9900\n",
      "Epoch 506/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0176 - acc: 0.9962WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0194 - acc: 0.9925\n",
      "\n",
      "Epoch 00506: val_loss did not improve from 0.00826\n",
      "81/81 [==============================] - 22s 267ms/step - loss: 0.0174 - acc: 0.9963 - val_loss: 0.0194 - val_acc: 0.9925\n",
      "Epoch 507/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0079 - acc: 0.9978WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0305 - acc: 0.9925\n",
      "\n",
      "Epoch 00507: val_loss did not improve from 0.00826\n",
      "81/81 [==============================] - 22s 274ms/step - loss: 0.0082 - acc: 0.9975 - val_loss: 0.0305 - val_acc: 0.9925\n",
      "Epoch 508/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0082 - acc: 0.9978WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.0200 - acc: 0.9931\n",
      "\n",
      "Epoch 00508: val_loss did not improve from 0.00826\n",
      "81/81 [==============================] - 23s 285ms/step - loss: 0.0082 - acc: 0.9978 - val_loss: 0.0200 - val_acc: 0.9931\n",
      "Epoch 509/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0041 - acc: 0.9984WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0413 - acc: 0.9950\n",
      "\n",
      "Epoch 00509: val_loss did not improve from 0.00826\n",
      "81/81 [==============================] - 26s 316ms/step - loss: 0.0041 - acc: 0.9984 - val_loss: 0.0413 - val_acc: 0.9950\n",
      "Epoch 510/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0064 - acc: 0.9981WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.0140 - acc: 0.9975\n",
      "\n",
      "Epoch 00510: val_loss did not improve from 0.00826\n",
      "81/81 [==============================] - 22s 270ms/step - loss: 0.0062 - acc: 0.9981 - val_loss: 0.0140 - val_acc: 0.9975\n",
      "Epoch 511/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0111 - acc: 0.9968WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 15s 5ms/sample - loss: 0.0168 - acc: 0.9969\n",
      "\n",
      "Epoch 00511: val_loss did not improve from 0.00826\n",
      "81/81 [==============================] - 22s 267ms/step - loss: 0.0109 - acc: 0.9969 - val_loss: 0.0168 - val_acc: 0.9969\n",
      "Epoch 512/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0072 - acc: 0.9978WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0322 - acc: 0.9950\n",
      "\n",
      "Epoch 00512: val_loss did not improve from 0.00826\n",
      "81/81 [==============================] - 22s 268ms/step - loss: 0.0075 - acc: 0.9975 - val_loss: 0.0322 - val_acc: 0.9950\n",
      "Epoch 513/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0031 - acc: 0.9987WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 28s 9ms/sample - loss: 0.0334 - acc: 0.9950\n",
      "\n",
      "Epoch 00513: val_loss did not improve from 0.00826\n",
      "81/81 [==============================] - 34s 414ms/step - loss: 0.0030 - acc: 0.9988 - val_loss: 0.0334 - val_acc: 0.9950\n",
      "Epoch 514/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0079 - acc: 0.9981WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.0323 - acc: 0.9950\n",
      "\n",
      "Epoch 00514: val_loss did not improve from 0.00826\n",
      "81/81 [==============================] - 23s 284ms/step - loss: 0.0079 - acc: 0.9981 - val_loss: 0.0323 - val_acc: 0.9950\n",
      "Epoch 515/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0037 - acc: 0.9990WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0446 - acc: 0.9950\n",
      "\n",
      "Epoch 00515: val_loss did not improve from 0.00826\n",
      "81/81 [==============================] - 22s 271ms/step - loss: 0.0037 - acc: 0.9991 - val_loss: 0.0446 - val_acc: 0.9950\n",
      "Epoch 516/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0063 - acc: 0.9981WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0276 - acc: 0.9944\n",
      "\n",
      "Epoch 00516: val_loss did not improve from 0.00826\n",
      "81/81 [==============================] - 24s 292ms/step - loss: 0.0062 - acc: 0.9981 - val_loss: 0.0276 - val_acc: 0.9944\n",
      "Epoch 517/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0083 - acc: 0.9984WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.0267 - acc: 0.9944\n",
      "\n",
      "Epoch 00517: val_loss did not improve from 0.00826\n",
      "81/81 [==============================] - 22s 277ms/step - loss: 0.0084 - acc: 0.9984 - val_loss: 0.0267 - val_acc: 0.9944\n",
      "Epoch 518/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0062 - acc: 0.9981WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0218 - acc: 0.9922\n",
      "\n",
      "Epoch 00518: val_loss did not improve from 0.00826\n",
      "81/81 [==============================] - 22s 273ms/step - loss: 0.0062 - acc: 0.9981 - val_loss: 0.0218 - val_acc: 0.9922\n",
      "Epoch 519/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0038 - acc: 0.9987WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - ETA: 0s - loss: 0.0298 - acc: 0.994 - 20s 6ms/sample - loss: 0.0294 - acc: 0.9950\n",
      "\n",
      "Epoch 00519: val_loss did not improve from 0.00826\n",
      "81/81 [==============================] - 23s 288ms/step - loss: 0.0042 - acc: 0.9984 - val_loss: 0.0294 - val_acc: 0.9950\n",
      "Epoch 520/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0055 - acc: 0.9987WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0264 - acc: 0.9925\n",
      "\n",
      "Epoch 00520: val_loss did not improve from 0.00826\n",
      "81/81 [==============================] - 22s 271ms/step - loss: 0.0054 - acc: 0.9988 - val_loss: 0.0264 - val_acc: 0.9925\n",
      "Epoch 521/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0138 - acc: 0.9968WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0189 - acc: 0.9900\n",
      "\n",
      "Epoch 00521: val_loss did not improve from 0.00826\n",
      "81/81 [==============================] - 21s 262ms/step - loss: 0.0135 - acc: 0.9969 - val_loss: 0.0189 - val_acc: 0.9900\n",
      "Epoch 522/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0036 - acc: 0.9987WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0201 - acc: 0.9950\n",
      "\n",
      "Epoch 00522: val_loss did not improve from 0.00826\n",
      "81/81 [==============================] - 23s 288ms/step - loss: 0.0036 - acc: 0.9988 - val_loss: 0.0201 - val_acc: 0.9950\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 523/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0048 - acc: 0.9987WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0312 - acc: 0.9922\n",
      "\n",
      "Epoch 00523: val_loss did not improve from 0.00826\n",
      "81/81 [==============================] - 22s 271ms/step - loss: 0.0053 - acc: 0.9984 - val_loss: 0.0312 - val_acc: 0.9922\n",
      "\n",
      "vis_imagenet_6_class_augmentation_2D_CNN_custom_ch_32_DO_075_DO_4_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3183/3183 [==============================] - 3s 935us/sample - loss: 10.6451 - acc: 0.3380\n",
      "Loss: 10.645130489546318 Accuracy: 0.33804587\n",
      "\n",
      "Epoch 1/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.9025 - acc: 0.4994WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.7418 - acc: 0.3244\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.74184, saving model to model/checkpoint/vis_imagenet_6_class_augmentation_2D_CNN_custom_ch_32_DO_075_DO_5_conv_checkpoint/001-0.7418.hdf5\n",
      "81/81 [==============================] - 24s 297ms/step - loss: 0.8988 - acc: 0.5000 - val_loss: 0.7418 - val_acc: 0.3244\n",
      "Epoch 2/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.5823 - acc: 0.6836WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.3538 - acc: 0.8559\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.74184 to 0.35377, saving model to model/checkpoint/vis_imagenet_6_class_augmentation_2D_CNN_custom_ch_32_DO_075_DO_5_conv_checkpoint/002-0.3538.hdf5\n",
      "81/81 [==============================] - 21s 259ms/step - loss: 0.5788 - acc: 0.6865 - val_loss: 0.3538 - val_acc: 0.8559\n",
      "Epoch 3/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.4665 - acc: 0.7810WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.2830 - acc: 0.8931\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.35377 to 0.28297, saving model to model/checkpoint/vis_imagenet_6_class_augmentation_2D_CNN_custom_ch_32_DO_075_DO_5_conv_checkpoint/003-0.2830.hdf5\n",
      "81/81 [==============================] - 23s 284ms/step - loss: 0.4645 - acc: 0.7818 - val_loss: 0.2830 - val_acc: 0.8931\n",
      "Epoch 4/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.3811 - acc: 0.8297WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.2339 - acc: 0.9175\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.28297 to 0.23394, saving model to model/checkpoint/vis_imagenet_6_class_augmentation_2D_CNN_custom_ch_32_DO_075_DO_5_conv_checkpoint/004-0.2339.hdf5\n",
      "81/81 [==============================] - 23s 287ms/step - loss: 0.3807 - acc: 0.8299 - val_loss: 0.2339 - val_acc: 0.9175\n",
      "Epoch 5/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.3251 - acc: 0.8612WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.1623 - acc: 0.9575\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.23394 to 0.16227, saving model to model/checkpoint/vis_imagenet_6_class_augmentation_2D_CNN_custom_ch_32_DO_075_DO_5_conv_checkpoint/005-0.1623.hdf5\n",
      "81/81 [==============================] - 21s 262ms/step - loss: 0.3266 - acc: 0.8606 - val_loss: 0.1623 - val_acc: 0.9575\n",
      "Epoch 6/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.2984 - acc: 0.8705WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.1778 - acc: 0.9306\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.16227\n",
      "81/81 [==============================] - 23s 289ms/step - loss: 0.2980 - acc: 0.8709 - val_loss: 0.1778 - val_acc: 0.9306\n",
      "Epoch 7/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.2693 - acc: 0.8892WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.1667 - acc: 0.9353\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.16227\n",
      "81/81 [==============================] - 23s 284ms/step - loss: 0.2686 - acc: 0.8898 - val_loss: 0.1667 - val_acc: 0.9353\n",
      "Epoch 8/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.2388 - acc: 0.9058WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 20s 6ms/sample - loss: 0.1182 - acc: 0.9681\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.16227 to 0.11818, saving model to model/checkpoint/vis_imagenet_6_class_augmentation_2D_CNN_custom_ch_32_DO_075_DO_5_conv_checkpoint/008-0.1182.hdf5\n",
      "81/81 [==============================] - 25s 312ms/step - loss: 0.2377 - acc: 0.9060 - val_loss: 0.1182 - val_acc: 0.9681\n",
      "Epoch 9/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.2311 - acc: 0.9039WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.2239 - acc: 0.9100\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.11818\n",
      "81/81 [==============================] - 22s 270ms/step - loss: 0.2321 - acc: 0.9038 - val_loss: 0.2239 - val_acc: 0.9100\n",
      "Epoch 10/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.2152 - acc: 0.9137WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.1865 - acc: 0.9200\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.11818\n",
      "81/81 [==============================] - 22s 276ms/step - loss: 0.2117 - acc: 0.9156 - val_loss: 0.1865 - val_acc: 0.9200\n",
      "Epoch 11/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.1813 - acc: 0.9236WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.1906 - acc: 0.9294\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.11818\n",
      "81/81 [==============================] - 21s 265ms/step - loss: 0.1829 - acc: 0.9233 - val_loss: 0.1906 - val_acc: 0.9294\n",
      "Epoch 12/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.1671 - acc: 0.9337WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.1215 - acc: 0.9625\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.11818\n",
      "81/81 [==============================] - 22s 272ms/step - loss: 0.1689 - acc: 0.9320 - val_loss: 0.1215 - val_acc: 0.9625\n",
      "Epoch 13/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.1799 - acc: 0.9309WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 21s 7ms/sample - loss: 0.2076 - acc: 0.9212\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.11818\n",
      "81/81 [==============================] - 25s 311ms/step - loss: 0.1785 - acc: 0.9311 - val_loss: 0.2076 - val_acc: 0.9212\n",
      "Epoch 14/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.1572 - acc: 0.9434WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0686 - acc: 0.9825\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.11818 to 0.06859, saving model to model/checkpoint/vis_imagenet_6_class_augmentation_2D_CNN_custom_ch_32_DO_075_DO_5_conv_checkpoint/014-0.0686.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81/81 [==============================] - 22s 271ms/step - loss: 0.1562 - acc: 0.9438 - val_loss: 0.0686 - val_acc: 0.9825\n",
      "Epoch 15/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.1510 - acc: 0.9466- ETA: 1s - losWARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 22s 7ms/sample - loss: 0.0625 - acc: 0.9819\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.06859 to 0.06251, saving model to model/checkpoint/vis_imagenet_6_class_augmentation_2D_CNN_custom_ch_32_DO_075_DO_5_conv_checkpoint/015-0.0625.hdf5\n",
      "81/81 [==============================] - 27s 329ms/step - loss: 0.1525 - acc: 0.9457 - val_loss: 0.0625 - val_acc: 0.9819\n",
      "Epoch 16/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.1585 - acc: 0.9378WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.0649 - acc: 0.9844\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.06251\n",
      "81/81 [==============================] - 24s 294ms/step - loss: 0.1573 - acc: 0.9382 - val_loss: 0.0649 - val_acc: 0.9844\n",
      "Epoch 17/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.1590 - acc: 0.9375WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.3933 - acc: 0.8219\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.06251\n",
      "81/81 [==============================] - 29s 361ms/step - loss: 0.1599 - acc: 0.9376 - val_loss: 0.3933 - val_acc: 0.8219\n",
      "Epoch 18/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.1419 - acc: 0.9522WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0661 - acc: 0.9775\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.06251\n",
      "81/81 [==============================] - 21s 260ms/step - loss: 0.1431 - acc: 0.9522 - val_loss: 0.0661 - val_acc: 0.9775\n",
      "Epoch 19/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.1326 - acc: 0.9538WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3190/3183 [==============================] - 18s 6ms/sample - loss: 0.0608 - acc: 0.9824\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.06251 to 0.06078, saving model to model/checkpoint/vis_imagenet_6_class_augmentation_2D_CNN_custom_ch_32_DO_075_DO_5_conv_checkpoint/019-0.0608.hdf5\n",
      "81/81 [==============================] - 22s 269ms/step - loss: 0.1323 - acc: 0.9538 - val_loss: 0.0608 - val_acc: 0.9824\n",
      "Epoch 20/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.1332 - acc: 0.9516WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 26s 8ms/sample - loss: 0.1731 - acc: 0.9375\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.06078\n",
      "81/81 [==============================] - 30s 371ms/step - loss: 0.1325 - acc: 0.9519 - val_loss: 0.1731 - val_acc: 0.9375\n",
      "Epoch 21/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.1267 - acc: 0.9513WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0765 - acc: 0.9791\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.06078\n",
      "81/81 [==============================] - 25s 305ms/step - loss: 0.1264 - acc: 0.9516 - val_loss: 0.0765 - val_acc: 0.9791\n",
      "Epoch 22/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.1357 - acc: 0.9526WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 5ms/sample - loss: 0.1121 - acc: 0.9578\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.06078\n",
      "81/81 [==============================] - 21s 264ms/step - loss: 0.1360 - acc: 0.9516 - val_loss: 0.1121 - val_acc: 0.9578\n",
      "Epoch 23/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.1218 - acc: 0.9561WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0679 - acc: 0.9750\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.06078\n",
      "81/81 [==============================] - 26s 319ms/step - loss: 0.1204 - acc: 0.9569 - val_loss: 0.0679 - val_acc: 0.9750\n",
      "Epoch 24/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.1323 - acc: 0.9510WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.1105 - acc: 0.9575\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.06078\n",
      "81/81 [==============================] - 22s 274ms/step - loss: 0.1327 - acc: 0.9510 - val_loss: 0.1105 - val_acc: 0.9575\n",
      "Epoch 25/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.1100 - acc: 0.9618WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.2820 - acc: 0.8725\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.06078\n",
      "81/81 [==============================] - 22s 272ms/step - loss: 0.1125 - acc: 0.9612 - val_loss: 0.2820 - val_acc: 0.8725\n",
      "Epoch 26/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.1116 - acc: 0.9574WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 14s 4ms/sample - loss: 0.0687 - acc: 0.9750\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.06078\n",
      "81/81 [==============================] - 21s 257ms/step - loss: 0.1115 - acc: 0.9569 - val_loss: 0.0687 - val_acc: 0.9750\n",
      "Epoch 27/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.1271 - acc: 0.9507WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 15s 5ms/sample - loss: 0.0714 - acc: 0.9750\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.06078\n",
      "81/81 [==============================] - 22s 276ms/step - loss: 0.1274 - acc: 0.9507 - val_loss: 0.0714 - val_acc: 0.9750\n",
      "Epoch 28/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.1079 - acc: 0.9556WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3190/3183 [==============================] - 15s 5ms/sample - loss: 0.1791 - acc: 0.9245\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.06078\n",
      "81/81 [==============================] - 22s 266ms/step - loss: 0.1076 - acc: 0.9556 - val_loss: 0.1791 - val_acc: 0.9245\n",
      "Epoch 29/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0968 - acc: 0.9640WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.1425 - acc: 0.94257s - loss: 0.1589 \n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.06078\n",
      "81/81 [==============================] - 23s 282ms/step - loss: 0.0971 - acc: 0.9637 - val_loss: 0.1425 - val_acc: 0.9425\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.1200 - acc: 0.9583WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.3651 - acc: 0.8375\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.06078\n",
      "81/81 [==============================] - 23s 288ms/step - loss: 0.1201 - acc: 0.9578 - val_loss: 0.3651 - val_acc: 0.8375\n",
      "Epoch 31/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.1221 - acc: 0.9551WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 14s 4ms/sample - loss: 0.1059 - acc: 0.9625\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.06078\n",
      "81/81 [==============================] - 22s 266ms/step - loss: 0.1201 - acc: 0.9562 - val_loss: 0.1059 - val_acc: 0.9625\n",
      "Epoch 32/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.1110 - acc: 0.9621WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 5ms/sample - loss: 0.0600 - acc: 0.9775\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.06078 to 0.05999, saving model to model/checkpoint/vis_imagenet_6_class_augmentation_2D_CNN_custom_ch_32_DO_075_DO_5_conv_checkpoint/032-0.0600.hdf5\n",
      "81/81 [==============================] - 21s 265ms/step - loss: 0.1105 - acc: 0.9621 - val_loss: 0.0600 - val_acc: 0.9775\n",
      "Epoch 33/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.1120 - acc: 0.9579WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.1697 - acc: 0.9322\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.05999\n",
      "81/81 [==============================] - 22s 266ms/step - loss: 0.1113 - acc: 0.9584 - val_loss: 0.1697 - val_acc: 0.9322\n",
      "Epoch 34/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0971 - acc: 0.9673- ETA: 1s - loss: 0.099WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 5ms/sample - loss: 0.0859 - acc: 0.9675\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.05999\n",
      "81/81 [==============================] - 23s 290ms/step - loss: 0.0964 - acc: 0.9674 - val_loss: 0.0859 - val_acc: 0.9675\n",
      "Epoch 35/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.1163 - acc: 0.9576WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.0696 - acc: 0.9769\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.05999\n",
      "81/81 [==============================] - 20s 248ms/step - loss: 0.1156 - acc: 0.9581 - val_loss: 0.0696 - val_acc: 0.9769\n",
      "Epoch 36/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0929 - acc: 0.9653WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0602 - acc: 0.9769\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.05999\n",
      "81/81 [==============================] - 23s 284ms/step - loss: 0.0941 - acc: 0.9646 - val_loss: 0.0602 - val_acc: 0.9769\n",
      "Epoch 37/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.1079 - acc: 0.9566WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.1027 - acc: 0.9675\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.05999\n",
      "81/81 [==============================] - 24s 301ms/step - loss: 0.1069 - acc: 0.9572 - val_loss: 0.1027 - val_acc: 0.9675\n",
      "Epoch 38/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0931 - acc: 0.9669WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 15s 5ms/sample - loss: 0.0806 - acc: 0.9700\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.05999\n",
      "81/81 [==============================] - 21s 253ms/step - loss: 0.0923 - acc: 0.9674 - val_loss: 0.0806 - val_acc: 0.9700\n",
      "Epoch 39/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0868 - acc: 0.9720WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 21s 7ms/sample - loss: 0.0837 - acc: 0.9663\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.05999\n",
      "81/81 [==============================] - 25s 308ms/step - loss: 0.0889 - acc: 0.9711 - val_loss: 0.0837 - val_acc: 0.9663\n",
      "Epoch 40/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0869 - acc: 0.9695WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0978 - acc: 0.9625\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.05999\n",
      "81/81 [==============================] - 23s 280ms/step - loss: 0.0865 - acc: 0.9699 - val_loss: 0.0978 - val_acc: 0.9625\n",
      "Epoch 41/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.1016 - acc: 0.9618WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 14s 4ms/sample - loss: 0.1208 - acc: 0.9481\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.05999\n",
      "81/81 [==============================] - 21s 257ms/step - loss: 0.1031 - acc: 0.9606 - val_loss: 0.1208 - val_acc: 0.9481\n",
      "Epoch 42/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0988 - acc: 0.9642WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 5ms/sample - loss: 0.1180 - acc: 0.9475\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.05999\n",
      "81/81 [==============================] - 22s 268ms/step - loss: 0.0990 - acc: 0.9640 - val_loss: 0.1180 - val_acc: 0.9475\n",
      "Epoch 43/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0881 - acc: 0.9691WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.1001 - acc: 0.9525\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.05999\n",
      "81/81 [==============================] - 22s 266ms/step - loss: 0.0869 - acc: 0.9699 - val_loss: 0.1001 - val_acc: 0.9525\n",
      "Epoch 44/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0938 - acc: 0.9670WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0525 - acc: 0.9828\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.05999 to 0.05250, saving model to model/checkpoint/vis_imagenet_6_class_augmentation_2D_CNN_custom_ch_32_DO_075_DO_5_conv_checkpoint/044-0.0525.hdf5\n",
      "81/81 [==============================] - 23s 288ms/step - loss: 0.0938 - acc: 0.9671 - val_loss: 0.0525 - val_acc: 0.9828\n",
      "Epoch 45/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/81 [============================>.] - ETA: 0s - loss: 0.0802 - acc: 0.9717WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 15s 5ms/sample - loss: 0.0676 - acc: 0.97500s - loss: 0.0649 - acc: 0.975\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.05250\n",
      "81/81 [==============================] - 22s 271ms/step - loss: 0.0823 - acc: 0.9711 - val_loss: 0.0676 - val_acc: 0.9750\n",
      "Epoch 46/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0806 - acc: 0.9692WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0796 - acc: 0.9769\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.05250\n",
      "81/81 [==============================] - 22s 268ms/step - loss: 0.0801 - acc: 0.9693 - val_loss: 0.0796 - val_acc: 0.9769\n",
      "Epoch 47/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.1037 - acc: 0.9621WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0515 - acc: 0.9850\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.05250 to 0.05153, saving model to model/checkpoint/vis_imagenet_6_class_augmentation_2D_CNN_custom_ch_32_DO_075_DO_5_conv_checkpoint/047-0.0515.hdf5\n",
      "81/81 [==============================] - 23s 286ms/step - loss: 0.1042 - acc: 0.9621 - val_loss: 0.0515 - val_acc: 0.9850\n",
      "Epoch 48/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.1063 - acc: 0.9593WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0614 - acc: 0.9800\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.05153\n",
      "81/81 [==============================] - 21s 261ms/step - loss: 0.1048 - acc: 0.9600 - val_loss: 0.0614 - val_acc: 0.9800\n",
      "Epoch 49/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0956 - acc: 0.9654WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 15s 5ms/sample - loss: 0.1046 - acc: 0.9553\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.05153\n",
      "81/81 [==============================] - 23s 282ms/step - loss: 0.0960 - acc: 0.9646 - val_loss: 0.1046 - val_acc: 0.9553\n",
      "Epoch 50/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0877 - acc: 0.9701WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0705 - acc: 0.9681\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.05153\n",
      "81/81 [==============================] - 23s 283ms/step - loss: 0.0871 - acc: 0.9705 - val_loss: 0.0705 - val_acc: 0.9681\n",
      "Epoch 51/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0936 - acc: 0.9669WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0701 - acc: 0.9734\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.05153\n",
      "81/81 [==============================] - 22s 275ms/step - loss: 0.0923 - acc: 0.9671 - val_loss: 0.0701 - val_acc: 0.9734\n",
      "Epoch 52/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0732 - acc: 0.9742WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 20s 6ms/sample - loss: 0.0812 - acc: 0.9675\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.05153\n",
      "81/81 [==============================] - 28s 345ms/step - loss: 0.0729 - acc: 0.9739 - val_loss: 0.0812 - val_acc: 0.9675\n",
      "Epoch 53/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0774 - acc: 0.9726WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0933 - acc: 0.9634\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.05153\n",
      "81/81 [==============================] - 25s 313ms/step - loss: 0.0785 - acc: 0.9718 - val_loss: 0.0933 - val_acc: 0.9634\n",
      "Epoch 54/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0718 - acc: 0.9733WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0833 - acc: 0.9634\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.05153\n",
      "81/81 [==============================] - 23s 286ms/step - loss: 0.0752 - acc: 0.9724 - val_loss: 0.0833 - val_acc: 0.9634\n",
      "Epoch 55/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0843 - acc: 0.9679- EWARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0616 - acc: 0.9816\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.05153\n",
      "81/81 [==============================] - 22s 268ms/step - loss: 0.0855 - acc: 0.9680 - val_loss: 0.0616 - val_acc: 0.9816\n",
      "Epoch 56/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0730 - acc: 0.9739WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 15s 5ms/sample - loss: 0.0397 - acc: 0.9900\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.05153 to 0.03966, saving model to model/checkpoint/vis_imagenet_6_class_augmentation_2D_CNN_custom_ch_32_DO_075_DO_5_conv_checkpoint/056-0.0397.hdf5\n",
      "81/81 [==============================] - 21s 263ms/step - loss: 0.0722 - acc: 0.9742 - val_loss: 0.0397 - val_acc: 0.9900\n",
      "Epoch 57/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0779 - acc: 0.9752WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0594 - acc: 0.9737\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.03966\n",
      "81/81 [==============================] - 22s 272ms/step - loss: 0.0769 - acc: 0.9755 - val_loss: 0.0594 - val_acc: 0.9737\n",
      "Epoch 58/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0753 - acc: 0.9761WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 25s 8ms/sample - loss: 0.0452 - acc: 0.9866\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.03966\n",
      "81/81 [==============================] - 28s 350ms/step - loss: 0.0744 - acc: 0.9764 - val_loss: 0.0452 - val_acc: 0.9866\n",
      "Epoch 59/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0863 - acc: 0.9688WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0609 - acc: 0.9719\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.03966\n",
      "81/81 [==============================] - 23s 287ms/step - loss: 0.0861 - acc: 0.9687 - val_loss: 0.0609 - val_acc: 0.9719\n",
      "Epoch 60/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/81 [============================>.] - ETA: 0s - loss: 0.0739 - acc: 0.9784WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.1151 - acc: 0.9544\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.03966\n",
      "81/81 [==============================] - 22s 268ms/step - loss: 0.0768 - acc: 0.9777 - val_loss: 0.1151 - val_acc: 0.9544\n",
      "Epoch 61/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0788 - acc: 0.9742WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0514 - acc: 0.9850\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.03966\n",
      "81/81 [==============================] - 23s 289ms/step - loss: 0.0795 - acc: 0.9742 - val_loss: 0.0514 - val_acc: 0.9850\n",
      "Epoch 62/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0693 - acc: 0.9742WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.1026 - acc: 0.9600\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.03966\n",
      "81/81 [==============================] - 22s 270ms/step - loss: 0.0678 - acc: 0.9749 - val_loss: 0.1026 - val_acc: 0.9600\n",
      "Epoch 63/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0792 - acc: 0.9723WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 20s 6ms/sample - loss: 0.0723 - acc: 0.9716\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.03966\n",
      "81/81 [==============================] - 24s 297ms/step - loss: 0.0794 - acc: 0.9718 - val_loss: 0.0723 - val_acc: 0.9716\n",
      "Epoch 64/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0604 - acc: 0.9796WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.1267 - acc: 0.9506\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.03966\n",
      "81/81 [==============================] - 24s 300ms/step - loss: 0.0621 - acc: 0.9786 - val_loss: 0.1267 - val_acc: 0.9506\n",
      "Epoch 65/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0723 - acc: 0.9758WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0941 - acc: 0.9625\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.03966\n",
      "81/81 [==============================] - 21s 264ms/step - loss: 0.0715 - acc: 0.9761 - val_loss: 0.0941 - val_acc: 0.9625\n",
      "Epoch 66/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0657 - acc: 0.9774WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0630 - acc: 0.9800\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.03966\n",
      "81/81 [==============================] - 22s 271ms/step - loss: 0.0655 - acc: 0.9773 - val_loss: 0.0630 - val_acc: 0.9800\n",
      "Epoch 67/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0565 - acc: 0.9793WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0759 - acc: 0.970014s - \n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.03966\n",
      "81/81 [==============================] - 23s 278ms/step - loss: 0.0560 - acc: 0.9795 - val_loss: 0.0759 - val_acc: 0.9700\n",
      "Epoch 68/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0643 - acc: 0.9767WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.1072 - acc: 0.9600\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.03966\n",
      "81/81 [==============================] - 21s 264ms/step - loss: 0.0637 - acc: 0.9770 - val_loss: 0.1072 - val_acc: 0.9600\n",
      "Epoch 69/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0564 - acc: 0.9815WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.0806 - acc: 0.9725\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.03966\n",
      "81/81 [==============================] - 22s 267ms/step - loss: 0.0570 - acc: 0.9814 - val_loss: 0.0806 - val_acc: 0.9725\n",
      "Epoch 70/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0637 - acc: 0.9774WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 13s 4ms/sample - loss: 0.0586 - acc: 0.97569s - loss: 0\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.03966\n",
      "81/81 [==============================] - 22s 266ms/step - loss: 0.0639 - acc: 0.9777 - val_loss: 0.0586 - val_acc: 0.9756\n",
      "Epoch 71/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0633 - acc: 0.9790WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 21s 6ms/sample - loss: 0.0755 - acc: 0.9725\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.03966\n",
      "81/81 [==============================] - 25s 306ms/step - loss: 0.0624 - acc: 0.9792 - val_loss: 0.0755 - val_acc: 0.9725\n",
      "Epoch 72/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0698 - acc: 0.9742WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.0592 - acc: 0.9750\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.03966\n",
      "81/81 [==============================] - 21s 259ms/step - loss: 0.0709 - acc: 0.9739 - val_loss: 0.0592 - val_acc: 0.9750\n",
      "Epoch 73/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0542 - acc: 0.9806WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 15s 5ms/sample - loss: 0.0482 - acc: 0.9825\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.03966\n",
      "81/81 [==============================] - 21s 264ms/step - loss: 0.0543 - acc: 0.9808 - val_loss: 0.0482 - val_acc: 0.9825\n",
      "Epoch 74/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0745 - acc: 0.9755WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0716 - acc: 0.9775\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.03966\n",
      "81/81 [==============================] - 22s 269ms/step - loss: 0.0737 - acc: 0.9755 - val_loss: 0.0716 - val_acc: 0.9775\n",
      "Epoch 75/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0453 - acc: 0.9849WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.0516 - acc: 0.9800\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.03966\n",
      "81/81 [==============================] - 21s 262ms/step - loss: 0.0450 - acc: 0.9851 - val_loss: 0.0516 - val_acc: 0.9800\n",
      "Epoch 76/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0548 - acc: 0.9812WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0530 - acc: 0.9900\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.03966\n",
      "81/81 [==============================] - 22s 266ms/step - loss: 0.0554 - acc: 0.9808 - val_loss: 0.0530 - val_acc: 0.9900\n",
      "Epoch 77/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0761 - acc: 0.9686WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 13s 4ms/sample - loss: 0.1268 - acc: 0.9566\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.03966\n",
      "81/81 [==============================] - 20s 247ms/step - loss: 0.0762 - acc: 0.9687 - val_loss: 0.1268 - val_acc: 0.9566\n",
      "Epoch 78/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0543 - acc: 0.9833WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0869 - acc: 0.9684\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.03966\n",
      "81/81 [==============================] - 24s 290ms/step - loss: 0.0547 - acc: 0.9829 - val_loss: 0.0869 - val_acc: 0.9684\n",
      "Epoch 79/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0523 - acc: 0.9827WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0564 - acc: 0.9775\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.03966\n",
      "81/81 [==============================] - 23s 285ms/step - loss: 0.0529 - acc: 0.9826 - val_loss: 0.0564 - val_acc: 0.9775\n",
      "Epoch 80/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0559 - acc: 0.9825WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 15s 5ms/sample - loss: 0.0498 - acc: 0.9794\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.03966\n",
      "81/81 [==============================] - 22s 268ms/step - loss: 0.0553 - acc: 0.9826 - val_loss: 0.0498 - val_acc: 0.9794\n",
      "Epoch 81/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0485 - acc: 0.9831WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 20s 6ms/sample - loss: 0.0568 - acc: 0.9784\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.03966\n",
      "81/81 [==============================] - 27s 327ms/step - loss: 0.0487 - acc: 0.9829 - val_loss: 0.0568 - val_acc: 0.9784\n",
      "Epoch 82/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0448 - acc: 0.9854WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0644 - acc: 0.9800\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.03966\n",
      "81/81 [==============================] - 22s 277ms/step - loss: 0.0454 - acc: 0.9851 - val_loss: 0.0644 - val_acc: 0.9800\n",
      "Epoch 83/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0689 - acc: 0.9786WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 15s 5ms/sample - loss: 0.0656 - acc: 0.9700\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.03966\n",
      "81/81 [==============================] - 21s 262ms/step - loss: 0.0685 - acc: 0.9786 - val_loss: 0.0656 - val_acc: 0.9700\n",
      "Epoch 84/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0477 - acc: 0.9824WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0422 - acc: 0.9875\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.03966\n",
      "81/81 [==============================] - 22s 269ms/step - loss: 0.0478 - acc: 0.9823 - val_loss: 0.0422 - val_acc: 0.9875\n",
      "Epoch 85/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0436 - acc: 0.9809WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0485 - acc: 0.9862\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.03966\n",
      "81/81 [==============================] - 23s 283ms/step - loss: 0.0433 - acc: 0.9814 - val_loss: 0.0485 - val_acc: 0.9862\n",
      "Epoch 86/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0585 - acc: 0.9803WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 21s 6ms/sample - loss: 0.0409 - acc: 0.9891\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.03966\n",
      "81/81 [==============================] - 25s 312ms/step - loss: 0.0587 - acc: 0.9798 - val_loss: 0.0409 - val_acc: 0.9891\n",
      "Epoch 87/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0548 - acc: 0.9825WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0726 - acc: 0.9700\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.03966\n",
      "81/81 [==============================] - 22s 268ms/step - loss: 0.0570 - acc: 0.9817 - val_loss: 0.0726 - val_acc: 0.9700\n",
      "Epoch 88/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0675 - acc: 0.9777WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 20s 6ms/sample - loss: 0.0434 - acc: 0.9862\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.03966\n",
      "81/81 [==============================] - 24s 298ms/step - loss: 0.0668 - acc: 0.9780 - val_loss: 0.0434 - val_acc: 0.9862\n",
      "Epoch 89/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0375 - acc: 0.9896WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 20s 6ms/sample - loss: 0.0462 - acc: 0.9850\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.03966\n",
      "81/81 [==============================] - 24s 297ms/step - loss: 0.0374 - acc: 0.9894 - val_loss: 0.0462 - val_acc: 0.9850\n",
      "Epoch 90/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0503 - acc: 0.9805WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.0373 - acc: 0.9900\n",
      "\n",
      "Epoch 00090: val_loss improved from 0.03966 to 0.03728, saving model to model/checkpoint/vis_imagenet_6_class_augmentation_2D_CNN_custom_ch_32_DO_075_DO_5_conv_checkpoint/090-0.0373.hdf5\n",
      "81/81 [==============================] - 22s 273ms/step - loss: 0.0498 - acc: 0.9808 - val_loss: 0.0373 - val_acc: 0.9900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0481 - acc: 0.9846WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0577 - acc: 0.9725\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.03728\n",
      "81/81 [==============================] - 21s 263ms/step - loss: 0.0478 - acc: 0.9848 - val_loss: 0.0577 - val_acc: 0.9725\n",
      "Epoch 92/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0372 - acc: 0.9879WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0480 - acc: 0.9850\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.03728\n",
      "81/81 [==============================] - 22s 268ms/step - loss: 0.0376 - acc: 0.9873 - val_loss: 0.0480 - val_acc: 0.9850\n",
      "Epoch 93/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0500 - acc: 0.9838- ETA: 1s - loss: 0.0415 -WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0393 - acc: 0.9850\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.03728\n",
      "81/81 [==============================] - 24s 290ms/step - loss: 0.0496 - acc: 0.9842 - val_loss: 0.0393 - val_acc: 0.9850\n",
      "Epoch 94/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0429 - acc: 0.9841WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0741 - acc: 0.9675\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.03728\n",
      "81/81 [==============================] - 24s 293ms/step - loss: 0.0423 - acc: 0.9845 - val_loss: 0.0741 - val_acc: 0.9675\n",
      "Epoch 95/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0418 - acc: 0.9866WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 23s 7ms/sample - loss: 0.0455 - acc: 0.9781\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.03728\n",
      "81/81 [==============================] - 29s 362ms/step - loss: 0.0414 - acc: 0.9870 - val_loss: 0.0455 - val_acc: 0.9781\n",
      "Epoch 96/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0429 - acc: 0.9865WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 20s 6ms/sample - loss: 0.0496 - acc: 0.9825\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.03728\n",
      "81/81 [==============================] - 26s 318ms/step - loss: 0.0427 - acc: 0.9867 - val_loss: 0.0496 - val_acc: 0.9825\n",
      "Epoch 97/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0498 - acc: 0.9811WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0297 - acc: 0.9875\n",
      "\n",
      "Epoch 00097: val_loss improved from 0.03728 to 0.02965, saving model to model/checkpoint/vis_imagenet_6_class_augmentation_2D_CNN_custom_ch_32_DO_075_DO_5_conv_checkpoint/097-0.0297.hdf5\n",
      "81/81 [==============================] - 23s 282ms/step - loss: 0.0526 - acc: 0.9801 - val_loss: 0.0297 - val_acc: 0.9875\n",
      "Epoch 98/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0531 - acc: 0.9862WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0680 - acc: 0.9803\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.02965\n",
      "81/81 [==============================] - 22s 266ms/step - loss: 0.0526 - acc: 0.9863 - val_loss: 0.0680 - val_acc: 0.9803\n",
      "Epoch 99/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0350 - acc: 0.9899WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 24s 8ms/sample - loss: 0.0631 - acc: 0.9809\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.02965\n",
      "81/81 [==============================] - 29s 360ms/step - loss: 0.0351 - acc: 0.9898 - val_loss: 0.0631 - val_acc: 0.9809\n",
      "Epoch 100/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0411 - acc: 0.9892WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0956 - acc: 0.9625\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.02965\n",
      "81/81 [==============================] - 23s 285ms/step - loss: 0.0408 - acc: 0.9891 - val_loss: 0.0956 - val_acc: 0.9625\n",
      "Epoch 101/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0411 - acc: 0.9844WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0501 - acc: 0.9887\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 0.02965\n",
      "81/81 [==============================] - 22s 270ms/step - loss: 0.0410 - acc: 0.9842 - val_loss: 0.0501 - val_acc: 0.9887\n",
      "Epoch 102/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0438 - acc: 0.9815WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 29s 9ms/sample - loss: 0.0506 - acc: 0.9875\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 0.02965\n",
      "81/81 [==============================] - 35s 436ms/step - loss: 0.0446 - acc: 0.9814 - val_loss: 0.0506 - val_acc: 0.9875\n",
      "Epoch 103/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0453 - acc: 0.9831WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.0532 - acc: 0.9800\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 0.02965\n",
      "81/81 [==============================] - 20s 250ms/step - loss: 0.0444 - acc: 0.9836 - val_loss: 0.0532 - val_acc: 0.9800\n",
      "Epoch 104/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0430 - acc: 0.9898WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.0408 - acc: 0.9859\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 0.02965\n",
      "81/81 [==============================] - 23s 289ms/step - loss: 0.0424 - acc: 0.9898 - val_loss: 0.0408 - val_acc: 0.9859\n",
      "Epoch 105/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0411 - acc: 0.9862WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0350 - acc: 0.9900\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 0.02965\n",
      "81/81 [==============================] - 24s 302ms/step - loss: 0.0407 - acc: 0.9863 - val_loss: 0.0350 - val_acc: 0.9900\n",
      "Epoch 106/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0468 - acc: 0.9859WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3200/3183 [==============================] - 20s 6ms/sample - loss: 0.0471 - acc: 0.9825\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 0.02965\n",
      "81/81 [==============================] - 23s 290ms/step - loss: 0.0464 - acc: 0.9860 - val_loss: 0.0471 - val_acc: 0.9825\n",
      "Epoch 107/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0408 - acc: 0.9852WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 21s 7ms/sample - loss: 0.0607 - acc: 0.9750\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 0.02965\n",
      "81/81 [==============================] - 25s 311ms/step - loss: 0.0406 - acc: 0.9851 - val_loss: 0.0607 - val_acc: 0.9750\n",
      "Epoch 108/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0372 - acc: 0.9870WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0511 - acc: 0.9825\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 0.02965\n",
      "81/81 [==============================] - 23s 284ms/step - loss: 0.0371 - acc: 0.9870 - val_loss: 0.0511 - val_acc: 0.9825\n",
      "Epoch 109/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0390 - acc: 0.9863WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 20s 6ms/sample - loss: 0.0480 - acc: 0.9825\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 0.02965\n",
      "81/81 [==============================] - 24s 297ms/step - loss: 0.0384 - acc: 0.9863 - val_loss: 0.0480 - val_acc: 0.9825\n",
      "Epoch 110/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0399 - acc: 0.9901WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 5ms/sample - loss: 0.0321 - acc: 0.9900\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 0.02965\n",
      "81/81 [==============================] - 22s 269ms/step - loss: 0.0415 - acc: 0.9891 - val_loss: 0.0321 - val_acc: 0.9900\n",
      "Epoch 111/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0410 - acc: 0.9889WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.0586 - acc: 0.9844\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 0.02965\n",
      "81/81 [==============================] - 22s 274ms/step - loss: 0.0411 - acc: 0.9888 - val_loss: 0.0586 - val_acc: 0.9844\n",
      "Epoch 112/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0487 - acc: 0.9854WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0370 - acc: 0.9909\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 0.02965\n",
      "81/81 [==============================] - 22s 274ms/step - loss: 0.0486 - acc: 0.9851 - val_loss: 0.0370 - val_acc: 0.9909\n",
      "Epoch 113/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0247 - acc: 0.9934WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 20s 6ms/sample - loss: 0.0640 - acc: 0.9747\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 0.02965\n",
      "81/81 [==============================] - 24s 297ms/step - loss: 0.0246 - acc: 0.9935 - val_loss: 0.0640 - val_acc: 0.9747\n",
      "Epoch 114/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0237 - acc: 0.9917WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0567 - acc: 0.9784\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 0.02965\n",
      "81/81 [==============================] - 22s 267ms/step - loss: 0.0232 - acc: 0.9919 - val_loss: 0.0567 - val_acc: 0.9784\n",
      "Epoch 115/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0345 - acc: 0.9889WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 20s 6ms/sample - loss: 0.0384 - acc: 0.9869\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 0.02965\n",
      "81/81 [==============================] - 28s 349ms/step - loss: 0.0345 - acc: 0.9888 - val_loss: 0.0384 - val_acc: 0.9869\n",
      "Epoch 116/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0658 - acc: 0.9780WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0532 - acc: 0.9825\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 0.02965\n",
      "81/81 [==============================] - 22s 276ms/step - loss: 0.0654 - acc: 0.9783 - val_loss: 0.0532 - val_acc: 0.9825\n",
      "Epoch 117/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0393 - acc: 0.9877WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0338 - acc: 0.9900\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 0.02965\n",
      "81/81 [==============================] - 23s 281ms/step - loss: 0.0391 - acc: 0.9879 - val_loss: 0.0338 - val_acc: 0.9900\n",
      "Epoch 118/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0365 - acc: 0.9874WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.0317 - acc: 0.9900\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 0.02965\n",
      "81/81 [==============================] - 21s 262ms/step - loss: 0.0362 - acc: 0.9876 - val_loss: 0.0317 - val_acc: 0.9900\n",
      "Epoch 119/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0309 - acc: 0.9917WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 21s 7ms/sample - loss: 0.0322 - acc: 0.9881\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 0.02965\n",
      "81/81 [==============================] - 26s 319ms/step - loss: 0.0320 - acc: 0.9910 - val_loss: 0.0322 - val_acc: 0.9881\n",
      "Epoch 120/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0437 - acc: 0.9843WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0346 - acc: 0.9850\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 0.02965\n",
      "81/81 [==============================] - 25s 315ms/step - loss: 0.0434 - acc: 0.9845 - val_loss: 0.0346 - val_acc: 0.9850\n",
      "Epoch 121/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0403 - acc: 0.9855WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0363 - acc: 0.9891\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 0.02965\n",
      "81/81 [==============================] - 27s 339ms/step - loss: 0.0400 - acc: 0.9857 - val_loss: 0.0363 - val_acc: 0.9891\n",
      "Epoch 122/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/81 [============================>.] - ETA: 0s - loss: 0.0475 - acc: 0.9824WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.0297 - acc: 0.9925\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 0.02965\n",
      "81/81 [==============================] - 24s 300ms/step - loss: 0.0482 - acc: 0.9823 - val_loss: 0.0297 - val_acc: 0.9925\n",
      "Epoch 123/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0317 - acc: 0.9908WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0398 - acc: 0.9884\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 0.02965\n",
      "81/81 [==============================] - 22s 274ms/step - loss: 0.0311 - acc: 0.9910 - val_loss: 0.0398 - val_acc: 0.9884\n",
      "Epoch 124/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0227 - acc: 0.9918- WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 21s 6ms/sample - loss: 0.0322 - acc: 0.9925\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 0.02965\n",
      "81/81 [==============================] - 25s 308ms/step - loss: 0.0241 - acc: 0.9913 - val_loss: 0.0322 - val_acc: 0.9925\n",
      "Epoch 125/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0311 - acc: 0.9899WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0432 - acc: 0.9850\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 0.02965\n",
      "81/81 [==============================] - 24s 295ms/step - loss: 0.0318 - acc: 0.9898 - val_loss: 0.0432 - val_acc: 0.9850\n",
      "Epoch 126/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0292 - acc: 0.9917WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0354 - acc: 0.9919\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 0.02965\n",
      "81/81 [==============================] - 24s 290ms/step - loss: 0.0301 - acc: 0.9913 - val_loss: 0.0354 - val_acc: 0.9919\n",
      "Epoch 127/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0267 - acc: 0.9899- ETA: 0s - loss: 0.0267 - acc:WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 20s 6ms/sample - loss: 0.0444 - acc: 0.9887\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 0.02965\n",
      "81/81 [==============================] - 24s 296ms/step - loss: 0.0265 - acc: 0.9901 - val_loss: 0.0444 - val_acc: 0.9887\n",
      "Epoch 128/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0318 - acc: 0.9903WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0424 - acc: 0.9891\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 0.02965\n",
      "81/81 [==============================] - 22s 275ms/step - loss: 0.0315 - acc: 0.9904 - val_loss: 0.0424 - val_acc: 0.9891\n",
      "Epoch 129/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0233 - acc: 0.9927WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.0504 - acc: 0.9887\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 0.02965\n",
      "81/81 [==============================] - 23s 283ms/step - loss: 0.0229 - acc: 0.9929 - val_loss: 0.0504 - val_acc: 0.9887\n",
      "Epoch 130/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0168 - acc: 0.9943WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 15s 5ms/sample - loss: 0.0457 - acc: 0.9866\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 0.02965\n",
      "81/81 [==============================] - 21s 253ms/step - loss: 0.0169 - acc: 0.9944 - val_loss: 0.0457 - val_acc: 0.9866\n",
      "Epoch 131/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0309 - acc: 0.9896WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0385 - acc: 0.9944\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 0.02965\n",
      "81/81 [==============================] - 22s 269ms/step - loss: 0.0310 - acc: 0.9898 - val_loss: 0.0385 - val_acc: 0.9944\n",
      "Epoch 132/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0332 - acc: 0.9890WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 24s 7ms/sample - loss: 0.0313 - acc: 0.9900\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 0.02965\n",
      "81/81 [==============================] - 29s 361ms/step - loss: 0.0332 - acc: 0.9891 - val_loss: 0.0313 - val_acc: 0.9900\n",
      "Epoch 133/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0333 - acc: 0.9877WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.0589 - acc: 0.9809\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 0.02965\n",
      "81/81 [==============================] - 24s 291ms/step - loss: 0.0331 - acc: 0.9879 - val_loss: 0.0589 - val_acc: 0.9809\n",
      "Epoch 134/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0225 - acc: 0.9933WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 20s 6ms/sample - loss: 0.1075 - acc: 0.9616\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 0.02965\n",
      "81/81 [==============================] - 23s 289ms/step - loss: 0.0226 - acc: 0.9932 - val_loss: 0.1075 - val_acc: 0.9616\n",
      "Epoch 135/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0161 - acc: 0.9959WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0449 - acc: 0.9875\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 0.02965\n",
      "81/81 [==============================] - 23s 281ms/step - loss: 0.0168 - acc: 0.9957 - val_loss: 0.0449 - val_acc: 0.9875\n",
      "Epoch 136/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0276 - acc: 0.9917WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 15s 5ms/sample - loss: 0.0320 - acc: 0.9875\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 0.02965\n",
      "81/81 [==============================] - 22s 267ms/step - loss: 0.0274 - acc: 0.9916 - val_loss: 0.0320 - val_acc: 0.9875\n",
      "Epoch 137/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0296 - acc: 0.9896WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0317 - acc: 0.9881\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 0.02965\n",
      "81/81 [==============================] - 23s 285ms/step - loss: 0.0297 - acc: 0.9894 - val_loss: 0.0317 - val_acc: 0.9881\n",
      "Epoch 138/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0259 - acc: 0.9940WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0443 - acc: 0.9856\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 0.02965\n",
      "81/81 [==============================] - 23s 279ms/step - loss: 0.0259 - acc: 0.9938 - val_loss: 0.0443 - val_acc: 0.9856\n",
      "Epoch 139/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0303 - acc: 0.9879- ETA: 2s - loss: 0.03WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 23s 7ms/sample - loss: 0.0305 - acc: 0.9900\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 0.02965\n",
      "81/81 [==============================] - 29s 364ms/step - loss: 0.0301 - acc: 0.9879 - val_loss: 0.0305 - val_acc: 0.9900\n",
      "Epoch 140/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0191 - acc: 0.9930WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0417 - acc: 0.9825\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 0.02965\n",
      "81/81 [==============================] - 22s 274ms/step - loss: 0.0187 - acc: 0.9932 - val_loss: 0.0417 - val_acc: 0.9825\n",
      "Epoch 141/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0251 - acc: 0.9920WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 26s 8ms/sample - loss: 0.0342 - acc: 0.9866\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 0.02965\n",
      "81/81 [==============================] - 30s 371ms/step - loss: 0.0249 - acc: 0.9919 - val_loss: 0.0342 - val_acc: 0.9866\n",
      "Epoch 142/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0241 - acc: 0.9934WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0238 - acc: 0.9925\n",
      "\n",
      "Epoch 00142: val_loss improved from 0.02965 to 0.02378, saving model to model/checkpoint/vis_imagenet_6_class_augmentation_2D_CNN_custom_ch_32_DO_075_DO_5_conv_checkpoint/142-0.0238.hdf5\n",
      "81/81 [==============================] - 26s 327ms/step - loss: 0.0241 - acc: 0.9935 - val_loss: 0.0238 - val_acc: 0.9925\n",
      "Epoch 143/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0270 - acc: 0.9931WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 22s 7ms/sample - loss: 0.0365 - acc: 0.9869\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 0.02378\n",
      "81/81 [==============================] - 26s 323ms/step - loss: 0.0268 - acc: 0.9932 - val_loss: 0.0365 - val_acc: 0.9869\n",
      "Epoch 144/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0228 - acc: 0.9947WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0451 - acc: 0.9825\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 0.02378\n",
      "81/81 [==============================] - 22s 276ms/step - loss: 0.0226 - acc: 0.9947 - val_loss: 0.0451 - val_acc: 0.9825\n",
      "Epoch 145/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0244 - acc: 0.9915WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0293 - acc: 0.9950\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 0.02378\n",
      "81/81 [==============================] - 23s 285ms/step - loss: 0.0242 - acc: 0.9916 - val_loss: 0.0293 - val_acc: 0.9950\n",
      "Epoch 146/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0183 - acc: 0.9950WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0385 - acc: 0.9819\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 0.02378\n",
      "81/81 [==============================] - 21s 261ms/step - loss: 0.0182 - acc: 0.9950 - val_loss: 0.0385 - val_acc: 0.9819\n",
      "Epoch 147/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0158 - acc: 0.9969WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0298 - acc: 0.9925\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 0.02378\n",
      "81/81 [==============================] - 23s 279ms/step - loss: 0.0157 - acc: 0.9969 - val_loss: 0.0298 - val_acc: 0.9925\n",
      "Epoch 148/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0221 - acc: 0.9930WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0252 - acc: 0.9925\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 0.02378\n",
      "81/81 [==============================] - 23s 285ms/step - loss: 0.0217 - acc: 0.9932 - val_loss: 0.0252 - val_acc: 0.9925\n",
      "Epoch 149/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0416 - acc: 0.9855WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0328 - acc: 0.9922\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 0.02378\n",
      "81/81 [==============================] - 23s 281ms/step - loss: 0.0412 - acc: 0.9857 - val_loss: 0.0328 - val_acc: 0.9922\n",
      "Epoch 150/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0169 - acc: 0.9946WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.0732 - acc: 0.9756\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 0.02378\n",
      "81/81 [==============================] - 23s 280ms/step - loss: 0.0171 - acc: 0.9944 - val_loss: 0.0732 - val_acc: 0.9756\n",
      "Epoch 151/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0237 - acc: 0.9937WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.0212 - acc: 0.9950\n",
      "\n",
      "Epoch 00151: val_loss improved from 0.02378 to 0.02116, saving model to model/checkpoint/vis_imagenet_6_class_augmentation_2D_CNN_custom_ch_32_DO_075_DO_5_conv_checkpoint/151-0.0212.hdf5\n",
      "81/81 [==============================] - 25s 304ms/step - loss: 0.0235 - acc: 0.9938 - val_loss: 0.0212 - val_acc: 0.9950\n",
      "Epoch 152/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0188 - acc: 0.9928WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0338 - acc: 0.9894\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 0.02116\n",
      "81/81 [==============================] - 25s 307ms/step - loss: 0.0186 - acc: 0.9929 - val_loss: 0.0338 - val_acc: 0.9894\n",
      "Epoch 153/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0223 - acc: 0.9936WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0465 - acc: 0.9850\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 0.02116\n",
      "81/81 [==============================] - 22s 266ms/step - loss: 0.0218 - acc: 0.9938 - val_loss: 0.0465 - val_acc: 0.9850\n",
      "Epoch 154/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0163 - acc: 0.9959WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0499 - acc: 0.9794\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 0.02116\n",
      "81/81 [==============================] - 22s 267ms/step - loss: 0.0161 - acc: 0.9960 - val_loss: 0.0499 - val_acc: 0.9794\n",
      "Epoch 155/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0336 - acc: 0.9862WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0358 - acc: 0.9937\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 0.02116\n",
      "81/81 [==============================] - 22s 270ms/step - loss: 0.0333 - acc: 0.9863 - val_loss: 0.0358 - val_acc: 0.9937\n",
      "Epoch 156/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0136 - acc: 0.9965WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0301 - acc: 0.9850\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 0.02116\n",
      "81/81 [==============================] - 21s 261ms/step - loss: 0.0136 - acc: 0.9963 - val_loss: 0.0301 - val_acc: 0.9850\n",
      "Epoch 157/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0451 - acc: 0.9835WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0554 - acc: 0.9784\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 0.02116\n",
      "81/81 [==============================] - 22s 273ms/step - loss: 0.0463 - acc: 0.9836 - val_loss: 0.0554 - val_acc: 0.9784\n",
      "Epoch 158/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0384 - acc: 0.9898WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0312 - acc: 0.9825\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 0.02116\n",
      "81/81 [==============================] - 22s 274ms/step - loss: 0.0375 - acc: 0.9901 - val_loss: 0.0312 - val_acc: 0.9825\n",
      "Epoch 159/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0214 - acc: 0.9921WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0292 - acc: 0.9925\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 0.02116\n",
      "81/81 [==============================] - 22s 269ms/step - loss: 0.0214 - acc: 0.9922 - val_loss: 0.0292 - val_acc: 0.9925\n",
      "Epoch 160/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0189 - acc: 0.9956WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.0406 - acc: 0.9925\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 0.02116\n",
      "81/81 [==============================] - 21s 262ms/step - loss: 0.0190 - acc: 0.9957 - val_loss: 0.0406 - val_acc: 0.9925\n",
      "Epoch 161/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0310 - acc: 0.9912WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0400 - acc: 0.9850\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 0.02116\n",
      "81/81 [==============================] - 22s 270ms/step - loss: 0.0307 - acc: 0.9913 - val_loss: 0.0400 - val_acc: 0.9850\n",
      "Epoch 162/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0158 - acc: 0.9940WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0265 - acc: 0.9937\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 0.02116\n",
      "81/81 [==============================] - 22s 269ms/step - loss: 0.0154 - acc: 0.9941 - val_loss: 0.0265 - val_acc: 0.9937\n",
      "Epoch 163/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0124 - acc: 0.9962WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 13s 4ms/sample - loss: 0.0354 - acc: 0.9925\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 0.02116\n",
      "81/81 [==============================] - 22s 266ms/step - loss: 0.0148 - acc: 0.9957 - val_loss: 0.0354 - val_acc: 0.9925\n",
      "Epoch 164/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0282 - acc: 0.9921WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0365 - acc: 0.9900\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 0.02116\n",
      "81/81 [==============================] - 22s 273ms/step - loss: 0.0285 - acc: 0.9922 - val_loss: 0.0365 - val_acc: 0.9900\n",
      "Epoch 165/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0155 - acc: 0.9943WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 15s 5ms/sample - loss: 0.0380 - acc: 0.9912\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 0.02116\n",
      "81/81 [==============================] - 23s 285ms/step - loss: 0.0155 - acc: 0.9941 - val_loss: 0.0380 - val_acc: 0.9912\n",
      "Epoch 166/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0258 - acc: 0.9931WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 20s 6ms/sample - loss: 0.0247 - acc: 0.9925\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 0.02116\n",
      "81/81 [==============================] - 27s 336ms/step - loss: 0.0255 - acc: 0.9932 - val_loss: 0.0247 - val_acc: 0.9925\n",
      "Epoch 167/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0197 - acc: 0.9955WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0377 - acc: 0.9881\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 0.02116\n",
      "81/81 [==============================] - 23s 287ms/step - loss: 0.0195 - acc: 0.9957 - val_loss: 0.0377 - val_acc: 0.9881\n",
      "Epoch 168/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/81 [============================>.] - ETA: 0s - loss: 0.0179 - acc: 0.9953WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 22s 7ms/sample - loss: 0.0436 - acc: 0.9825\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 0.02116\n",
      "81/81 [==============================] - 26s 318ms/step - loss: 0.0178 - acc: 0.9953 - val_loss: 0.0436 - val_acc: 0.9825\n",
      "Epoch 169/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0238 - acc: 0.9912WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0359 - acc: 0.9900\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 0.02116\n",
      "81/81 [==============================] - 23s 288ms/step - loss: 0.0236 - acc: 0.9913 - val_loss: 0.0359 - val_acc: 0.9900\n",
      "Epoch 170/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0106 - acc: 0.9965WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.0311 - acc: 0.9950\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 0.02116\n",
      "81/81 [==============================] - 21s 264ms/step - loss: 0.0106 - acc: 0.9966 - val_loss: 0.0311 - val_acc: 0.9950\n",
      "Epoch 171/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0155 - acc: 0.9952WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.0365 - acc: 0.9931\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 0.02116\n",
      "81/81 [==============================] - 21s 265ms/step - loss: 0.0152 - acc: 0.9953 - val_loss: 0.0365 - val_acc: 0.9931\n",
      "Epoch 172/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0163 - acc: 0.9956WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0320 - acc: 0.9925\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 0.02116\n",
      "81/81 [==============================] - 22s 266ms/step - loss: 0.0162 - acc: 0.9957 - val_loss: 0.0320 - val_acc: 0.9925\n",
      "Epoch 173/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0306 - acc: 0.9901WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0267 - acc: 0.9950\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 0.02116\n",
      "81/81 [==============================] - 21s 262ms/step - loss: 0.0299 - acc: 0.9904 - val_loss: 0.0267 - val_acc: 0.9950\n",
      "Epoch 174/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0294 - acc: 0.9903WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0634 - acc: 0.9753\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 0.02116\n",
      "81/81 [==============================] - 22s 266ms/step - loss: 0.0292 - acc: 0.9904 - val_loss: 0.0634 - val_acc: 0.9753\n",
      "Epoch 175/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0263 - acc: 0.9908WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 22s 7ms/sample - loss: 0.0323 - acc: 0.9937\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 0.02116\n",
      "81/81 [==============================] - 28s 340ms/step - loss: 0.0264 - acc: 0.9907 - val_loss: 0.0323 - val_acc: 0.9937\n",
      "Epoch 176/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0180 - acc: 0.9933WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0207 - acc: 0.9941\n",
      "\n",
      "Epoch 00176: val_loss improved from 0.02116 to 0.02069, saving model to model/checkpoint/vis_imagenet_6_class_augmentation_2D_CNN_custom_ch_32_DO_075_DO_5_conv_checkpoint/176-0.0207.hdf5\n",
      "81/81 [==============================] - 23s 286ms/step - loss: 0.0178 - acc: 0.9935 - val_loss: 0.0207 - val_acc: 0.9941\n",
      "Epoch 177/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0165 - acc: 0.9934WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0389 - acc: 0.9900\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 0.02069\n",
      "81/81 [==============================] - 23s 284ms/step - loss: 0.0169 - acc: 0.9932 - val_loss: 0.0389 - val_acc: 0.9900\n",
      "Epoch 178/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0204 - acc: 0.9940WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 20s 6ms/sample - loss: 0.0342 - acc: 0.9837\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 0.02069\n",
      "81/81 [==============================] - 25s 310ms/step - loss: 0.0206 - acc: 0.9938 - val_loss: 0.0342 - val_acc: 0.9837\n",
      "Epoch 179/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0135 - acc: 0.9955WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0209 - acc: 0.9925\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 0.02069\n",
      "81/81 [==============================] - 22s 267ms/step - loss: 0.0165 - acc: 0.9950 - val_loss: 0.0209 - val_acc: 0.9925\n",
      "Epoch 180/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0178 - acc: 0.9928WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0554 - acc: 0.9750\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 0.02069\n",
      "81/81 [==============================] - 22s 267ms/step - loss: 0.0176 - acc: 0.9929 - val_loss: 0.0554 - val_acc: 0.9750\n",
      "Epoch 181/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0198 - acc: 0.9934WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 15s 5ms/sample - loss: 0.0289 - acc: 0.9950\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 0.02069\n",
      "81/81 [==============================] - 22s 266ms/step - loss: 0.0197 - acc: 0.9935 - val_loss: 0.0289 - val_acc: 0.9950\n",
      "Epoch 182/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0208 - acc: 0.9940WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0265 - acc: 0.9900\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 0.02069\n",
      "81/81 [==============================] - 22s 266ms/step - loss: 0.0206 - acc: 0.9941 - val_loss: 0.0265 - val_acc: 0.9900\n",
      "Epoch 183/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0234 - acc: 0.9936WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3200/3183 [==============================] - 20s 6ms/sample - loss: 0.0354 - acc: 0.9950\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 0.02069\n",
      "81/81 [==============================] - 25s 306ms/step - loss: 0.0236 - acc: 0.9935 - val_loss: 0.0354 - val_acc: 0.9950\n",
      "Epoch 184/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0173 - acc: 0.9947WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0313 - acc: 0.9884\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 0.02069\n",
      "81/81 [==============================] - 24s 300ms/step - loss: 0.0171 - acc: 0.9947 - val_loss: 0.0313 - val_acc: 0.9884\n",
      "Epoch 185/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0145 - acc: 0.9949WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0253 - acc: 0.9937\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 0.02069\n",
      "81/81 [==============================] - 23s 281ms/step - loss: 0.0143 - acc: 0.9950 - val_loss: 0.0253 - val_acc: 0.9937\n",
      "Epoch 186/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0241 - acc: 0.9915WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.0253 - acc: 0.9931\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 0.02069\n",
      "81/81 [==============================] - 22s 276ms/step - loss: 0.0242 - acc: 0.9913 - val_loss: 0.0253 - val_acc: 0.9931\n",
      "Epoch 187/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0304 - acc: 0.9895WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.0163 - acc: 0.9950\n",
      "\n",
      "Epoch 00187: val_loss improved from 0.02069 to 0.01627, saving model to model/checkpoint/vis_imagenet_6_class_augmentation_2D_CNN_custom_ch_32_DO_075_DO_5_conv_checkpoint/187-0.0163.hdf5\n",
      "81/81 [==============================] - 22s 273ms/step - loss: 0.0304 - acc: 0.9894 - val_loss: 0.0163 - val_acc: 0.9950\n",
      "Epoch 188/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0177 - acc: 0.9949WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0199 - acc: 0.9950\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 0.01627\n",
      "81/81 [==============================] - 22s 268ms/step - loss: 0.0175 - acc: 0.9950 - val_loss: 0.0199 - val_acc: 0.9950\n",
      "Epoch 189/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0130 - acc: 0.9975WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0272 - acc: 0.9944\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 0.01627\n",
      "81/81 [==============================] - 23s 290ms/step - loss: 0.0129 - acc: 0.9975 - val_loss: 0.0272 - val_acc: 0.9944\n",
      "Epoch 190/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0132 - acc: 0.9975WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0211 - acc: 0.9950\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 0.01627\n",
      "81/81 [==============================] - 21s 263ms/step - loss: 0.0131 - acc: 0.9975 - val_loss: 0.0211 - val_acc: 0.9950\n",
      "Epoch 191/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0175 - acc: 0.9947WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 22s 7ms/sample - loss: 0.0287 - acc: 0.9891\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 0.01627\n",
      "81/81 [==============================] - 26s 316ms/step - loss: 0.0173 - acc: 0.9947 - val_loss: 0.0287 - val_acc: 0.9891\n",
      "Epoch 192/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0192 - acc: 0.9937WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0232 - acc: 0.9931\n",
      "\n",
      "Epoch 00192: val_loss did not improve from 0.01627\n",
      "81/81 [==============================] - 21s 264ms/step - loss: 0.0190 - acc: 0.9938 - val_loss: 0.0232 - val_acc: 0.9931\n",
      "Epoch 193/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0179 - acc: 0.9959WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0463 - acc: 0.9875\n",
      "\n",
      "Epoch 00193: val_loss did not improve from 0.01627\n",
      "81/81 [==============================] - 21s 257ms/step - loss: 0.0184 - acc: 0.9957 - val_loss: 0.0463 - val_acc: 0.9875\n",
      "Epoch 194/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0120 - acc: 0.9972WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0229 - acc: 0.9944\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 0.01627\n",
      "81/81 [==============================] - 22s 276ms/step - loss: 0.0119 - acc: 0.9972 - val_loss: 0.0229 - val_acc: 0.9944\n",
      "Epoch 195/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0119 - acc: 0.9968WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0413 - acc: 0.9891\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 0.01627\n",
      "81/81 [==============================] - 22s 277ms/step - loss: 0.0117 - acc: 0.9969 - val_loss: 0.0413 - val_acc: 0.9891\n",
      "Epoch 196/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0125 - acc: 0.9959WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0318 - acc: 0.9925\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 0.01627\n",
      "81/81 [==============================] - 22s 271ms/step - loss: 0.0132 - acc: 0.9953 - val_loss: 0.0318 - val_acc: 0.9925\n",
      "Epoch 197/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0151 - acc: 0.9959WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 20s 6ms/sample - loss: 0.0257 - acc: 0.9931\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 0.01627\n",
      "81/81 [==============================] - 24s 292ms/step - loss: 0.0158 - acc: 0.9957 - val_loss: 0.0257 - val_acc: 0.9931\n",
      "Epoch 198/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0147 - acc: 0.9959WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0402 - acc: 0.9809\n",
      "\n",
      "Epoch 00198: val_loss did not improve from 0.01627\n",
      "81/81 [==============================] - 22s 269ms/step - loss: 0.0144 - acc: 0.9960 - val_loss: 0.0402 - val_acc: 0.9809\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 199/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0192 - acc: 0.9934WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0186 - acc: 0.9875\n",
      "\n",
      "Epoch 00199: val_loss did not improve from 0.01627\n",
      "81/81 [==============================] - 22s 271ms/step - loss: 0.0191 - acc: 0.9935 - val_loss: 0.0186 - val_acc: 0.9875\n",
      "Epoch 200/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0280 - acc: 0.9918WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0196 - acc: 0.9922\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 0.01627\n",
      "81/81 [==============================] - 23s 282ms/step - loss: 0.0277 - acc: 0.9919 - val_loss: 0.0196 - val_acc: 0.9922\n",
      "Epoch 201/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0117 - acc: 0.9971WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 20s 6ms/sample - loss: 0.0180 - acc: 0.9900\n",
      "\n",
      "Epoch 00201: val_loss did not improve from 0.01627\n",
      "81/81 [==============================] - 27s 334ms/step - loss: 0.0115 - acc: 0.9972 - val_loss: 0.0180 - val_acc: 0.9900\n",
      "Epoch 202/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0162 - acc: 0.9952WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0277 - acc: 0.9850\n",
      "\n",
      "Epoch 00202: val_loss did not improve from 0.01627\n",
      "81/81 [==============================] - 22s 272ms/step - loss: 0.0159 - acc: 0.9953 - val_loss: 0.0277 - val_acc: 0.9850\n",
      "Epoch 203/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0120 - acc: 0.9952WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 20s 6ms/sample - loss: 0.0179 - acc: 0.9947\n",
      "\n",
      "Epoch 00203: val_loss did not improve from 0.01627\n",
      "81/81 [==============================] - 24s 290ms/step - loss: 0.0117 - acc: 0.9953 - val_loss: 0.0179 - val_acc: 0.9947\n",
      "Epoch 204/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0231 - acc: 0.9911WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 21s 7ms/sample - loss: 0.0266 - acc: 0.9909\n",
      "\n",
      "Epoch 00204: val_loss did not improve from 0.01627\n",
      "81/81 [==============================] - 25s 313ms/step - loss: 0.0239 - acc: 0.9901 - val_loss: 0.0266 - val_acc: 0.9909\n",
      "Epoch 205/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0276 - acc: 0.9931WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 14s 4ms/sample - loss: 0.0100 - acc: 1.0000\n",
      "\n",
      "Epoch 00205: val_loss improved from 0.01627 to 0.00998, saving model to model/checkpoint/vis_imagenet_6_class_augmentation_2D_CNN_custom_ch_32_DO_075_DO_5_conv_checkpoint/205-0.0100.hdf5\n",
      "81/81 [==============================] - 22s 272ms/step - loss: 0.0277 - acc: 0.9929 - val_loss: 0.0100 - val_acc: 1.0000\n",
      "Epoch 206/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0160 - acc: 0.9955WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 14s 4ms/sample - loss: 0.0227 - acc: 0.9925\n",
      "\n",
      "Epoch 00206: val_loss did not improve from 0.00998\n",
      "81/81 [==============================] - 23s 287ms/step - loss: 0.0157 - acc: 0.9957 - val_loss: 0.0227 - val_acc: 0.9925\n",
      "Epoch 207/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0125 - acc: 0.9981WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.0320 - acc: 0.9862\n",
      "\n",
      "Epoch 00207: val_loss did not improve from 0.00998\n",
      "81/81 [==============================] - 23s 278ms/step - loss: 0.0122 - acc: 0.9981 - val_loss: 0.0320 - val_acc: 0.9862\n",
      "Epoch 208/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0087 - acc: 0.9971WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0231 - acc: 0.9937\n",
      "\n",
      "Epoch 00208: val_loss did not improve from 0.00998\n",
      "81/81 [==============================] - 21s 264ms/step - loss: 0.0086 - acc: 0.9972 - val_loss: 0.0231 - val_acc: 0.9937\n",
      "Epoch 209/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0141 - acc: 0.9955WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0068 - acc: 0.9975\n",
      "\n",
      "Epoch 00209: val_loss improved from 0.00998 to 0.00682, saving model to model/checkpoint/vis_imagenet_6_class_augmentation_2D_CNN_custom_ch_32_DO_075_DO_5_conv_checkpoint/209-0.0068.hdf5\n",
      "81/81 [==============================] - 23s 282ms/step - loss: 0.0143 - acc: 0.9953 - val_loss: 0.0068 - val_acc: 0.9975\n",
      "Epoch 210/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0144 - acc: 0.9975WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0109 - acc: 0.9975\n",
      "\n",
      "Epoch 00210: val_loss did not improve from 0.00682\n",
      "81/81 [==============================] - 23s 285ms/step - loss: 0.0143 - acc: 0.9975 - val_loss: 0.0109 - val_acc: 0.9975\n",
      "Epoch 211/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0148 - acc: 0.9962WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0252 - acc: 0.9950\n",
      "\n",
      "Epoch 00211: val_loss did not improve from 0.00682\n",
      "81/81 [==============================] - 21s 264ms/step - loss: 0.0149 - acc: 0.9960 - val_loss: 0.0252 - val_acc: 0.9950\n",
      "Epoch 212/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0138 - acc: 0.9965WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 15s 5ms/sample - loss: 0.0327 - acc: 0.9919\n",
      "\n",
      "Epoch 00212: val_loss did not improve from 0.00682\n",
      "81/81 [==============================] - 23s 284ms/step - loss: 0.0145 - acc: 0.9963 - val_loss: 0.0327 - val_acc: 0.9919\n",
      "Epoch 213/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0172 - acc: 0.9953WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0286 - acc: 0.99169s - loss: 0.04\n",
      "\n",
      "Epoch 00213: val_loss did not improve from 0.00682\n",
      "81/81 [==============================] - 23s 283ms/step - loss: 0.0181 - acc: 0.9950 - val_loss: 0.0286 - val_acc: 0.9916\n",
      "Epoch 214/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/81 [============================>.] - ETA: 0s - loss: 0.0151 - acc: 0.9950WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.0327 - acc: 0.9834\n",
      "\n",
      "Epoch 00214: val_loss did not improve from 0.00682\n",
      "81/81 [==============================] - 22s 276ms/step - loss: 0.0150 - acc: 0.9950 - val_loss: 0.0327 - val_acc: 0.9834\n",
      "Epoch 215/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0133 - acc: 0.9965WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.0404 - acc: 0.9825\n",
      "\n",
      "Epoch 00215: val_loss did not improve from 0.00682\n",
      "81/81 [==============================] - 23s 290ms/step - loss: 0.0131 - acc: 0.9966 - val_loss: 0.0404 - val_acc: 0.9825\n",
      "Epoch 216/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0102 - acc: 0.9968WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0244 - acc: 0.9912\n",
      "\n",
      "Epoch 00216: val_loss did not improve from 0.00682\n",
      "81/81 [==============================] - 22s 271ms/step - loss: 0.0100 - acc: 0.9969 - val_loss: 0.0244 - val_acc: 0.9912\n",
      "Epoch 217/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0109 - acc: 0.9959WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0234 - acc: 0.9975\n",
      "\n",
      "Epoch 00217: val_loss did not improve from 0.00682\n",
      "81/81 [==============================] - 22s 272ms/step - loss: 0.0108 - acc: 0.9960 - val_loss: 0.0234 - val_acc: 0.9975\n",
      "Epoch 218/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0135 - acc: 0.9959WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0321 - acc: 0.9941\n",
      "\n",
      "Epoch 00218: val_loss did not improve from 0.00682\n",
      "81/81 [==============================] - 23s 279ms/step - loss: 0.0133 - acc: 0.9960 - val_loss: 0.0321 - val_acc: 0.9941\n",
      "Epoch 219/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0113 - acc: 0.9972WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0296 - acc: 0.9944\n",
      "\n",
      "Epoch 00219: val_loss did not improve from 0.00682\n",
      "81/81 [==============================] - 22s 272ms/step - loss: 0.0112 - acc: 0.9972 - val_loss: 0.0296 - val_acc: 0.9944\n",
      "Epoch 220/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0109 - acc: 0.9978WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0279 - acc: 0.9950\n",
      "\n",
      "Epoch 00220: val_loss did not improve from 0.00682\n",
      "81/81 [==============================] - 22s 271ms/step - loss: 0.0107 - acc: 0.9978 - val_loss: 0.0279 - val_acc: 0.9950\n",
      "Epoch 221/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0097 - acc: 0.9972WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0485 - acc: 0.9812\n",
      "\n",
      "Epoch 00221: val_loss did not improve from 0.00682\n",
      "81/81 [==============================] - 23s 284ms/step - loss: 0.0096 - acc: 0.9972 - val_loss: 0.0485 - val_acc: 0.9812\n",
      "Epoch 222/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0090 - acc: 0.9984WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0413 - acc: 0.9919\n",
      "\n",
      "Epoch 00222: val_loss did not improve from 0.00682\n",
      "81/81 [==============================] - 23s 286ms/step - loss: 0.0089 - acc: 0.9984 - val_loss: 0.0413 - val_acc: 0.9919\n",
      "Epoch 223/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0175 - acc: 0.9953WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0291 - acc: 0.9944\n",
      "\n",
      "Epoch 00223: val_loss did not improve from 0.00682\n",
      "81/81 [==============================] - 21s 263ms/step - loss: 0.0190 - acc: 0.9947 - val_loss: 0.0291 - val_acc: 0.9944\n",
      "Epoch 224/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0114 - acc: 0.9965WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0317 - acc: 0.9900\n",
      "\n",
      "Epoch 00224: val_loss did not improve from 0.00682\n",
      "81/81 [==============================] - 22s 269ms/step - loss: 0.0146 - acc: 0.9960 - val_loss: 0.0317 - val_acc: 0.9900\n",
      "Epoch 225/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0285 - acc: 0.9914WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 15s 5ms/sample - loss: 0.0693 - acc: 0.9787\n",
      "\n",
      "Epoch 00225: val_loss did not improve from 0.00682\n",
      "81/81 [==============================] - 21s 263ms/step - loss: 0.0298 - acc: 0.9910 - val_loss: 0.0693 - val_acc: 0.9787\n",
      "Epoch 226/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0171 - acc: 0.9946WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0345 - acc: 0.9941\n",
      "\n",
      "Epoch 00226: val_loss did not improve from 0.00682\n",
      "81/81 [==============================] - 25s 304ms/step - loss: 0.0169 - acc: 0.9947 - val_loss: 0.0345 - val_acc: 0.9941\n",
      "Epoch 227/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0112 - acc: 0.9965WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0282 - acc: 0.9925\n",
      "\n",
      "Epoch 00227: val_loss did not improve from 0.00682\n",
      "81/81 [==============================] - 22s 278ms/step - loss: 0.0109 - acc: 0.9966 - val_loss: 0.0282 - val_acc: 0.9925\n",
      "Epoch 228/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0126 - acc: 0.9969WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0353 - acc: 0.9903\n",
      "\n",
      "Epoch 00228: val_loss did not improve from 0.00682\n",
      "81/81 [==============================] - 23s 278ms/step - loss: 0.0126 - acc: 0.9969 - val_loss: 0.0353 - val_acc: 0.9903\n",
      "Epoch 229/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0236 - acc: 0.9937WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3200/3183 [==============================] - 14s 4ms/sample - loss: 0.0115 - acc: 0.9975\n",
      "\n",
      "Epoch 00229: val_loss did not improve from 0.00682\n",
      "81/81 [==============================] - 23s 278ms/step - loss: 0.0233 - acc: 0.9938 - val_loss: 0.0115 - val_acc: 0.9975\n",
      "Epoch 230/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0124 - acc: 0.9978WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0316 - acc: 0.9950s may duplicate your \n",
      "\n",
      "Epoch 00230: val_loss did not improve from 0.00682\n",
      "81/81 [==============================] - 21s 259ms/step - loss: 0.0122 - acc: 0.9978 - val_loss: 0.0316 - val_acc: 0.9950\n",
      "Epoch 231/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0069 - acc: 0.9981WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0325 - acc: 0.9941\n",
      "\n",
      "Epoch 00231: val_loss did not improve from 0.00682\n",
      "81/81 [==============================] - 24s 302ms/step - loss: 0.0074 - acc: 0.9978 - val_loss: 0.0325 - val_acc: 0.9941\n",
      "Epoch 232/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0191 - acc: 0.9925WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 15s 5ms/sample - loss: 0.0200 - acc: 0.9947\n",
      "\n",
      "Epoch 00232: val_loss did not improve from 0.00682\n",
      "81/81 [==============================] - 22s 269ms/step - loss: 0.0190 - acc: 0.9926 - val_loss: 0.0200 - val_acc: 0.9947\n",
      "Epoch 233/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0111 - acc: 0.9975WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0197 - acc: 0.9925\n",
      "\n",
      "Epoch 00233: val_loss did not improve from 0.00682\n",
      "81/81 [==============================] - 22s 271ms/step - loss: 0.0109 - acc: 0.9975 - val_loss: 0.0197 - val_acc: 0.9925\n",
      "Epoch 234/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0070 - acc: 0.9987WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0267 - acc: 0.9950\n",
      "\n",
      "Epoch 00234: val_loss did not improve from 0.00682\n",
      "81/81 [==============================] - 22s 272ms/step - loss: 0.0069 - acc: 0.9988 - val_loss: 0.0267 - val_acc: 0.9950\n",
      "Epoch 235/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0207 - acc: 0.9947WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0145 - acc: 0.9944\n",
      "\n",
      "Epoch 00235: val_loss did not improve from 0.00682\n",
      "81/81 [==============================] - 23s 285ms/step - loss: 0.0208 - acc: 0.9944 - val_loss: 0.0145 - val_acc: 0.9944\n",
      "Epoch 236/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0074 - acc: 0.9978WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 14s 5ms/sample - loss: 0.0179 - acc: 0.9975\n",
      "\n",
      "Epoch 00236: val_loss did not improve from 0.00682\n",
      "81/81 [==============================] - 21s 260ms/step - loss: 0.0074 - acc: 0.9978 - val_loss: 0.0179 - val_acc: 0.9975\n",
      "Epoch 237/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0116 - acc: 0.9962WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.0165 - acc: 0.9944\n",
      "\n",
      "Epoch 00237: val_loss did not improve from 0.00682\n",
      "81/81 [==============================] - 22s 266ms/step - loss: 0.0118 - acc: 0.9960 - val_loss: 0.0165 - val_acc: 0.9944\n",
      "Epoch 238/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0154 - acc: 0.9946WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 15s 5ms/sample - loss: 0.0438 - acc: 0.9900\n",
      "\n",
      "Epoch 00238: val_loss did not improve from 0.00682\n",
      "81/81 [==============================] - 22s 271ms/step - loss: 0.0151 - acc: 0.9947 - val_loss: 0.0438 - val_acc: 0.9900\n",
      "Epoch 239/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0211 - acc: 0.9903WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0283 - acc: 0.9866\n",
      "\n",
      "Epoch 00239: val_loss did not improve from 0.00682\n",
      "81/81 [==============================] - 24s 298ms/step - loss: 0.0208 - acc: 0.9904 - val_loss: 0.0283 - val_acc: 0.9866\n",
      "Epoch 240/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0101 - acc: 0.9956WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0290 - acc: 0.9900\n",
      "\n",
      "Epoch 00240: val_loss did not improve from 0.00682\n",
      "81/81 [==============================] - 22s 275ms/step - loss: 0.0100 - acc: 0.9957 - val_loss: 0.0290 - val_acc: 0.9900\n",
      "Epoch 241/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0164 - acc: 0.9936WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 14s 4ms/sample - loss: 0.0110 - acc: 0.9975\n",
      "\n",
      "Epoch 00241: val_loss did not improve from 0.00682\n",
      "81/81 [==============================] - 20s 249ms/step - loss: 0.0162 - acc: 0.9938 - val_loss: 0.0110 - val_acc: 0.9975\n",
      "Epoch 242/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0060 - acc: 0.9978WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0137 - acc: 0.9975\n",
      "\n",
      "Epoch 00242: val_loss did not improve from 0.00682\n",
      "81/81 [==============================] - 23s 279ms/step - loss: 0.0071 - acc: 0.9975 - val_loss: 0.0137 - val_acc: 0.9975\n",
      "Epoch 243/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0062 - acc: 0.9990WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0256 - acc: 0.9966\n",
      "\n",
      "Epoch 00243: val_loss did not improve from 0.00682\n",
      "81/81 [==============================] - 23s 280ms/step - loss: 0.0061 - acc: 0.9991 - val_loss: 0.0256 - val_acc: 0.9966\n",
      "Epoch 244/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0163 - acc: 0.9928WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0136 - acc: 0.9950\n",
      "\n",
      "Epoch 00244: val_loss did not improve from 0.00682\n",
      "81/81 [==============================] - 23s 290ms/step - loss: 0.0163 - acc: 0.9929 - val_loss: 0.0136 - val_acc: 0.9950\n",
      "Epoch 245/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/81 [============================>.] - ETA: 0s - loss: 0.0095 - acc: 0.9965WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 23s 7ms/sample - loss: 0.0242 - acc: 0.9950\n",
      "\n",
      "Epoch 00245: val_loss did not improve from 0.00682\n",
      "81/81 [==============================] - 27s 333ms/step - loss: 0.0096 - acc: 0.9966 - val_loss: 0.0242 - val_acc: 0.9950\n",
      "Epoch 246/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0139 - acc: 0.9959WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0237 - acc: 0.9900\n",
      "\n",
      "Epoch 00246: val_loss did not improve from 0.00682\n",
      "81/81 [==============================] - 22s 276ms/step - loss: 0.0136 - acc: 0.9960 - val_loss: 0.0237 - val_acc: 0.9900\n",
      "Epoch 247/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0125 - acc: 0.9959WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0288 - acc: 0.9925\n",
      "\n",
      "Epoch 00247: val_loss did not improve from 0.00682\n",
      "81/81 [==============================] - 22s 275ms/step - loss: 0.0124 - acc: 0.9960 - val_loss: 0.0288 - val_acc: 0.9925\n",
      "Epoch 248/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0094 - acc: 0.9965WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0163 - acc: 0.9925\n",
      "\n",
      "Epoch 00248: val_loss did not improve from 0.00682\n",
      "81/81 [==============================] - 22s 273ms/step - loss: 0.0105 - acc: 0.9963 - val_loss: 0.0163 - val_acc: 0.9925\n",
      "Epoch 249/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0076 - acc: 0.9984WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 5ms/sample - loss: 0.0131 - acc: 0.9925\n",
      "\n",
      "Epoch 00249: val_loss did not improve from 0.00682\n",
      "81/81 [==============================] - 22s 267ms/step - loss: 0.0074 - acc: 0.9984 - val_loss: 0.0131 - val_acc: 0.9925\n",
      "Epoch 250/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0112 - acc: 0.9969WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3190/3183 [==============================] - 17s 5ms/sample - loss: 0.0136 - acc: 0.9975\n",
      "\n",
      "Epoch 00250: val_loss did not improve from 0.00682\n",
      "81/81 [==============================] - 22s 265ms/step - loss: 0.0111 - acc: 0.9969 - val_loss: 0.0136 - val_acc: 0.9975\n",
      "Epoch 251/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0045 - acc: 0.9994WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 21s 6ms/sample - loss: 0.0136 - acc: 0.9950\n",
      "\n",
      "Epoch 00251: val_loss did not improve from 0.00682\n",
      "81/81 [==============================] - 26s 325ms/step - loss: 0.0044 - acc: 0.9994 - val_loss: 0.0136 - val_acc: 0.9950\n",
      "Epoch 252/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0151 - acc: 0.9962WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.0168 - acc: 0.9975\n",
      "\n",
      "Epoch 00252: val_loss did not improve from 0.00682\n",
      "81/81 [==============================] - 22s 275ms/step - loss: 0.0149 - acc: 0.9963 - val_loss: 0.0168 - val_acc: 0.9975\n",
      "Epoch 253/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0102 - acc: 0.9965WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0294 - acc: 0.9962\n",
      "\n",
      "Epoch 00253: val_loss did not improve from 0.00682\n",
      "81/81 [==============================] - 25s 307ms/step - loss: 0.0102 - acc: 0.9966 - val_loss: 0.0294 - val_acc: 0.9962\n",
      "Epoch 254/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0124 - acc: 0.9965WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.0141 - acc: 0.9962\n",
      "\n",
      "Epoch 00254: val_loss did not improve from 0.00682\n",
      "81/81 [==============================] - 21s 254ms/step - loss: 0.0133 - acc: 0.9963 - val_loss: 0.0141 - val_acc: 0.9962\n",
      "Epoch 255/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0117 - acc: 0.9971WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0122 - acc: 0.9950\n",
      "\n",
      "Epoch 00255: val_loss did not improve from 0.00682\n",
      "81/81 [==============================] - 23s 279ms/step - loss: 0.0115 - acc: 0.9972 - val_loss: 0.0122 - val_acc: 0.9950\n",
      "Epoch 256/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0078 - acc: 0.9981WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0143 - acc: 0.9975\n",
      "\n",
      "Epoch 00256: val_loss did not improve from 0.00682\n",
      "81/81 [==============================] - 22s 270ms/step - loss: 0.0077 - acc: 0.9981 - val_loss: 0.0143 - val_acc: 0.9975\n",
      "Epoch 257/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0062 - acc: 0.9981WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0236 - acc: 0.9925\n",
      "\n",
      "Epoch 00257: val_loss did not improve from 0.00682\n",
      "81/81 [==============================] - 24s 297ms/step - loss: 0.0061 - acc: 0.9981 - val_loss: 0.0236 - val_acc: 0.9925\n",
      "Epoch 258/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0075 - acc: 0.9975WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 20s 6ms/sample - loss: 0.0359 - acc: 0.9875\n",
      "\n",
      "Epoch 00258: val_loss did not improve from 0.00682\n",
      "81/81 [==============================] - 24s 299ms/step - loss: 0.0089 - acc: 0.9972 - val_loss: 0.0359 - val_acc: 0.9875\n",
      "Epoch 259/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0092 - acc: 0.9978WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.0169 - acc: 0.9950\n",
      "\n",
      "Epoch 00259: val_loss did not improve from 0.00682\n",
      "81/81 [==============================] - 23s 285ms/step - loss: 0.0091 - acc: 0.9978 - val_loss: 0.0169 - val_acc: 0.9950\n",
      "Epoch 260/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0109 - acc: 0.9972WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0194 - acc: 0.9950\n",
      "\n",
      "Epoch 00260: val_loss did not improve from 0.00682\n",
      "81/81 [==============================] - 22s 277ms/step - loss: 0.0108 - acc: 0.9972 - val_loss: 0.0194 - val_acc: 0.9950\n",
      "Epoch 261/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0098 - acc: 0.9962WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0130 - acc: 0.9944\n",
      "\n",
      "Epoch 00261: val_loss did not improve from 0.00682\n",
      "81/81 [==============================] - 25s 314ms/step - loss: 0.0097 - acc: 0.9963 - val_loss: 0.0130 - val_acc: 0.9944\n",
      "Epoch 262/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0100 - acc: 0.9965WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0300 - acc: 0.9950\n",
      "\n",
      "Epoch 00262: val_loss did not improve from 0.00682\n",
      "81/81 [==============================] - 24s 290ms/step - loss: 0.0099 - acc: 0.9966 - val_loss: 0.0300 - val_acc: 0.9950\n",
      "Epoch 263/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0046 - acc: 0.9984WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0124 - acc: 0.9969\n",
      "\n",
      "Epoch 00263: val_loss did not improve from 0.00682\n",
      "81/81 [==============================] - 22s 270ms/step - loss: 0.0045 - acc: 0.9984 - val_loss: 0.0124 - val_acc: 0.9969\n",
      "Epoch 264/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0179 - acc: 0.9943WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0207 - acc: 0.9909\n",
      "\n",
      "Epoch 00264: val_loss did not improve from 0.00682\n",
      "81/81 [==============================] - 23s 285ms/step - loss: 0.0183 - acc: 0.9938 - val_loss: 0.0207 - val_acc: 0.9909\n",
      "Epoch 265/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0145 - acc: 0.9959WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.0332 - acc: 0.9950\n",
      "\n",
      "Epoch 00265: val_loss did not improve from 0.00682\n",
      "81/81 [==============================] - 22s 275ms/step - loss: 0.0145 - acc: 0.9960 - val_loss: 0.0332 - val_acc: 0.9950\n",
      "Epoch 266/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0113 - acc: 0.9959WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0153 - acc: 0.9975\n",
      "\n",
      "Epoch 00266: val_loss did not improve from 0.00682\n",
      "81/81 [==============================] - 22s 274ms/step - loss: 0.0112 - acc: 0.9960 - val_loss: 0.0153 - val_acc: 0.9975\n",
      "Epoch 267/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0066 - acc: 0.9971WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 22s 7ms/sample - loss: 0.0227 - acc: 0.9925\n",
      "\n",
      "Epoch 00267: val_loss did not improve from 0.00682\n",
      "81/81 [==============================] - 26s 319ms/step - loss: 0.0064 - acc: 0.9972 - val_loss: 0.0227 - val_acc: 0.9925\n",
      "Epoch 268/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0042 - acc: 0.9981WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 20s 6ms/sample - loss: 0.0252 - acc: 0.9912\n",
      "\n",
      "Epoch 00268: val_loss did not improve from 0.00682\n",
      "81/81 [==============================] - 25s 310ms/step - loss: 0.0043 - acc: 0.9981 - val_loss: 0.0252 - val_acc: 0.9912\n",
      "Epoch 269/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0109 - acc: 0.9962WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0180 - acc: 0.9950\n",
      "\n",
      "Epoch 00269: val_loss did not improve from 0.00682\n",
      "81/81 [==============================] - 22s 268ms/step - loss: 0.0108 - acc: 0.9963 - val_loss: 0.0180 - val_acc: 0.9950\n",
      "Epoch 270/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0077 - acc: 0.9984WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 14s 4ms/sample - loss: 0.0279 - acc: 0.9875\n",
      "\n",
      "Epoch 00270: val_loss did not improve from 0.00682\n",
      "81/81 [==============================] - 21s 265ms/step - loss: 0.0076 - acc: 0.9984 - val_loss: 0.0279 - val_acc: 0.9875\n",
      "Epoch 271/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0114 - acc: 0.9955WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0265 - acc: 0.9912\n",
      "\n",
      "Epoch 00271: val_loss did not improve from 0.00682\n",
      "81/81 [==============================] - 23s 281ms/step - loss: 0.0112 - acc: 0.9957 - val_loss: 0.0265 - val_acc: 0.9912\n",
      "Epoch 272/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0108 - acc: 0.9969WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0281 - acc: 0.9919\n",
      "\n",
      "Epoch 00272: val_loss did not improve from 0.00682\n",
      "81/81 [==============================] - 23s 289ms/step - loss: 0.0107 - acc: 0.9969 - val_loss: 0.0281 - val_acc: 0.9919\n",
      "Epoch 273/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0073 - acc: 0.9975WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.0237 - acc: 0.9912\n",
      "\n",
      "Epoch 00273: val_loss did not improve from 0.00682\n",
      "81/81 [==============================] - 23s 284ms/step - loss: 0.0072 - acc: 0.9975 - val_loss: 0.0237 - val_acc: 0.9912\n",
      "Epoch 274/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0056 - acc: 0.9981WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 15s 5ms/sample - loss: 0.0270 - acc: 0.9969\n",
      "\n",
      "Epoch 00274: val_loss did not improve from 0.00682\n",
      "81/81 [==============================] - 23s 279ms/step - loss: 0.0078 - acc: 0.9975 - val_loss: 0.0270 - val_acc: 0.9969\n",
      "Epoch 275/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0160 - acc: 0.9959WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0393 - acc: 0.9950\n",
      "\n",
      "Epoch 00275: val_loss did not improve from 0.00682\n",
      "81/81 [==============================] - 22s 276ms/step - loss: 0.0159 - acc: 0.9960 - val_loss: 0.0393 - val_acc: 0.9950\n",
      "Epoch 276/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/81 [============================>.] - ETA: 0s - loss: 0.0149 - acc: 0.9949WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0666 - acc: 0.9925\n",
      "\n",
      "Epoch 00276: val_loss did not improve from 0.00682\n",
      "81/81 [==============================] - 22s 267ms/step - loss: 0.0147 - acc: 0.9950 - val_loss: 0.0666 - val_acc: 0.9925\n",
      "Epoch 277/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0113 - acc: 0.9959WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0250 - acc: 0.9925\n",
      "\n",
      "Epoch 00277: val_loss did not improve from 0.00682\n",
      "81/81 [==============================] - 22s 273ms/step - loss: 0.0113 - acc: 0.9960 - val_loss: 0.0250 - val_acc: 0.9925\n",
      "Epoch 278/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0099 - acc: 0.9971WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0251 - acc: 0.9925\n",
      "\n",
      "Epoch 00278: val_loss did not improve from 0.00682\n",
      "81/81 [==============================] - 23s 280ms/step - loss: 0.0102 - acc: 0.9969 - val_loss: 0.0251 - val_acc: 0.9925\n",
      "Epoch 279/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0119 - acc: 0.9965WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.0420 - acc: 0.9900\n",
      "\n",
      "Epoch 00279: val_loss did not improve from 0.00682\n",
      "81/81 [==============================] - 22s 266ms/step - loss: 0.0124 - acc: 0.9963 - val_loss: 0.0420 - val_acc: 0.9900\n",
      "Epoch 280/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0124 - acc: 0.9969WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 5ms/sample - loss: 0.0371 - acc: 0.9950\n",
      "\n",
      "Epoch 00280: val_loss did not improve from 0.00682\n",
      "81/81 [==============================] - 21s 265ms/step - loss: 0.0128 - acc: 0.9966 - val_loss: 0.0371 - val_acc: 0.9950\n",
      "Epoch 281/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0103 - acc: 0.9965WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 14s 4ms/sample - loss: 0.0188 - acc: 0.99754s - loss: 0.0248 -\n",
      "\n",
      "Epoch 00281: val_loss did not improve from 0.00682\n",
      "81/81 [==============================] - 21s 263ms/step - loss: 0.0104 - acc: 0.9966 - val_loss: 0.0188 - val_acc: 0.9975\n",
      "Epoch 282/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0055 - acc: 0.9981WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0131 - acc: 0.9950\n",
      "\n",
      "Epoch 00282: val_loss did not improve from 0.00682\n",
      "81/81 [==============================] - 22s 270ms/step - loss: 0.0054 - acc: 0.9981 - val_loss: 0.0131 - val_acc: 0.9950\n",
      "Epoch 283/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0087 - acc: 0.9975WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0218 - acc: 0.9975\n",
      "\n",
      "Epoch 00283: val_loss did not improve from 0.00682\n",
      "81/81 [==============================] - 22s 277ms/step - loss: 0.0085 - acc: 0.9975 - val_loss: 0.0218 - val_acc: 0.9975\n",
      "Epoch 284/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0100 - acc: 0.9972WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0357 - acc: 0.9950\n",
      "\n",
      "Epoch 00284: val_loss did not improve from 0.00682\n",
      "81/81 [==============================] - 21s 262ms/step - loss: 0.0099 - acc: 0.9972 - val_loss: 0.0357 - val_acc: 0.9950\n",
      "Epoch 285/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0088 - acc: 0.9978WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0156 - acc: 0.9950\n",
      "\n",
      "Epoch 00285: val_loss did not improve from 0.00682\n",
      "81/81 [==============================] - 21s 262ms/step - loss: 0.0087 - acc: 0.9978 - val_loss: 0.0156 - val_acc: 0.9950\n",
      "Epoch 286/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0053 - acc: 0.9978WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0177 - acc: 0.9956\n",
      "\n",
      "Epoch 00286: val_loss did not improve from 0.00682\n",
      "81/81 [==============================] - 22s 271ms/step - loss: 0.0052 - acc: 0.9978 - val_loss: 0.0177 - val_acc: 0.9956\n",
      "Epoch 287/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0029 - acc: 0.9991WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0151 - acc: 0.9975\n",
      "\n",
      "Epoch 00287: val_loss did not improve from 0.00682\n",
      "81/81 [==============================] - 21s 261ms/step - loss: 0.0029 - acc: 0.9991 - val_loss: 0.0151 - val_acc: 0.9975\n",
      "Epoch 288/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0066 - acc: 0.9987WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 13s 4ms/sample - loss: 0.0237 - acc: 0.9966\n",
      "\n",
      "Epoch 00288: val_loss did not improve from 0.00682\n",
      "81/81 [==============================] - 21s 265ms/step - loss: 0.0065 - acc: 0.9988 - val_loss: 0.0237 - val_acc: 0.9966\n",
      "Epoch 289/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0287 - acc: 0.9899WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 28s 9ms/sample - loss: 0.0181 - acc: 0.9900\n",
      "\n",
      "Epoch 00289: val_loss did not improve from 0.00682\n",
      "81/81 [==============================] - 32s 399ms/step - loss: 0.0284 - acc: 0.9901 - val_loss: 0.0181 - val_acc: 0.9900\n",
      "Epoch 290/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0122 - acc: 0.9965WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0145 - acc: 0.9975\n",
      "\n",
      "Epoch 00290: val_loss did not improve from 0.00682\n",
      "81/81 [==============================] - 23s 285ms/step - loss: 0.0120 - acc: 0.9966 - val_loss: 0.0145 - val_acc: 0.9975\n",
      "Epoch 291/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0089 - acc: 0.9984WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.0199 - acc: 0.9969\n",
      "\n",
      "Epoch 00291: val_loss did not improve from 0.00682\n",
      "81/81 [==============================] - 21s 264ms/step - loss: 0.0093 - acc: 0.9981 - val_loss: 0.0199 - val_acc: 0.9969\n",
      "Epoch 292/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0063 - acc: 0.9978WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 20s 6ms/sample - loss: 0.0216 - acc: 0.9947\n",
      "\n",
      "Epoch 00292: val_loss did not improve from 0.00682\n",
      "81/81 [==============================] - 24s 290ms/step - loss: 0.0064 - acc: 0.9978 - val_loss: 0.0216 - val_acc: 0.9947\n",
      "Epoch 293/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0113 - acc: 0.9959WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.0109 - acc: 0.9975\n",
      "\n",
      "Epoch 00293: val_loss did not improve from 0.00682\n",
      "81/81 [==============================] - 23s 285ms/step - loss: 0.0111 - acc: 0.9960 - val_loss: 0.0109 - val_acc: 0.9975\n",
      "Epoch 294/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0041 - acc: 0.9994WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 5ms/sample - loss: 0.0276 - acc: 0.9975\n",
      "\n",
      "Epoch 00294: val_loss did not improve from 0.00682\n",
      "81/81 [==============================] - 22s 266ms/step - loss: 0.0041 - acc: 0.9994 - val_loss: 0.0276 - val_acc: 0.9975\n",
      "Epoch 295/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0057 - acc: 0.9981WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.0265 - acc: 0.9944\n",
      "\n",
      "Epoch 00295: val_loss did not improve from 0.00682\n",
      "81/81 [==============================] - 22s 270ms/step - loss: 0.0057 - acc: 0.9981 - val_loss: 0.0265 - val_acc: 0.9944\n",
      "Epoch 296/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0055 - acc: 0.9987WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0271 - acc: 0.9950\n",
      "\n",
      "Epoch 00296: val_loss did not improve from 0.00682\n",
      "81/81 [==============================] - 23s 278ms/step - loss: 0.0055 - acc: 0.9988 - val_loss: 0.0271 - val_acc: 0.9950\n",
      "Epoch 297/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0126 - acc: 0.9962WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0204 - acc: 0.9975\n",
      "\n",
      "Epoch 00297: val_loss did not improve from 0.00682\n",
      "81/81 [==============================] - 21s 264ms/step - loss: 0.0124 - acc: 0.9963 - val_loss: 0.0204 - val_acc: 0.9975\n",
      "Epoch 298/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0072 - acc: 0.9978WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0134 - acc: 0.9966\n",
      "\n",
      "Epoch 00298: val_loss did not improve from 0.00682\n",
      "81/81 [==============================] - 22s 268ms/step - loss: 0.0071 - acc: 0.9978 - val_loss: 0.0134 - val_acc: 0.9966\n",
      "Epoch 299/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0085 - acc: 0.9972WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0172 - acc: 0.9950\n",
      "\n",
      "Epoch 00299: val_loss did not improve from 0.00682\n",
      "81/81 [==============================] - 23s 280ms/step - loss: 0.0085 - acc: 0.9972 - val_loss: 0.0172 - val_acc: 0.9950\n",
      "Epoch 300/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0037 - acc: 0.9994WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0122 - acc: 0.9944\n",
      "\n",
      "Epoch 00300: val_loss did not improve from 0.00682\n",
      "81/81 [==============================] - 22s 272ms/step - loss: 0.0037 - acc: 0.9994 - val_loss: 0.0122 - val_acc: 0.9944\n",
      "Epoch 301/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0048 - acc: 0.9975WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 10s 3ms/sample - loss: 0.0424 - acc: 0.9950\n",
      "\n",
      "Epoch 00301: val_loss did not improve from 0.00682\n",
      "81/81 [==============================] - 22s 267ms/step - loss: 0.0062 - acc: 0.9972 - val_loss: 0.0424 - val_acc: 0.9950\n",
      "Epoch 302/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0072 - acc: 0.9981WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0308 - acc: 0.9947\n",
      "\n",
      "Epoch 00302: val_loss did not improve from 0.00682\n",
      "81/81 [==============================] - 22s 272ms/step - loss: 0.0071 - acc: 0.9981 - val_loss: 0.0308 - val_acc: 0.9947\n",
      "Epoch 303/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0102 - acc: 0.9965WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 15s 5ms/sample - loss: 0.0169 - acc: 0.9925\n",
      "\n",
      "Epoch 00303: val_loss did not improve from 0.00682\n",
      "81/81 [==============================] - 22s 278ms/step - loss: 0.0101 - acc: 0.9966 - val_loss: 0.0169 - val_acc: 0.9925\n",
      "Epoch 304/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0095 - acc: 0.9972WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0046 - acc: 0.9975\n",
      "\n",
      "Epoch 00304: val_loss improved from 0.00682 to 0.00465, saving model to model/checkpoint/vis_imagenet_6_class_augmentation_2D_CNN_custom_ch_32_DO_075_DO_5_conv_checkpoint/304-0.0046.hdf5\n",
      "81/81 [==============================] - 22s 275ms/step - loss: 0.0094 - acc: 0.9972 - val_loss: 0.0046 - val_acc: 0.9975\n",
      "Epoch 305/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0092 - acc: 0.9981WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0310 - acc: 0.9950\n",
      "\n",
      "Epoch 00305: val_loss did not improve from 0.00465\n",
      "81/81 [==============================] - 23s 289ms/step - loss: 0.0090 - acc: 0.9981 - val_loss: 0.0310 - val_acc: 0.9950\n",
      "Epoch 306/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0119 - acc: 0.9968WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0286 - acc: 0.9950\n",
      "\n",
      "Epoch 00306: val_loss did not improve from 0.00465\n",
      "81/81 [==============================] - 22s 274ms/step - loss: 0.0117 - acc: 0.9969 - val_loss: 0.0286 - val_acc: 0.9950\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 307/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0068 - acc: 0.9978WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0136 - acc: 0.9944\n",
      "\n",
      "Epoch 00307: val_loss did not improve from 0.00465\n",
      "81/81 [==============================] - 22s 267ms/step - loss: 0.0070 - acc: 0.9975 - val_loss: 0.0136 - val_acc: 0.9944\n",
      "Epoch 308/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0168 - acc: 0.9934WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3190/3183 [==============================] - 19s 6ms/sample - loss: 0.0285 - acc: 0.9950\n",
      "\n",
      "Epoch 00308: val_loss did not improve from 0.00465\n",
      "81/81 [==============================] - 23s 281ms/step - loss: 0.0168 - acc: 0.9935 - val_loss: 0.0285 - val_acc: 0.9950\n",
      "Epoch 309/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0054 - acc: 0.9981WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0219 - acc: 0.9950\n",
      "\n",
      "Epoch 00309: val_loss did not improve from 0.00465\n",
      "81/81 [==============================] - 21s 264ms/step - loss: 0.0053 - acc: 0.9981 - val_loss: 0.0219 - val_acc: 0.9950\n",
      "Epoch 310/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0086 - acc: 0.9978WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 24s 8ms/sample - loss: 0.0251 - acc: 0.9950\n",
      "\n",
      "Epoch 00310: val_loss did not improve from 0.00465\n",
      "81/81 [==============================] - 28s 349ms/step - loss: 0.0099 - acc: 0.9975 - val_loss: 0.0251 - val_acc: 0.9950\n",
      "Epoch 311/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0081 - acc: 0.9971WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 15s 5ms/sample - loss: 0.0095 - acc: 0.9969\n",
      "\n",
      "Epoch 00311: val_loss did not improve from 0.00465\n",
      "81/81 [==============================] - 23s 285ms/step - loss: 0.0089 - acc: 0.9966 - val_loss: 0.0095 - val_acc: 0.9969\n",
      "Epoch 312/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0031 - acc: 0.9991WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0098 - acc: 0.9950\n",
      "\n",
      "Epoch 00312: val_loss did not improve from 0.00465\n",
      "81/81 [==============================] - 22s 271ms/step - loss: 0.0031 - acc: 0.9991 - val_loss: 0.0098 - val_acc: 0.9950\n",
      "Epoch 313/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0041 - acc: 0.9990WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 22s 7ms/sample - loss: 0.0279 - acc: 0.9947\n",
      "\n",
      "Epoch 00313: val_loss did not improve from 0.00465\n",
      "81/81 [==============================] - 30s 367ms/step - loss: 0.0041 - acc: 0.9991 - val_loss: 0.0279 - val_acc: 0.9947\n",
      "Epoch 314/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0057 - acc: 0.9984WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0078 - acc: 0.9975\n",
      "\n",
      "Epoch 00314: val_loss did not improve from 0.00465\n",
      "81/81 [==============================] - 23s 280ms/step - loss: 0.0056 - acc: 0.9984 - val_loss: 0.0078 - val_acc: 0.9975\n",
      "Epoch 315/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0137 - acc: 0.9968WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0173 - acc: 0.9950\n",
      "\n",
      "Epoch 00315: val_loss did not improve from 0.00465\n",
      "81/81 [==============================] - 22s 265ms/step - loss: 0.0133 - acc: 0.9969 - val_loss: 0.0173 - val_acc: 0.9950\n",
      "Epoch 316/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0038 - acc: 0.9987WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0211 - acc: 0.9950\n",
      "\n",
      "Epoch 00316: val_loss did not improve from 0.00465\n",
      "81/81 [==============================] - 23s 288ms/step - loss: 0.0037 - acc: 0.9988 - val_loss: 0.0211 - val_acc: 0.9950\n",
      "Epoch 317/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0033 - acc: 0.9994WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0152 - acc: 0.9975\n",
      "\n",
      "Epoch 00317: val_loss did not improve from 0.00465\n",
      "81/81 [==============================] - 22s 267ms/step - loss: 0.0032 - acc: 0.9994 - val_loss: 0.0152 - val_acc: 0.9975\n",
      "Epoch 318/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0027 - acc: 0.9997WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 5ms/sample - loss: 0.0343 - acc: 0.9947\n",
      "\n",
      "Epoch 00318: val_loss did not improve from 0.00465\n",
      "81/81 [==============================] - 22s 276ms/step - loss: 0.0028 - acc: 0.9997 - val_loss: 0.0343 - val_acc: 0.9947\n",
      "Epoch 319/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0208 - acc: 0.9934WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.0151 - acc: 0.9975\n",
      "\n",
      "Epoch 00319: val_loss did not improve from 0.00465\n",
      "81/81 [==============================] - 22s 272ms/step - loss: 0.0206 - acc: 0.9935 - val_loss: 0.0151 - val_acc: 0.9975\n",
      "Epoch 320/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0023 - acc: 0.9997WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0235 - acc: 0.9975\n",
      "\n",
      "Epoch 00320: val_loss did not improve from 0.00465\n",
      "81/81 [==============================] - 22s 276ms/step - loss: 0.0029 - acc: 0.9994 - val_loss: 0.0235 - val_acc: 0.9975\n",
      "Epoch 321/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0162 - acc: 0.9949WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0163 - acc: 0.9950\n",
      "\n",
      "Epoch 00321: val_loss did not improve from 0.00465\n",
      "81/81 [==============================] - 21s 264ms/step - loss: 0.0164 - acc: 0.9947 - val_loss: 0.0163 - val_acc: 0.9950\n",
      "Epoch 322/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0063 - acc: 0.9984WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3200/3183 [==============================] - 13s 4ms/sample - loss: 0.0152 - acc: 0.9975\n",
      "\n",
      "Epoch 00322: val_loss did not improve from 0.00465\n",
      "81/81 [==============================] - 22s 268ms/step - loss: 0.0063 - acc: 0.9984 - val_loss: 0.0152 - val_acc: 0.9975\n",
      "Epoch 323/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0034 - acc: 0.9994WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0246 - acc: 0.9966\n",
      "\n",
      "Epoch 00323: val_loss did not improve from 0.00465\n",
      "81/81 [==============================] - 22s 276ms/step - loss: 0.0034 - acc: 0.9994 - val_loss: 0.0246 - val_acc: 0.9966\n",
      "Epoch 324/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0096 - acc: 0.9959WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0214 - acc: 0.9950\n",
      "\n",
      "Epoch 00324: val_loss did not improve from 0.00465\n",
      "81/81 [==============================] - 24s 295ms/step - loss: 0.0095 - acc: 0.9960 - val_loss: 0.0214 - val_acc: 0.9950\n",
      "Epoch 325/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0060 - acc: 0.9981WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0229 - acc: 0.9950\n",
      "\n",
      "Epoch 00325: val_loss did not improve from 0.00465\n",
      "81/81 [==============================] - 22s 278ms/step - loss: 0.0061 - acc: 0.9981 - val_loss: 0.0229 - val_acc: 0.9950\n",
      "Epoch 326/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0081 - acc: 0.9971WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0125 - acc: 0.9950\n",
      "\n",
      "Epoch 00326: val_loss did not improve from 0.00465\n",
      "81/81 [==============================] - 21s 265ms/step - loss: 0.0079 - acc: 0.9972 - val_loss: 0.0125 - val_acc: 0.9950\n",
      "Epoch 327/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0045 - acc: 0.9994WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0196 - acc: 0.9972\n",
      "\n",
      "Epoch 00327: val_loss did not improve from 0.00465\n",
      "81/81 [==============================] - 22s 269ms/step - loss: 0.0046 - acc: 0.9994 - val_loss: 0.0196 - val_acc: 0.9972\n",
      "Epoch 328/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0081 - acc: 0.9975WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0148 - acc: 0.9937\n",
      "\n",
      "Epoch 00328: val_loss did not improve from 0.00465\n",
      "81/81 [==============================] - 23s 282ms/step - loss: 0.0080 - acc: 0.9975 - val_loss: 0.0148 - val_acc: 0.9937\n",
      "Epoch 329/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0045 - acc: 0.9987WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 20s 6ms/sample - loss: 0.0199 - acc: 0.9966\n",
      "\n",
      "Epoch 00329: val_loss did not improve from 0.00465\n",
      "81/81 [==============================] - 25s 305ms/step - loss: 0.0044 - acc: 0.9988 - val_loss: 0.0199 - val_acc: 0.9966\n",
      "Epoch 330/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0050 - acc: 0.9971WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0274 - acc: 0.9887\n",
      "\n",
      "Epoch 00330: val_loss did not improve from 0.00465\n",
      "81/81 [==============================] - 23s 280ms/step - loss: 0.0051 - acc: 0.9972 - val_loss: 0.0274 - val_acc: 0.9887\n",
      "Epoch 331/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0170 - acc: 0.9946WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0172 - acc: 0.9950\n",
      "\n",
      "Epoch 00331: val_loss did not improve from 0.00465\n",
      "81/81 [==============================] - 22s 275ms/step - loss: 0.0168 - acc: 0.9947 - val_loss: 0.0172 - val_acc: 0.9950\n",
      "Epoch 332/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0059 - acc: 0.9990WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 21s 6ms/sample - loss: 0.0093 - acc: 0.9969\n",
      "\n",
      "Epoch 00332: val_loss did not improve from 0.00465\n",
      "81/81 [==============================] - 25s 308ms/step - loss: 0.0058 - acc: 0.9991 - val_loss: 0.0093 - val_acc: 0.9969\n",
      "Epoch 333/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0019 - acc: 0.9991WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3190/3183 [==============================] - 18s 6ms/sample - loss: 0.0155 - acc: 0.9975\n",
      "\n",
      "Epoch 00333: val_loss did not improve from 0.00465\n",
      "81/81 [==============================] - 22s 273ms/step - loss: 0.0018 - acc: 0.9991 - val_loss: 0.0155 - val_acc: 0.9975\n",
      "Epoch 334/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0083 - acc: 0.9975WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0173 - acc: 0.9950\n",
      "\n",
      "Epoch 00334: val_loss did not improve from 0.00465\n",
      "81/81 [==============================] - 22s 274ms/step - loss: 0.0086 - acc: 0.9972 - val_loss: 0.0173 - val_acc: 0.9950\n",
      "Epoch 335/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0127 - acc: 0.9962WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 12s 4ms/sample - loss: 0.0174 - acc: 0.9925\n",
      "\n",
      "Epoch 00335: val_loss did not improve from 0.00465\n",
      "81/81 [==============================] - 26s 320ms/step - loss: 0.0125 - acc: 0.9963 - val_loss: 0.0174 - val_acc: 0.9925\n",
      "Epoch 336/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0090 - acc: 0.9981WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 20s 6ms/sample - loss: 0.0238 - acc: 0.9944\n",
      "\n",
      "Epoch 00336: val_loss did not improve from 0.00465\n",
      "81/81 [==============================] - 24s 291ms/step - loss: 0.0089 - acc: 0.9981 - val_loss: 0.0238 - val_acc: 0.9944\n",
      "Epoch 337/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0120 - acc: 0.9968WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0309 - acc: 0.9950\n",
      "\n",
      "Epoch 00337: val_loss did not improve from 0.00465\n",
      "81/81 [==============================] - 23s 282ms/step - loss: 0.0118 - acc: 0.9969 - val_loss: 0.0309 - val_acc: 0.9950\n",
      "Epoch 338/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/81 [============================>.] - ETA: 0s - loss: 0.0075 - acc: 0.9987WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.0179 - acc: 0.9944\n",
      "\n",
      "Epoch 00338: val_loss did not improve from 0.00465\n",
      "81/81 [==============================] - 21s 264ms/step - loss: 0.0074 - acc: 0.9988 - val_loss: 0.0179 - val_acc: 0.9944\n",
      "Epoch 339/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0037 - acc: 0.9991WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0072 - acc: 0.9969\n",
      "\n",
      "Epoch 00339: val_loss did not improve from 0.00465\n",
      "81/81 [==============================] - 23s 289ms/step - loss: 0.0036 - acc: 0.9991 - val_loss: 0.0072 - val_acc: 0.9969\n",
      "Epoch 340/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0011 - acc: 1.0000WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.0134 - acc: 0.9975\n",
      "\n",
      "Epoch 00340: val_loss did not improve from 0.00465\n",
      "81/81 [==============================] - 23s 279ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.0134 - val_acc: 0.9975\n",
      "Epoch 341/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0021 - acc: 0.9994WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0177 - acc: 0.9944\n",
      "\n",
      "Epoch 00341: val_loss did not improve from 0.00465\n",
      "81/81 [==============================] - 23s 285ms/step - loss: 0.0021 - acc: 0.9994 - val_loss: 0.0177 - val_acc: 0.9944\n",
      "Epoch 342/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0070 - acc: 0.9968WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 21s 6ms/sample - loss: 0.0162 - acc: 0.9925\n",
      "\n",
      "Epoch 00342: val_loss did not improve from 0.00465\n",
      "81/81 [==============================] - 25s 305ms/step - loss: 0.0068 - acc: 0.9969 - val_loss: 0.0162 - val_acc: 0.9925\n",
      "Epoch 343/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0212 - acc: 0.9927WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 12s 4ms/sample - loss: 0.0188 - acc: 0.9891\n",
      "\n",
      "Epoch 00343: val_loss did not improve from 0.00465\n",
      "81/81 [==============================] - 22s 266ms/step - loss: 0.0207 - acc: 0.9929 - val_loss: 0.0188 - val_acc: 0.9891\n",
      "Epoch 344/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0104 - acc: 0.9969WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0224 - acc: 0.9950\n",
      "\n",
      "Epoch 00344: val_loss did not improve from 0.00465\n",
      "81/81 [==============================] - 22s 274ms/step - loss: 0.0103 - acc: 0.9969 - val_loss: 0.0224 - val_acc: 0.9950\n",
      "Epoch 345/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0078 - acc: 0.9981WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.0193 - acc: 0.9975\n",
      "\n",
      "Epoch 00345: val_loss did not improve from 0.00465\n",
      "81/81 [==============================] - 22s 273ms/step - loss: 0.0077 - acc: 0.9981 - val_loss: 0.0193 - val_acc: 0.9975\n",
      "Epoch 346/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0036 - acc: 0.9987WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 15s 5ms/sample - loss: 0.0169 - acc: 0.9975\n",
      "\n",
      "Epoch 00346: val_loss did not improve from 0.00465\n",
      "81/81 [==============================] - 22s 274ms/step - loss: 0.0035 - acc: 0.9988 - val_loss: 0.0169 - val_acc: 0.9975\n",
      "Epoch 347/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0043 - acc: 0.9984WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 20s 6ms/sample - loss: 0.0158 - acc: 0.9972\n",
      "\n",
      "Epoch 00347: val_loss did not improve from 0.00465\n",
      "81/81 [==============================] - 24s 293ms/step - loss: 0.0043 - acc: 0.9984 - val_loss: 0.0158 - val_acc: 0.9972\n",
      "Epoch 348/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0046 - acc: 0.9981WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0379 - acc: 0.9947\n",
      "\n",
      "Epoch 00348: val_loss did not improve from 0.00465\n",
      "81/81 [==============================] - 23s 286ms/step - loss: 0.0046 - acc: 0.9981 - val_loss: 0.0379 - val_acc: 0.9947\n",
      "Epoch 349/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0038 - acc: 0.9984WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0183 - acc: 0.9969\n",
      "\n",
      "Epoch 00349: val_loss did not improve from 0.00465\n",
      "81/81 [==============================] - 22s 273ms/step - loss: 0.0037 - acc: 0.9984 - val_loss: 0.0183 - val_acc: 0.9969\n",
      "Epoch 350/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0083 - acc: 0.9981WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0087 - acc: 0.9975\n",
      "\n",
      "Epoch 00350: val_loss did not improve from 0.00465\n",
      "81/81 [==============================] - 22s 274ms/step - loss: 0.0082 - acc: 0.9981 - val_loss: 0.0087 - val_acc: 0.9975\n",
      "Epoch 351/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0033 - acc: 0.9984WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.0455 - acc: 0.9925\n",
      "\n",
      "Epoch 00351: val_loss did not improve from 0.00465\n",
      "81/81 [==============================] - 22s 271ms/step - loss: 0.0033 - acc: 0.9984 - val_loss: 0.0455 - val_acc: 0.9925\n",
      "Epoch 352/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0039 - acc: 0.9984WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0162 - acc: 0.9975\n",
      "\n",
      "Epoch 00352: val_loss did not improve from 0.00465\n",
      "81/81 [==============================] - 21s 264ms/step - loss: 0.0048 - acc: 0.9981 - val_loss: 0.0162 - val_acc: 0.9975\n",
      "Epoch 353/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0040 - acc: 0.9984WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0136 - acc: 0.9969\n",
      "\n",
      "Epoch 00353: val_loss did not improve from 0.00465\n",
      "81/81 [==============================] - 22s 268ms/step - loss: 0.0039 - acc: 0.9984 - val_loss: 0.0136 - val_acc: 0.9969\n",
      "Epoch 354/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0081 - acc: 0.9968WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0109 - acc: 0.9950\n",
      "\n",
      "Epoch 00354: val_loss did not improve from 0.00465\n",
      "81/81 [==============================] - 22s 267ms/step - loss: 0.0088 - acc: 0.9966 - val_loss: 0.0109 - val_acc: 0.9950\n",
      "Epoch 355/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0085 - acc: 0.9969WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0374 - acc: 0.9856\n",
      "\n",
      "Epoch 00355: val_loss did not improve from 0.00465\n",
      "81/81 [==============================] - 22s 270ms/step - loss: 0.0086 - acc: 0.9969 - val_loss: 0.0374 - val_acc: 0.9856\n",
      "Epoch 356/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0066 - acc: 0.9981WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0055 - acc: 0.9975\n",
      "\n",
      "Epoch 00356: val_loss did not improve from 0.00465\n",
      "81/81 [==============================] - 23s 288ms/step - loss: 0.0065 - acc: 0.9981 - val_loss: 0.0055 - val_acc: 0.9975\n",
      "Epoch 357/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0028 - acc: 0.9991WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.0161 - acc: 0.9950\n",
      "\n",
      "Epoch 00357: val_loss did not improve from 0.00465\n",
      "81/81 [==============================] - 21s 257ms/step - loss: 0.0027 - acc: 0.9991 - val_loss: 0.0161 - val_acc: 0.9950\n",
      "Epoch 358/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0088 - acc: 0.9971WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.0204 - acc: 0.9969\n",
      "\n",
      "Epoch 00358: val_loss did not improve from 0.00465\n",
      "81/81 [==============================] - 22s 274ms/step - loss: 0.0086 - acc: 0.9972 - val_loss: 0.0204 - val_acc: 0.9969\n",
      "Epoch 359/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0074 - acc: 0.9978WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 15s 5ms/sample - loss: 0.0248 - acc: 0.9900\n",
      "\n",
      "Epoch 00359: val_loss did not improve from 0.00465\n",
      "81/81 [==============================] - 22s 272ms/step - loss: 0.0073 - acc: 0.9978 - val_loss: 0.0248 - val_acc: 0.9900\n",
      "Epoch 360/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0048 - acc: 0.9984WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0171 - acc: 0.9975\n",
      "\n",
      "Epoch 00360: val_loss did not improve from 0.00465\n",
      "81/81 [==============================] - 22s 267ms/step - loss: 0.0047 - acc: 0.9984 - val_loss: 0.0171 - val_acc: 0.9975\n",
      "Epoch 361/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0137 - acc: 0.9952WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0375 - acc: 0.9950\n",
      "\n",
      "Epoch 00361: val_loss did not improve from 0.00465\n",
      "81/81 [==============================] - 21s 261ms/step - loss: 0.0135 - acc: 0.9953 - val_loss: 0.0375 - val_acc: 0.9950\n",
      "Epoch 362/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0140 - acc: 0.9962WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0170 - acc: 0.9950\n",
      "\n",
      "Epoch 00362: val_loss did not improve from 0.00465\n",
      "81/81 [==============================] - 23s 285ms/step - loss: 0.0137 - acc: 0.9963 - val_loss: 0.0170 - val_acc: 0.9950\n",
      "Epoch 363/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0038 - acc: 0.9984WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 23s 7ms/sample - loss: 0.0175 - acc: 0.9950\n",
      "\n",
      "Epoch 00363: val_loss did not improve from 0.00465\n",
      "81/81 [==============================] - 27s 331ms/step - loss: 0.0038 - acc: 0.9984 - val_loss: 0.0175 - val_acc: 0.9950\n",
      "Epoch 364/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0037 - acc: 0.9984WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0144 - acc: 0.9975\n",
      "\n",
      "Epoch 00364: val_loss did not improve from 0.00465\n",
      "81/81 [==============================] - 23s 282ms/step - loss: 0.0038 - acc: 0.9984 - val_loss: 0.0144 - val_acc: 0.9975\n",
      "Epoch 365/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0034 - acc: 0.9991WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.0182 - acc: 0.9950\n",
      "\n",
      "Epoch 00365: val_loss did not improve from 0.00465\n",
      "81/81 [==============================] - 22s 274ms/step - loss: 0.0034 - acc: 0.9991 - val_loss: 0.0182 - val_acc: 0.9950\n",
      "Epoch 366/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0111 - acc: 0.9962WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0086 - acc: 0.9975\n",
      "\n",
      "Epoch 00366: val_loss did not improve from 0.00465\n",
      "81/81 [==============================] - 22s 272ms/step - loss: 0.0110 - acc: 0.9963 - val_loss: 0.0086 - val_acc: 0.9975\n",
      "Epoch 367/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0091 - acc: 0.9965WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0253 - acc: 0.9931\n",
      "\n",
      "Epoch 00367: val_loss did not improve from 0.00465\n",
      "81/81 [==============================] - 21s 258ms/step - loss: 0.0090 - acc: 0.9966 - val_loss: 0.0253 - val_acc: 0.9931\n",
      "Epoch 368/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0036 - acc: 0.9991WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 20s 6ms/sample - loss: 0.0176 - acc: 0.9912\n",
      "\n",
      "Epoch 00368: val_loss did not improve from 0.00465\n",
      "81/81 [==============================] - 25s 303ms/step - loss: 0.0035 - acc: 0.9991 - val_loss: 0.0176 - val_acc: 0.9912\n",
      "Epoch 369/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/81 [============================>.] - ETA: 0s - loss: 0.0051 - acc: 0.9978WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0084 - acc: 0.9975\n",
      "\n",
      "Epoch 00369: val_loss did not improve from 0.00465\n",
      "81/81 [==============================] - 24s 295ms/step - loss: 0.0051 - acc: 0.9978 - val_loss: 0.0084 - val_acc: 0.9975\n",
      "Epoch 370/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0053 - acc: 0.9987WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0277 - acc: 0.9900\n",
      "\n",
      "Epoch 00370: val_loss did not improve from 0.00465\n",
      "81/81 [==============================] - 22s 273ms/step - loss: 0.0052 - acc: 0.9988 - val_loss: 0.0277 - val_acc: 0.9900\n",
      "Epoch 371/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0161 - acc: 0.9947WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.0245 - acc: 0.9912\n",
      "\n",
      "Epoch 00371: val_loss did not improve from 0.00465\n",
      "81/81 [==============================] - 21s 265ms/step - loss: 0.0159 - acc: 0.9947 - val_loss: 0.0245 - val_acc: 0.9912\n",
      "Epoch 372/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0034 - acc: 0.9987WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 20s 6ms/sample - loss: 0.0167 - acc: 0.9950\n",
      "\n",
      "Epoch 00372: val_loss did not improve from 0.00465\n",
      "81/81 [==============================] - 25s 305ms/step - loss: 0.0034 - acc: 0.9988 - val_loss: 0.0167 - val_acc: 0.9950\n",
      "Epoch 373/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 7.2632e-04 - acc: 1.0000WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0230 - acc: 0.9944\n",
      "\n",
      "Epoch 00373: val_loss did not improve from 0.00465\n",
      "81/81 [==============================] - 23s 285ms/step - loss: 7.4312e-04 - acc: 1.0000 - val_loss: 0.0230 - val_acc: 0.9944\n",
      "Epoch 374/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0014 - acc: 0.9997WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0227 - acc: 0.9950\n",
      "\n",
      "Epoch 00374: val_loss did not improve from 0.00465\n",
      "81/81 [==============================] - 22s 278ms/step - loss: 0.0016 - acc: 0.9997 - val_loss: 0.0227 - val_acc: 0.9950\n",
      "Epoch 375/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0012 - acc: 1.0000WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0335 - acc: 0.9950\n",
      "\n",
      "Epoch 00375: val_loss did not improve from 0.00465\n",
      "81/81 [==============================] - 24s 302ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.0335 - val_acc: 0.9950\n",
      "Epoch 376/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0016 - acc: 0.9997WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0138 - acc: 0.9925\n",
      "\n",
      "Epoch 00376: val_loss did not improve from 0.00465\n",
      "81/81 [==============================] - 22s 266ms/step - loss: 0.0020 - acc: 0.9994 - val_loss: 0.0138 - val_acc: 0.9925\n",
      "Epoch 377/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0020 - acc: 0.9997WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 22s 7ms/sample - loss: 0.0357 - acc: 0.9950\n",
      "\n",
      "Epoch 00377: val_loss did not improve from 0.00465\n",
      "81/81 [==============================] - 27s 335ms/step - loss: 0.0020 - acc: 0.9997 - val_loss: 0.0357 - val_acc: 0.9950\n",
      "Epoch 378/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 6.3740e-04 - acc: 1.0000WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0226 - acc: 0.9925\n",
      "\n",
      "Epoch 00378: val_loss did not improve from 0.00465\n",
      "81/81 [==============================] - 22s 276ms/step - loss: 0.0015 - acc: 0.9994 - val_loss: 0.0226 - val_acc: 0.9925\n",
      "Epoch 379/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0084 - acc: 0.9965WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 13s 4ms/sample - loss: 0.0202 - acc: 0.9944\n",
      "\n",
      "Epoch 00379: val_loss did not improve from 0.00465\n",
      "81/81 [==============================] - 22s 270ms/step - loss: 0.0083 - acc: 0.9966 - val_loss: 0.0202 - val_acc: 0.9944\n",
      "Epoch 380/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0061 - acc: 0.9972WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 24s 7ms/sample - loss: 0.0156 - acc: 0.9925\n",
      "\n",
      "Epoch 00380: val_loss did not improve from 0.00465\n",
      "81/81 [==============================] - 30s 366ms/step - loss: 0.0060 - acc: 0.9972 - val_loss: 0.0156 - val_acc: 0.9925\n",
      "Epoch 381/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0052 - acc: 0.9978WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0166 - acc: 0.9947\n",
      "\n",
      "Epoch 00381: val_loss did not improve from 0.00465\n",
      "81/81 [==============================] - 22s 277ms/step - loss: 0.0051 - acc: 0.9978 - val_loss: 0.0166 - val_acc: 0.9947\n",
      "Epoch 382/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0155 - acc: 0.9965WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 26s 8ms/sample - loss: 0.0183 - acc: 0.9937\n",
      "\n",
      "Epoch 00382: val_loss did not improve from 0.00465\n",
      "81/81 [==============================] - 32s 391ms/step - loss: 0.0152 - acc: 0.9966 - val_loss: 0.0183 - val_acc: 0.9937\n",
      "Epoch 383/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0079 - acc: 0.9981WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 29s 9ms/sample - loss: 0.0407 - acc: 0.9950\n",
      "\n",
      "Epoch 00383: val_loss did not improve from 0.00465\n",
      "81/81 [==============================] - 36s 440ms/step - loss: 0.0078 - acc: 0.9981 - val_loss: 0.0407 - val_acc: 0.9950\n",
      "Epoch 384/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0079 - acc: 0.9971WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3200/3183 [==============================] - 21s 6ms/sample - loss: 0.0173 - acc: 0.9950\n",
      "\n",
      "Epoch 00384: val_loss did not improve from 0.00465\n",
      "81/81 [==============================] - 25s 307ms/step - loss: 0.0078 - acc: 0.9972 - val_loss: 0.0173 - val_acc: 0.9950\n",
      "Epoch 385/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0064 - acc: 0.9987WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0250 - acc: 0.9950\n",
      "\n",
      "Epoch 00385: val_loss did not improve from 0.00465\n",
      "81/81 [==============================] - 22s 272ms/step - loss: 0.0066 - acc: 0.9984 - val_loss: 0.0250 - val_acc: 0.9950\n",
      "Epoch 386/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0041 - acc: 0.9987WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 15s 5ms/sample - loss: 0.0182 - acc: 0.9919\n",
      "\n",
      "Epoch 00386: val_loss did not improve from 0.00465\n",
      "81/81 [==============================] - 24s 300ms/step - loss: 0.0048 - acc: 0.9981 - val_loss: 0.0182 - val_acc: 0.9919\n",
      "Epoch 387/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0044 - acc: 0.9981WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0174 - acc: 0.9975\n",
      "\n",
      "Epoch 00387: val_loss did not improve from 0.00465\n",
      "81/81 [==============================] - 23s 279ms/step - loss: 0.0044 - acc: 0.9981 - val_loss: 0.0174 - val_acc: 0.9975\n",
      "Epoch 388/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0028 - acc: 0.9990- ETA: 0s - loss: 0.0026 - accWARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0070 - acc: 0.9975\n",
      "\n",
      "Epoch 00388: val_loss did not improve from 0.00465\n",
      "81/81 [==============================] - 23s 286ms/step - loss: 0.0028 - acc: 0.9991 - val_loss: 0.0070 - val_acc: 0.9975\n",
      "Epoch 389/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0066 - acc: 0.9978WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 5ms/sample - loss: 0.0291 - acc: 0.9850\n",
      "\n",
      "Epoch 00389: val_loss did not improve from 0.00465\n",
      "81/81 [==============================] - 23s 287ms/step - loss: 0.0070 - acc: 0.9975 - val_loss: 0.0291 - val_acc: 0.9850\n",
      "Epoch 390/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0047 - acc: 0.9987WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0187 - acc: 0.9947\n",
      "\n",
      "Epoch 00390: val_loss did not improve from 0.00465\n",
      "81/81 [==============================] - 22s 277ms/step - loss: 0.0046 - acc: 0.9988 - val_loss: 0.0187 - val_acc: 0.9947\n",
      "Epoch 391/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0025 - acc: 0.9987WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 27s 9ms/sample - loss: 0.0124 - acc: 0.9972\n",
      "\n",
      "Epoch 00391: val_loss did not improve from 0.00465\n",
      "81/81 [==============================] - 31s 386ms/step - loss: 0.0025 - acc: 0.9988 - val_loss: 0.0124 - val_acc: 0.9972\n",
      "Epoch 392/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0019 - acc: 0.9990WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0327 - acc: 0.9947\n",
      "\n",
      "Epoch 00392: val_loss did not improve from 0.00465\n",
      "81/81 [==============================] - 24s 296ms/step - loss: 0.0019 - acc: 0.9991 - val_loss: 0.0327 - val_acc: 0.9947\n",
      "Epoch 393/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0016 - acc: 0.9997WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0339 - acc: 0.9947\n",
      "\n",
      "Epoch 00393: val_loss did not improve from 0.00465\n",
      "81/81 [==============================] - 22s 271ms/step - loss: 0.0016 - acc: 0.9997 - val_loss: 0.0339 - val_acc: 0.9947\n",
      "Epoch 394/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 7.9258e-04 - acc: 1.0000WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0137 - acc: 0.9972\n",
      "\n",
      "Epoch 00394: val_loss did not improve from 0.00465\n",
      "81/81 [==============================] - 22s 277ms/step - loss: 7.8049e-04 - acc: 1.0000 - val_loss: 0.0137 - val_acc: 0.9972\n",
      "Epoch 395/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0026 - acc: 0.9994WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0416 - acc: 0.9950\n",
      "\n",
      "Epoch 00395: val_loss did not improve from 0.00465\n",
      "81/81 [==============================] - 22s 269ms/step - loss: 0.0026 - acc: 0.9994 - val_loss: 0.0416 - val_acc: 0.9950\n",
      "Epoch 396/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0057 - acc: 0.9984WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 21s 7ms/sample - loss: 0.0412 - acc: 0.9887\n",
      "\n",
      "Epoch 00396: val_loss did not improve from 0.00465\n",
      "81/81 [==============================] - 25s 307ms/step - loss: 0.0057 - acc: 0.9984 - val_loss: 0.0412 - val_acc: 0.9887\n",
      "Epoch 397/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0167 - acc: 0.9943WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.0158 - acc: 0.9966\n",
      "\n",
      "Epoch 00397: val_loss did not improve from 0.00465\n",
      "81/81 [==============================] - 25s 303ms/step - loss: 0.0165 - acc: 0.9944 - val_loss: 0.0158 - val_acc: 0.9966\n",
      "Epoch 398/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0113 - acc: 0.9956- ETA: 0s - loss: 0.0113 - acc:WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0089 - acc: 0.9950\n",
      "\n",
      "Epoch 00398: val_loss did not improve from 0.00465\n",
      "81/81 [==============================] - 22s 271ms/step - loss: 0.0111 - acc: 0.9957 - val_loss: 0.0089 - val_acc: 0.9950\n",
      "Epoch 399/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0094 - acc: 0.9965WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0174 - acc: 0.9950\n",
      "\n",
      "Epoch 00399: val_loss did not improve from 0.00465\n",
      "81/81 [==============================] - 22s 271ms/step - loss: 0.0094 - acc: 0.9966 - val_loss: 0.0174 - val_acc: 0.9950\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0042 - acc: 0.9987WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.0209 - acc: 0.9950\n",
      "\n",
      "Epoch 00400: val_loss did not improve from 0.00465\n",
      "81/81 [==============================] - 20s 246ms/step - loss: 0.0041 - acc: 0.9988 - val_loss: 0.0209 - val_acc: 0.9950\n",
      "Epoch 401/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0066 - acc: 0.9978WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 15s 5ms/sample - loss: 0.0159 - acc: 0.9966\n",
      "\n",
      "Epoch 00401: val_loss did not improve from 0.00465\n",
      "81/81 [==============================] - 22s 273ms/step - loss: 0.0064 - acc: 0.9978 - val_loss: 0.0159 - val_acc: 0.9966\n",
      "Epoch 402/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0028 - acc: 0.9991WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 15s 5ms/sample - loss: 0.0194 - acc: 0.9975\n",
      "\n",
      "Epoch 00402: val_loss did not improve from 0.00465\n",
      "81/81 [==============================] - 21s 261ms/step - loss: 0.0028 - acc: 0.9991 - val_loss: 0.0194 - val_acc: 0.9975\n",
      "Epoch 403/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0039 - acc: 0.9984WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0336 - acc: 0.9950s may du\n",
      "\n",
      "Epoch 00403: val_loss did not improve from 0.00465\n",
      "81/81 [==============================] - 23s 283ms/step - loss: 0.0038 - acc: 0.9984 - val_loss: 0.0336 - val_acc: 0.9950\n",
      "Epoch 404/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0067 - acc: 0.9968WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0046 - acc: 1.0000\n",
      "\n",
      "Epoch 00404: val_loss improved from 0.00465 to 0.00456, saving model to model/checkpoint/vis_imagenet_6_class_augmentation_2D_CNN_custom_ch_32_DO_075_DO_5_conv_checkpoint/404-0.0046.hdf5\n",
      "81/81 [==============================] - 22s 272ms/step - loss: 0.0066 - acc: 0.9969 - val_loss: 0.0046 - val_acc: 1.0000\n",
      "Epoch 405/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0122 - acc: 0.9952WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 13s 4ms/sample - loss: 0.0515 - acc: 0.9925\n",
      "\n",
      "Epoch 00405: val_loss did not improve from 0.00456\n",
      "81/81 [==============================] - 22s 266ms/step - loss: 0.0121 - acc: 0.9953 - val_loss: 0.0515 - val_acc: 0.9925\n",
      "Epoch 406/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0167 - acc: 0.9940WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 14s 4ms/sample - loss: 0.0148 - acc: 0.9975\n",
      "\n",
      "Epoch 00406: val_loss did not improve from 0.00456\n",
      "81/81 [==============================] - 22s 269ms/step - loss: 0.0168 - acc: 0.9938 - val_loss: 0.0148 - val_acc: 0.9975\n",
      "Epoch 407/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0010 - acc: 1.0000WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0153 - acc: 0.9975\n",
      "\n",
      "Epoch 00407: val_loss did not improve from 0.00456\n",
      "81/81 [==============================] - 21s 264ms/step - loss: 9.7863e-04 - acc: 1.0000 - val_loss: 0.0153 - val_acc: 0.9975\n",
      "Epoch 408/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0092 - acc: 0.9971WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0307 - acc: 0.9950\n",
      "\n",
      "Epoch 00408: val_loss did not improve from 0.00456\n",
      "81/81 [==============================] - 22s 268ms/step - loss: 0.0090 - acc: 0.9972 - val_loss: 0.0307 - val_acc: 0.9950\n",
      "Epoch 409/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0019 - acc: 0.9997WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0294 - acc: 0.9950\n",
      "\n",
      "Epoch 00409: val_loss did not improve from 0.00456\n",
      "81/81 [==============================] - 22s 276ms/step - loss: 0.0019 - acc: 0.9997 - val_loss: 0.0294 - val_acc: 0.9950\n",
      "Epoch 410/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0064 - acc: 0.9978WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0200 - acc: 0.9975\n",
      "\n",
      "Epoch 00410: val_loss did not improve from 0.00456\n",
      "81/81 [==============================] - 22s 272ms/step - loss: 0.0063 - acc: 0.9978 - val_loss: 0.0200 - val_acc: 0.9975\n",
      "Epoch 411/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0047 - acc: 0.9984WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0219 - acc: 0.9975\n",
      "\n",
      "Epoch 00411: val_loss did not improve from 0.00456\n",
      "81/81 [==============================] - 22s 272ms/step - loss: 0.0048 - acc: 0.9984 - val_loss: 0.0219 - val_acc: 0.9975\n",
      "Epoch 412/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0109 - acc: 0.9956WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0296 - acc: 0.9925\n",
      "\n",
      "Epoch 00412: val_loss did not improve from 0.00456\n",
      "81/81 [==============================] - 21s 265ms/step - loss: 0.0111 - acc: 0.9957 - val_loss: 0.0296 - val_acc: 0.9925\n",
      "Epoch 413/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0063 - acc: 0.9984WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0127 - acc: 0.9975\n",
      "\n",
      "Epoch 00413: val_loss did not improve from 0.00456\n",
      "81/81 [==============================] - 22s 266ms/step - loss: 0.0063 - acc: 0.9984 - val_loss: 0.0127 - val_acc: 0.9975\n",
      "Epoch 414/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0023 - acc: 0.9994WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 5ms/sample - loss: 0.0179 - acc: 0.9941\n",
      "\n",
      "Epoch 00414: val_loss did not improve from 0.00456\n",
      "81/81 [==============================] - 21s 264ms/step - loss: 0.0023 - acc: 0.9994 - val_loss: 0.0179 - val_acc: 0.9941\n",
      "Epoch 415/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 7.2475e-04 - acc: 1.0000WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3200/3183 [==============================] - 14s 4ms/sample - loss: 0.0119 - acc: 0.9972\n",
      "\n",
      "Epoch 00415: val_loss did not improve from 0.00456\n",
      "81/81 [==============================] - 23s 280ms/step - loss: 7.3275e-04 - acc: 1.0000 - val_loss: 0.0119 - val_acc: 0.9972\n",
      "Epoch 416/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0014 - acc: 0.9997WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0388 - acc: 0.9950\n",
      "\n",
      "Epoch 00416: val_loss did not improve from 0.00456\n",
      "81/81 [==============================] - 22s 276ms/step - loss: 0.0014 - acc: 0.9997 - val_loss: 0.0388 - val_acc: 0.9950\n",
      "Epoch 417/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0068 - acc: 0.9984WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 15s 5ms/sample - loss: 0.0281 - acc: 0.9925\n",
      "\n",
      "Epoch 00417: val_loss did not improve from 0.00456\n",
      "81/81 [==============================] - 21s 264ms/step - loss: 0.0067 - acc: 0.9984 - val_loss: 0.0281 - val_acc: 0.9925\n",
      "Epoch 418/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0018 - acc: 0.9997WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0118 - acc: 0.9975\n",
      "\n",
      "Epoch 00418: val_loss did not improve from 0.00456\n",
      "81/81 [==============================] - 23s 280ms/step - loss: 0.0018 - acc: 0.9997 - val_loss: 0.0118 - val_acc: 0.9975\n",
      "Epoch 419/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0067 - acc: 0.9984WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 14s 4ms/sample - loss: 0.0302 - acc: 0.9941\n",
      "\n",
      "Epoch 00419: val_loss did not improve from 0.00456\n",
      "81/81 [==============================] - 23s 283ms/step - loss: 0.0066 - acc: 0.9984 - val_loss: 0.0302 - val_acc: 0.9941\n",
      "Epoch 420/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0049 - acc: 0.9990WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0117 - acc: 0.9969\n",
      "\n",
      "Epoch 00420: val_loss did not improve from 0.00456\n",
      "81/81 [==============================] - 24s 290ms/step - loss: 0.0047 - acc: 0.9991 - val_loss: 0.0117 - val_acc: 0.9969\n",
      "Epoch 421/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0068 - acc: 0.9978WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0250 - acc: 0.9922\n",
      "\n",
      "Epoch 00421: val_loss did not improve from 0.00456\n",
      "81/81 [==============================] - 22s 276ms/step - loss: 0.0066 - acc: 0.9978 - val_loss: 0.0250 - val_acc: 0.9922\n",
      "Epoch 422/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0044 - acc: 0.9984WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 20s 6ms/sample - loss: 0.0268 - acc: 0.9950\n",
      "\n",
      "Epoch 00422: val_loss did not improve from 0.00456\n",
      "81/81 [==============================] - 24s 296ms/step - loss: 0.0043 - acc: 0.9984 - val_loss: 0.0268 - val_acc: 0.9950\n",
      "Epoch 423/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0040 - acc: 0.9987WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 15s 5ms/sample - loss: 0.0231 - acc: 0.9919\n",
      "\n",
      "Epoch 00423: val_loss did not improve from 0.00456\n",
      "81/81 [==============================] - 22s 275ms/step - loss: 0.0046 - acc: 0.9984 - val_loss: 0.0231 - val_acc: 0.9919\n",
      "Epoch 424/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0038 - acc: 0.9984WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 20s 6ms/sample - loss: 0.0295 - acc: 0.9950\n",
      "\n",
      "Epoch 00424: val_loss did not improve from 0.00456\n",
      "81/81 [==============================] - 26s 315ms/step - loss: 0.0038 - acc: 0.9984 - val_loss: 0.0295 - val_acc: 0.9950\n",
      "Epoch 425/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0049 - acc: 0.9984WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3190/3183 [==============================] - 18s 6ms/sample - loss: 0.0211 - acc: 0.9950\n",
      "\n",
      "Epoch 00425: val_loss did not improve from 0.00456\n",
      "81/81 [==============================] - 22s 278ms/step - loss: 0.0052 - acc: 0.9981 - val_loss: 0.0211 - val_acc: 0.9950\n",
      "Epoch 426/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0119 - acc: 0.9947WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.0224 - acc: 0.9900\n",
      "\n",
      "Epoch 00426: val_loss did not improve from 0.00456\n",
      "81/81 [==============================] - 22s 276ms/step - loss: 0.0118 - acc: 0.9947 - val_loss: 0.0224 - val_acc: 0.9900\n",
      "Epoch 427/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0036 - acc: 0.9984WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0172 - acc: 0.9950\n",
      "\n",
      "Epoch 00427: val_loss did not improve from 0.00456\n",
      "81/81 [==============================] - 22s 271ms/step - loss: 0.0036 - acc: 0.9984 - val_loss: 0.0172 - val_acc: 0.9950\n",
      "Epoch 428/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0015 - acc: 1.0000- ETA: 1s - loss:WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0253 - acc: 0.9950\n",
      "\n",
      "Epoch 00428: val_loss did not improve from 0.00456\n",
      "81/81 [==============================] - 22s 269ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.0253 - val_acc: 0.9950\n",
      "Epoch 429/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0023 - acc: 0.9994WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0245 - acc: 0.9947\n",
      "\n",
      "Epoch 00429: val_loss did not improve from 0.00456\n",
      "81/81 [==============================] - 22s 272ms/step - loss: 0.0023 - acc: 0.9994 - val_loss: 0.0245 - val_acc: 0.9947\n",
      "Epoch 430/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0032 - acc: 0.9997WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 21s 6ms/sample - loss: 0.0233 - acc: 0.9962\n",
      "\n",
      "Epoch 00430: val_loss did not improve from 0.00456\n",
      "81/81 [==============================] - 25s 308ms/step - loss: 0.0031 - acc: 0.9997 - val_loss: 0.0233 - val_acc: 0.9962\n",
      "Epoch 431/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/81 [============================>.] - ETA: 0s - loss: 8.2241e-04 - acc: 0.9997WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0320 - acc: 0.9950\n",
      "\n",
      "Epoch 00431: val_loss did not improve from 0.00456\n",
      "81/81 [==============================] - 22s 272ms/step - loss: 8.1631e-04 - acc: 0.9997 - val_loss: 0.0320 - val_acc: 0.9950\n",
      "Epoch 432/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0040 - acc: 0.9984WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 15s 5ms/sample - loss: 0.0305 - acc: 0.9950\n",
      "\n",
      "Epoch 00432: val_loss did not improve from 0.00456\n",
      "81/81 [==============================] - 23s 284ms/step - loss: 0.0040 - acc: 0.9984 - val_loss: 0.0305 - val_acc: 0.9950\n",
      "Epoch 433/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0041 - acc: 0.9987WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0561 - acc: 0.9950\n",
      "\n",
      "Epoch 00433: val_loss did not improve from 0.00456\n",
      "81/81 [==============================] - 24s 292ms/step - loss: 0.0052 - acc: 0.9984 - val_loss: 0.0561 - val_acc: 0.9950\n",
      "Epoch 434/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0067 - acc: 0.9978WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0375 - acc: 0.9925\n",
      "\n",
      "Epoch 00434: val_loss did not improve from 0.00456\n",
      "81/81 [==============================] - 23s 287ms/step - loss: 0.0066 - acc: 0.9978 - val_loss: 0.0375 - val_acc: 0.9925\n",
      "Epoch 435/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0051 - acc: 0.9981WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 15s 5ms/sample - loss: 0.0252 - acc: 0.9950\n",
      "\n",
      "Epoch 00435: val_loss did not improve from 0.00456\n",
      "81/81 [==============================] - 22s 271ms/step - loss: 0.0049 - acc: 0.9981 - val_loss: 0.0252 - val_acc: 0.9950\n",
      "Epoch 436/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0069 - acc: 0.9971WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0208 - acc: 0.9969\n",
      "\n",
      "Epoch 00436: val_loss did not improve from 0.00456\n",
      "81/81 [==============================] - 24s 302ms/step - loss: 0.0067 - acc: 0.9972 - val_loss: 0.0208 - val_acc: 0.9969\n",
      "Epoch 437/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0060 - acc: 0.9981WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0361 - acc: 0.9887\n",
      "\n",
      "Epoch 00437: val_loss did not improve from 0.00456\n",
      "81/81 [==============================] - 22s 266ms/step - loss: 0.0059 - acc: 0.9981 - val_loss: 0.0361 - val_acc: 0.9887\n",
      "Epoch 438/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0090 - acc: 0.9975WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0366 - acc: 0.9950\n",
      "\n",
      "Epoch 00438: val_loss did not improve from 0.00456\n",
      "81/81 [==============================] - 22s 271ms/step - loss: 0.0092 - acc: 0.9972 - val_loss: 0.0366 - val_acc: 0.9950\n",
      "Epoch 439/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0019 - acc: 1.0000WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.0207 - acc: 0.9950\n",
      "\n",
      "Epoch 00439: val_loss did not improve from 0.00456\n",
      "81/81 [==============================] - 22s 268ms/step - loss: 0.0023 - acc: 0.9997 - val_loss: 0.0207 - val_acc: 0.9950\n",
      "Epoch 440/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0021 - acc: 0.9994WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0466 - acc: 0.9925\n",
      "\n",
      "Epoch 00440: val_loss did not improve from 0.00456\n",
      "81/81 [==============================] - 23s 281ms/step - loss: 0.0021 - acc: 0.9994 - val_loss: 0.0466 - val_acc: 0.9925\n",
      "Epoch 441/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0088 - acc: 0.9972WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0475 - acc: 0.9944\n",
      "\n",
      "Epoch 00441: val_loss did not improve from 0.00456\n",
      "81/81 [==============================] - 24s 294ms/step - loss: 0.0087 - acc: 0.9972 - val_loss: 0.0475 - val_acc: 0.9944\n",
      "Epoch 442/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0076 - acc: 0.9981WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 20s 6ms/sample - loss: 0.0239 - acc: 0.9944\n",
      "\n",
      "Epoch 00442: val_loss did not improve from 0.00456\n",
      "81/81 [==============================] - 27s 328ms/step - loss: 0.0075 - acc: 0.9981 - val_loss: 0.0239 - val_acc: 0.9944\n",
      "Epoch 443/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0024 - acc: 0.9994WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0365 - acc: 0.9947\n",
      "\n",
      "Epoch 00443: val_loss did not improve from 0.00456\n",
      "81/81 [==============================] - 22s 275ms/step - loss: 0.0023 - acc: 0.9994 - val_loss: 0.0365 - val_acc: 0.9947\n",
      "Epoch 444/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 8.8434e-04 - acc: 0.9997WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0234 - acc: 0.9950\n",
      "\n",
      "Epoch 00444: val_loss did not improve from 0.00456\n",
      "81/81 [==============================] - 27s 330ms/step - loss: 9.6135e-04 - acc: 0.9997 - val_loss: 0.0234 - val_acc: 0.9950\n",
      "Epoch 445/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0034 - acc: 0.9990WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0137 - acc: 0.9956\n",
      "\n",
      "Epoch 00445: val_loss did not improve from 0.00456\n",
      "81/81 [==============================] - 23s 278ms/step - loss: 0.0033 - acc: 0.9991 - val_loss: 0.0137 - val_acc: 0.9956\n",
      "Epoch 446/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0025 - acc: 0.9997WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0193 - acc: 0.9947\n",
      "\n",
      "Epoch 00446: val_loss did not improve from 0.00456\n",
      "81/81 [==============================] - 24s 298ms/step - loss: 0.0024 - acc: 0.9997 - val_loss: 0.0193 - val_acc: 0.9947\n",
      "Epoch 447/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0051 - acc: 0.9978WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0083 - acc: 0.9975s may duplicate your\n",
      "\n",
      "Epoch 00447: val_loss did not improve from 0.00456\n",
      "81/81 [==============================] - 22s 267ms/step - loss: 0.0054 - acc: 0.9975 - val_loss: 0.0083 - val_acc: 0.9975\n",
      "Epoch 448/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0046 - acc: 0.9987WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0134 - acc: 0.9975\n",
      "\n",
      "Epoch 00448: val_loss did not improve from 0.00456\n",
      "81/81 [==============================] - 22s 266ms/step - loss: 0.0051 - acc: 0.9984 - val_loss: 0.0134 - val_acc: 0.9975\n",
      "Epoch 449/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0087 - acc: 0.9975WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0314 - acc: 0.9894\n",
      "\n",
      "Epoch 00449: val_loss did not improve from 0.00456\n",
      "81/81 [==============================] - 23s 279ms/step - loss: 0.0105 - acc: 0.9966 - val_loss: 0.0314 - val_acc: 0.9894\n",
      "Epoch 450/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0067 - acc: 0.9975WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0255 - acc: 0.9950\n",
      "\n",
      "Epoch 00450: val_loss did not improve from 0.00456\n",
      "81/81 [==============================] - 22s 277ms/step - loss: 0.0068 - acc: 0.9975 - val_loss: 0.0255 - val_acc: 0.9950\n",
      "Epoch 451/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0057 - acc: 0.9981WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0152 - acc: 0.9947\n",
      "\n",
      "Epoch 00451: val_loss did not improve from 0.00456\n",
      "81/81 [==============================] - 21s 265ms/step - loss: 0.0056 - acc: 0.9981 - val_loss: 0.0152 - val_acc: 0.9947\n",
      "Epoch 452/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0050 - acc: 0.9981WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0087 - acc: 0.9947\n",
      "\n",
      "Epoch 00452: val_loss did not improve from 0.00456\n",
      "81/81 [==============================] - 22s 268ms/step - loss: 0.0049 - acc: 0.9981 - val_loss: 0.0087 - val_acc: 0.9947\n",
      "Epoch 453/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0028 - acc: 0.9991WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 22s 7ms/sample - loss: 0.0208 - acc: 0.9897\n",
      "\n",
      "Epoch 00453: val_loss did not improve from 0.00456\n",
      "81/81 [==============================] - 26s 326ms/step - loss: 0.0028 - acc: 0.9991 - val_loss: 0.0208 - val_acc: 0.9897\n",
      "Epoch 454/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.9994WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 25s 8ms/sample - loss: 0.0323 - acc: 0.9947\n",
      "\n",
      "Epoch 00454: val_loss did not improve from 0.00456\n",
      "81/81 [==============================] - 32s 400ms/step - loss: 0.0017 - acc: 0.9994 - val_loss: 0.0323 - val_acc: 0.9947\n",
      "Epoch 455/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0130 - acc: 0.9962WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 15s 5ms/sample - loss: 0.0123 - acc: 0.9950\n",
      "\n",
      "Epoch 00455: val_loss did not improve from 0.00456\n",
      "81/81 [==============================] - 22s 272ms/step - loss: 0.0127 - acc: 0.9963 - val_loss: 0.0123 - val_acc: 0.9950\n",
      "Epoch 456/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0061 - acc: 0.9975WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0263 - acc: 0.9950\n",
      "\n",
      "Epoch 00456: val_loss did not improve from 0.00456\n",
      "81/81 [==============================] - 22s 273ms/step - loss: 0.0060 - acc: 0.9975 - val_loss: 0.0263 - val_acc: 0.9950\n",
      "Epoch 457/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0056 - acc: 0.9987WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0285 - acc: 0.9944\n",
      "\n",
      "Epoch 00457: val_loss did not improve from 0.00456\n",
      "81/81 [==============================] - 23s 283ms/step - loss: 0.0055 - acc: 0.9988 - val_loss: 0.0285 - val_acc: 0.9944\n",
      "Epoch 458/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0018 - acc: 0.9997WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0179 - acc: 0.9941\n",
      "\n",
      "Epoch 00458: val_loss did not improve from 0.00456\n",
      "81/81 [==============================] - 21s 264ms/step - loss: 0.0018 - acc: 0.9997 - val_loss: 0.0179 - val_acc: 0.9941\n",
      "Epoch 459/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0037 - acc: 0.9994WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0316 - acc: 0.9950\n",
      "\n",
      "Epoch 00459: val_loss did not improve from 0.00456\n",
      "81/81 [==============================] - 26s 323ms/step - loss: 0.0036 - acc: 0.9994 - val_loss: 0.0316 - val_acc: 0.9950\n",
      "Epoch 460/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0039 - acc: 0.9984WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0370 - acc: 0.9950\n",
      "\n",
      "Epoch 00460: val_loss did not improve from 0.00456\n",
      "81/81 [==============================] - 23s 279ms/step - loss: 0.0038 - acc: 0.9984 - val_loss: 0.0370 - val_acc: 0.9950\n",
      "Epoch 461/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0074 - acc: 0.9978WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.0077 - acc: 0.9969\n",
      "\n",
      "Epoch 00461: val_loss did not improve from 0.00456\n",
      "81/81 [==============================] - 22s 269ms/step - loss: 0.0073 - acc: 0.9978 - val_loss: 0.0077 - val_acc: 0.9969\n",
      "Epoch 462/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/81 [============================>.] - ETA: 0s - loss: 0.0078 - acc: 0.9959WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.0060 - acc: 0.9972\n",
      "\n",
      "Epoch 00462: val_loss did not improve from 0.00456\n",
      "81/81 [==============================] - 22s 275ms/step - loss: 0.0077 - acc: 0.9960 - val_loss: 0.0060 - val_acc: 0.9972\n",
      "Epoch 463/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0054 - acc: 0.9984WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0183 - acc: 0.9937\n",
      "\n",
      "Epoch 00463: val_loss did not improve from 0.00456\n",
      "81/81 [==============================] - 22s 274ms/step - loss: 0.0053 - acc: 0.9984 - val_loss: 0.0183 - val_acc: 0.9937\n",
      "Epoch 464/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0038 - acc: 0.9978WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 21s 6ms/sample - loss: 0.0227 - acc: 0.9944\n",
      "\n",
      "Epoch 00464: val_loss did not improve from 0.00456\n",
      "81/81 [==============================] - 27s 331ms/step - loss: 0.0037 - acc: 0.9978 - val_loss: 0.0227 - val_acc: 0.9944\n",
      "Epoch 465/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0056 - acc: 0.9991WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0099 - acc: 0.9944\n",
      "\n",
      "Epoch 00465: val_loss did not improve from 0.00456\n",
      "81/81 [==============================] - 22s 277ms/step - loss: 0.0056 - acc: 0.9991 - val_loss: 0.0099 - val_acc: 0.9944\n",
      "Epoch 466/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0022 - acc: 0.9997WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0099 - acc: 0.9975\n",
      "\n",
      "Epoch 00466: val_loss did not improve from 0.00456\n",
      "81/81 [==============================] - 22s 275ms/step - loss: 0.0022 - acc: 0.9997 - val_loss: 0.0099 - val_acc: 0.9975\n",
      "Epoch 467/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 2.6648e-04 - acc: 1.0000WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 14s 5ms/sample - loss: 0.0231 - acc: 0.9941\n",
      "\n",
      "Epoch 00467: val_loss did not improve from 0.00456\n",
      "81/81 [==============================] - 23s 288ms/step - loss: 2.7038e-04 - acc: 1.0000 - val_loss: 0.0231 - val_acc: 0.9941\n",
      "Epoch 468/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 6.3275e-04 - acc: 0.9997WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0170 - acc: 0.9950\n",
      "\n",
      "Epoch 00468: val_loss did not improve from 0.00456\n",
      "81/81 [==============================] - 26s 316ms/step - loss: 6.2502e-04 - acc: 0.9997 - val_loss: 0.0170 - val_acc: 0.9950\n",
      "Epoch 469/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.9990WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0157 - acc: 0.9969\n",
      "\n",
      "Epoch 00469: val_loss did not improve from 0.00456\n",
      "81/81 [==============================] - 22s 271ms/step - loss: 0.0017 - acc: 0.9991 - val_loss: 0.0157 - val_acc: 0.9969\n",
      "Epoch 470/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0035 - acc: 0.9991WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0316 - acc: 0.9906\n",
      "\n",
      "Epoch 00470: val_loss did not improve from 0.00456\n",
      "81/81 [==============================] - 24s 297ms/step - loss: 0.0035 - acc: 0.9991 - val_loss: 0.0316 - val_acc: 0.9906\n",
      "Epoch 471/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0071 - acc: 0.9981WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 21s 6ms/sample - loss: 0.0194 - acc: 0.9934\n",
      "\n",
      "Epoch 00471: val_loss did not improve from 0.00456\n",
      "81/81 [==============================] - 25s 306ms/step - loss: 0.0070 - acc: 0.9981 - val_loss: 0.0194 - val_acc: 0.9934\n",
      "Epoch 472/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0037 - acc: 0.9990WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0262 - acc: 0.9950\n",
      "\n",
      "Epoch 00472: val_loss did not improve from 0.00456\n",
      "81/81 [==============================] - 23s 282ms/step - loss: 0.0036 - acc: 0.9991 - val_loss: 0.0262 - val_acc: 0.9950\n",
      "Epoch 473/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 7.8914e-04 - acc: 1.0000WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 15s 5ms/sample - loss: 0.0200 - acc: 0.9950\n",
      "\n",
      "Epoch 00473: val_loss did not improve from 0.00456\n",
      "81/81 [==============================] - 21s 263ms/step - loss: 7.8261e-04 - acc: 1.0000 - val_loss: 0.0200 - val_acc: 0.9950\n",
      "Epoch 474/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 3.9724e-04 - acc: 1.0000WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0166 - acc: 0.9975\n",
      "\n",
      "Epoch 00474: val_loss did not improve from 0.00456\n",
      "81/81 [==============================] - 22s 268ms/step - loss: 3.8855e-04 - acc: 1.0000 - val_loss: 0.0166 - val_acc: 0.9975\n",
      "Epoch 475/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 6.2082e-04 - acc: 0.9997WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 15s 5ms/sample - loss: 0.0326 - acc: 0.9931\n",
      "\n",
      "Epoch 00475: val_loss did not improve from 0.00456\n",
      "81/81 [==============================] - 22s 270ms/step - loss: 6.0635e-04 - acc: 0.9997 - val_loss: 0.0326 - val_acc: 0.9931\n",
      "Epoch 476/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0036 - acc: 0.9984WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0147 - acc: 0.9931\n",
      "\n",
      "Epoch 00476: val_loss did not improve from 0.00456\n",
      "81/81 [==============================] - 23s 282ms/step - loss: 0.0036 - acc: 0.9984 - val_loss: 0.0147 - val_acc: 0.9931\n",
      "Epoch 477/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0055 - acc: 0.9984WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0245 - acc: 0.9925\n",
      "\n",
      "Epoch 00477: val_loss did not improve from 0.00456\n",
      "81/81 [==============================] - 22s 276ms/step - loss: 0.0059 - acc: 0.9984 - val_loss: 0.0245 - val_acc: 0.9925\n",
      "Epoch 478/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0102 - acc: 0.9972WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 12s 4ms/sample - loss: 0.0369 - acc: 0.9950\n",
      "\n",
      "Epoch 00478: val_loss did not improve from 0.00456\n",
      "81/81 [==============================] - 22s 267ms/step - loss: 0.0101 - acc: 0.9972 - val_loss: 0.0369 - val_acc: 0.9950\n",
      "Epoch 479/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0054 - acc: 0.9987WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0126 - acc: 0.9950\n",
      "\n",
      "Epoch 00479: val_loss did not improve from 0.00456\n",
      "81/81 [==============================] - 22s 270ms/step - loss: 0.0053 - acc: 0.9988 - val_loss: 0.0126 - val_acc: 0.9950\n",
      "Epoch 480/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0027 - acc: 0.9991WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0070 - acc: 0.9950\n",
      "\n",
      "Epoch 00480: val_loss did not improve from 0.00456\n",
      "81/81 [==============================] - 23s 282ms/step - loss: 0.0028 - acc: 0.9991 - val_loss: 0.0070 - val_acc: 0.9950\n",
      "Epoch 481/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0031 - acc: 0.9987WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0237 - acc: 0.9922\n",
      "\n",
      "Epoch 00481: val_loss did not improve from 0.00456\n",
      "81/81 [==============================] - 22s 271ms/step - loss: 0.0030 - acc: 0.9988 - val_loss: 0.0237 - val_acc: 0.9922\n",
      "Epoch 482/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0106 - acc: 0.9968WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3190/3183 [==============================] - 17s 5ms/sample - loss: 0.0182 - acc: 0.9950\n",
      "\n",
      "Epoch 00482: val_loss did not improve from 0.00456\n",
      "81/81 [==============================] - 21s 260ms/step - loss: 0.0103 - acc: 0.9969 - val_loss: 0.0182 - val_acc: 0.9950\n",
      "Epoch 483/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0065 - acc: 0.9975WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0260 - acc: 0.9950\n",
      "\n",
      "Epoch 00483: val_loss did not improve from 0.00456\n",
      "81/81 [==============================] - 22s 277ms/step - loss: 0.0064 - acc: 0.9975 - val_loss: 0.0260 - val_acc: 0.9950\n",
      "Epoch 484/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0036 - acc: 0.9987WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0137 - acc: 0.9937\n",
      "\n",
      "Epoch 00484: val_loss did not improve from 0.00456\n",
      "81/81 [==============================] - 22s 273ms/step - loss: 0.0035 - acc: 0.9988 - val_loss: 0.0137 - val_acc: 0.9937\n",
      "Epoch 485/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0053 - acc: 0.9978WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0178 - acc: 0.9950\n",
      "\n",
      "Epoch 00485: val_loss did not improve from 0.00456\n",
      "81/81 [==============================] - 22s 275ms/step - loss: 0.0052 - acc: 0.9978 - val_loss: 0.0178 - val_acc: 0.9950\n",
      "Epoch 486/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0024 - acc: 0.9987WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0121 - acc: 0.9950\n",
      "\n",
      "Epoch 00486: val_loss did not improve from 0.00456\n",
      "81/81 [==============================] - 23s 285ms/step - loss: 0.0023 - acc: 0.9988 - val_loss: 0.0121 - val_acc: 0.9950\n",
      "Epoch 487/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 5.5680e-04 - acc: 1.0000WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 20s 6ms/sample - loss: 0.0200 - acc: 0.9950\n",
      "\n",
      "Epoch 00487: val_loss did not improve from 0.00456\n",
      "81/81 [==============================] - 24s 301ms/step - loss: 5.4774e-04 - acc: 1.0000 - val_loss: 0.0200 - val_acc: 0.9950\n",
      "Epoch 488/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0063 - acc: 0.9978WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0085 - acc: 0.9975\n",
      "\n",
      "Epoch 00488: val_loss did not improve from 0.00456\n",
      "81/81 [==============================] - 25s 313ms/step - loss: 0.0064 - acc: 0.9975 - val_loss: 0.0085 - val_acc: 0.9975\n",
      "Epoch 489/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0052 - acc: 0.9984WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0218 - acc: 0.9950\n",
      "\n",
      "Epoch 00489: val_loss did not improve from 0.00456\n",
      "81/81 [==============================] - 22s 269ms/step - loss: 0.0051 - acc: 0.9984 - val_loss: 0.0218 - val_acc: 0.9950\n",
      "Epoch 490/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0010 - acc: 1.0000WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 20s 6ms/sample - loss: 0.0311 - acc: 0.9941\n",
      "\n",
      "Epoch 00490: val_loss did not improve from 0.00456\n",
      "81/81 [==============================] - 24s 291ms/step - loss: 0.0010 - acc: 1.0000 - val_loss: 0.0311 - val_acc: 0.9941\n",
      "Epoch 491/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 4.5007e-04 - acc: 1.0000WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 29s 9ms/sample - loss: 0.0357 - acc: 0.9950\n",
      "\n",
      "Epoch 00491: val_loss did not improve from 0.00456\n",
      "81/81 [==============================] - 35s 430ms/step - loss: 4.4470e-04 - acc: 1.0000 - val_loss: 0.0357 - val_acc: 0.9950\n",
      "Epoch 492/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 8.6463e-05 - acc: 1.0000WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0295 - acc: 0.9950\n",
      "\n",
      "Epoch 00492: val_loss did not improve from 0.00456\n",
      "81/81 [==============================] - 23s 283ms/step - loss: 8.5446e-05 - acc: 1.0000 - val_loss: 0.0295 - val_acc: 0.9950\n",
      "Epoch 493/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/81 [============================>.] - ETA: 0s - loss: 7.9828e-04 - acc: 0.9997WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 22s 7ms/sample - loss: 0.0140 - acc: 0.9944\n",
      "\n",
      "Epoch 00493: val_loss did not improve from 0.00456\n",
      "81/81 [==============================] - 26s 321ms/step - loss: 7.8182e-04 - acc: 0.9997 - val_loss: 0.0140 - val_acc: 0.9944\n",
      "Epoch 494/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0041 - acc: 0.9984WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0310 - acc: 0.9947\n",
      "\n",
      "Epoch 00494: val_loss did not improve from 0.00456\n",
      "81/81 [==============================] - 21s 260ms/step - loss: 0.0042 - acc: 0.9984 - val_loss: 0.0310 - val_acc: 0.9947\n",
      "Epoch 495/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0034 - acc: 0.9994WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0238 - acc: 0.9944\n",
      "\n",
      "Epoch 00495: val_loss did not improve from 0.00456\n",
      "81/81 [==============================] - 22s 269ms/step - loss: 0.0033 - acc: 0.9994 - val_loss: 0.0238 - val_acc: 0.9944\n",
      "Epoch 496/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0014 - acc: 1.0000WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.0131 - acc: 0.9972\n",
      "\n",
      "Epoch 00496: val_loss did not improve from 0.00456\n",
      "81/81 [==============================] - 21s 264ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.0131 - val_acc: 0.9972\n",
      "Epoch 497/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0051 - acc: 0.9990WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 5ms/sample - loss: 0.0067 - acc: 0.9972\n",
      "\n",
      "Epoch 00497: val_loss did not improve from 0.00456\n",
      "81/81 [==============================] - 22s 266ms/step - loss: 0.0051 - acc: 0.9991 - val_loss: 0.0067 - val_acc: 0.9972\n",
      "Epoch 498/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0089 - acc: 0.9978WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0180 - acc: 0.9950\n",
      "\n",
      "Epoch 00498: val_loss did not improve from 0.00456\n",
      "81/81 [==============================] - 26s 323ms/step - loss: 0.0087 - acc: 0.9978 - val_loss: 0.0180 - val_acc: 0.9950\n",
      "Epoch 499/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0030 - acc: 0.9987WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 5ms/sample - loss: 0.0165 - acc: 0.9950\n",
      "\n",
      "Epoch 00499: val_loss did not improve from 0.00456\n",
      "81/81 [==============================] - 23s 280ms/step - loss: 0.0029 - acc: 0.9988 - val_loss: 0.0165 - val_acc: 0.9950\n",
      "Epoch 500/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0065 - acc: 0.9981WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0179 - acc: 0.9950\n",
      "\n",
      "Epoch 00500: val_loss did not improve from 0.00456\n",
      "81/81 [==============================] - 22s 270ms/step - loss: 0.0064 - acc: 0.9981 - val_loss: 0.0179 - val_acc: 0.9950\n",
      "Epoch 501/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0013 - acc: 1.0000WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0197 - acc: 0.9944\n",
      "\n",
      "Epoch 00501: val_loss did not improve from 0.00456\n",
      "81/81 [==============================] - 23s 281ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.0197 - val_acc: 0.9944\n",
      "Epoch 502/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0070 - acc: 0.9972WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0453 - acc: 0.99259s - loss: 0.0724\n",
      "\n",
      "Epoch 00502: val_loss did not improve from 0.00456\n",
      "81/81 [==============================] - 22s 265ms/step - loss: 0.0069 - acc: 0.9972 - val_loss: 0.0453 - val_acc: 0.9925\n",
      "Epoch 503/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0023 - acc: 0.9994WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0168 - acc: 0.99503s - loss: 0.0200 - acc:\n",
      "\n",
      "Epoch 00503: val_loss did not improve from 0.00456\n",
      "81/81 [==============================] - 23s 284ms/step - loss: 0.0022 - acc: 0.9994 - val_loss: 0.0168 - val_acc: 0.9950\n",
      "Epoch 504/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 9.0141e-04 - acc: 0.9997WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0266 - acc: 0.9950\n",
      "\n",
      "Epoch 00504: val_loss did not improve from 0.00456\n",
      "81/81 [==============================] - 23s 282ms/step - loss: 8.8617e-04 - acc: 0.9997 - val_loss: 0.0266 - val_acc: 0.9950\n",
      "\n",
      "vis_imagenet_6_class_augmentation_2D_CNN_custom_ch_32_DO_075_DO_5_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3183/3183 [==============================] - 3s 900us/sample - loss: 10.6499 - acc: 0.3374\n",
      "Loss: 10.649943708605003 Accuracy: 0.33741754\n",
      "\n",
      "Epoch 1/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.9560 - acc: 0.4984WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 5ms/sample - loss: 0.6617 - acc: 0.8575\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.66169, saving model to model/checkpoint/vis_imagenet_6_class_augmentation_2D_CNN_custom_ch_32_DO_075_DO_6_conv_checkpoint/001-0.6617.hdf5\n",
      "81/81 [==============================] - 23s 290ms/step - loss: 0.9534 - acc: 0.4994 - val_loss: 0.6617 - val_acc: 0.8575\n",
      "Epoch 2/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.7429 - acc: 0.5537WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.8002 - acc: 0.5125\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.66169\n",
      "81/81 [==============================] - 23s 278ms/step - loss: 0.7383 - acc: 0.5574 - val_loss: 0.8002 - val_acc: 0.5125\n",
      "Epoch 3/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.4857 - acc: 0.7813WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 20s 6ms/sample - loss: 0.7100 - acc: 0.6194\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.66169\n",
      "81/81 [==============================] - 24s 295ms/step - loss: 0.4834 - acc: 0.7824 - val_loss: 0.7100 - val_acc: 0.6194\n",
      "Epoch 4/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.3966 - acc: 0.8291WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.3239 - acc: 0.8775\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.66169 to 0.32392, saving model to model/checkpoint/vis_imagenet_6_class_augmentation_2D_CNN_custom_ch_32_DO_075_DO_6_conv_checkpoint/004-0.3239.hdf5\n",
      "81/81 [==============================] - 22s 266ms/step - loss: 0.3922 - acc: 0.8318 - val_loss: 0.3239 - val_acc: 0.8775\n",
      "Epoch 5/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.3417 - acc: 0.8614WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 23s 7ms/sample - loss: 0.3403 - acc: 0.8675\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.32392\n",
      "81/81 [==============================] - 27s 334ms/step - loss: 0.3410 - acc: 0.8616 - val_loss: 0.3403 - val_acc: 0.8675\n",
      "Epoch 6/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.3174 - acc: 0.8781WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.1729 - acc: 0.9381\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.32392 to 0.17294, saving model to model/checkpoint/vis_imagenet_6_class_augmentation_2D_CNN_custom_ch_32_DO_075_DO_6_conv_checkpoint/006-0.1729.hdf5\n",
      "81/81 [==============================] - 25s 305ms/step - loss: 0.3138 - acc: 0.8793 - val_loss: 0.1729 - val_acc: 0.9381\n",
      "Epoch 7/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.2556 - acc: 0.8969WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 22s 7ms/sample - loss: 0.2167 - acc: 0.9125\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.17294\n",
      "81/81 [==============================] - 27s 336ms/step - loss: 0.2572 - acc: 0.8966 - val_loss: 0.2167 - val_acc: 0.9125\n",
      "Epoch 8/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.2381 - acc: 0.9092WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0961 - acc: 0.9700\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.17294 to 0.09613, saving model to model/checkpoint/vis_imagenet_6_class_augmentation_2D_CNN_custom_ch_32_DO_075_DO_6_conv_checkpoint/008-0.0961.hdf5\n",
      "81/81 [==============================] - 23s 283ms/step - loss: 0.2376 - acc: 0.9094 - val_loss: 0.0961 - val_acc: 0.9700\n",
      "Epoch 9/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.2321 - acc: 0.9142WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 5ms/sample - loss: 0.1059 - acc: 0.9750\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.09613\n",
      "81/81 [==============================] - 21s 264ms/step - loss: 0.2315 - acc: 0.9140 - val_loss: 0.1059 - val_acc: 0.9750\n",
      "Epoch 10/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.2173 - acc: 0.9157WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.1793 - acc: 0.9300\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.09613\n",
      "81/81 [==============================] - 22s 271ms/step - loss: 0.2172 - acc: 0.9153 - val_loss: 0.1793 - val_acc: 0.9300\n",
      "Epoch 11/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.2044 - acc: 0.9214WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 23s 7ms/sample - loss: 0.0913 - acc: 0.9775\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.09613 to 0.09126, saving model to model/checkpoint/vis_imagenet_6_class_augmentation_2D_CNN_custom_ch_32_DO_075_DO_6_conv_checkpoint/011-0.0913.hdf5\n",
      "81/81 [==============================] - 27s 339ms/step - loss: 0.2032 - acc: 0.9218 - val_loss: 0.0913 - val_acc: 0.9775\n",
      "Epoch 12/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.1629 - acc: 0.9419WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0891 - acc: 0.9688\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.09126 to 0.08911, saving model to model/checkpoint/vis_imagenet_6_class_augmentation_2D_CNN_custom_ch_32_DO_075_DO_6_conv_checkpoint/012-0.0891.hdf5\n",
      "81/81 [==============================] - 23s 285ms/step - loss: 0.1625 - acc: 0.9420 - val_loss: 0.0891 - val_acc: 0.9688\n",
      "Epoch 13/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.1623 - acc: 0.9376WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0743 - acc: 0.9800\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.08911 to 0.07427, saving model to model/checkpoint/vis_imagenet_6_class_augmentation_2D_CNN_custom_ch_32_DO_075_DO_6_conv_checkpoint/013-0.0743.hdf5\n",
      "81/81 [==============================] - 22s 270ms/step - loss: 0.1611 - acc: 0.9379 - val_loss: 0.0743 - val_acc: 0.9800\n",
      "Epoch 14/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.1591 - acc: 0.9447WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3200/3183 [==============================] - 18s 5ms/sample - loss: 0.0654 - acc: 0.9825\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.07427 to 0.06537, saving model to model/checkpoint/vis_imagenet_6_class_augmentation_2D_CNN_custom_ch_32_DO_075_DO_6_conv_checkpoint/014-0.0654.hdf5\n",
      "81/81 [==============================] - 21s 265ms/step - loss: 0.1594 - acc: 0.9444 - val_loss: 0.0654 - val_acc: 0.9825\n",
      "Epoch 15/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.1412 - acc: 0.9513WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.1492 - acc: 0.9400\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.06537\n",
      "81/81 [==============================] - 21s 261ms/step - loss: 0.1404 - acc: 0.9516 - val_loss: 0.1492 - val_acc: 0.9400\n",
      "Epoch 16/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.1456 - acc: 0.9475WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.1928 - acc: 0.9147\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.06537\n",
      "81/81 [==============================] - 24s 296ms/step - loss: 0.1455 - acc: 0.9475 - val_loss: 0.1928 - val_acc: 0.9147\n",
      "Epoch 17/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.1396 - acc: 0.9491WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.1178 - acc: 0.9575\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.06537\n",
      "81/81 [==============================] - 22s 266ms/step - loss: 0.1401 - acc: 0.9488 - val_loss: 0.1178 - val_acc: 0.9575\n",
      "Epoch 18/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.1352 - acc: 0.9538WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 21s 7ms/sample - loss: 0.2082 - acc: 0.8975\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.06537\n",
      "81/81 [==============================] - 25s 314ms/step - loss: 0.1369 - acc: 0.9538 - val_loss: 0.2082 - val_acc: 0.8975\n",
      "Epoch 19/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.1343 - acc: 0.9516WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 20s 6ms/sample - loss: 0.0749 - acc: 0.9722\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.06537\n",
      "81/81 [==============================] - 25s 312ms/step - loss: 0.1348 - acc: 0.9516 - val_loss: 0.0749 - val_acc: 0.9722\n",
      "Epoch 20/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.1357 - acc: 0.9547WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.1373 - acc: 0.9375\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.06537\n",
      "81/81 [==============================] - 22s 270ms/step - loss: 0.1352 - acc: 0.9550 - val_loss: 0.1373 - val_acc: 0.9375\n",
      "Epoch 21/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.1334 - acc: 0.9542WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 20s 6ms/sample - loss: 0.1344 - acc: 0.9469\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.06537\n",
      "81/81 [==============================] - 24s 301ms/step - loss: 0.1321 - acc: 0.9550 - val_loss: 0.1344 - val_acc: 0.9469\n",
      "Epoch 22/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.1242 - acc: 0.9588WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 13s 4ms/sample - loss: 0.0918 - acc: 0.9675\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.06537\n",
      "81/81 [==============================] - 21s 263ms/step - loss: 0.1239 - acc: 0.9587 - val_loss: 0.0918 - val_acc: 0.9675\n",
      "Epoch 23/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.1368 - acc: 0.9424WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.1035 - acc: 0.9525\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.06537\n",
      "81/81 [==============================] - 24s 295ms/step - loss: 0.1360 - acc: 0.9432 - val_loss: 0.1035 - val_acc: 0.9525\n",
      "Epoch 24/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.1272 - acc: 0.9561WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0594 - acc: 0.9825\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.06537 to 0.05944, saving model to model/checkpoint/vis_imagenet_6_class_augmentation_2D_CNN_custom_ch_32_DO_075_DO_6_conv_checkpoint/024-0.0594.hdf5\n",
      "81/81 [==============================] - 23s 278ms/step - loss: 0.1269 - acc: 0.9569 - val_loss: 0.0594 - val_acc: 0.9825\n",
      "Epoch 25/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.1131 - acc: 0.9613WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.1457 - acc: 0.9328\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.05944\n",
      "81/81 [==============================] - 22s 270ms/step - loss: 0.1139 - acc: 0.9612 - val_loss: 0.1457 - val_acc: 0.9328\n",
      "Epoch 26/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.1178 - acc: 0.9595WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.1391 - acc: 0.9350\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.05944\n",
      "81/81 [==============================] - 23s 284ms/step - loss: 0.1189 - acc: 0.9590 - val_loss: 0.1391 - val_acc: 0.9350\n",
      "Epoch 27/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.1116 - acc: 0.9613WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 21s 7ms/sample - loss: 0.0598 - acc: 0.9759\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.05944\n",
      "81/81 [==============================] - 28s 346ms/step - loss: 0.1118 - acc: 0.9612 - val_loss: 0.0598 - val_acc: 0.9759\n",
      "Epoch 28/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.1111 - acc: 0.9617WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0793 - acc: 0.9688\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.05944\n",
      "81/81 [==============================] - 24s 292ms/step - loss: 0.1103 - acc: 0.9621 - val_loss: 0.0793 - val_acc: 0.9688\n",
      "Epoch 29/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.1002 - acc: 0.9667WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3200/3183 [==============================] - 22s 7ms/sample - loss: 0.1031 - acc: 0.9531\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.05944\n",
      "81/81 [==============================] - 27s 329ms/step - loss: 0.0993 - acc: 0.9671 - val_loss: 0.1031 - val_acc: 0.9531\n",
      "Epoch 30/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0930 - acc: 0.9679WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.0751 - acc: 0.9688\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.05944\n",
      "81/81 [==============================] - 26s 319ms/step - loss: 0.0925 - acc: 0.9677 - val_loss: 0.0751 - val_acc: 0.9688\n",
      "Epoch 31/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0903 - acc: 0.9664WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0438 - acc: 0.9900\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.05944 to 0.04384, saving model to model/checkpoint/vis_imagenet_6_class_augmentation_2D_CNN_custom_ch_32_DO_075_DO_6_conv_checkpoint/031-0.0438.hdf5\n",
      "81/81 [==============================] - 23s 288ms/step - loss: 0.0895 - acc: 0.9668 - val_loss: 0.0438 - val_acc: 0.9900\n",
      "Epoch 32/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0891 - acc: 0.9698WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0939 - acc: 0.9650\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.04384\n",
      "81/81 [==============================] - 22s 270ms/step - loss: 0.0885 - acc: 0.9702 - val_loss: 0.0939 - val_acc: 0.9650\n",
      "Epoch 33/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0942 - acc: 0.9701WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.1547 - acc: 0.9325\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.04384\n",
      "81/81 [==============================] - 22s 269ms/step - loss: 0.0939 - acc: 0.9702 - val_loss: 0.1547 - val_acc: 0.9325\n",
      "Epoch 34/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0781 - acc: 0.9710WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 20s 6ms/sample - loss: 0.1155 - acc: 0.9550\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.04384\n",
      "81/81 [==============================] - 24s 291ms/step - loss: 0.0777 - acc: 0.9714 - val_loss: 0.1155 - val_acc: 0.9550\n",
      "Epoch 35/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0913 - acc: 0.9683WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0885 - acc: 0.9588\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.04384\n",
      "81/81 [==============================] - 22s 278ms/step - loss: 0.0912 - acc: 0.9683 - val_loss: 0.0885 - val_acc: 0.9588\n",
      "Epoch 36/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0861 - acc: 0.9705WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.2373 - acc: 0.8850\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.04384\n",
      "81/81 [==============================] - 22s 267ms/step - loss: 0.0882 - acc: 0.9693 - val_loss: 0.2373 - val_acc: 0.8850\n",
      "Epoch 37/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0898 - acc: 0.9688WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 26s 8ms/sample - loss: 0.1384 - acc: 0.9325\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.04384\n",
      "81/81 [==============================] - 30s 371ms/step - loss: 0.0890 - acc: 0.9687 - val_loss: 0.1384 - val_acc: 0.9325\n",
      "Epoch 38/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.1053 - acc: 0.9624WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.1722 - acc: 0.9162\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.04384\n",
      "81/81 [==============================] - 23s 287ms/step - loss: 0.1055 - acc: 0.9628 - val_loss: 0.1722 - val_acc: 0.9162\n",
      "Epoch 39/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0845 - acc: 0.9736WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0421 - acc: 0.9875\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.04384 to 0.04215, saving model to model/checkpoint/vis_imagenet_6_class_augmentation_2D_CNN_custom_ch_32_DO_075_DO_6_conv_checkpoint/039-0.0421.hdf5\n",
      "81/81 [==============================] - 22s 270ms/step - loss: 0.0839 - acc: 0.9739 - val_loss: 0.0421 - val_acc: 0.9875\n",
      "Epoch 40/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0730 - acc: 0.9727WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0897 - acc: 0.9600\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.04215\n",
      "81/81 [==============================] - 22s 267ms/step - loss: 0.0725 - acc: 0.9730 - val_loss: 0.0897 - val_acc: 0.9600\n",
      "Epoch 41/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0757 - acc: 0.9723WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.1443 - acc: 0.9475\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.04215\n",
      "81/81 [==============================] - 21s 260ms/step - loss: 0.0760 - acc: 0.9721 - val_loss: 0.1443 - val_acc: 0.9475\n",
      "Epoch 42/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0687 - acc: 0.9769WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3190/3183 [==============================] - 18s 6ms/sample - loss: 0.0504 - acc: 0.9853\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.04215\n",
      "81/81 [==============================] - 22s 274ms/step - loss: 0.0686 - acc: 0.9767 - val_loss: 0.0504 - val_acc: 0.9853\n",
      "Epoch 43/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0717 - acc: 0.9771WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0335 - acc: 0.9900\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.04215 to 0.03353, saving model to model/checkpoint/vis_imagenet_6_class_augmentation_2D_CNN_custom_ch_32_DO_075_DO_6_conv_checkpoint/043-0.0335.hdf5\n",
      "81/81 [==============================] - 21s 262ms/step - loss: 0.0720 - acc: 0.9767 - val_loss: 0.0335 - val_acc: 0.9900\n",
      "Epoch 44/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0719 - acc: 0.9768WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.0505 - acc: 0.9825\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.03353\n",
      "81/81 [==============================] - 21s 265ms/step - loss: 0.0730 - acc: 0.9758 - val_loss: 0.0505 - val_acc: 0.9825\n",
      "Epoch 45/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0682 - acc: 0.9764WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0378 - acc: 0.9812\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.03353\n",
      "81/81 [==============================] - 22s 272ms/step - loss: 0.0674 - acc: 0.9770 - val_loss: 0.0378 - val_acc: 0.9812\n",
      "Epoch 46/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0665 - acc: 0.9784WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0475 - acc: 0.9769\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.03353\n",
      "81/81 [==============================] - 23s 284ms/step - loss: 0.0685 - acc: 0.9777 - val_loss: 0.0475 - val_acc: 0.9769\n",
      "Epoch 47/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0646 - acc: 0.9764WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0428 - acc: 0.9825\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.03353\n",
      "81/81 [==============================] - 22s 266ms/step - loss: 0.0640 - acc: 0.9767 - val_loss: 0.0428 - val_acc: 0.9825\n",
      "Epoch 48/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0583 - acc: 0.9793WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0425 - acc: 0.9812\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.03353\n",
      "81/81 [==============================] - 22s 268ms/step - loss: 0.0578 - acc: 0.9795 - val_loss: 0.0425 - val_acc: 0.9812\n",
      "Epoch 49/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0539 - acc: 0.9821- WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.1013 - acc: 0.9500\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.03353\n",
      "81/81 [==============================] - 22s 270ms/step - loss: 0.0534 - acc: 0.9823 - val_loss: 0.1013 - val_acc: 0.9500\n",
      "Epoch 50/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0667 - acc: 0.9758WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 21s 7ms/sample - loss: 0.0884 - acc: 0.9638\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.03353\n",
      "81/81 [==============================] - 26s 319ms/step - loss: 0.0663 - acc: 0.9761 - val_loss: 0.0884 - val_acc: 0.9638\n",
      "Epoch 51/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0865 - acc: 0.9695WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0378 - acc: 0.9850\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.03353\n",
      "81/81 [==============================] - 23s 279ms/step - loss: 0.0865 - acc: 0.9696 - val_loss: 0.0378 - val_acc: 0.9850\n",
      "Epoch 52/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0688 - acc: 0.9787WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0579 - acc: 0.9831\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.03353\n",
      "81/81 [==============================] - 21s 259ms/step - loss: 0.0691 - acc: 0.9783 - val_loss: 0.0579 - val_acc: 0.9831\n",
      "Epoch 53/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0643 - acc: 0.9761WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0580 - acc: 0.9756\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.03353\n",
      "81/81 [==============================] - 22s 268ms/step - loss: 0.0637 - acc: 0.9764 - val_loss: 0.0580 - val_acc: 0.9756\n",
      "Epoch 54/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0638 - acc: 0.9793WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 15s 5ms/sample - loss: 0.0539 - acc: 0.977511s - loss\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.03353\n",
      "81/81 [==============================] - 21s 260ms/step - loss: 0.0633 - acc: 0.9795 - val_loss: 0.0539 - val_acc: 0.9775\n",
      "Epoch 55/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0598 - acc: 0.9803WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0549 - acc: 0.9756\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.03353\n",
      "81/81 [==============================] - 21s 264ms/step - loss: 0.0637 - acc: 0.9804 - val_loss: 0.0549 - val_acc: 0.9756\n",
      "Epoch 56/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0439 - acc: 0.9855WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0699 - acc: 0.9606\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.03353\n",
      "81/81 [==============================] - 22s 270ms/step - loss: 0.0440 - acc: 0.9851 - val_loss: 0.0699 - val_acc: 0.9606\n",
      "Epoch 57/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0499 - acc: 0.9808WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 14s 5ms/sample - loss: 0.0604 - acc: 0.9750\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.03353\n",
      "81/81 [==============================] - 21s 261ms/step - loss: 0.0496 - acc: 0.9811 - val_loss: 0.0604 - val_acc: 0.9750\n",
      "Epoch 58/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0506 - acc: 0.9824WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 15s 5ms/sample - loss: 0.0216 - acc: 0.9950\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.03353 to 0.02162, saving model to model/checkpoint/vis_imagenet_6_class_augmentation_2D_CNN_custom_ch_32_DO_075_DO_6_conv_checkpoint/058-0.0216.hdf5\n",
      "81/81 [==============================] - 22s 266ms/step - loss: 0.0502 - acc: 0.9826 - val_loss: 0.0216 - val_acc: 0.9950\n",
      "Epoch 59/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0611 - acc: 0.9764WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0261 - acc: 0.9950\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.02162\n",
      "81/81 [==============================] - 21s 259ms/step - loss: 0.0606 - acc: 0.9767 - val_loss: 0.0261 - val_acc: 0.9950\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0615 - acc: 0.9805WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 22s 7ms/sample - loss: 0.0877 - acc: 0.9553\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.02162\n",
      "81/81 [==============================] - 26s 325ms/step - loss: 0.0611 - acc: 0.9808 - val_loss: 0.0877 - val_acc: 0.9553\n",
      "Epoch 61/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0418 - acc: 0.9862WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0347 - acc: 0.9875\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.02162\n",
      "81/81 [==============================] - 22s 275ms/step - loss: 0.0415 - acc: 0.9863 - val_loss: 0.0347 - val_acc: 0.9875\n",
      "Epoch 62/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0469 - acc: 0.9859WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0468 - acc: 0.9806\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.02162\n",
      "81/81 [==============================] - 21s 265ms/step - loss: 0.0468 - acc: 0.9857 - val_loss: 0.0468 - val_acc: 0.9806\n",
      "Epoch 63/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0464 - acc: 0.9835WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 20s 6ms/sample - loss: 0.0534 - acc: 0.9703\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.02162\n",
      "81/81 [==============================] - 24s 300ms/step - loss: 0.0464 - acc: 0.9836 - val_loss: 0.0534 - val_acc: 0.9703\n",
      "Epoch 64/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0422 - acc: 0.9863WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 24s 8ms/sample - loss: 0.0448 - acc: 0.9856\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.02162\n",
      "81/81 [==============================] - 28s 351ms/step - loss: 0.0412 - acc: 0.9867 - val_loss: 0.0448 - val_acc: 0.9856\n",
      "Epoch 65/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0433 - acc: 0.9854WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0367 - acc: 0.9875\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.02162\n",
      "81/81 [==============================] - 23s 286ms/step - loss: 0.0433 - acc: 0.9851 - val_loss: 0.0367 - val_acc: 0.9875\n",
      "Epoch 66/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0608 - acc: 0.9784WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0243 - acc: 0.9925\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.02162\n",
      "81/81 [==============================] - 23s 285ms/step - loss: 0.0598 - acc: 0.9786 - val_loss: 0.0243 - val_acc: 0.9925\n",
      "Epoch 67/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0443 - acc: 0.9838WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 5ms/sample - loss: 0.0491 - acc: 0.9812\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.02162\n",
      "81/81 [==============================] - 22s 269ms/step - loss: 0.0438 - acc: 0.9842 - val_loss: 0.0491 - val_acc: 0.9812\n",
      "Epoch 68/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0385 - acc: 0.9874WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 20s 6ms/sample - loss: 0.0467 - acc: 0.9850\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.02162\n",
      "81/81 [==============================] - 24s 294ms/step - loss: 0.0382 - acc: 0.9876 - val_loss: 0.0467 - val_acc: 0.9850\n",
      "Epoch 69/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0384 - acc: 0.9890WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 5ms/sample - loss: 0.0494 - acc: 0.9844\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.02162\n",
      "81/81 [==============================] - 22s 267ms/step - loss: 0.0380 - acc: 0.9891 - val_loss: 0.0494 - val_acc: 0.9844\n",
      "Epoch 70/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0404 - acc: 0.9860WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0567 - acc: 0.9775\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.02162\n",
      "81/81 [==============================] - 23s 280ms/step - loss: 0.0420 - acc: 0.9851 - val_loss: 0.0567 - val_acc: 0.9775\n",
      "Epoch 71/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0432 - acc: 0.9837WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0350 - acc: 0.9850\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.02162\n",
      "81/81 [==============================] - 22s 266ms/step - loss: 0.0428 - acc: 0.9839 - val_loss: 0.0350 - val_acc: 0.9850\n",
      "Epoch 72/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0243 - acc: 0.9930WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0324 - acc: 0.9881\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.02162\n",
      "81/81 [==============================] - 22s 276ms/step - loss: 0.0257 - acc: 0.9926 - val_loss: 0.0324 - val_acc: 0.9881\n",
      "Epoch 73/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0501 - acc: 0.9799WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0281 - acc: 0.9950\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.02162\n",
      "81/81 [==============================] - 23s 278ms/step - loss: 0.0504 - acc: 0.9801 - val_loss: 0.0281 - val_acc: 0.9950\n",
      "Epoch 74/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0412 - acc: 0.9876WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0256 - acc: 0.9900\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.02162\n",
      "81/81 [==============================] - 24s 296ms/step - loss: 0.0419 - acc: 0.9876 - val_loss: 0.0256 - val_acc: 0.9900\n",
      "Epoch 75/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0365 - acc: 0.9909WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3200/3183 [==============================] - 18s 5ms/sample - loss: 0.0438 - acc: 0.9809\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.02162\n",
      "81/81 [==============================] - 22s 268ms/step - loss: 0.0362 - acc: 0.9910 - val_loss: 0.0438 - val_acc: 0.9809\n",
      "Epoch 76/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0393 - acc: 0.9889WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0527 - acc: 0.9800\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.02162\n",
      "81/81 [==============================] - 22s 266ms/step - loss: 0.0403 - acc: 0.9888 - val_loss: 0.0527 - val_acc: 0.9800\n",
      "Epoch 77/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0532 - acc: 0.9818WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 21s 6ms/sample - loss: 0.0265 - acc: 0.9906\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.02162\n",
      "81/81 [==============================] - 24s 301ms/step - loss: 0.0528 - acc: 0.9820 - val_loss: 0.0265 - val_acc: 0.9906\n",
      "Epoch 78/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0317 - acc: 0.9898WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 21s 7ms/sample - loss: 0.0546 - acc: 0.9819\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.02162\n",
      "81/81 [==============================] - 26s 315ms/step - loss: 0.0318 - acc: 0.9894 - val_loss: 0.0546 - val_acc: 0.9819\n",
      "Epoch 79/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0304 - acc: 0.9906WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0225 - acc: 0.9950\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.02162\n",
      "81/81 [==============================] - 23s 284ms/step - loss: 0.0302 - acc: 0.9907 - val_loss: 0.0225 - val_acc: 0.9950\n",
      "Epoch 80/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0401 - acc: 0.9863WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0702 - acc: 0.9700\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.02162\n",
      "81/81 [==============================] - 23s 283ms/step - loss: 0.0392 - acc: 0.9867 - val_loss: 0.0702 - val_acc: 0.9700\n",
      "Epoch 81/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0340 - acc: 0.9874WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 21s 6ms/sample - loss: 0.0273 - acc: 0.9925\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.02162\n",
      "81/81 [==============================] - 24s 301ms/step - loss: 0.0338 - acc: 0.9876 - val_loss: 0.0273 - val_acc: 0.9925\n",
      "Epoch 82/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0366 - acc: 0.9895- ETA: 0s - loss: 0.0361 - acc: 0.WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0268 - acc: 0.9925\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.02162\n",
      "81/81 [==============================] - 24s 294ms/step - loss: 0.0360 - acc: 0.9894 - val_loss: 0.0268 - val_acc: 0.9925\n",
      "Epoch 83/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0361 - acc: 0.9887WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0221 - acc: 0.9900\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.02162\n",
      "81/81 [==============================] - 23s 283ms/step - loss: 0.0362 - acc: 0.9888 - val_loss: 0.0221 - val_acc: 0.9900\n",
      "Epoch 84/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0238 - acc: 0.9934WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 25s 8ms/sample - loss: 0.0222 - acc: 0.9941\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.02162\n",
      "81/81 [==============================] - 29s 357ms/step - loss: 0.0246 - acc: 0.9932 - val_loss: 0.0222 - val_acc: 0.9941\n",
      "Epoch 85/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0529 - acc: 0.9822WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0247 - acc: 0.9887\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.02162\n",
      "81/81 [==============================] - 23s 286ms/step - loss: 0.0526 - acc: 0.9823 - val_loss: 0.0247 - val_acc: 0.9887\n",
      "Epoch 86/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0255 - acc: 0.9931WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 21s 7ms/sample - loss: 0.0273 - acc: 0.9950\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.02162\n",
      "81/81 [==============================] - 25s 312ms/step - loss: 0.0253 - acc: 0.9932 - val_loss: 0.0273 - val_acc: 0.9950\n",
      "Epoch 87/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0373 - acc: 0.9860WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0307 - acc: 0.9887\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.02162\n",
      "81/81 [==============================] - 24s 291ms/step - loss: 0.0365 - acc: 0.9863 - val_loss: 0.0307 - val_acc: 0.9887\n",
      "Epoch 88/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0246 - acc: 0.9927WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 22s 7ms/sample - loss: 0.0272 - acc: 0.9894\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.02162\n",
      "81/81 [==============================] - 26s 322ms/step - loss: 0.0260 - acc: 0.9926 - val_loss: 0.0272 - val_acc: 0.9894\n",
      "Epoch 89/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0339 - acc: 0.9889WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.0235 - acc: 0.9900\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.02162\n",
      "81/81 [==============================] - 21s 265ms/step - loss: 0.0336 - acc: 0.9891 - val_loss: 0.0235 - val_acc: 0.9900\n",
      "Epoch 90/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0281 - acc: 0.9909WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0309 - acc: 0.9875\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.02162\n",
      "81/81 [==============================] - 22s 273ms/step - loss: 0.0279 - acc: 0.9910 - val_loss: 0.0309 - val_acc: 0.9875\n",
      "Epoch 91/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/81 [============================>.] - ETA: 0s - loss: 0.0267 - acc: 0.9921WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0252 - acc: 0.9931\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.02162\n",
      "81/81 [==============================] - 22s 277ms/step - loss: 0.0264 - acc: 0.9922 - val_loss: 0.0252 - val_acc: 0.9931\n",
      "Epoch 92/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0227 - acc: 0.9934WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3190/3183 [==============================] - 15s 5ms/sample - loss: 0.0195 - acc: 0.9900\n",
      "\n",
      "Epoch 00092: val_loss improved from 0.02162 to 0.01954, saving model to model/checkpoint/vis_imagenet_6_class_augmentation_2D_CNN_custom_ch_32_DO_075_DO_6_conv_checkpoint/092-0.0195.hdf5\n",
      "81/81 [==============================] - 21s 261ms/step - loss: 0.0265 - acc: 0.9922 - val_loss: 0.0195 - val_acc: 0.9900\n",
      "Epoch 93/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0323 - acc: 0.9918WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0214 - acc: 0.9950\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.01954\n",
      "81/81 [==============================] - 22s 268ms/step - loss: 0.0316 - acc: 0.9919 - val_loss: 0.0214 - val_acc: 0.9950\n",
      "Epoch 94/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0307 - acc: 0.9895WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0306 - acc: 0.9875\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.01954\n",
      "81/81 [==============================] - 21s 265ms/step - loss: 0.0302 - acc: 0.9898 - val_loss: 0.0306 - val_acc: 0.9875\n",
      "Epoch 95/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0341 - acc: 0.9881WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0319 - acc: 0.9912\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.01954\n",
      "81/81 [==============================] - 23s 283ms/step - loss: 0.0350 - acc: 0.9879 - val_loss: 0.0319 - val_acc: 0.9912\n",
      "Epoch 96/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0282 - acc: 0.9912WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0295 - acc: 0.9925\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.01954\n",
      "81/81 [==============================] - 21s 262ms/step - loss: 0.0279 - acc: 0.9913 - val_loss: 0.0295 - val_acc: 0.9925\n",
      "Epoch 97/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0263 - acc: 0.9925WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0309 - acc: 0.9891\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.01954\n",
      "81/81 [==============================] - 22s 269ms/step - loss: 0.0260 - acc: 0.9926 - val_loss: 0.0309 - val_acc: 0.9891\n",
      "Epoch 98/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0203 - acc: 0.9947WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0395 - acc: 0.9800\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.01954\n",
      "81/81 [==============================] - 23s 281ms/step - loss: 0.0201 - acc: 0.9947 - val_loss: 0.0395 - val_acc: 0.9800\n",
      "Epoch 99/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0168 - acc: 0.9965WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 5ms/sample - loss: 0.0266 - acc: 0.9912\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.01954\n",
      "81/81 [==============================] - 21s 263ms/step - loss: 0.0166 - acc: 0.9966 - val_loss: 0.0266 - val_acc: 0.9912\n",
      "Epoch 100/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0170 - acc: 0.9947WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 15s 5ms/sample - loss: 0.0376 - acc: 0.9850\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.01954\n",
      "81/81 [==============================] - 21s 259ms/step - loss: 0.0168 - acc: 0.9947 - val_loss: 0.0376 - val_acc: 0.9850\n",
      "Epoch 101/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0285 - acc: 0.9917WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 20s 6ms/sample - loss: 0.0559 - acc: 0.9769\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 0.01954\n",
      "81/81 [==============================] - 24s 290ms/step - loss: 0.0278 - acc: 0.9919 - val_loss: 0.0559 - val_acc: 0.9769\n",
      "Epoch 102/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0227 - acc: 0.9934WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3190/3183 [==============================] - 18s 6ms/sample - loss: 0.0261 - acc: 0.9975\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 0.01954\n",
      "81/81 [==============================] - 22s 273ms/step - loss: 0.0224 - acc: 0.9935 - val_loss: 0.0261 - val_acc: 0.9975\n",
      "Epoch 103/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0409 - acc: 0.9868WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0253 - acc: 0.9906\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 0.01954\n",
      "81/81 [==============================] - 22s 270ms/step - loss: 0.0409 - acc: 0.9867 - val_loss: 0.0253 - val_acc: 0.9906\n",
      "Epoch 104/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0197 - acc: 0.9947WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0264 - acc: 0.9966\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 0.01954\n",
      "81/81 [==============================] - 24s 299ms/step - loss: 0.0196 - acc: 0.9947 - val_loss: 0.0264 - val_acc: 0.9966\n",
      "Epoch 105/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0332 - acc: 0.9892WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0176 - acc: 0.9975\n",
      "\n",
      "Epoch 00105: val_loss improved from 0.01954 to 0.01756, saving model to model/checkpoint/vis_imagenet_6_class_augmentation_2D_CNN_custom_ch_32_DO_075_DO_6_conv_checkpoint/105-0.0176.hdf5\n",
      "81/81 [==============================] - 22s 267ms/step - loss: 0.0329 - acc: 0.9894 - val_loss: 0.0176 - val_acc: 0.9975\n",
      "Epoch 106/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/81 [============================>.] - ETA: 0s - loss: 0.0244 - acc: 0.9924WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0147 - acc: 0.9950\n",
      "\n",
      "Epoch 00106: val_loss improved from 0.01756 to 0.01472, saving model to model/checkpoint/vis_imagenet_6_class_augmentation_2D_CNN_custom_ch_32_DO_075_DO_6_conv_checkpoint/106-0.0147.hdf5\n",
      "81/81 [==============================] - 21s 258ms/step - loss: 0.0240 - acc: 0.9926 - val_loss: 0.0147 - val_acc: 0.9950\n",
      "Epoch 107/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0215 - acc: 0.9928WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0233 - acc: 0.9969\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 0.01472\n",
      "81/81 [==============================] - 22s 268ms/step - loss: 0.0213 - acc: 0.9929 - val_loss: 0.0233 - val_acc: 0.9969\n",
      "Epoch 108/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0335 - acc: 0.9896WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0287 - acc: 0.9919\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 0.01472\n",
      "81/81 [==============================] - 23s 282ms/step - loss: 0.0336 - acc: 0.9894 - val_loss: 0.0287 - val_acc: 0.9919\n",
      "Epoch 109/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0293 - acc: 0.9915WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0292 - acc: 0.9925\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 0.01472\n",
      "81/81 [==============================] - 23s 278ms/step - loss: 0.0289 - acc: 0.9916 - val_loss: 0.0292 - val_acc: 0.9925\n",
      "Epoch 110/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0367 - acc: 0.9885WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0358 - acc: 0.9900\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 0.01472\n",
      "81/81 [==============================] - 22s 276ms/step - loss: 0.0358 - acc: 0.9888 - val_loss: 0.0358 - val_acc: 0.9900\n",
      "Epoch 111/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0246 - acc: 0.9911WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0318 - acc: 0.9912\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 0.01472\n",
      "81/81 [==============================] - 24s 298ms/step - loss: 0.0242 - acc: 0.9913 - val_loss: 0.0318 - val_acc: 0.9912\n",
      "Epoch 112/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0256 - acc: 0.9908WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.0189 - acc: 0.9950\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 0.01472\n",
      "81/81 [==============================] - 21s 260ms/step - loss: 0.0251 - acc: 0.9910 - val_loss: 0.0189 - val_acc: 0.9950\n",
      "Epoch 113/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0215 - acc: 0.9920WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0328 - acc: 0.9881\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 0.01472\n",
      "81/81 [==============================] - 23s 282ms/step - loss: 0.0210 - acc: 0.9922 - val_loss: 0.0328 - val_acc: 0.9881\n",
      "Epoch 114/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0158 - acc: 0.9972WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0369 - acc: 0.9894\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 0.01472\n",
      "81/81 [==============================] - 22s 270ms/step - loss: 0.0159 - acc: 0.9969 - val_loss: 0.0369 - val_acc: 0.9894\n",
      "Epoch 115/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0267 - acc: 0.9917WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0243 - acc: 0.9941\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 0.01472\n",
      "81/81 [==============================] - 22s 269ms/step - loss: 0.0261 - acc: 0.9919 - val_loss: 0.0243 - val_acc: 0.9941\n",
      "Epoch 116/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0161 - acc: 0.9952WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.0176 - acc: 0.9941\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 0.01472\n",
      "81/81 [==============================] - 21s 260ms/step - loss: 0.0166 - acc: 0.9950 - val_loss: 0.0176 - val_acc: 0.9941\n",
      "Epoch 117/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0205 - acc: 0.9947WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0470 - acc: 0.9862\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 0.01472\n",
      "81/81 [==============================] - 23s 283ms/step - loss: 0.0203 - acc: 0.9947 - val_loss: 0.0470 - val_acc: 0.9862\n",
      "Epoch 118/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0226 - acc: 0.9934WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 20s 6ms/sample - loss: 0.0524 - acc: 0.9822\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 0.01472\n",
      "81/81 [==============================] - 23s 290ms/step - loss: 0.0224 - acc: 0.9935 - val_loss: 0.0524 - val_acc: 0.9822\n",
      "Epoch 119/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0223 - acc: 0.9962WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3190/3183 [==============================] - 18s 6ms/sample - loss: 0.0238 - acc: 0.9925\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 0.01472\n",
      "81/81 [==============================] - 22s 274ms/step - loss: 0.0233 - acc: 0.9957 - val_loss: 0.0238 - val_acc: 0.9925\n",
      "Epoch 120/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0226 - acc: 0.9909WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0260 - acc: 0.9975\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 0.01472\n",
      "81/81 [==============================] - 21s 260ms/step - loss: 0.0224 - acc: 0.9910 - val_loss: 0.0260 - val_acc: 0.9975\n",
      "Epoch 121/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0215 - acc: 0.9921WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0143 - acc: 0.9950\n",
      "\n",
      "Epoch 00121: val_loss improved from 0.01472 to 0.01434, saving model to model/checkpoint/vis_imagenet_6_class_augmentation_2D_CNN_custom_ch_32_DO_075_DO_6_conv_checkpoint/121-0.0143.hdf5\n",
      "81/81 [==============================] - 22s 270ms/step - loss: 0.0213 - acc: 0.9922 - val_loss: 0.0143 - val_acc: 0.9950\n",
      "Epoch 122/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0189 - acc: 0.9943WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0189 - acc: 0.9925\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 0.01434\n",
      "81/81 [==============================] - 22s 273ms/step - loss: 0.0191 - acc: 0.9941 - val_loss: 0.0189 - val_acc: 0.9925\n",
      "Epoch 123/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0272 - acc: 0.9918WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 21s 6ms/sample - loss: 0.0327 - acc: 0.9872\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 0.01434\n",
      "81/81 [==============================] - 25s 303ms/step - loss: 0.0279 - acc: 0.9916 - val_loss: 0.0327 - val_acc: 0.9872\n",
      "Epoch 124/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0176 - acc: 0.9947WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 21s 7ms/sample - loss: 0.0172 - acc: 0.9925\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 0.01434\n",
      "81/81 [==============================] - 25s 311ms/step - loss: 0.0174 - acc: 0.9947 - val_loss: 0.0172 - val_acc: 0.9925\n",
      "Epoch 125/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0133 - acc: 0.9959WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 14s 4ms/sample - loss: 0.0146 - acc: 0.9941\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 0.01434\n",
      "81/81 [==============================] - 24s 295ms/step - loss: 0.0131 - acc: 0.9960 - val_loss: 0.0146 - val_acc: 0.9941\n",
      "Epoch 126/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0179 - acc: 0.9943WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0228 - acc: 0.9928\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 0.01434\n",
      "81/81 [==============================] - 24s 295ms/step - loss: 0.0180 - acc: 0.9944 - val_loss: 0.0228 - val_acc: 0.9928\n",
      "Epoch 127/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0296 - acc: 0.9884WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0227 - acc: 0.9900\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 0.01434\n",
      "81/81 [==============================] - 22s 275ms/step - loss: 0.0293 - acc: 0.9885 - val_loss: 0.0227 - val_acc: 0.9900\n",
      "Epoch 128/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0145 - acc: 0.9965WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 25s 8ms/sample - loss: 0.0122 - acc: 0.9950\n",
      "\n",
      "Epoch 00128: val_loss improved from 0.01434 to 0.01221, saving model to model/checkpoint/vis_imagenet_6_class_augmentation_2D_CNN_custom_ch_32_DO_075_DO_6_conv_checkpoint/128-0.0122.hdf5\n",
      "81/81 [==============================] - 31s 382ms/step - loss: 0.0142 - acc: 0.9966 - val_loss: 0.0122 - val_acc: 0.9950\n",
      "Epoch 129/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0209 - acc: 0.9937WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0170 - acc: 0.9950\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 0.01221\n",
      "81/81 [==============================] - 24s 295ms/step - loss: 0.0207 - acc: 0.9938 - val_loss: 0.0170 - val_acc: 0.9950\n",
      "Epoch 130/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0161 - acc: 0.9965WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.0160 - acc: 0.9900\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 0.01221\n",
      "81/81 [==============================] - 21s 262ms/step - loss: 0.0163 - acc: 0.9963 - val_loss: 0.0160 - val_acc: 0.9900\n",
      "Epoch 131/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0187 - acc: 0.9931WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 20s 6ms/sample - loss: 0.0271 - acc: 0.9925\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 0.01221\n",
      "81/81 [==============================] - 24s 298ms/step - loss: 0.0187 - acc: 0.9932 - val_loss: 0.0271 - val_acc: 0.9925\n",
      "Epoch 132/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0070 - acc: 0.9984WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0210 - acc: 0.9900\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 0.01221\n",
      "81/81 [==============================] - 22s 270ms/step - loss: 0.0071 - acc: 0.9981 - val_loss: 0.0210 - val_acc: 0.9900\n",
      "Epoch 133/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0257 - acc: 0.9905WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0190 - acc: 0.9975\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 0.01221\n",
      "81/81 [==============================] - 22s 275ms/step - loss: 0.0262 - acc: 0.9904 - val_loss: 0.0190 - val_acc: 0.9975\n",
      "Epoch 134/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0179 - acc: 0.9952WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0199 - acc: 0.9956\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 0.01221\n",
      "81/81 [==============================] - 22s 274ms/step - loss: 0.0182 - acc: 0.9947 - val_loss: 0.0199 - val_acc: 0.9956\n",
      "Epoch 135/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0129 - acc: 0.9962WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 22s 7ms/sample - loss: 0.0119 - acc: 0.9975\n",
      "\n",
      "Epoch 00135: val_loss improved from 0.01221 to 0.01187, saving model to model/checkpoint/vis_imagenet_6_class_augmentation_2D_CNN_custom_ch_32_DO_075_DO_6_conv_checkpoint/135-0.0119.hdf5\n",
      "81/81 [==============================] - 27s 330ms/step - loss: 0.0129 - acc: 0.9963 - val_loss: 0.0119 - val_acc: 0.9975\n",
      "Epoch 136/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0147 - acc: 0.9981WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0198 - acc: 0.9975\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 0.01187\n",
      "81/81 [==============================] - 21s 265ms/step - loss: 0.0144 - acc: 0.9981 - val_loss: 0.0198 - val_acc: 0.9975\n",
      "Epoch 137/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0196 - acc: 0.9950WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0221 - acc: 0.9941\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 0.01187\n",
      "81/81 [==============================] - 21s 260ms/step - loss: 0.0194 - acc: 0.9950 - val_loss: 0.0221 - val_acc: 0.9941\n",
      "Epoch 138/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0241 - acc: 0.9937WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 20s 6ms/sample - loss: 0.0212 - acc: 0.9956\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 0.01187\n",
      "81/81 [==============================] - 24s 292ms/step - loss: 0.0239 - acc: 0.9938 - val_loss: 0.0212 - val_acc: 0.9956\n",
      "Epoch 139/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0107 - acc: 0.9965WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 5ms/sample - loss: 0.0219 - acc: 0.9975\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 0.01187\n",
      "81/81 [==============================] - 22s 267ms/step - loss: 0.0104 - acc: 0.9966 - val_loss: 0.0219 - val_acc: 0.9975\n",
      "Epoch 140/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0103 - acc: 0.9969WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0238 - acc: 0.9972\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 0.01187\n",
      "81/81 [==============================] - 23s 283ms/step - loss: 0.0102 - acc: 0.9969 - val_loss: 0.0238 - val_acc: 0.9972\n",
      "Epoch 141/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0126 - acc: 0.9969WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0122 - acc: 0.9944\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 0.01187\n",
      "81/81 [==============================] - 23s 282ms/step - loss: 0.0125 - acc: 0.9969 - val_loss: 0.0122 - val_acc: 0.9944\n",
      "Epoch 142/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0144 - acc: 0.9946WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 15s 5ms/sample - loss: 0.0429 - acc: 0.9937\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 0.01187\n",
      "81/81 [==============================] - 22s 269ms/step - loss: 0.0168 - acc: 0.9944 - val_loss: 0.0429 - val_acc: 0.9937\n",
      "Epoch 143/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0201 - acc: 0.9953WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0242 - acc: 0.9925\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 0.01187\n",
      "81/81 [==============================] - 22s 271ms/step - loss: 0.0200 - acc: 0.9953 - val_loss: 0.0242 - val_acc: 0.9925\n",
      "Epoch 144/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0360 - acc: 0.9889WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.0341 - acc: 0.9944\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 0.01187\n",
      "81/81 [==============================] - 22s 273ms/step - loss: 0.0364 - acc: 0.9888 - val_loss: 0.0341 - val_acc: 0.9944\n",
      "Epoch 145/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0156 - acc: 0.9959WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0315 - acc: 0.9944\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 0.01187\n",
      "81/81 [==============================] - 23s 286ms/step - loss: 0.0156 - acc: 0.9957 - val_loss: 0.0315 - val_acc: 0.9944\n",
      "Epoch 146/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0164 - acc: 0.9943WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0202 - acc: 0.9975\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 0.01187\n",
      "81/81 [==============================] - 23s 280ms/step - loss: 0.0174 - acc: 0.9938 - val_loss: 0.0202 - val_acc: 0.9975\n",
      "Epoch 147/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0233 - acc: 0.9943WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0174 - acc: 0.9934\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 0.01187\n",
      "81/81 [==============================] - 22s 266ms/step - loss: 0.0228 - acc: 0.9944 - val_loss: 0.0174 - val_acc: 0.9934\n",
      "Epoch 148/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0197 - acc: 0.9965WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0278 - acc: 0.9950\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 0.01187\n",
      "81/81 [==============================] - 22s 271ms/step - loss: 0.0199 - acc: 0.9963 - val_loss: 0.0278 - val_acc: 0.9950\n",
      "Epoch 149/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0179 - acc: 0.9962WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0162 - acc: 0.9962\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 0.01187\n",
      "81/81 [==============================] - 22s 274ms/step - loss: 0.0196 - acc: 0.9960 - val_loss: 0.0162 - val_acc: 0.9962\n",
      "Epoch 150/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0202 - acc: 0.9925WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0362 - acc: 0.9900\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 0.01187\n",
      "81/81 [==============================] - 21s 261ms/step - loss: 0.0203 - acc: 0.9926 - val_loss: 0.0362 - val_acc: 0.9900\n",
      "Epoch 151/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0133 - acc: 0.9952WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 15s 5ms/sample - loss: 0.0208 - acc: 0.9962\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 0.01187\n",
      "81/81 [==============================] - 23s 283ms/step - loss: 0.0131 - acc: 0.9953 - val_loss: 0.0208 - val_acc: 0.9962\n",
      "Epoch 152/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/81 [============================>.] - ETA: 0s - loss: 0.0145 - acc: 0.9962WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0353 - acc: 0.9950\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 0.01187\n",
      "81/81 [==============================] - 23s 284ms/step - loss: 0.0142 - acc: 0.9963 - val_loss: 0.0353 - val_acc: 0.9950\n",
      "Epoch 153/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0110 - acc: 0.9965WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.0280 - acc: 0.9925\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 0.01187\n",
      "81/81 [==============================] - 22s 269ms/step - loss: 0.0111 - acc: 0.9966 - val_loss: 0.0280 - val_acc: 0.9925\n",
      "Epoch 154/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0115 - acc: 0.9965WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 21s 6ms/sample - loss: 0.0190 - acc: 0.9950\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 0.01187\n",
      "81/81 [==============================] - 25s 304ms/step - loss: 0.0114 - acc: 0.9966 - val_loss: 0.0190 - val_acc: 0.9950\n",
      "Epoch 155/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0123 - acc: 0.9946WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 5ms/sample - loss: 0.0408 - acc: 0.9950\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 0.01187\n",
      "81/81 [==============================] - 22s 271ms/step - loss: 0.0120 - acc: 0.9947 - val_loss: 0.0408 - val_acc: 0.9950\n",
      "Epoch 156/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0225 - acc: 0.9927WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0236 - acc: 0.9925\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 0.01187\n",
      "81/81 [==============================] - 22s 271ms/step - loss: 0.0219 - acc: 0.9929 - val_loss: 0.0236 - val_acc: 0.9925\n",
      "Epoch 157/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0167 - acc: 0.9943WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 20s 6ms/sample - loss: 0.0251 - acc: 0.9959\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 0.01187\n",
      "81/81 [==============================] - 25s 304ms/step - loss: 0.0164 - acc: 0.9944 - val_loss: 0.0251 - val_acc: 0.9959\n",
      "Epoch 158/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0090 - acc: 0.9975WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 22s 7ms/sample - loss: 0.0152 - acc: 0.9925\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 0.01187\n",
      "81/81 [==============================] - 26s 319ms/step - loss: 0.0103 - acc: 0.9972 - val_loss: 0.0152 - val_acc: 0.9925\n",
      "Epoch 159/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0159 - acc: 0.9959WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 21s 6ms/sample - loss: 0.0296 - acc: 0.9947\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 0.01187\n",
      "81/81 [==============================] - 25s 314ms/step - loss: 0.0156 - acc: 0.9960 - val_loss: 0.0296 - val_acc: 0.9947\n",
      "Epoch 160/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0096 - acc: 0.9972WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 20s 6ms/sample - loss: 0.0397 - acc: 0.9950\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 0.01187\n",
      "81/81 [==============================] - 23s 289ms/step - loss: 0.0095 - acc: 0.9972 - val_loss: 0.0397 - val_acc: 0.9950\n",
      "Epoch 161/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0153 - acc: 0.9955WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 22s 7ms/sample - loss: 0.0277 - acc: 0.9944\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 0.01187\n",
      "81/81 [==============================] - 26s 319ms/step - loss: 0.0153 - acc: 0.9953 - val_loss: 0.0277 - val_acc: 0.9944\n",
      "Epoch 162/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0081 - acc: 0.9969WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 22s 7ms/sample - loss: 0.0111 - acc: 0.9972\n",
      "\n",
      "Epoch 00162: val_loss improved from 0.01187 to 0.01112, saving model to model/checkpoint/vis_imagenet_6_class_augmentation_2D_CNN_custom_ch_32_DO_075_DO_6_conv_checkpoint/162-0.0111.hdf5\n",
      "81/81 [==============================] - 26s 321ms/step - loss: 0.0081 - acc: 0.9969 - val_loss: 0.0111 - val_acc: 0.9972\n",
      "Epoch 163/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0176 - acc: 0.9936WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 20s 6ms/sample - loss: 0.0278 - acc: 0.9975\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 0.01112\n",
      "81/81 [==============================] - 24s 294ms/step - loss: 0.0182 - acc: 0.9935 - val_loss: 0.0278 - val_acc: 0.9975\n",
      "Epoch 164/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0072 - acc: 0.9978WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0078 - acc: 0.9975\n",
      "\n",
      "Epoch 00164: val_loss improved from 0.01112 to 0.00778, saving model to model/checkpoint/vis_imagenet_6_class_augmentation_2D_CNN_custom_ch_32_DO_075_DO_6_conv_checkpoint/164-0.0078.hdf5\n",
      "81/81 [==============================] - 23s 290ms/step - loss: 0.0070 - acc: 0.9978 - val_loss: 0.0078 - val_acc: 0.9975\n",
      "Epoch 165/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0120 - acc: 0.9972WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 22s 7ms/sample - loss: 0.0215 - acc: 0.9944\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 0.00778\n",
      "81/81 [==============================] - 26s 321ms/step - loss: 0.0118 - acc: 0.9972 - val_loss: 0.0215 - val_acc: 0.9944\n",
      "Epoch 166/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0134 - acc: 0.9965WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0140 - acc: 0.9975\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 0.00778\n",
      "81/81 [==============================] - 21s 262ms/step - loss: 0.0132 - acc: 0.9966 - val_loss: 0.0140 - val_acc: 0.9975\n",
      "Epoch 167/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/81 [============================>.] - ETA: 0s - loss: 0.0110 - acc: 0.9968WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0393 - acc: 0.9950\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 0.00778\n",
      "81/81 [==============================] - 22s 268ms/step - loss: 0.0109 - acc: 0.9969 - val_loss: 0.0393 - val_acc: 0.9950\n",
      "Epoch 168/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0191 - acc: 0.9940WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0246 - acc: 0.9937\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 0.00778\n",
      "81/81 [==============================] - 22s 271ms/step - loss: 0.0189 - acc: 0.9941 - val_loss: 0.0246 - val_acc: 0.9937\n",
      "Epoch 169/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0143 - acc: 0.9949WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 25s 8ms/sample - loss: 0.0131 - acc: 0.99098s - loss: 0.0\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 0.00778\n",
      "81/81 [==============================] - 30s 364ms/step - loss: 0.0141 - acc: 0.9950 - val_loss: 0.0131 - val_acc: 0.9909\n",
      "Epoch 170/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0144 - acc: 0.9953WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0144 - acc: 0.9956\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 0.00778\n",
      "81/81 [==============================] - 23s 284ms/step - loss: 0.0142 - acc: 0.9953 - val_loss: 0.0144 - val_acc: 0.9956\n",
      "Epoch 171/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0115 - acc: 0.9971WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0209 - acc: 0.9950\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 0.00778\n",
      "81/81 [==============================] - 23s 284ms/step - loss: 0.0127 - acc: 0.9969 - val_loss: 0.0209 - val_acc: 0.9950\n",
      "Epoch 172/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0107 - acc: 0.9978WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0080 - acc: 0.9950\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 0.00778\n",
      "81/81 [==============================] - 22s 268ms/step - loss: 0.0110 - acc: 0.9975 - val_loss: 0.0080 - val_acc: 0.9950\n",
      "Epoch 173/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0149 - acc: 0.9946WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0338 - acc: 0.9950\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 0.00778\n",
      "81/81 [==============================] - 21s 265ms/step - loss: 0.0146 - acc: 0.9947 - val_loss: 0.0338 - val_acc: 0.9950\n",
      "Epoch 174/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0127 - acc: 0.9962WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 20s 6ms/sample - loss: 0.0137 - acc: 0.9950\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 0.00778\n",
      "81/81 [==============================] - 23s 289ms/step - loss: 0.0124 - acc: 0.9963 - val_loss: 0.0137 - val_acc: 0.9950\n",
      "Epoch 175/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0085 - acc: 0.9965WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0202 - acc: 0.9950\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 0.00778\n",
      "81/81 [==============================] - 22s 266ms/step - loss: 0.0085 - acc: 0.9966 - val_loss: 0.0202 - val_acc: 0.9950\n",
      "Epoch 176/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0048 - acc: 0.9978WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0194 - acc: 0.9944\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 0.00778\n",
      "81/81 [==============================] - 22s 278ms/step - loss: 0.0047 - acc: 0.9978 - val_loss: 0.0194 - val_acc: 0.9944\n",
      "Epoch 177/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0131 - acc: 0.9959WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0239 - acc: 0.9925\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 0.00778\n",
      "81/81 [==============================] - 22s 269ms/step - loss: 0.0129 - acc: 0.9960 - val_loss: 0.0239 - val_acc: 0.9925\n",
      "Epoch 178/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0065 - acc: 0.9981WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 26s 8ms/sample - loss: 0.0216 - acc: 0.9925\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 0.00778\n",
      "81/81 [==============================] - 30s 368ms/step - loss: 0.0064 - acc: 0.9981 - val_loss: 0.0216 - val_acc: 0.9925\n",
      "Epoch 179/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0151 - acc: 0.9947WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0332 - acc: 0.9887\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 0.00778\n",
      "81/81 [==============================] - 23s 285ms/step - loss: 0.0149 - acc: 0.9947 - val_loss: 0.0332 - val_acc: 0.9887\n",
      "Epoch 180/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0147 - acc: 0.9962WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0162 - acc: 0.9950\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 0.00778\n",
      "81/81 [==============================] - 21s 263ms/step - loss: 0.0144 - acc: 0.9963 - val_loss: 0.0162 - val_acc: 0.9950\n",
      "Epoch 181/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0032 - acc: 0.9990WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0196 - acc: 0.9950\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 0.00778\n",
      "81/81 [==============================] - 22s 269ms/step - loss: 0.0032 - acc: 0.9991 - val_loss: 0.0196 - val_acc: 0.9950\n",
      "Epoch 182/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0187 - acc: 0.9949WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3200/3183 [==============================] - 22s 7ms/sample - loss: 0.0201 - acc: 0.9900\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 0.00778\n",
      "81/81 [==============================] - 26s 316ms/step - loss: 0.0187 - acc: 0.9947 - val_loss: 0.0201 - val_acc: 0.9900\n",
      "Epoch 183/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0175 - acc: 0.9965WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0242 - acc: 0.9950\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 0.00778\n",
      "81/81 [==============================] - 22s 267ms/step - loss: 0.0173 - acc: 0.9966 - val_loss: 0.0242 - val_acc: 0.9950\n",
      "Epoch 184/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0117 - acc: 0.9968WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 20s 6ms/sample - loss: 0.0218 - acc: 0.9966\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 0.00778\n",
      "81/81 [==============================] - 24s 292ms/step - loss: 0.0114 - acc: 0.9969 - val_loss: 0.0218 - val_acc: 0.9966\n",
      "Epoch 185/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0067 - acc: 0.9978WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 22s 7ms/sample - loss: 0.0309 - acc: 0.9912\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 0.00778\n",
      "81/81 [==============================] - 26s 325ms/step - loss: 0.0067 - acc: 0.9978 - val_loss: 0.0309 - val_acc: 0.9912\n",
      "Epoch 186/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0041 - acc: 0.9990WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0171 - acc: 0.9975\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 0.00778\n",
      "81/81 [==============================] - 21s 265ms/step - loss: 0.0041 - acc: 0.9991 - val_loss: 0.0171 - val_acc: 0.9975\n",
      "Epoch 187/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0131 - acc: 0.9969WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0506 - acc: 0.9919\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 0.00778\n",
      "81/81 [==============================] - 22s 276ms/step - loss: 0.0139 - acc: 0.9966 - val_loss: 0.0506 - val_acc: 0.9919\n",
      "Epoch 188/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0151 - acc: 0.9959WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0114 - acc: 0.9925\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 0.00778\n",
      "81/81 [==============================] - 22s 273ms/step - loss: 0.0149 - acc: 0.9960 - val_loss: 0.0114 - val_acc: 0.9925\n",
      "Epoch 189/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0044 - acc: 0.9994WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 21s 7ms/sample - loss: 0.0184 - acc: 0.9944\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 0.00778\n",
      "81/81 [==============================] - 25s 313ms/step - loss: 0.0044 - acc: 0.9994 - val_loss: 0.0184 - val_acc: 0.9944\n",
      "Epoch 190/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0108 - acc: 0.9962WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0236 - acc: 0.9925\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 0.00778\n",
      "81/81 [==============================] - 23s 278ms/step - loss: 0.0106 - acc: 0.9963 - val_loss: 0.0236 - val_acc: 0.9925\n",
      "Epoch 191/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0165 - acc: 0.9940WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0145 - acc: 0.9925\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 0.00778\n",
      "81/81 [==============================] - 23s 279ms/step - loss: 0.0162 - acc: 0.9941 - val_loss: 0.0145 - val_acc: 0.9925\n",
      "Epoch 192/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0119 - acc: 0.9971WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0131 - acc: 0.9900\n",
      "\n",
      "Epoch 00192: val_loss did not improve from 0.00778\n",
      "81/81 [==============================] - 23s 287ms/step - loss: 0.0116 - acc: 0.9972 - val_loss: 0.0131 - val_acc: 0.9900\n",
      "Epoch 193/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0039 - acc: 0.9987WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0202 - acc: 0.9912\n",
      "\n",
      "Epoch 00193: val_loss did not improve from 0.00778\n",
      "81/81 [==============================] - 21s 263ms/step - loss: 0.0038 - acc: 0.9988 - val_loss: 0.0202 - val_acc: 0.9912\n",
      "Epoch 194/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0066 - acc: 0.9984WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0229 - acc: 0.9950\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 0.00778\n",
      "81/81 [==============================] - 22s 270ms/step - loss: 0.0069 - acc: 0.9981 - val_loss: 0.0229 - val_acc: 0.9950\n",
      "Epoch 195/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0096 - acc: 0.9975WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 20s 6ms/sample - loss: 0.0264 - acc: 0.9950\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 0.00778\n",
      "81/81 [==============================] - 24s 291ms/step - loss: 0.0097 - acc: 0.9975 - val_loss: 0.0264 - val_acc: 0.9950\n",
      "Epoch 196/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0063 - acc: 0.9994WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 25s 8ms/sample - loss: 0.0307 - acc: 0.9950\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 0.00778\n",
      "81/81 [==============================] - 31s 377ms/step - loss: 0.0077 - acc: 0.9991 - val_loss: 0.0307 - val_acc: 0.9950\n",
      "Epoch 197/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0137 - acc: 0.9940WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0261 - acc: 0.9925\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 0.00778\n",
      "81/81 [==============================] - 23s 290ms/step - loss: 0.0144 - acc: 0.9938 - val_loss: 0.0261 - val_acc: 0.9925\n",
      "Epoch 198/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/81 [============================>.] - ETA: 0s - loss: 0.0099 - acc: 0.9984WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 25s 8ms/sample - loss: 0.0200 - acc: 0.9950\n",
      "\n",
      "Epoch 00198: val_loss did not improve from 0.00778\n",
      "81/81 [==============================] - 29s 353ms/step - loss: 0.0098 - acc: 0.9984 - val_loss: 0.0200 - val_acc: 0.9950\n",
      "Epoch 199/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0100 - acc: 0.9962- EWARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0175 - acc: 0.9950\n",
      "\n",
      "Epoch 00199: val_loss did not improve from 0.00778\n",
      "81/81 [==============================] - 24s 301ms/step - loss: 0.0099 - acc: 0.9963 - val_loss: 0.0175 - val_acc: 0.9950\n",
      "Epoch 200/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0119 - acc: 0.9962WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 24s 7ms/sample - loss: 0.0286 - acc: 0.9875\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 0.00778\n",
      "81/81 [==============================] - 28s 341ms/step - loss: 0.0118 - acc: 0.9963 - val_loss: 0.0286 - val_acc: 0.9875\n",
      "Epoch 201/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0106 - acc: 0.9978WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 14s 4ms/sample - loss: 0.0326 - acc: 0.9947\n",
      "\n",
      "Epoch 00201: val_loss did not improve from 0.00778\n",
      "81/81 [==============================] - 22s 274ms/step - loss: 0.0107 - acc: 0.9975 - val_loss: 0.0326 - val_acc: 0.9947\n",
      "Epoch 202/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0086 - acc: 0.9975WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0028 - acc: 1.0000\n",
      "\n",
      "Epoch 00202: val_loss improved from 0.00778 to 0.00280, saving model to model/checkpoint/vis_imagenet_6_class_augmentation_2D_CNN_custom_ch_32_DO_075_DO_6_conv_checkpoint/202-0.0028.hdf5\n",
      "81/81 [==============================] - 21s 261ms/step - loss: 0.0086 - acc: 0.9972 - val_loss: 0.0028 - val_acc: 1.0000\n",
      "Epoch 203/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0122 - acc: 0.9956WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 29s 9ms/sample - loss: 0.0391 - acc: 0.9950\n",
      "\n",
      "Epoch 00203: val_loss did not improve from 0.00280\n",
      "81/81 [==============================] - 32s 400ms/step - loss: 0.0122 - acc: 0.9957 - val_loss: 0.0391 - val_acc: 0.9950\n",
      "Epoch 204/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0138 - acc: 0.9968WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 20s 6ms/sample - loss: 0.0163 - acc: 0.9950\n",
      "\n",
      "Epoch 00204: val_loss did not improve from 0.00280\n",
      "81/81 [==============================] - 26s 323ms/step - loss: 0.0138 - acc: 0.9969 - val_loss: 0.0163 - val_acc: 0.9950\n",
      "Epoch 205/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0107 - acc: 0.9955WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0137 - acc: 0.9950\n",
      "\n",
      "Epoch 00205: val_loss did not improve from 0.00280\n",
      "81/81 [==============================] - 22s 268ms/step - loss: 0.0107 - acc: 0.9957 - val_loss: 0.0137 - val_acc: 0.9950\n",
      "Epoch 206/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0057 - acc: 0.9990WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0292 - acc: 0.9947\n",
      "\n",
      "Epoch 00206: val_loss did not improve from 0.00280\n",
      "81/81 [==============================] - 23s 286ms/step - loss: 0.0056 - acc: 0.9991 - val_loss: 0.0292 - val_acc: 0.9947\n",
      "Epoch 207/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0037 - acc: 0.9991WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 20s 6ms/sample - loss: 0.0390 - acc: 0.9950\n",
      "\n",
      "Epoch 00207: val_loss did not improve from 0.00280\n",
      "81/81 [==============================] - 26s 316ms/step - loss: 0.0036 - acc: 0.9991 - val_loss: 0.0390 - val_acc: 0.9950\n",
      "Epoch 208/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0152 - acc: 0.9952WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 21s 7ms/sample - loss: 0.0336 - acc: 0.9850\n",
      "\n",
      "Epoch 00208: val_loss did not improve from 0.00280\n",
      "81/81 [==============================] - 27s 328ms/step - loss: 0.0149 - acc: 0.9953 - val_loss: 0.0336 - val_acc: 0.9850\n",
      "Epoch 209/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0198 - acc: 0.9940WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0271 - acc: 0.9894\n",
      "\n",
      "Epoch 00209: val_loss did not improve from 0.00280\n",
      "81/81 [==============================] - 26s 320ms/step - loss: 0.0196 - acc: 0.9941 - val_loss: 0.0271 - val_acc: 0.9894\n",
      "Epoch 210/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0214 - acc: 0.9930WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 22s 7ms/sample - loss: 0.0265 - acc: 0.9975\n",
      "\n",
      "Epoch 00210: val_loss did not improve from 0.00280\n",
      "81/81 [==============================] - 26s 320ms/step - loss: 0.0212 - acc: 0.9932 - val_loss: 0.0265 - val_acc: 0.9975\n",
      "Epoch 211/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0101 - acc: 0.9962WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0312 - acc: 0.9947\n",
      "\n",
      "Epoch 00211: val_loss did not improve from 0.00280\n",
      "81/81 [==============================] - 23s 283ms/step - loss: 0.0100 - acc: 0.9963 - val_loss: 0.0312 - val_acc: 0.9947\n",
      "Epoch 212/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0043 - acc: 0.9990WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 14s 4ms/sample - loss: 0.0271 - acc: 0.9925\n",
      "\n",
      "Epoch 00212: val_loss did not improve from 0.00280\n",
      "81/81 [==============================] - 23s 288ms/step - loss: 0.0063 - acc: 0.9981 - val_loss: 0.0271 - val_acc: 0.9925\n",
      "Epoch 213/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0166 - acc: 0.9950WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0380 - acc: 0.9925\n",
      "\n",
      "Epoch 00213: val_loss did not improve from 0.00280\n",
      "81/81 [==============================] - 22s 268ms/step - loss: 0.0167 - acc: 0.9950 - val_loss: 0.0380 - val_acc: 0.9925\n",
      "Epoch 214/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0083 - acc: 0.9962WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 29s 9ms/sample - loss: 0.0167 - acc: 0.9975\n",
      "\n",
      "Epoch 00214: val_loss did not improve from 0.00280\n",
      "81/81 [==============================] - 33s 411ms/step - loss: 0.0105 - acc: 0.9957 - val_loss: 0.0167 - val_acc: 0.9975\n",
      "Epoch 215/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0019 - acc: 1.0000WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0264 - acc: 0.9944\n",
      "\n",
      "Epoch 00215: val_loss did not improve from 0.00280\n",
      "81/81 [==============================] - 25s 309ms/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.0264 - val_acc: 0.9944\n",
      "Epoch 216/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0049 - acc: 0.9987WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0316 - acc: 0.9975\n",
      "\n",
      "Epoch 00216: val_loss did not improve from 0.00280\n",
      "81/81 [==============================] - 22s 277ms/step - loss: 0.0048 - acc: 0.9988 - val_loss: 0.0316 - val_acc: 0.9975\n",
      "Epoch 217/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0078 - acc: 0.9972WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0620 - acc: 0.9925\n",
      "\n",
      "Epoch 00217: val_loss did not improve from 0.00280\n",
      "81/81 [==============================] - 23s 280ms/step - loss: 0.0078 - acc: 0.9972 - val_loss: 0.0620 - val_acc: 0.9925\n",
      "Epoch 218/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0129 - acc: 0.9947WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0252 - acc: 0.9937\n",
      "\n",
      "Epoch 00218: val_loss did not improve from 0.00280\n",
      "81/81 [==============================] - 22s 266ms/step - loss: 0.0127 - acc: 0.9947 - val_loss: 0.0252 - val_acc: 0.9937\n",
      "Epoch 219/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0187 - acc: 0.9943WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 24s 7ms/sample - loss: 0.0312 - acc: 0.9925\n",
      "\n",
      "Epoch 00219: val_loss did not improve from 0.00280\n",
      "81/81 [==============================] - 27s 339ms/step - loss: 0.0187 - acc: 0.9944 - val_loss: 0.0312 - val_acc: 0.9925\n",
      "Epoch 220/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0140 - acc: 0.9947WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0406 - acc: 0.9900\n",
      "\n",
      "Epoch 00220: val_loss did not improve from 0.00280\n",
      "81/81 [==============================] - 23s 287ms/step - loss: 0.0138 - acc: 0.9947 - val_loss: 0.0406 - val_acc: 0.9900\n",
      "Epoch 221/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0080 - acc: 0.9975WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 20s 6ms/sample - loss: 0.0298 - acc: 0.99501\n",
      "\n",
      "Epoch 00221: val_loss did not improve from 0.00280\n",
      "81/81 [==============================] - 24s 301ms/step - loss: 0.0088 - acc: 0.9972 - val_loss: 0.0298 - val_acc: 0.9950\n",
      "Epoch 222/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0065 - acc: 0.9975WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0114 - acc: 0.9944\n",
      "\n",
      "Epoch 00222: val_loss did not improve from 0.00280\n",
      "81/81 [==============================] - 24s 295ms/step - loss: 0.0068 - acc: 0.9972 - val_loss: 0.0114 - val_acc: 0.9944\n",
      "Epoch 223/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0061 - acc: 0.9994WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0239 - acc: 0.9975\n",
      "\n",
      "Epoch 00223: val_loss did not improve from 0.00280\n",
      "81/81 [==============================] - 23s 286ms/step - loss: 0.0060 - acc: 0.9994 - val_loss: 0.0239 - val_acc: 0.9975\n",
      "Epoch 224/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 8.5909e-04 - acc: 1.0000WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 15s 5ms/sample - loss: 0.0325 - acc: 0.9975\n",
      "\n",
      "Epoch 00224: val_loss did not improve from 0.00280\n",
      "81/81 [==============================] - 23s 285ms/step - loss: 8.4065e-04 - acc: 1.0000 - val_loss: 0.0325 - val_acc: 0.9975\n",
      "Epoch 225/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0057 - acc: 0.9981WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 23s 7ms/sample - loss: 0.0247 - acc: 0.9941\n",
      "\n",
      "Epoch 00225: val_loss did not improve from 0.00280\n",
      "81/81 [==============================] - 27s 332ms/step - loss: 0.0056 - acc: 0.9981 - val_loss: 0.0247 - val_acc: 0.9941\n",
      "Epoch 226/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0045 - acc: 0.9987WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0231 - acc: 0.9975\n",
      "\n",
      "Epoch 00226: val_loss did not improve from 0.00280\n",
      "81/81 [==============================] - 23s 285ms/step - loss: 0.0045 - acc: 0.9988 - val_loss: 0.0231 - val_acc: 0.9975\n",
      "Epoch 227/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0035 - acc: 0.9987WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0118 - acc: 0.9950\n",
      "\n",
      "Epoch 00227: val_loss did not improve from 0.00280\n",
      "81/81 [==============================] - 23s 282ms/step - loss: 0.0035 - acc: 0.9988 - val_loss: 0.0118 - val_acc: 0.9950\n",
      "Epoch 228/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0044 - acc: 0.9994WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0372 - acc: 0.9950\n",
      "\n",
      "Epoch 00228: val_loss did not improve from 0.00280\n",
      "81/81 [==============================] - 24s 300ms/step - loss: 0.0043 - acc: 0.9994 - val_loss: 0.0372 - val_acc: 0.9950\n",
      "Epoch 229/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/81 [============================>.] - ETA: 0s - loss: 0.0050 - acc: 0.9978WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0636 - acc: 0.9950\n",
      "\n",
      "Epoch 00229: val_loss did not improve from 0.00280\n",
      "81/81 [==============================] - 22s 267ms/step - loss: 0.0050 - acc: 0.9978 - val_loss: 0.0636 - val_acc: 0.9950\n",
      "Epoch 230/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0035 - acc: 0.9990WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0144 - acc: 0.9950\n",
      "\n",
      "Epoch 00230: val_loss did not improve from 0.00280\n",
      "81/81 [==============================] - 23s 279ms/step - loss: 0.0034 - acc: 0.9991 - val_loss: 0.0144 - val_acc: 0.9950\n",
      "Epoch 231/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0066 - acc: 0.9981WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 24s 8ms/sample - loss: 0.0335 - acc: 0.9937\n",
      "\n",
      "Epoch 00231: val_loss did not improve from 0.00280\n",
      "81/81 [==============================] - 28s 348ms/step - loss: 0.0065 - acc: 0.9981 - val_loss: 0.0335 - val_acc: 0.9937\n",
      "Epoch 232/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0092 - acc: 0.9975WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 22s 7ms/sample - loss: 0.0182 - acc: 0.9919\n",
      "\n",
      "Epoch 00232: val_loss did not improve from 0.00280\n",
      "81/81 [==============================] - 27s 337ms/step - loss: 0.0091 - acc: 0.9975 - val_loss: 0.0182 - val_acc: 0.9919\n",
      "Epoch 233/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0110 - acc: 0.9978WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0186 - acc: 0.9972\n",
      "\n",
      "Epoch 00233: val_loss did not improve from 0.00280\n",
      "81/81 [==============================] - 23s 290ms/step - loss: 0.0117 - acc: 0.9975 - val_loss: 0.0186 - val_acc: 0.9972\n",
      "Epoch 234/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0058 - acc: 0.9990WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 24s 7ms/sample - loss: 0.0259 - acc: 0.9941\n",
      "\n",
      "Epoch 00234: val_loss did not improve from 0.00280\n",
      "81/81 [==============================] - 30s 373ms/step - loss: 0.0056 - acc: 0.9991 - val_loss: 0.0259 - val_acc: 0.9941\n",
      "Epoch 235/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0099 - acc: 0.9969WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0182 - acc: 0.9897\n",
      "\n",
      "Epoch 00235: val_loss did not improve from 0.00280\n",
      "81/81 [==============================] - 29s 361ms/step - loss: 0.0099 - acc: 0.9969 - val_loss: 0.0182 - val_acc: 0.9897\n",
      "Epoch 236/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0072 - acc: 0.9984WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 26s 8ms/sample - loss: 0.0143 - acc: 0.9975\n",
      "\n",
      "Epoch 00236: val_loss did not improve from 0.00280\n",
      "81/81 [==============================] - 30s 367ms/step - loss: 0.0070 - acc: 0.9984 - val_loss: 0.0143 - val_acc: 0.9975\n",
      "Epoch 237/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0039 - acc: 0.9981WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 20s 6ms/sample - loss: 0.0126 - acc: 0.9962\n",
      "\n",
      "Epoch 00237: val_loss did not improve from 0.00280\n",
      "81/81 [==============================] - 27s 337ms/step - loss: 0.0039 - acc: 0.9981 - val_loss: 0.0126 - val_acc: 0.9962\n",
      "Epoch 238/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0224 - acc: 0.9917WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0272 - acc: 0.9950\n",
      "\n",
      "Epoch 00238: val_loss did not improve from 0.00280\n",
      "81/81 [==============================] - 23s 288ms/step - loss: 0.0219 - acc: 0.9919 - val_loss: 0.0272 - val_acc: 0.9950\n",
      "Epoch 239/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0156 - acc: 0.9953WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 20s 6ms/sample - loss: 0.0399 - acc: 0.9950\n",
      "\n",
      "Epoch 00239: val_loss did not improve from 0.00280\n",
      "81/81 [==============================] - 25s 307ms/step - loss: 0.0155 - acc: 0.9953 - val_loss: 0.0399 - val_acc: 0.9950\n",
      "Epoch 240/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0050 - acc: 0.9987WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 24s 8ms/sample - loss: 0.0265 - acc: 0.9916\n",
      "\n",
      "Epoch 00240: val_loss did not improve from 0.00280\n",
      "81/81 [==============================] - 28s 351ms/step - loss: 0.0050 - acc: 0.9988 - val_loss: 0.0265 - val_acc: 0.9916\n",
      "Epoch 241/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0037 - acc: 0.9987WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0252 - acc: 0.9925\n",
      "\n",
      "Epoch 00241: val_loss did not improve from 0.00280\n",
      "81/81 [==============================] - 23s 289ms/step - loss: 0.0036 - acc: 0.9988 - val_loss: 0.0252 - val_acc: 0.9925\n",
      "Epoch 242/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0013 - acc: 0.9997    WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 27s 8ms/sample - loss: 0.0429 - acc: 0.9950\n",
      "\n",
      "Epoch 00242: val_loss did not improve from 0.00280\n",
      "81/81 [==============================] - 32s 399ms/step - loss: 0.0012 - acc: 0.9997 - val_loss: 0.0429 - val_acc: 0.9950\n",
      "Epoch 243/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0060 - acc: 0.9984WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0143 - acc: 0.9950\n",
      "\n",
      "Epoch 00243: val_loss did not improve from 0.00280\n",
      "81/81 [==============================] - 23s 282ms/step - loss: 0.0060 - acc: 0.9984 - val_loss: 0.0143 - val_acc: 0.9950\n",
      "Epoch 244/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0114 - acc: 0.9975WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0211 - acc: 0.9925\n",
      "\n",
      "Epoch 00244: val_loss did not improve from 0.00280\n",
      "81/81 [==============================] - 22s 272ms/step - loss: 0.0111 - acc: 0.9975 - val_loss: 0.0211 - val_acc: 0.9925\n",
      "Epoch 245/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0130 - acc: 0.9943WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 20s 6ms/sample - loss: 0.0152 - acc: 0.9941\n",
      "\n",
      "Epoch 00245: val_loss did not improve from 0.00280\n",
      "81/81 [==============================] - 24s 302ms/step - loss: 0.0136 - acc: 0.9941 - val_loss: 0.0152 - val_acc: 0.9941\n",
      "Epoch 246/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0016 - acc: 0.9997- ETA: 2WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 24s 8ms/sample - loss: 0.0539 - acc: 0.9925\n",
      "\n",
      "Epoch 00246: val_loss did not improve from 0.00280\n",
      "81/81 [==============================] - 31s 381ms/step - loss: 0.0016 - acc: 0.9997 - val_loss: 0.0539 - val_acc: 0.9925\n",
      "Epoch 247/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0044 - acc: 0.9994WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 21s 6ms/sample - loss: 0.0308 - acc: 0.9950\n",
      "\n",
      "Epoch 00247: val_loss did not improve from 0.00280\n",
      "81/81 [==============================] - 28s 351ms/step - loss: 0.0043 - acc: 0.9994 - val_loss: 0.0308 - val_acc: 0.9950\n",
      "Epoch 248/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0060 - acc: 0.9984WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0336 - acc: 0.9950\n",
      "\n",
      "Epoch 00248: val_loss did not improve from 0.00280\n",
      "81/81 [==============================] - 23s 289ms/step - loss: 0.0059 - acc: 0.9984 - val_loss: 0.0336 - val_acc: 0.9950\n",
      "Epoch 249/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0112 - acc: 0.9959WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 23s 7ms/sample - loss: 0.0572 - acc: 0.9950\n",
      "\n",
      "Epoch 00249: val_loss did not improve from 0.00280\n",
      "81/81 [==============================] - 29s 357ms/step - loss: 0.0111 - acc: 0.9960 - val_loss: 0.0572 - val_acc: 0.9950\n",
      "Epoch 250/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0050 - acc: 0.9987WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0489 - acc: 0.9950\n",
      "\n",
      "Epoch 00250: val_loss did not improve from 0.00280\n",
      "81/81 [==============================] - 24s 302ms/step - loss: 0.0049 - acc: 0.9988 - val_loss: 0.0489 - val_acc: 0.9950\n",
      "Epoch 251/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0031 - acc: 0.9997WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0357 - acc: 0.9950\n",
      "\n",
      "Epoch 00251: val_loss did not improve from 0.00280\n",
      "81/81 [==============================] - 23s 290ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0357 - val_acc: 0.9950\n",
      "Epoch 252/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0029 - acc: 0.9991WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 23s 7ms/sample - loss: 0.0230 - acc: 0.9975\n",
      "\n",
      "Epoch 00252: val_loss did not improve from 0.00280\n",
      "81/81 [==============================] - 27s 333ms/step - loss: 0.0029 - acc: 0.9991 - val_loss: 0.0230 - val_acc: 0.9975\n",
      "Epoch 253/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0090 - acc: 0.9975WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0315 - acc: 0.9950\n",
      "\n",
      "Epoch 00253: val_loss did not improve from 0.00280\n",
      "81/81 [==============================] - 23s 280ms/step - loss: 0.0088 - acc: 0.9975 - val_loss: 0.0315 - val_acc: 0.9950\n",
      "Epoch 254/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0072 - acc: 0.9975WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 28s 9ms/sample - loss: 0.0357 - acc: 0.9950\n",
      "\n",
      "Epoch 00254: val_loss did not improve from 0.00280\n",
      "81/81 [==============================] - 33s 403ms/step - loss: 0.0071 - acc: 0.9975 - val_loss: 0.0357 - val_acc: 0.9950\n",
      "Epoch 255/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0076 - acc: 0.9981WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 23s 7ms/sample - loss: 0.0320 - acc: 0.9950\n",
      "\n",
      "Epoch 00255: val_loss did not improve from 0.00280\n",
      "81/81 [==============================] - 28s 341ms/step - loss: 0.0075 - acc: 0.9981 - val_loss: 0.0320 - val_acc: 0.9950\n",
      "Epoch 256/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0050 - acc: 0.9987WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0385 - acc: 0.9875\n",
      "\n",
      "Epoch 00256: val_loss did not improve from 0.00280\n",
      "81/81 [==============================] - 23s 282ms/step - loss: 0.0049 - acc: 0.9988 - val_loss: 0.0385 - val_acc: 0.9875\n",
      "Epoch 257/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0046 - acc: 0.9987WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0490 - acc: 0.9925\n",
      "\n",
      "Epoch 00257: val_loss did not improve from 0.00280\n",
      "81/81 [==============================] - 24s 295ms/step - loss: 0.0054 - acc: 0.9984 - val_loss: 0.0490 - val_acc: 0.9925\n",
      "Epoch 258/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0170 - acc: 0.9956WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 23s 7ms/sample - loss: 0.0229 - acc: 0.9947\n",
      "\n",
      "Epoch 00258: val_loss did not improve from 0.00280\n",
      "81/81 [==============================] - 28s 341ms/step - loss: 0.0168 - acc: 0.9957 - val_loss: 0.0229 - val_acc: 0.9947\n",
      "Epoch 259/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0056 - acc: 0.9984WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 22s 7ms/sample - loss: 0.0239 - acc: 0.9947\n",
      "\n",
      "Epoch 00259: val_loss did not improve from 0.00280\n",
      "81/81 [==============================] - 26s 320ms/step - loss: 0.0055 - acc: 0.9984 - val_loss: 0.0239 - val_acc: 0.9947\n",
      "Epoch 260/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/81 [============================>.] - ETA: 0s - loss: 0.0136 - acc: 0.9959WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 22s 7ms/sample - loss: 0.0308 - acc: 0.9950\n",
      "\n",
      "Epoch 00260: val_loss did not improve from 0.00280\n",
      "81/81 [==============================] - 26s 325ms/step - loss: 0.0134 - acc: 0.9960 - val_loss: 0.0308 - val_acc: 0.9950\n",
      "Epoch 261/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0018 - acc: 0.9997WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0536 - acc: 0.9950\n",
      "\n",
      "Epoch 00261: val_loss did not improve from 0.00280\n",
      "81/81 [==============================] - 22s 267ms/step - loss: 0.0019 - acc: 0.9997 - val_loss: 0.0536 - val_acc: 0.9950\n",
      "Epoch 262/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0084 - acc: 0.9978WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 5ms/sample - loss: 0.0164 - acc: 0.9953\n",
      "\n",
      "Epoch 00262: val_loss did not improve from 0.00280\n",
      "81/81 [==============================] - 22s 268ms/step - loss: 0.0083 - acc: 0.9978 - val_loss: 0.0164 - val_acc: 0.9953\n",
      "Epoch 263/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0087 - acc: 0.9971WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 20s 6ms/sample - loss: 0.0122 - acc: 0.9975\n",
      "\n",
      "Epoch 00263: val_loss did not improve from 0.00280\n",
      "81/81 [==============================] - 24s 291ms/step - loss: 0.0085 - acc: 0.9972 - val_loss: 0.0122 - val_acc: 0.9975\n",
      "Epoch 264/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0015 - acc: 0.9994WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 20s 6ms/sample - loss: 0.0350 - acc: 0.9950\n",
      "\n",
      "Epoch 00264: val_loss did not improve from 0.00280\n",
      "81/81 [==============================] - 25s 311ms/step - loss: 0.0014 - acc: 0.9994 - val_loss: 0.0350 - val_acc: 0.9950\n",
      "Epoch 265/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0021 - acc: 0.9991WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 21s 6ms/sample - loss: 0.0032 - acc: 0.9997\n",
      "\n",
      "Epoch 00265: val_loss did not improve from 0.00280\n",
      "81/81 [==============================] - 24s 301ms/step - loss: 0.0021 - acc: 0.9991 - val_loss: 0.0032 - val_acc: 0.9997\n",
      "Epoch 266/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0124 - acc: 0.9949WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 20s 6ms/sample - loss: 0.0152 - acc: 0.9916\n",
      "\n",
      "Epoch 00266: val_loss did not improve from 0.00280\n",
      "81/81 [==============================] - 24s 293ms/step - loss: 0.0122 - acc: 0.9950 - val_loss: 0.0152 - val_acc: 0.9916\n",
      "Epoch 267/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0170 - acc: 0.9946WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 20s 6ms/sample - loss: 0.0266 - acc: 0.9916\n",
      "\n",
      "Epoch 00267: val_loss did not improve from 0.00280\n",
      "81/81 [==============================] - 25s 309ms/step - loss: 0.0166 - acc: 0.9947 - val_loss: 0.0266 - val_acc: 0.9916\n",
      "Epoch 268/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0059 - acc: 0.9978WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 23s 7ms/sample - loss: 0.0242 - acc: 0.9937\n",
      "\n",
      "Epoch 00268: val_loss did not improve from 0.00280\n",
      "81/81 [==============================] - 28s 342ms/step - loss: 0.0058 - acc: 0.9978 - val_loss: 0.0242 - val_acc: 0.9937\n",
      "Epoch 269/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0044 - acc: 0.9981WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0360 - acc: 0.9975\n",
      "\n",
      "Epoch 00269: val_loss did not improve from 0.00280\n",
      "81/81 [==============================] - 23s 285ms/step - loss: 0.0043 - acc: 0.9981 - val_loss: 0.0360 - val_acc: 0.9975\n",
      "Epoch 270/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0066 - acc: 0.9975WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 20s 6ms/sample - loss: 0.0548 - acc: 0.9950\n",
      "\n",
      "Epoch 00270: val_loss did not improve from 0.00280\n",
      "81/81 [==============================] - 24s 301ms/step - loss: 0.0068 - acc: 0.9972 - val_loss: 0.0548 - val_acc: 0.9950\n",
      "Epoch 271/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0082 - acc: 0.9975WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0354 - acc: 0.9950\n",
      "\n",
      "Epoch 00271: val_loss did not improve from 0.00280\n",
      "81/81 [==============================] - 23s 278ms/step - loss: 0.0081 - acc: 0.9975 - val_loss: 0.0354 - val_acc: 0.9950\n",
      "Epoch 272/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0062 - acc: 0.9987WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0434 - acc: 0.9950\n",
      "\n",
      "Epoch 00272: val_loss did not improve from 0.00280\n",
      "81/81 [==============================] - 22s 267ms/step - loss: 0.0074 - acc: 0.9984 - val_loss: 0.0434 - val_acc: 0.9950\n",
      "Epoch 273/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0036 - acc: 0.9987WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0543 - acc: 0.9950\n",
      "\n",
      "Epoch 00273: val_loss did not improve from 0.00280\n",
      "81/81 [==============================] - 23s 283ms/step - loss: 0.0037 - acc: 0.9988 - val_loss: 0.0543 - val_acc: 0.9950\n",
      "Epoch 274/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0174 - acc: 0.9949WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 22s 7ms/sample - loss: 0.0330 - acc: 0.9900\n",
      "\n",
      "Epoch 00274: val_loss did not improve from 0.00280\n",
      "81/81 [==============================] - 26s 320ms/step - loss: 0.0176 - acc: 0.9947 - val_loss: 0.0330 - val_acc: 0.9900\n",
      "Epoch 275/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0055 - acc: 0.9978WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3200/3183 [==============================] - 20s 6ms/sample - loss: 0.0320 - acc: 0.9931\n",
      "\n",
      "Epoch 00275: val_loss did not improve from 0.00280\n",
      "81/81 [==============================] - 25s 303ms/step - loss: 0.0054 - acc: 0.9978 - val_loss: 0.0320 - val_acc: 0.9931\n",
      "Epoch 276/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0060 - acc: 0.9978WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0377 - acc: 0.9950\n",
      "\n",
      "Epoch 00276: val_loss did not improve from 0.00280\n",
      "81/81 [==============================] - 26s 316ms/step - loss: 0.0059 - acc: 0.9978 - val_loss: 0.0377 - val_acc: 0.9950\n",
      "Epoch 277/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0049 - acc: 0.9987WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0635 - acc: 0.9950\n",
      "\n",
      "Epoch 00277: val_loss did not improve from 0.00280\n",
      "81/81 [==============================] - 25s 308ms/step - loss: 0.0049 - acc: 0.9988 - val_loss: 0.0635 - val_acc: 0.9950\n",
      "Epoch 278/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0039 - acc: 0.9990WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 29s 9ms/sample - loss: 0.0450 - acc: 0.9950\n",
      "\n",
      "Epoch 00278: val_loss did not improve from 0.00280\n",
      "81/81 [==============================] - 33s 403ms/step - loss: 0.0038 - acc: 0.9991 - val_loss: 0.0450 - val_acc: 0.9950\n",
      "Epoch 279/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 7.8601e-04 - acc: 1.0000WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 21s 6ms/sample - loss: 0.0357 - acc: 0.9944\n",
      "\n",
      "Epoch 00279: val_loss did not improve from 0.00280\n",
      "81/81 [==============================] - 26s 327ms/step - loss: 7.6848e-04 - acc: 1.0000 - val_loss: 0.0357 - val_acc: 0.9944\n",
      "Epoch 280/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 9.7822e-04 - acc: 0.9994WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3190/3183 [==============================] - 23s 7ms/sample - loss: 0.0462 - acc: 0.9950\n",
      "\n",
      "Epoch 00280: val_loss did not improve from 0.00280\n",
      "81/81 [==============================] - 28s 344ms/step - loss: 9.6726e-04 - acc: 0.9994 - val_loss: 0.0462 - val_acc: 0.9950\n",
      "Epoch 281/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0068 - acc: 0.9975WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0209 - acc: 0.9925\n",
      "\n",
      "Epoch 00281: val_loss did not improve from 0.00280\n",
      "81/81 [==============================] - 22s 275ms/step - loss: 0.0067 - acc: 0.9975 - val_loss: 0.0209 - val_acc: 0.9925\n",
      "Epoch 282/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0042 - acc: 0.9994WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0326 - acc: 0.9975\n",
      "\n",
      "Epoch 00282: val_loss did not improve from 0.00280\n",
      "81/81 [==============================] - 23s 278ms/step - loss: 0.0042 - acc: 0.9994 - val_loss: 0.0326 - val_acc: 0.9975\n",
      "Epoch 283/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0031 - acc: 0.9997WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 25s 8ms/sample - loss: 0.0458 - acc: 0.9950\n",
      "\n",
      "Epoch 00283: val_loss did not improve from 0.00280\n",
      "81/81 [==============================] - 32s 389ms/step - loss: 0.0031 - acc: 0.9997 - val_loss: 0.0458 - val_acc: 0.9950\n",
      "Epoch 284/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0024 - acc: 0.9994WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0412 - acc: 0.9975\n",
      "\n",
      "Epoch 00284: val_loss did not improve from 0.00280\n",
      "81/81 [==============================] - 23s 283ms/step - loss: 0.0024 - acc: 0.9994 - val_loss: 0.0412 - val_acc: 0.9975\n",
      "Epoch 285/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0191 - acc: 0.9956WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0468 - acc: 0.9897\n",
      "\n",
      "Epoch 00285: val_loss did not improve from 0.00280\n",
      "81/81 [==============================] - 22s 269ms/step - loss: 0.0191 - acc: 0.9953 - val_loss: 0.0468 - val_acc: 0.9897\n",
      "Epoch 286/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0111 - acc: 0.9962WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 22s 7ms/sample - loss: 0.0330 - acc: 0.9916\n",
      "\n",
      "Epoch 00286: val_loss did not improve from 0.00280\n",
      "81/81 [==============================] - 26s 324ms/step - loss: 0.0109 - acc: 0.9963 - val_loss: 0.0330 - val_acc: 0.9916\n",
      "Epoch 287/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0057 - acc: 0.9981WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0190 - acc: 0.9944\n",
      "\n",
      "Epoch 00287: val_loss did not improve from 0.00280\n",
      "81/81 [==============================] - 24s 293ms/step - loss: 0.0056 - acc: 0.9981 - val_loss: 0.0190 - val_acc: 0.9944\n",
      "Epoch 288/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0089 - acc: 0.9978WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 30s 10ms/sample - loss: 0.0216 - acc: 0.9975\n",
      "\n",
      "Epoch 00288: val_loss did not improve from 0.00280\n",
      "81/81 [==============================] - 34s 426ms/step - loss: 0.0087 - acc: 0.9978 - val_loss: 0.0216 - val_acc: 0.9975\n",
      "Epoch 289/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0038 - acc: 0.9987WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0409 - acc: 0.9950\n",
      "\n",
      "Epoch 00289: val_loss did not improve from 0.00280\n",
      "81/81 [==============================] - 25s 307ms/step - loss: 0.0037 - acc: 0.9988 - val_loss: 0.0409 - val_acc: 0.9950\n",
      "Epoch 290/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0031 - acc: 0.9987WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0243 - acc: 0.9875\n",
      "\n",
      "Epoch 00290: val_loss did not improve from 0.00280\n",
      "81/81 [==============================] - 23s 283ms/step - loss: 0.0030 - acc: 0.9988 - val_loss: 0.0243 - val_acc: 0.9875\n",
      "Epoch 291/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/81 [============================>.] - ETA: 0s - loss: 0.0027 - acc: 0.9994WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0028 - acc: 1.0000\n",
      "\n",
      "Epoch 00291: val_loss did not improve from 0.00280\n",
      "81/81 [==============================] - 23s 287ms/step - loss: 0.0027 - acc: 0.9994 - val_loss: 0.0028 - val_acc: 1.0000\n",
      "Epoch 292/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0015 - acc: 0.9997WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 21s 7ms/sample - loss: 0.0247 - acc: 0.9975\n",
      "\n",
      "Epoch 00292: val_loss did not improve from 0.00280\n",
      "81/81 [==============================] - 25s 312ms/step - loss: 0.0015 - acc: 0.9997 - val_loss: 0.0247 - val_acc: 0.9975\n",
      "Epoch 293/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0026 - acc: 0.9987WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0135 - acc: 0.9975\n",
      "\n",
      "Epoch 00293: val_loss did not improve from 0.00280\n",
      "81/81 [==============================] - 22s 274ms/step - loss: 0.0025 - acc: 0.9988 - val_loss: 0.0135 - val_acc: 0.9975\n",
      "Epoch 294/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0011 - acc: 0.9994WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 20s 6ms/sample - loss: 0.0301 - acc: 0.9975\n",
      "\n",
      "Epoch 00294: val_loss did not improve from 0.00280\n",
      "81/81 [==============================] - 25s 309ms/step - loss: 0.0015 - acc: 0.9991 - val_loss: 0.0301 - val_acc: 0.9975\n",
      "Epoch 295/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0069 - acc: 0.9981WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0138 - acc: 0.9975\n",
      "\n",
      "Epoch 00295: val_loss did not improve from 0.00280\n",
      "81/81 [==============================] - 23s 282ms/step - loss: 0.0068 - acc: 0.9981 - val_loss: 0.0138 - val_acc: 0.9975\n",
      "Epoch 296/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0131 - acc: 0.9965WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 29s 9ms/sample - loss: 0.0202 - acc: 0.9950\n",
      "\n",
      "Epoch 00296: val_loss did not improve from 0.00280\n",
      "81/81 [==============================] - 34s 417ms/step - loss: 0.0130 - acc: 0.9966 - val_loss: 0.0202 - val_acc: 0.9950\n",
      "Epoch 297/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0015 - acc: 0.9994WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0293 - acc: 0.9950\n",
      "\n",
      "Epoch 00297: val_loss did not improve from 0.00280\n",
      "81/81 [==============================] - 24s 292ms/step - loss: 0.0016 - acc: 0.9994 - val_loss: 0.0293 - val_acc: 0.9950\n",
      "Epoch 298/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0028 - acc: 0.9984WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 20s 6ms/sample - loss: 0.0258 - acc: 0.9975\n",
      "\n",
      "Epoch 00298: val_loss did not improve from 0.00280\n",
      "81/81 [==============================] - 24s 297ms/step - loss: 0.0027 - acc: 0.9984 - val_loss: 0.0258 - val_acc: 0.9975\n",
      "Epoch 299/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0053 - acc: 0.9987WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0272 - acc: 0.9966\n",
      "\n",
      "Epoch 00299: val_loss did not improve from 0.00280\n",
      "81/81 [==============================] - 26s 326ms/step - loss: 0.0052 - acc: 0.9988 - val_loss: 0.0272 - val_acc: 0.9966\n",
      "Epoch 300/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0159 - acc: 0.9940WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0291 - acc: 0.9944\n",
      "\n",
      "Epoch 00300: val_loss did not improve from 0.00280\n",
      "81/81 [==============================] - 23s 287ms/step - loss: 0.0169 - acc: 0.9938 - val_loss: 0.0291 - val_acc: 0.9944\n",
      "Epoch 301/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0179 - acc: 0.9946WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 20s 6ms/sample - loss: 0.0326 - acc: 0.9975\n",
      "\n",
      "Epoch 00301: val_loss did not improve from 0.00280\n",
      "81/81 [==============================] - 25s 305ms/step - loss: 0.0182 - acc: 0.9944 - val_loss: 0.0326 - val_acc: 0.9975\n",
      "Epoch 302/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0013 - acc: 1.0000WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0346 - acc: 0.9969\n",
      "\n",
      "Epoch 00302: val_loss did not improve from 0.00280\n",
      "81/81 [==============================] - 23s 288ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.0346 - val_acc: 0.9969\n",
      "\n",
      "vis_imagenet_6_class_augmentation_2D_CNN_custom_ch_32_DO_075_DO_6_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzs3Xl8VNX5+PHPmSWTfSEEwh72XXZEreJXcQEUrRbRaq1opVZFra3VWrV8q9/auvxq3fe64lLUWi0VRUFcQAUFBFmFsARCFrInk9me3x8nk0nIBMIyBsjzfr1g5t577r3nzkzOc885955rRASllFIKwNHaGVBKKXX40KCglFKqngYFpZRS9TQoKKWUqqdBQSmlVD0NCkoppeppUFBKKVVPg4JSSql6GhSUUkrVc7V2BvZX+/btJScnp7WzoZRSR5Rly5YViUjWvtIdcUEhJyeHpUuXtnY2lFLqiGKM2dKSdNp8pJRSqp4GBaWUUvU0KCillKp3xPUpROP3+9m+fTter7e1s3LEio+Pp2vXrrjd7tbOilKqFR0VQWH79u2kpKSQk5ODMaa1s3PEERGKi4vZvn07PXv2bO3sKKVaUcyaj4wxzxpjCowxq5pZbowxDxpjNhpjVhpjRh7ovrxeL5mZmRoQDpAxhszMTK1pKaVi2qfwHHDmXpZPBPrW/ZsBPHYwO9OAcHD081NKQQybj0RkkTEmZy9JzgFeEPs80CXGmHRjTCcR2RmrPKmjm4jsV3CrqoLERDDGrltWHiIl2YnTaacherDc3/00JxQSamshIaH5bYnY/IXf+/3gdNrX+HgoLYV16+DYY8PbhPXrIT9fOPFEQ2UlfPwxTJwIbrc95hUroEMHSEqCtWth/HjYsgVycuy+qnzVvLjyBaYNnkZGQgahEHz0EXi9MGGC3W9YeTmkpEAgILz4oiEjQzjlFENaWuPj8Pth7lxh9XchjhnqpF07qK6GwkK739pacLmgf39ITYVvvrF5jI+HkhI73+WCvDxYs8a+ulwwdiz06QMrV8Inn0DXrnD88fazmj8fKithyBAYM8a+37LFvvbuDRkZ9vMoLbX7O/VUKC6GuZ9uh6zVXH/WGYjYPAYCQqdOhpIS2LjR/m6GDLHrlpbaeTt3wtat0KMHjBoFixcLFRWGjh3h/PNtfnfsgGAQNm+Gymo/czY/TXf/aQzr0RNjoG8fQ5/eDt57D9LT7fGPHg0g3HKL4brroHv3g/7p7ZWJ5TOa64LCuyIyJMqyd4G/iMinddMfAjeLSJM704wxM7C1Cbp37z5qy5bG92CsWbOGgQMHHvL8t1RpaSmzZ8/m6quv3u91J02axOzZs0lPT29R+lmzZpGcnMxvf/vbqMvLvGVU+ipJj08nKS4paprmCrUVq1aQ68rlnAHnNJq/tmgt64vXM6X/FHxBHy6Hi5KaUtbu3EJ2Rhoff7+Y6aN/CphIAVtbRnltOR9u+pDLhl9Wv7/16+Hpp2HJEpg0CY6Z/Dk/+8+53PajP3L/J49SKlv4nx6nkluay2NnP8IJ3U7AGENJTQmzv51N76qfcdvvUpgwYz4FhQH6Ok6ndy8nryxZwMdZFzA+ZzwTk27j7DHDeeWNKt755nOGdu/Ob6b3Ycr/PkVS9k4yt1/K4E69efjZIlxXjSMtIZkdVVsJuEtI2TGFob068FXFW/gdFSTkncEI83OGdBxKz5EbWbrpez6ufpjshB4kbD6fLc4PGZ19HBJXyoq8dcTnnmsL7O6rOHPUICocW1jwWQ21G48jkLUMB078XRdSlr6IkMMLu3vhru6OpG2ly64ruOCYc9hUlMcX5W9SuCUTt9vQsxcUFUJZsQffjoFklZ9O0Y5kJl2Yx7yCZ/EWdeCkLmewIvVuKl25BL8fD6MfJ/vjtwiWZ1HoWkb/+PGcPC6D5//hxOvKh5FPg8sL/gR6u8bzfXABmWkJZO+8gtUDp0HvD0iqGIZny1k4HFBUBATdDKqcydRLi3mw4iQcO06g+M0/MGx0Dd8NPR9/7mjo+gXm6xmc2vVsThrRlWBpZx759HlKQlsJjngMUvJh/SRotxEqs2HriZEfWkkv2D4OJv8KvOnw/v1w7s8hPZf2VeMZ3qMXi176Eb61E2Dw65D1HRQMpldGH/J2hKj1bIPs5TidNrgFAgK934f4Ulj7YwjGwfZjYf1ZOHt9Snzfz6n2+nDE+QnihW6fQfoWcPghuYAz8z+iZtNIPo6/EQa8jVl1EeKti3aV2YwI/pJvij+DnAXgCELIBTUZ4PTbNCf+H+wYA9nf0G/pXCjuy/rsO2HYi7D2HCgYAhNvaPxHGHLiWHs+oep0GPIqVGfRPTSe/Iw38XldXNb5fv5xw6X7LCeiMcYsE5HR+0x3JASFhkaPHi173tHc2kEhNzeXs846i1Wrmnaf+P1+Sn2lZCRk4HLsu2ImIhTXFJMcl0y8K77J8r0FBRFhxa4VBEIBUj2p9G3XF4ic7QZCATaVbMJpnPTK6E1VlT17iY+H73N9bNi5kInvn8G5ngfI3nI9I3/yIdtqv+X5JW+zw7mEO8b/kTs+/j3Jjvb4auLwxe0kQbKocRQwtOImNq3oxMiRsLpoBbu7vIypTUcSixgmP2eX60sKqncRev9uHNtPJHXy/1H62v1w4p9h3IP2AEpySCv/EWWZH4AYSC7AiIu+Mpkt/q+ojd+OWXeO/cMc9oJd59ObYekv4ZrBmKpsJKEYPOXw1a/sH1VCif0MyrsjqVvtOtXtIeS07xN2Q94YUqUHfTt14mvHo0jQhWfLFHq0z2Jz2j/wO8sbf9C7e0PqdnDV4vCnEHJXAOCozSDkKan7MgyY6H9bztpMXKt/RqAmmfTj3qCSfFJqB1KU8LlNEHJgggng8hL+8zQGxATrtxHnz8JflYKkb7IzAnE4jQuHw+A3VRgMIgZMKLJjfzzdvWdRlvExZYFCHDgJEdkmgKe2C7WePIZUXcca90uE3GWIgMMBIYIkf3cNlfFroMuXGJyIp8weU1VnTFIRWfFd2OndHNlgUT9ovx6AfonHMqH/8Ty1/FGyPb3wU01h7fa6YxRC2Lw6icPtiMMX8hIiwADnRNaWrICUnWCEeEcS3lDdMdL4M3bgsMeNzXNOah+cvkw21nyB1G3/mNSTWVG+oNF6cY540qUXaaYL/sQtFJf5qPCXgCOAiauml+tHbPYvqf88QwQxlZ2Q5J0YDAZHk8+yT+pgqoKllNfUUFuRjImrJuAuZkDcBNb65gPQM7U/lwz6BfnF1SCwMb+AT8tfBGctx7U7h/zdFawLvgebJjCiZw4PXHExJ/U4Kerval+OhKDwBLBQRF6pm14HnLyv5qPDMShceOGFvP322/Tv35/TTjuNyZMnc/vtt5ORkcGaNWt45eNXuG3GbRTuLMTr9XL99dczY8YMwA7b8fS7T5Nm0rj0J5cybOwwvlzyJdmdsvlg7gckJSY1asqYNWsWDo+Da66/hi3rtnD1r66murqabt1688DDj1Dm2cGrz7zKWy++hdPppmff3jzz6Lt89Ok7/N+dNyHYWsI/XvoPcfGJ4EsjLT1ImcmlaNtOps2+n/J2C3A/s4LABZOR9NzIgVa1h9o0KO4HGZuhOhM6L4W8sdDjk0afSafAcVSbXVDdgbKUJbBjJCmeFCoyP6ZXWl82lW1gWMYJ5BdXUSBrkNyTGLL1YdZ93o/p06Hakc/s7/9OUociKjq9Q2LVINIC/dnZ5XEATpTbSe+Ry9xtsxmcdhxry7/itDUbyW6XzJreV/F5+Wt08vTimfMf5vUFa3huzYOMdlzJ/Veczy8+PId2phc7fetIWHE9P+19PbfdZguRcm8F27a4yekaT1ISVPmq+HbnOj5au4x7bu9En+QRvPpUNtvKdpDZqZL+Wb046ZHzSXVn8N+r/sF7G9/DYRxMyDmDv/37AyTgYezIOEoDu5jUdxLBUBCXw0V5iYeKCuiRE8Qf8hPvimfL7p38v08epkzyeHjSwyTHJQORJqTaQC2Lty9m8bbFzFkzh5W7VjL/Z/P5Iu8Lnv76aV6f+jo1/hqeW/4cV4+5mpe/fZns5GxGZI/gy7yvWLlzLfO3/IeRnUZy32n3MbjDYLaVbWf2l+/xs2Mn87cl/4/7Ft/HVaOu4rGzmnbxzXhnBk99/RQAM3s+wU0TL+Dfm1+mJlDDJcdcQkpcCgnuBOZ8N4dQ0MHKvHW8vPYpLh32M35z/G9I86RhjKG4uphUTypuZ+TyZxFhdeFq3lzzJsd1PY6c9Bx+/NqPGdNlDP845x+88goE8bGj+9/ZWraFM/ucycQ+E/nvxv9SVFEOOMhISuDs/mfjMNG7SitqKxj2+DA2l27mTyf/iZnHziQ5LhmncTapOX+z8xvu/fxe0jzpzBh1JSM6jWi0/G+L/8YDXzzA73/0ey4ddimJ7kT8QT+l3lLKastYsHkBPx/+c+Kccby38T3Oe+08Tu11KrPGz2JU51Hc/MHN3PP5PTw08SGuHXvtXsuXDZv8JMS56dp1r8n26UgICpOBa4FJwLHAgyIydl/b3FdQ2LDhBiorlx903gXBG/ASDAXpkHEc/fs91GzadRvXMfmsyaz8diWJ7kQWLlzI5MmTWbVqFQlZCWwv346pMYzqPYqamhrGjBnDxx9/TGZmZn1QqK6q5rwTzuP5uc8zauQoZk6fyf+c8T/8/NLL2F2zm0AwiCnvznNPPICklPKzq37Gxaddwv1/fZyBg8Zz95//SJUvn9/8ZQaTRkzmX0v+RZzHTUVZBSmO/vz62ou47KpfMKz/2VS7VxGX4MLlcoE4QAxG3BStC3DmuZ3w3NSXtIQkCmrywZcEcVX1x3pG6o08dNb9pKbCzy/3M29RMY/c04GluWv5863Z5BbnkVu9mmmDp9UXAC8ueY9+vgs45VRhyGOD+L7ke47vdjyfb7NnxtePuJ30r//Eb38LHo9t+wbqz5Lz8qBLF3su+eGmD+mb2Zec9BxKvaWc/NzJrNi1gpljZ/LgRFvjCIQCPP3105zV7yy6ptq/pE2bbFuv03ngv4nSUtuWHBd34Ns4VPxBPwVVBXRJ7XLItlkbqOXtdW9zdr+zSXAnNFm+tWwrk16exIxRM7ju2OsO2X6bs7d+nQO1cfdGvt/9PWf0OeOQbfNA+II+3l3/Lmf3O7tRcIyllgaFmHU0G2NeAU4G2htjtgN/BNwAIvI4MBcbEDYC1cD0WOWlJURC+EMBnA4n1f5qXA4XgVAAoP61OdX+agShyleFx+lhR8UORo8ZTc+ePdlQvAGApx97mss/uByAbdu2sWHDBjIzMxtVf3v0yKH/kP7UFHZkyIDj2ba5gJ2VO+qaOgwOz26qvT4SUqCqWCgrLSV7RColoW+56LIfc+2vLsEhM+nddzC3X3sb488cz8lnngxJOxg2ZiiP/uUBTju1hJPP/B96Dm9Ph+R2rClaQ0hC9G/Xh1U7NjPtrI6cfe4T/OmTWfRKPobJiX+i2/C13DDvBkq9pVx5xvH0ta1SPP6Im6VLs/nJTwAGAZCd1o5xDK0/pszETG445eL66YcmPsSN79/IGxe8wWkvnsaqglWcPWQ8p05p+rmGy4LwGZLBwWm9T6tfnh6fzmeXf8aLK1/kwiEX1s93OVxcNfqqRtvq1WuvX2GLtLDb5wfhdroPaUAA8Lg8XDD4gmaXd0/rzqqro15hHhOxuCKuT7s+9GnX55Bvd3/FOeM4b+B5rZ2NqGJ59dFF+1guwDWHer99+z6w3+v4gj5W7lqJE8iIzwCvbRduF5dMpa+SrLRId3+Nv4bVhasZlDWIRHciIkJtoBYAf8hPtb+aitoKQq4QwVCQSl8lyz5fxuJFi3n5lU9wmlSuuOJk8vO97N4dORsGwGHPGFISPcQ5Ugj5IN10x0kyXvcOQnFenB4fALK7JwYnSc50Aq4qat07EYJkJqXy6pw3+O8nr/HJB5/w4sMv8uIHL3L5zMu5ctqVzJ37Hr/8+VnMmzcPz4BO9M/sT0hCJMXFk5oKr74KcBEXD2v49R3LS9++xPxN8zmu23H1c3Ny7L/9MbHvRCb2nQjAR5d+xHPLn2N8zvj920gDSXFJTQKAUurAHRV3NB+sUm9p/fuaQE39+26p3VhbtBZf0NckbXF1MSbR8F3Rd/hdfqorq/EH/Y3SLt+8DUkIUllkSElLIWAg9/u1LFu2hF27bJNGIBCJCg6n7ajq2c1DVhZUVhr6dOoAwPbyeHZVluGM82FCHvr2aU+H9u0p2pBH/5H9eej1hxg5biTpnnTyi/IZfcJoho8dznnvnkcKKZQVlHH8sOMZNmwYy5Z9xdq1axkwYEDUZoJoLhpyEclxyXRO6XwAn3B0WUlZ3HTCTYdse0qpg6dBgcbNQ96AF4/Tw4D2A3A73cQ54+oLehGpv4IoEApQ5i1DREhIS2DYmGGceuxpnPQ/p3LshOEgBkkoAmDK6dN44/XnmHruKAYPHMyYsWPI6Rlqcr1xCNsJ6XQ0bfhOcCUgCL5gLWmeVLp0geeff56rrrqKquoqMjtnctff7yLBmcAVl11BfnE+CMycOZPB3Qcz896ZzFgwA4fDweDBg5k4ceJ+fUaXj7icy0dcvl/rKKWOPDHtaI6FA736KBCoIBgsJy6uc5O2yi2lW9hds5ug2DP1lLgU+rfvD8C6onUIQve07qwpXEOqqz1lgULiJI1AAELussiG/IngT8TEl5HkaE8lO0n1pNIvsx/L85eTHp9OIBSg1FtKj7QeZCVlsXV3PgXe7fWX1yW5kxiY1fRYqnxVrClaA0D/zP6keFIaLd9RsYM4ZxztE9sDsHLXSlwOF4OyBrXgU23556iUOjK1tKO5zQydHQpV4fPtBEJNlvlDfuKcccQ57WUlDa8GMKE4qry1FOyuQhDKaioB8AV8hFyVEPDYhEEXLo+flPRaEj1xdM/KAKBdQjsA4l3xlNSU1Dc/hWsfDlcAg6Fjcke7v2Y61xresxC+VLGhzimd6wMCQPvE9o2mlVKqJdpMUABb2EarGQVCAVwOF+66jt5wcPD7obIsDnH4KSq1ncnGbV9x14AJkmo6Q3FfPKEsAiE/tcFaPC4Pie5EBmcNJjMhE7DNP+GaCFD/PhgK4nQ4yUrMarTvPTkdTtoltCMnvWUjwXZO6UyHpA77TKeUUg21oT6FcPyLBAURoTZYiz/oJynO3iRW5a9CAm6WL7d3+4rT1gQS0iqpCVF/V2RYdno65bucpCb6KPTbGkC4YG/YiRs+03c73DiMo9Hlri6HC4/L9mNEu4s5rFfGIbiuUiml9qINBYXw2XWkUN9ZuZMdFTsASHOkYerSeKvjCAQgEIDs7h7yA+ANVe25QToldyI1xcnQoVAjbgp32/meukDSULiwT45LpjZYSzAUJBgK1geF8DKllGpNbSYohJtcGjYfVfkiBX34DB7AWxVHcrK9AzbOk0h+Po1uMkv1pJKdnE1KnO3s9Xgg5Pc0Wr6nBJetNSTHJROsDeIL+vgm/xvA3oSllFKHgzYTFCI1hUjh3rD93u10k+ROIjUujfLKeDI7QUICgJN4VzzeQOQBNC6Hq0nBn+BOYFDWIOJd8VHHXolzxTGg/QAS3YlU+iqpCFTUL4t2CapSSrWGNtTR3LRPISSRpiSXw0WCO4H0UF8QJykNrvhMcjcegrq50U4T3YnNDsYFtpbgMA5cDhcn9o0MGdyw9pKcrE1ISqnW02aCQuSKnUgB3PCmNRNys20bbNtmHxrSsGxOdCcC1F+d5DQHd2a/Z1BpGJyUUqo1tZmgELkkNVIAN7xEdMtmFwUFNiD06hUZjA1sm39yXDJp8fYBG3sW6rfccguPPPJI/fSsWbO47777qKys5NRTT2XkyJEMHTqUt99+G2jcXNQttRvd05o+SklEuOmmmxgyZAhDhw7ltddeA2Dnzp2cdNJJDB8+nCFDhvDJJ58QDAa57LLL6tP+7W9/O9APSSnVxh19fQo33ADLmw6d7ZQgCaFqnI5EqDvT7+avss09QQ8Bn4PExOhDK3uGD2fAAw+QX5lvt7VHH8C0adO44YYbuOYaO77f66+/zrx584iPj+ett94iNTWVoqIixo0bx5QpU+qDisvhqr9pbU9vvvkmy5cvZ8WKFRQVFTFmzBhOOukkZs+ezRlnnMEf/vAHgsEg1dXVLF++nLy8vPqH/JSWlkbdplJK7cvRFxT2qfF9CsYY/H4HLve+x9oPNx/tWVMYMWIEBQUF7Nixg8LCQjIyMujWrRt+v59bb72VRYsW4XA4yMvLY9euXXjSPI22F82nn37KRRddhNPppGPHjowfP56vvvqKMWPGcPnll+P3+zn33HMZPnw4vXr1YtOmTcycOZPJkydz+umnH+Bno5Rq646+oPBA9KGzQ8Fqaqq/Iz6+D253OiLC2p3LSHd2onRbF/r3B1KirlrP47KFebS7jqdOncqcOXPIz89n2rRpALz88ssUFhaybNky3G43OTk5eL1ekjKSmt3Ovpx00kksWrSI//znP1x22WXceOONXHrppaxYsYJ58+bx+OOP8/rrr/Pss8/u97aVUqrN9SmEb14L9yfUep243Y07lpuTHJfMkKwh9R3PDU2bNo1XX32VOXPmMHXqVADKysro0KEDbrebBQsWsGXLFiBS09hbUDjxxBN57bXXCAaDFBYWsmjRIsaOHcuWLVvo2LEjV155Jb/4xS/4+uuvKSoqIhQKcf7553PXXXfx9ddft/RDUUqpRo6+mkKzGl99FAzVBYVqF+3SGncs7028O/owFIMHD6aiooIuXbrQqVMnAC6++GLOPvtshg4dyujRoxkwYAAQ6ZPY22P4fvzjH7N48WKGDRuGMYZ77rmH7Oxsnn/+ee69917cbjfJycm88MIL5OXlMX36dEIhG/Duvvvulh2MUkrtoc0MnR0K1VJV9S0eTw4udztKvaVsKtkEu/vQu0s6GRmxzHVjIsK28m1kJWa1+CE3PwQdOlupo1erP6P58BOpKRRWFbKtfFvdpIvUpqNSxDYnxkS9DFUppVpbG+pTCB9qqNFNa0nxzn1edaSUUm1FmwkKDe9objgURVpK8+36SinV1rSZoFAb8FHht+359SOe7jqGjLQ21IKmlFL70GaCQom3lB1eO85QuHPdIW7im3+mjVJKtTltJihEnqcQsjUFMSQkmBZfiqqUUm1B2wkK4QHxkLqagql7XsLBKy0t5dFHHz2gdSdNmqRjFSmlDhttJyg0qCkEQ+GawqHZ9t6CQiAQiDo/bO7cuaSn65PXlFKHh7YTFBrUFPyBQ1tTuOWWW/j+++8ZPnw4N910EwsXLuTEE09kypQpDBo0CIBzzz2XUaNGMXjwYJ588sn6dXNycigqKiI3N5eBAwdy5ZVXMnjwYE4//XRqamqa7Oudd97h2GOPZcSIEUyYMIFdu3YBUFlZyfTp0xk6dCjHHHMMb7zxBgDvvfceI0eOZNiwYZx66qmH5oCVUketo+6O5mZGzsYf9OEN1pLodFEbNAQlQHJccov6FIYPb3acPQByc3M566yz6oeuXrhwIZMnT2bVqlX07NkTgN27d9OuXTtqamoYM2YMH3/8MZmZmeTk5LB06VIqKyvp06cPS5cuZfjw4VxwwQVMmTKFSy65pNG+SkpKSE9PxxjD008/zZo1a7j//vu5+eabqa2t5YG6jJaUlBAIBBg5ciSLFi2iZ8+e9Xlojt7RrNTRS+9o3lO4+YjI4y9j2ck8duzY+oAA8OCDD/LWW28BsG3bNjZs2EBmZmajdXr27Mnw4cMBGDVqFLm5uU22u337dqZNm8bOnTvx+Xz1+5g/fz6vvvpqfbqMjAzeeecdTjrppPo0ewsISikFR2FQaO6Mvri6nM2lm+mbmsqWEhd+qhjVbWjM8pGUFHmu88KFC5k/fz6LFy8mMTGRk08+Ga/X22Qdj8dT/97pdEZtPpo5cyY33ngjU6ZMYeHChcyaNSsm+VdKtU0x7VMwxpxpjFlnjNlojLklyvLuxpgFxphvjDErjTGTYpgXwPYphETq+xgOhZSUFCoqKppdXlZWRkZGBomJiaxdu5YlS5Yc8L7Kysro0qULAM8//3z9/NNOO63RI0FLSkoYN24cixYtYvPmzYBtwlJKqb2JWVAwxjiBR4CJwCDgImPMoD2S3Qa8LiIjgAuBA7uusyX5qX9GsxAKSYNhLw5eZmYmJ5xwAkOGDOGmm25qsvzMM88kEAgwcOBAbrnlFsaNG3fA+5o1axZTp05l1KhRtG/fvn7+bbfdRklJCUOGDGHYsGEsWLCArKwsnnzySc477zyGDRtW//AfpZRqTsw6mo0xxwGzROSMuunfA4jI3Q3SPAFsEpG/1qW/X0SO39t2D3To7JKaEr4v+Z5eKUlsKnLhivMzvMueMapt045mpY5eh0NHcxdgW4Pp7cCxe6SZBbxvjJkJJAETYpWZcM3Aub0WPE4ceiuzUko10dr3KVwEPCciXYFJwIvGmCZ5MsbMMMYsNcYsLSwsPKAdhZuPgn4HGNGgoJRSUcQyKOQB3RpMd62b19AVwOsAIrIYiAfa75EGEXlSREaLyOisrKwDyky4puDHZYOCQ4OCUkrtKZZB4SugrzGmpzEmDtuR/O890mwFTgUwxgzEBoUDqwrsQ7imEMAFaFBQSqloYhYURCQAXAvMA9ZgrzJabYz5kzFmSl2y3wBXGmNWAK8Al0mMb7EOGG0+Ukqp5sT05jURmQvM3WPeHQ3efwecEMs8hEXuUzD2fw0KSinVRGt3NP9gws1HITgsagrJycmtun+llIqmzQUFMVpTUEqp5rSZoBAe1UIAzKENCrfcckujISZmzZrFfffdR2VlJaeeeiojR45k6NChvP322/vcVnNDbEcbAru54bKVUupAHXUD4t3w3g0sz286dnZIQlT5q3D53QRcAdxOF/Gulj2geXj2cB44s/mxs6dNm8YNN9zANddcA8Drr7/OvHnziI+P56233iI1NZWioiLGjRvHlClT9hqQnn322UZDbJ9//vmEQiGuvPLKRkNgA9x5552kpaXx7bffAna8I6WUOhhHXVBoDSNGjKCgoIAdO3ZQWFhIRkYG3bp1w+/3c+utt7Jo0SIcDgd5eXns2rUTX//sAAAgAElEQVSL7OzsZrcVbYjtwsLCqENgRxsuWymlDsZRFxSaO6OvDdTybcG3pJRkUpFWQoeU9nRP637I9jt16lTmzJlDfn5+/cBzL7/8MoWFhSxbtgy3201OTk7UIbPDWjrEtlJKxUrb6VOoI8aA4ZAOnQ22CenVV19lzpw5TJ06FbDDXHfo0AG3282CBQvYsmXLXrfR3BDbzQ2BHW24bKWUOhhtJiiYBk9ei8XVR4MHD6aiooIuXbrQqVMnAC6++GKWLl3K0KFDeeGFFxgwYMBet9HcENvNDYEdbbhspZQ6GEfdM5qb4w/6WbFrBYll7alOK6JTcie6pHaJZVaPODp0tlJHr5YOnd12agp1r+EQqPcpKKVUU20mKISjQcjYN4e6T0EppY4GR01Q2FczmKlbLuGgoDWFRo60ZkSlVGwcFUEhPj6e4uLivRZsJlQXFBx1QUHLwHoiQnFxMfHxLbuZTyl19Doq7lPo2rUr27dvZ29PZRO/n6KqIhy+akJx1YTig+yO10s4w+Lj4+natWtrZ0Mp1cqOiqDgdrvr7/ZtjqxcyeD3J5Lx7dmUDH2HZ07+f1w+4tc/UA6VUurIcFQ0H7WEqanBGYKAyw+AW9rMoSulVIu1nZKxpgZXCIIuHwBunK2cIaWUOvy0naBQXb1HUGg7h66UUi3VdkrGuuajkDYfKaVUs9pOyVhXUwi5agGtKSilVDRtp2Ss61OQcFAI6c1rSim1p7YTFOprCvb5BFpTUEqpptpOyehy4cJAOChon4JSSjXRdkrGa6/F0a1rJCho85FSSjXRdoIC4DRucNUA4BYNCkoptac2FhRc4NaaglJKNaeNBQV3/XutKSilVFNtLChExv/ToKCUUk21qaBgGgwKG6fNR0op1USbCgpOGjQfaVBQSqkm2lRQcDSoKbiDrZgRpZQ6TMU0KBhjzjTGrDPGbDTG3NJMmguMMd8ZY1YbY2bHMj8Ng0KSHBXPF1JKqUMqZiWjMcYJPAKcBmwHvjLG/FtEvmuQpi/we+AEESkxxnSIVX4g0qfgChji9I5mpZRqIpYl41hgo4hsEhEf8Cpwzh5prgQeEZESABEpiGF+MGIfrJPgc0IgEMtdKaXUESmWQaELsK3B9Pa6eQ31A/oZYz4zxiwxxpwZbUPGmBnGmKXGmKWFhYUHnCFT12SU5HNCUDsVlFJqT63dhuIC+gInAxcBTxlj0vdMJCJPishoERmdlZV1wDsL9ykk+hwaFJRSKopYBoU8oFuD6a518xraDvxbRPwishlYjw0SsSHhoGC0+UgppaKIZVD4CuhrjOlpjIkDLgT+vUeaf2FrCRhj2mObkzbFLEch26eQ5DNaU1BKqShiFhREJABcC8wD1gCvi8hqY8yfjDFT6pLNA4qNMd8BC4CbRKQ4VnkK9ymk1KI1BaWUiiKmF+uLyFxg7h7z7mjwXoAb6/7FXsgebrIPrSkopVQUrd3R/IOqryn4RIOCUkpF0aaCQrimkOITbT5SSqko2lRQCFcOUn0hrSkopVQUbSooVNXap65l+nxaU1BKqSjaVlDw2qCQqn0KSikVVZsKCtU+GxT06iOllIquTQWFmkANAEl+tPlIKaWiaFFQMMZcb4xJNdYzxpivjTGnxzpzh5o3aINCsh+tKSilVBQtrSlcLiLlwOlABvAz4C8xy1WM+EO2+SghhNYUlFIqipYGhfADjScBL4rI6gbzjghVVRBy1AWFIFpTUEqpKFoaFJYZY97HBoV5xpgUIBS7bB16BQWA2zYfeQQNCkopFUVLxz66AhgObBKRamNMO2B67LJ16O3aBRT1h3bfk6YdzUopFVVLawrHAetEpNQYcwlwG1AWu2wdegUFwBuz+d/eV5NVi9YUlFIqipYGhceAamPMMOA3wPfACzHLVQzs2gXUpnFKTg7iRGsKSikVRUuDQqBumOtzgIdF5BEgJXbZOvSKiuxrVlYt4gAJalBQSqk9tTQoVBhjfo+9FPU/xhgH4I5dtg69W26B8nKIj3fU1RT8rZ0lpZQ67LQ0KEwDarH3K+Rjn7d8b8xyFQPGQEoKGOO2NQUNCkop1USLgkJdIHgZSDPGnAV4ReSI6lMIczg89qgDvtbOilJKHXZaOszFBcCXwFTgAuALY8xPYpmxWHE6UxAnSKC2tbOilFKHnZbep/AHYIyIFAAYY7KA+cCcWGUsVlyuVNt85Pe2dlaUUuqw09I+BUc4INQp3o91DytOZ1pdTUGbj5RSak8trSm8Z4yZB7xSNz0NmBubLMWWy5WqzUdKKdWMFgUFEbnJGHM+cELdrCdF5K3YZSt2XK40/A4NCkopFU1LawqIyBvAGzHMyw/C6UzF59RLUpVSKpq9BgVjTAUg0RYBIiKpMclVDLlcqXpJqlJKNWOvQUFEjqihLFrC4UhEHOgdzUopFcUReQXRwTDGgMulzUdKKRVFmwsKALhcoAPiKaVUE200KLh16GyllIqiTQYF43JrTUEppaKIaVAwxpxpjFlnjNlojLllL+nON8aIMWZ0LPNTzxkHAX3ymlJK7SlmQcEY4wQeASYCg4CLjDGDoqRLAa4HvohVXprs0x2nj+NUSqkoYllTGAtsFJFNIuIDXsU+uW1PdwJ/BX6wEeqMMw6CoR9qd0opdcSIZVDoAmxrML29bl49Y8xIoJuI/CeG+WjCuD1aU1BKqSharaO57pGe/w/4TQvSzjDGLDXGLC0sLDz4fbs8mCCEQjr+kVJKNRTLoJAHdGsw3bVuXlgKMARYaIzJBcYB/47W2SwiT4rIaBEZnZWVddAZM654TAgCgdKD3pZSSh1NYhkUvgL6GmN6GmPigAuBf4cXikiZiLQXkRwRyQGWAFNEZGkM8wSAiUvChMDny4/1rpRS6ogSs6AgIgHgWmAesAZ4XURWG2P+ZIyZEqv9toQzLgUThNrana2ZDaWUOuy0eOjsAyEic9njYTwickczaU+OZV4acsalQhB8Pg0KSinVUJu8o9nhTsVoUFBKqSbaaFDwQEiDglJK7alNBgVcLkxI+xSUUmpPbTMoOJ3afKSUUlG0zaDgcmEEfN68fadVSqk2pG0GBacTAF/NTkSiPYJaKaXapjYdFH50ho9AxY5WzoxSSh0+2mZQcNnbMxxBqN66uJUzo5RSh4+2GRRqIwPhVZUsb8WMKKXU4aVtBoXvvqt/W1OyshUzopRSh5e2GRRuvx26dwegpmR1K2dGKaUOH20zKAwcCE8/DYCvfDPBYHUrZ0gppQ4PbTMoAMTHA+DwCbW121s5M0opdXjQoOADn29XK2dGKaUODxoU/OD3F7RyZpRS6vDQdoOCxwNoTUEppRpqu0GhUfOR1hSUUgo0KOAOJuH3a01BKaVAgwLuYLLWFJRSqk6bDwquYKL2KSilVJ22GxTcbgBcgUS9+kgppeq03aBgDMTH4wrGa01BKaXqtN2gADYo+OMIBssJBr2tnRullGp1bT4oOANxAHi9ua2bF6WUOgy0+aDgCbUDoLT0o1bOjFJKtb62HRQ8HpzBOOLjcygpmd/auVFKqVbXtoNCfDzG6yUjYwIlJR8RCtXue51DQQTuuw+2bfth9qeUUi3U5oMCXi9ZWVMJBstYufJMQiFf7PdbXAw33QSvvRb7fSml1H7QoOD10q7d6fTr9zilpQspLn439vutrnuoT3l57PellFL7QYOC116Kmp19BW53R3btein2+62psa8VFbHfl1JK7Ye2HRQ8Hti5E558Eodx0rHjRRQX/we/f3ds96tBQSl1mIppUDDGnGmMWWeM2WiMuSXK8huNMd8ZY1YaYz40xvSIZX6aiI+HrVvhl7+EtWvp2PFniPgoLPxnbPerQUEpdZiKWVAwxjiBR4CJwCDgImPMoD2SfQOMFpFjgDnAPbHKT1R1g+IBIEJy8ggSEwc134S0YwecfDIUFh7cfuuarLRPQSl1uIllTWEssFFENomID3gVOKdhAhFZICJ1va4sAbrGMD9NNQwKVVUYY+jY8RLKyj6ltjavafqlS+Hjj+Hbbw9uv1pTUEodpmIZFLoADS/E3143rzlXAP+NYX6aqnskJwBVVQCkph4LQHX1+qbpy8qoW3hw+9WgoJQ6TB0WHc3GmEuA0cC9zSyfYYxZaoxZWniwTTcN7VFTsLNst0Zt7dbIsrw8OPts2/8AGhSUUkctVwy3nQd0azDdtW5eI8aYCcAfgPEiEvWWYhF5EngSYPTo0XLIcmhM5H1dUPB4bAuW17slsuyjj+Ddd6G2LnvhQv1AhdfXPgWl1GEmljWFr4C+xpiexpg44ELg3w0TGGNGAE8AU0Tkh3/STXFx5H1dUHB4g8TFdWocFMI1hNxc+3qwNYVwR7PWFJRSh5mYBQURCQDXAvOANcDrIrLaGPMnY8yUumT3AsnAP40xy40x/25mc7FR0CAOVVXB/PmQmUlSVafGzUfhoHCom498PvtPKaUOE7FsPkJE5gJz95h3R4P3E2K5/31yOiPvq6th7VrwekkuzaQoNTeyLBwMws1HhyooAEyfbsdBGj784LaplFKHwGHR0dxqHnsM7q3r266qgt32Tub42nZ4vVsRqeu+2Lq18XqHqk8BYPZs+NnPDm57Sil1iLTtoJCdDb/9LSQmNgoKHm8KIrWsXj2VstLPmgaFQ1lTAGjX7uC2p5RSh0jbDgphewSF5GB3PJ4e7N79Ht9+ciJUVjZOf6BBYd06CAQiHc1h3bpFT6+UUj8wDQoASUmNm4986Rx3XC7HHrsBz64oV8AeSFAoLIQhQ+Cll5rWFJKSDiDTSil16GlQgCZBIXznssfTifTK3gCEMpIj6aMFhWAQHn8cSkuj72P7dltLWL26aVAIT+/apVcjKaValQYFiASFkhI7HR7OAkgL2TH8Kjs2aEKK1tH8zTfwq1/BoEEQCjVdHr78dfNmu35mZmRZdTX4/dC/PzzxxMEejVJKHTANCmCDQnV1k5oCQJoMBcD07l8/L/j9d/hOHk7oyccIBqv4/vtb8Bdstgt37oT332+6j/DwHOGg0LFjZFl1ta0llJU17dRWSqkfkAYFaLb5CMBTkwBAytAf189zbthK3McrcPzyagrf+g3btv2Vgg0NzvB37Gi6j3BNYdMm29HcqRPMmwcjRkSCAujQF0qpVqVBAWxQyM+3bf7QKChQVmavTmp4Zt9A2ZInAEPF9o8iM8PNUA2FawqlpbY2kZAAp59uL4utrrb7Bw0KSqlWpUEBbKHf8Oy+YVAoLYW0NMjIsNN73FMQvwt69vw/3NWRj1KiBYWGQ2ps3myDQnjfGhSUUocJDQrQ+JJQt7tpTSE9Hdq3t9OdO9vX+HikWzeyfRPo3v1mUkIDEAP+ZKjY2kyfgtsdmQ4P2x2+R0KDglLqMKBBARoHhR49GhfM4ZrCaafBU0/Bqafa+VlZmB498OT7MMZBqvQnmAiBVCc1O79i8+Y7CIUajAReUACjRkWmtaaglDoMaVCAxkGhZ8+mzUfp6RAXB7/4BSTX3a+QlWUDyJYtUFpKvDcFR0Y2nuyhJNZms2XLnWzd8tfIdgoLoVcv6G3veyAhARGhPLAKqW5QU9DhtJVSrUiDAjQOCsccY4e1CAbtdLj5KCwx0b6mp0eCQkYGvPsujvT2ODIySQn2okPgVLoN/iPB99+16QsKoEOHyGioCQlUVa2ipPYzW1PYudPO31tN4c9/tsN7K6VUjGhQgMjZ+YwZ0NU+ea2+cA43H4WFm32SkqB798j84uJIh3RJCTlbT8JZA6Vv3oFUV0NlJb50kKH2vgcCAUpK3ifoAROSyP0J5eUgUYbWEIE//ME2Y0VbrpRSh4AGBYALLoCf/ATuuScSAN6tO8NvrqaQlNT0MtW0NJu2tJTEb+uuQFrxDes/+wkAmysfoKj9WgBqVrxHUdHbhMKPid62zb76/ZHnNjTUsFnpiy8O8ECVUmrvNCiAHZrin/+0hfoJJ9i2/0svhYULbQHdsKYQlpRk7zO48cbGTUp1NYVwwZ22NY3qjfYehtpM2JT5BgCFmasoK/sEZ0p2ZJvhmke0JqQGl7SWPH4Vu3a9svdjuvhimzellNoPGhT21K8fLF9uLxl99FE7r2FNoe5ZziQl2WBw//32rmSI1BS8Xli8GBITce0oY5jzfgAyh/6Cmmw/37zcgZS/vUePHrfTqffMyLYH2XGW9hUUghtXsG3bfXs/js8/t/+UUmo/aFCIJiUFJk+2tQdoXFMIB4XkBqOmhs/wG97kBvDTnwLgeH8BAOmD7HTauMvJyD6Dnj3/RHy7AfXJSzsV2TfRgkLdMBihzFTiiqGy8mtqa3c2fwyFhZHOa6WUaiENCs255JLI+4Y1hXPPta8XXhiZF35ITrimEHbddfZ1/nxwu0nqMZ4hQ96he/dbI2nCTU/ArsylAKz76kIWLUpkw4brKC//ikCgor6mUDPABgWA3bsbPP56/nw7UivYAffCN8Qdqk7p776DOXMOzbaUUoctDQrNmTIl8j4lJfJ+6FBb0IavIoLmawpDhtggUVZmB8BzOGjf/ixcrgbba3A5bPsT/wCAlJWSmXk2eXkP8fXXY1m2bDT+HesBKMupwrPbEB/Xi9zcWRQX/5eKwiXI+efDeefZPpDwOEs+X/RxmA7E/ffbZ0nrlU/qUMvLa/p0wyNJKGSHrjlKaFBojsNh+wXGjYPBg/eetmFQCA9fMXAgGBPpJwgPj7GnBjWFzEGXAdAv+24GD36NIUPeoV+/x/H5drF7zT8IpSVTmVmCCQpDk/+Oe0s5q76ZxJbHj8OUl0NuLjz5JPkr741s/1A1IW3fbvtKwgFHqWh8Pvs3M3fuvtOCPckYOxb++MfY5iuWXn0V+vaFDRtaOyeHhAaFvRk3zgaGPQbBa2LYMBsQBg+2/+Li4MEH7bKBA+1rC4ICqakAOCrtJant259F586/ZMiQNzEFpXhTq/BnxQGQNOxsRl9Uzo+u60nPtzLwpxtkyBCC/3qNgtWPRLaZn2/7KOr6Kdavv5a1a6+ILP/972Fmg87usGCQkLea4IbvYMECezYH9ma9QyU3Fy67LPpDi/ZHtIcaqdaxbp298u6DD1qWPjfXDka5fv3B7TcvL/Lb/N3v4JRTWv67qKqy+dib/Hz7KF2wf0vhS9YBPv3U3uz63//ud7YPRxoUDoXu3e1NbsOG2eEvamthwgS7bD9qCvXNVGVl9u7lr76CYJCMjFNI9w/EnwHJ/SZF0l94Ic78UpK+KWHrBUJVjuDfsIy4Mmd9Ev83i2xT1/HH46/ayc6dT1K67FlqF7wFr7wCf/kLPPww+HwUFb3N1q332BXPPJPAgE6UXnsccu65tqYAjR4ClJf3OF980Q+RAyyUn30Wnn8eliw5sPXBnpEmJcFHH+07bVuydSv85jeR4eB/KKtX29eNG1uW/uuv7Wu0Z5DsjyuvhPPPt+/vvdeeyDz1VPS0O3dG9gtwxx0wevTem0bvucc2n27YYE+kzj47UjNYtsy+zpt3cMdwuBCRI+rfqFGj5Ijy3/+KgMif/xx9eUGBXQ4ioZBIx44iY8fa6XHjRHr1EvnJT0TS0iT447MkuHl9JP2aNSJVVeItWCcLFiC5P0WCLmT37ydF0oAEnfa15HeTZMECpHQwjZYLiH/RB7JgAbJgAVL+34fq53vb75H2/vvrs/7tt+fJggVIVdX6A/tsxoyx23zwwQNbf9cuEYfDbuPWWw9sGy1RXi7i9cZu+7Fwzz32c/nmmx92v7ffbvc7cGDL0v/+9zZ9x477t5/qapGamsh0To79LXz/feS3mp0t4vM1XTf8mwkG7fSIEXZ6x47m9zd4sE3zv/8rEh9v3z/9tN2+x2O3mZgosnSpyFln2d/M1q0il10m8uijIsOGiWzatH/HeIgBS6UFZazWFGJtxAg7NEbDjumGwjWFESNsH8TkyfDll3bekiX2SW1vvAFlZTi69sTRuUdk3f79ITERT1Y/MjIm4Og9CEcAMnLTkAbDdBdd0Y/CEyHl73NpXzqE1DUQSISK+69m9dxxAOz856X16f1/uaX+vadoj/w2qClUVa0EoLJyecs/j927bQ2hsBCW2qutAssXs3r1BQQC+zlC7BdfRJoIvvtu/9bdH8cfD7/+9f6t8/TTkftcwhYvbr6JYfNm+PjjA8tfNGvXRrZ7IETg7bcjNQ0Re/ZdXd007a5dke8hXFPYtMmu++tf770mGD5jLyiwd/PvzbvvRj6jc86pv+Qbv9/+LkMheOghO+93v7NNPg2becA29YTzummT7eBeaX/HfP999P3u2BE5rjvvtP0mycnwySewZo1tGZg+3X42o0dH8nnvvfDcc3D11bBihf1NgP3tT516+F4y3pLIcTj9O+JqCiIiFRW2FtCct98WKSy07//1L3sW0qOHSFycyLnniixZIvLMMyJ5eTYNiLRv32gToVBQZP58u6xnT5EuXSJnTHl5kv/VfRJMjJPg4AEiIOtntZcFC5CFC+PE2z1RSoYii/6DrF15hfgTkIKTmtYmBKT0lGxZsqSvfPPN/9TXLD7/vIcsWzZOfL5iKS9f2uTwqqrWy9atf5Ng0C9y8cV2W9Om2dd27aRmdDdZsADZtet1qa7eXHc8IamoWC6+dd9I1eRhEvjkQ7ux2bPt8X35pa19gcgZZ9gaVUOlpXv/zFuqrMzuo1MnyX11iuT/56amae64w9agXnxR5KWX7LwePUTS00X8fjtdU2O/k6Qkm7c9TZtmz0DLyxvPLy4WWbasaXqfb+9nniec0KRm12Jer8jnn9v1X37Zzpszx06fckrjM/S1a+3v9Jln7HT//iLG2LR33WVfx46NfBe1tZF1QyH7O/Z4bLoFC+zxRlNRIZKSYmsEhYX2zLxDB7usYe0ARJxO+zl27iwycaLdz9//LnL11faMPZzutddEPvooMv3cc7b2/eSTjff97LN2+ahR9vXXv7Z/lzk5IjNn2nnr19vPJryt3/1OJDVVZMIEkRtusN9Ht262dvLYYzbNPfe0/DvZsEHkD38Q+fbblq+zB1pYU2j1Qn5//x2RQWF/VFaKZGTYaurXX4uUlDRNs2ZNJIg0tGlT5Ec5fLj9I7jiisjycFUdxLfqCyks/JdUVq4S359+KwJS0xGpvedWEZDCp6+QULduIiAhh12nuptLyvsgXy87oT4gLPgIWftrJP9U5Ks3s+Sb+5Cqc8dKaHex7NjxtCz/R5aU93dIbQZSMXFA4z/eY46RwIzLxJ/slAUfIUuW9JUFC5Ciov/Iru0vyao7kIo+TpsHt1Pk8ccj615wgchFF9nC98477bxwgbp1q4QS4iX07DP1h15U9K74fLsjn0VLA8aSJfX7DDfDyZ132mWlpfZfUpL9ztLSRFwukTffjOTz449t2ocfjsz7+99twdowAPTqZZe9+GLj/V9/vS00Kysbz7/lFjt/z9/BkiUi551n8wQi11zT/LF99ZXIhReKfPednQ4GRa67LrIe2N9QIGCbgzp0sPMuvdSuM368yOjRke9j/XpbIB93XORYExPt64cf2rx26WILSRHbvAIikxo0d06dGj2vTz0VSXPllZH3+fkiH3zQ+Hd14ol2ndtvtwHq0ksjy4yxJ15ut8jNN4vcdpud73DY99OnN/4tiYgcf7xInz4in31mP9uKCvsdhrd57bU23Xff2d9k584iCQl22aef2mWzZ9vpjz4SOf98+/5HP4rso6bGFvqFhfbzfuEF25y1ZYvNp8Nh/z32WPPf5z5oUDiSFRdHzjD3h98f+aGedlrT5bm59oeVlhZpT62z+ske4m1vIuuXl4ucc46EEhOkamiGLZgv+7l97dtHvnwGWXkXUt6P+sDhS0Z8qXYbpcNdsug9l1QMjBdfuzgpO6Wz1GYgRWdkSOCXdju7H54h626w65ccg1T2QBa/hHyxeKAUnZkpAhKIQzbckSWBBCTkckgoMUGCV1xm32dlikyeLL45z9k8JCZIaOlXUnPbr2yQO763iIhUbJwnXzyLbFh7nT3Y8nKRfv0kdOutsnz56bJjxz8iH0QwKLuLPxJvea7IvHmRs926YywZhoSSksSXt0FCA/rbWkvDAilcCDb898ILIgMG2D6iceNEBg0S+fnPRYYOjXzf4bQTJzb+zsIF7Lx5djo/3561p6dHti0ism2bPcNteCYcLnBrauyZfzgQBoO2nTtccGVkiKxcGSm4wP5GwLa3v/eeff/KKyJ//GMkTbhtPnzW3rWrPfMP11hBZOFCu/3p0xsX5g8+aLcHkTNnsLWligqRG2+0bfZ1QmPHSmjAgEi+wv8++EDkiSfs+7vvFvnNb2xfU/j3Hq61TJ9ua5fvvmuXhfsR4uNFJk+2Z/0XXWRrOmDTvvyySO/eUh/IG/J6Rf75TxvEA4HGyy65xK4zdGjkM6+qsjWdSy+1n4fbbT+3vDyRe++NBL277468D38/YPsmtm9v+je9HzQotFXhH9Hs2dGXX365/QPZQ0HBW7Jj+d222nvXXXbm11+LvP66yIwZ9o9++3b7A27fvn4/gZxOsv2ucVLxzb+kZkQXCSUkSPlN9kzI2zWhvuAKBn2Sl/e4LFqULF+/P0h8f7lVlnzaRz573TZVVQ5Nk0A8UjK+nay/ri5Q3DRJQhVlUlKyUHZMsvPyT3fLuncn1O9/1/Qc+ewNJOCx00XHuaS6u6u+EA/Me0eCHlvb2PKLZNm4/rdS+b+X16+/8wxk21SXeD99R0J33SWB1HjxJyHBOEckGMTHS8WwFNl2vlO+fMbOKx/oalQ4BRM99jN67bX6eeUndarLR922nnjCFoYgoXCTycyZtoAACY4ZYdNu3mwLpKuuihQM48fb766u9lZfaPTtK8FrrpJgVnrTYJSUZIPWaafZ6TlzbG0yXCBOmGBrFp072xrXwIH2X4PvV5xOW5tISRGpqZGAr0Ly/3y65F2WJWVfvWwL9r/+NZJ+8WIbdDo/NYUAABHZSURBVM45Ryr+8UeprS20Z/8ZGbYQnDEj0gwT3n5ubuN8n3mmfXW5bEf5entxRd6N/SX09lv2eG6+uXFgcrmaFs4iNii2b9+0WepX9sRBunSxgXbCBFsbCOfh2WftdGKiSPfuthmxgVAoJLW1+dH/xh54wG7j0UdFRCQY9MqOHc9IaPplkfzecIN9/elP7Wv493DMMbbTfdQo+3f6l79IYN0qKS1dLMFglE7z/XBYBAXgTGAdsBG4JcpyD/Ba3fIvgJx9bVODwj589JHIokWHdpsFBSIrVkSmN22S0N/+JsHXXmlcowkERHbXNdE89JD9Y7r55ka1kuLiebJoUXJ981N+/ktSVrZEKitXybZr6gpRt0uqf9RTAv6K+vV8X3wooXiPrH68h73S6he2eWTtbYmyefP/b+/Oo6uq7gWOf38ZbgYCBDIhQ2SQKKgUEFvF2lr1aR2WQ5+2dkDt62SrPtHaPmz7Wm2fr9r6bH2rttRWu6T4qtViq9YurXABKQgEISljEhLITAJJyHzH3/vj7FzSQEigQLjw+6yVlTPse+9v333v+d2zzzn7PKL76t7U1vnXx77U+74029vQpiRoYCTaMidNQ8PQwCiXcGagNZ9I1nCqNx8a4SWOvRehtTen6e5PiYY/d6v3HElerJWVT6rfj9Zc7z2mPd9LRm1nJej2B0UbnrpV9za+rtELL9TADR/V5W+ha3+DRpITNOpL1Ir35+uedU8cvPF2f8UvTNFIItp+8ViNJiUcXCYtTaNnn63BhT/Wrqe+o82fmOrFl5asLeehO340QQMLH/N++YJ2XDntQNLKHaXd41I1PNP92l68WDUa1VBov9a/8YBGc3O89/7ZZ2N949G01AOv/ZnPaDjcpRs2XKJ+f4KuXJmhGzdeoYFAvRb9znV99er6qatbpH6/1yUY/MWPvfUiXgKIRr1uqZ69lEjkwOv0JL0rr/Q2jjk5GrnhWo0Kuvr3aEXFwwc+b33fn0NpavL2ovqo2PRN3fLsFA02V2lHx3YvAfd6ruiMGaqgZY9O0nC4/aDHV1f/Qpcv92lnZ9nBr1lb6yV71+VXW/tr73Pz6pe8jf/tt3vrMjIOJImevRbQaFKSt6eiqt3dNfruu1nq96NVVUd5lp4z5EkBSAR2ApMBH1AETO9T5mvAQjd9G/DSQM9rSSH+dXaWa0XFI1pd/bR3gLxHKKT66KNeF8j27Qc/MBjUQGCPlpV9U7s6d+meP9ynXW07D6yvq1OdNk2jjz+uGo3q3sdu0fZ8tPzH52pg9ZuqoMGJWdr2ubm648W56vej6/52jrb80Ttg3XoWWrLlHm1v36x+P7rh7QJv4z8lUZuavAPdlZU/0dLS+7VrxStav/ZR3ffzL2vozSW6Zs3EWKJb4U9T/zJ01apcrax8UkvvRsvvJLa+bQoaTkWDI7yNQccE7zRhvx/dd12eKmjbZDSU5q2vu8rb69mz+jHdtu1OXb48SdesmahrFotW3IGufmOY+v3ou++O1lWr8rS17m9a8/PrtOwulwA/fZ4WPZUeS4Cdi57Qtra/a3n597So6OPq96PrV5ytZQvn6PJlyVr/ydGqoDXXofWXo1FB25c8qTU1z8QS+a5dP1S/Hy0qulb9y9BtD4q27HhVVVUbGpbo8uU+LSycoytXjtANf3Ib+uuvP9BWFRXeslmzvPnLLtPotx7S+o1PaNFvx+m2zXdo7dIFGjxnrCpo00x09ep8XbEi3dv7UNXoF/9N2+aO0Yp56K6vZWokEtJoNKIlJffp1q3zvBMbVLW9favu2fOydnaWaTC4T0OhltgPk1WrcnXFilTtfO/1AxvniRNV8U7HXv5XtKrqp6qq2tVVqU1Ny7S7u0bXr79A/X60tPTrA37ei4tvdCd1pOj+lve0ra1Yo9Go6lVXea+Xl+ftMT39tEZGZej2B9DaWq/rbOfOb6nfL+r3oxs3fmwwX69+DTYpiFf22BORi4GHVfVqN/+QO9vph73KvOXKrBGRJKAeyNHDBDVnzhwtdKcyGjOQ7u5KfL6xJCQkwcqV3hXnWVl0dpaybt3ZjBt3L1OnPkX3H59Bzp9FypQLASgru5/W1rVkV+STN/PrseX9CQb3Eom00tT0Np2d2/H5csnKuoGMjPOoqvopoVAj4XAzgUA1vtWlJNTvZfSaCBmFzdS/930SfMNQwuRn34NWVdE9IZnwV+eR/vomune9R9m2e2nu8k7HFElGNcS0aYspK7ufUKiRgoJfMnLkpRQXX00o1IRqiLG+W0l7ZRU7r9lNcvo4zpvyIqX+GwjkpxAMNgDeqZl5ebfT2roWkQQyMy8jddE75D9ayp4FHyLpwYfZufVeAtSTmDgCn28MF1xQSDjcTGHhBwgEqsnOvon29iISEtLIyJhFQ8MLjBhxMeef/wZdXeUUF19N9utNdMwcRc4lC+js3EYk0kHOhuEEJ2XSntNEcnIeTU1/pqNjM6mpE+nu3uW9sVEYsSOR8BnDmX7luxQWziAr63rGj3+AqqonaGr6M9nZN7N376uMHz+ftraN7N/vvU+5ubeRk/NJSkq+QijU6N67FIYNO5f29vdJTs4mFPLOuU5ISCOpoYuURuG8v1xEyutr2DP/PGpvH01n51aGDTuflha/a+1EIEJiYgaqYdLSzmLYsBmMHHkJY8Z8nsbGlykru4/c3E8zatSVbNs2j9Gjr6GtrZBAwLvqOifnU0z6vxTS/3sR+uADdM3/NJ0ptWwp/lc0IUxaWgEFBQvZsuVWMjMvJT39HKqqnmDu3EaSk3sNunkERGSDqs4ZsNxxTAq3AB9X1S+6+XnAh1T1nl5lNrsy1W5+pyvT9+z4GEsK5lhpaVlJevp0fL7sE/q60WiQSKSTyL5KgvsqGHHujYcu2N3t3eZ13DhUI+ze/V/s37+GKVOeoK1tPWPG3Ell5WPs3v0DLrpoFz5fLoFADaWl99LSspI5czbQ3b2L0tJ/Z9q0RWRkfIDGxiVs2/ZZzjjjS0yY8A0CgRpGjPgQInLgdTduhNmzYelSuPxyAoFatm+/k+bmdzj33D+Qk3MzAKFQM3V1z5CXdzttbevYvPkmRFLIz/8G+fkPkZiY7sq10Nj4Eg0NL9PSshSRJFJSxsc2/D7fGILBBlJTJzFlyo/Izr6JsrL7SUkZS2rqZMrLFzB69DUUFPyM8vJvUVX1JKreUDAFBQsZM+YLrF07mUCgitTUSYwffx+h0F4qKx9DNUxS0igKCp4hEmmjtXUNbW2FZGVdR2bmx2huXkZb23qam9/m7LN/TWXl42T/ppQzF0P3lnchawQlJXcRCFQzduxdDB9+IXV1v6K5+R2mT/891dU/BbxrdYLBGpKSsgiHW0hLm0R3925UvWsvzj//L6SnF7B79w9ITBxBTc3PGL41ygV3Q9Hj0PxB763PyJjF2LFfoaTkLgCSk3OYMeMtotFuNm6cy7RpvyMvr9cIzUfglEoKIvJl4MsA+fn5F+w+luPvGBPHVKOEQo34fHl9lus/buj7PEZkgOtWd+zwbjjV6zmi0QAJCSn9PKeyd+8SMjJmkZY2+ZBlotEQu3c/SmbmpYwadQWhUBMJCakkJqYTDreRkJDm7dENIBLpoL5+ET7fmFiCam1dF9tr6albMLiXrq4dpKVNxefL7ff5AoE6OjqKGT36arq6ymmoXcxImUHm5Jv6fUw0Gj4o1uZmP/X1z5GcnM3EiY8gkkx7exHBYC3Z2Tf/Q3sEg3vp7NxOcPNKOscFSUmdQCTSQV7eZ0lKyqS2diHJyblkZV1HYmI6qhFKSr7KmDF3MnLk3AHfo0M5GZKCdR8ZY8xJYrBJ4XgOc7EemCoik0TEh3cg+bU+ZV4D7nDTtwDLDpcQjDHGHF8D76sdJVUNi8g9wFt4R2aeU9UtIvJ9vKPgrwHPAr8VkTKgCS9xGGOMGSLHLSkAqOqbwJt9ln2313Q3cOvxjMEYY8zg2SipxhhjYiwpGGOMibGkYIwxJsaSgjHGmBhLCsYYY2KO28Vrx4uINAJHe0lzNtDvEBpx5lSpy6lSD7C6nIxOlXrAP1+XM1U1Z6BCcZcU/hkiUjiYK/riwalSl1OlHmB1ORmdKvWAE1cX6z4yxhgTY0nBGGNMzOmWFJ4Z6gCOoVOlLqdKPcDqcjI6VeoBJ6gup9UxBWOMMYd3uu0pGGOMOYzTJimIyMdFZIeIlInIgqGO50iIyC4R+buIbBKRQrdstIj8VURK3f9RQx3noYjIcyLS4G6o1LPskLGL539dGxWLyOyhi/xg/dTlYRGpcW2zSUSu7bXuIVeXHSJy9dBEfTARmSAifhHZKiJbROQ+tzyu2uUw9YjHNkkVkXUiUuTq8ohbPklE1rqYX3K3IUBEUtx8mVs/8ZgFM5gbOcf7H97Q3TuByYAPKAKmD3VcRxD/LiC7z7IfAQvc9ALg8aGOs5/YPwLMBjYPFDtwLfAXQICLgLVDHf8g6vIw8OAhyk53n7MUYJL7/CUOdR1cbGcAs930cKDExRtX7XKYesRjmwiQ4aaTgbXuvf49cJtbvhD4qpv+GrDQTd8GvHSsYjld9hQ+CJSparmqBoEXgX5ujBs3bgSed9PPA/3fO3AIqepKvHtl9NZf7DcCi9TzHpApImecmEgH1k9d+nMj8KKqBlS1AijD+xwOOVWtU9X33XQbsA0YR5y1y2Hq0Z+TuU1UVdvdbLL7U+By4BW3vG+b9LTVK8AV0t/9V4/Q6ZIUxgFVvearOfyH52SjwNsissHdrxogT1Xr3HQ9kHfoh56U+os9XtvpHtet8lyvbry4qIvrdpiF98s0btulTz0gDttERBJFZBPQAPwVb0+mRVXDrkjveGN1cev3A1nHIo7TJSnEuw+r6mzgGuBuEflI75Xq7UPG5Wlk8Ry78wtgCjATqAP+Z2jDGTwRyQD+AMxX1dbe6+KpXQ5Rj7hsE1WNqOpMYDzeHsw5QxHH6ZIUaoAJvebHu2VxQVVr3P8G4FW8D8yenl14979h6CI8Yv3FHnftpKp73Jc5CvyKA90RJ3VdRCQZb0P6gqoucYvjrl0OVY94bZMeqtoC+IGL8brqeu6Q2TveWF3c+pHAvmPx+qdLUlgPTHVH8n14B2ZeG+KYBkVEhonI8J5p4CpgM178d7hidwB/GpoIj0p/sb8G3O7OdrkI2N+rO+Ok1Kdv/Wa8tgGvLre5s0QmAVOBdSc6vkNxfc/PAttU9cleq+KqXfqrR5y2SY6IZLrpNOBf8I6R+IFbXLG+bdLTVrcAy9ze3T9vqI+6n6g/vDMoSvD66b491PEcQdyT8c6YKAK29MSO13+4FCgF3gFGD3Ws/cT/O7xd+BBen+gX+osd7wyMp10b/R2YM9TxD6Iuv3WxFrsv6hm9yn/b1WUHcM1Qx98rrg/jdQ0VA5vc37Xx1i6HqUc8tskMYKOLeTPwXbd8Ml7iKgNeBlLc8lQ3X+bWTz5WsdgVzcYYY2JOl+4jY4wxg2BJwRhjTIwlBWOMMTGWFIwxxsRYUjDGGBNjScGYE0hELhORN4Y6DmP6Y0nBGGNMjCUFYw5BRD7nxrffJCK/dIOVtYvIT9x490tFJMeVnSki77kB2F7tdR+Cs0TkHTdG/vsiMsU9fYaIvCIi20XkhWM1uqUxx4IlBWP6EJFpwKeAS9QboCwCfBYYBhSq6rnACuB77iGLgP9Q1Rl4V9L2LH8BeFpVPwDMxbsaGrzRPOfjje8/GbjkuFfKmEFKGriIMaedK4ALgPXuR3wa3uBwUeAlV2YxsERERgKZqrrCLX8eeNmNVzVOVV8FUNVuAPd861S12s1vAiYCq45/tYwZmCUFYw4mwPOq+tA/LBT5zz7ljnaMmECv6Qj2PTQnEes+MuZgS4FbRCQXYvcuPhPv+9IzYuVngFWquh9oFpFL3fJ5wAr17gRWLSI3uedIEZH0E1oLY46C/UIxpg9V3Soi38G7210C3qiodwMdwAfduga84w7gDWG80G30y4HPu+XzgF+KyPfdc9x6AqthzFGxUVKNGSQRaVfVjKGOw5jjybqPjDHGxNiegjHGmBjbUzDGGBNjScEYY0yMJQVjjDExlhSMMcbEWFIwxhgTY0nBGGNMzP8DcYzHWlwrhxQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3183/3183 [==============================] - 3s 965us/sample - loss: 10.5307 - acc: 0.3384\n",
      "Loss: 10.530664003067498 Accuracy: 0.33836004\n",
      "\n",
      "Epoch 1/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.8620 - acc: 0.5051WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 20s 6ms/sample - loss: 0.6398 - acc: 0.9200\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.63982, saving model to model/checkpoint/vis_imagenet_6_class_augmentation_2D_CNN_custom_ch_32_DO_075_DO_7_conv_checkpoint/001-0.6398.hdf5\n",
      "81/81 [==============================] - 26s 324ms/step - loss: 0.8598 - acc: 0.5047 - val_loss: 0.6398 - val_acc: 0.9200\n",
      "Epoch 2/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.7240 - acc: 0.5446WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 25s 8ms/sample - loss: 0.3961 - acc: 0.9150\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.63982 to 0.39606, saving model to model/checkpoint/vis_imagenet_6_class_augmentation_2D_CNN_custom_ch_32_DO_075_DO_7_conv_checkpoint/002-0.3961.hdf5\n",
      "81/81 [==============================] - 30s 366ms/step - loss: 0.7218 - acc: 0.5472 - val_loss: 0.3961 - val_acc: 0.9150\n",
      "Epoch 3/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.5375 - acc: 0.7346WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.1828 - acc: 0.9425\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.39606 to 0.18280, saving model to model/checkpoint/vis_imagenet_6_class_augmentation_2D_CNN_custom_ch_32_DO_075_DO_7_conv_checkpoint/003-0.1828.hdf5\n",
      "81/81 [==============================] - 25s 315ms/step - loss: 0.5352 - acc: 0.7362 - val_loss: 0.1828 - val_acc: 0.9425\n",
      "Epoch 4/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.4200 - acc: 0.8157WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 20s 6ms/sample - loss: 0.2821 - acc: 0.8809\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.18280\n",
      "81/81 [==============================] - 23s 287ms/step - loss: 0.4147 - acc: 0.8187 - val_loss: 0.2821 - val_acc: 0.8809\n",
      "Epoch 5/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.3075 - acc: 0.8762WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 29s 9ms/sample - loss: 0.1596 - acc: 0.9459\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.18280 to 0.15961, saving model to model/checkpoint/vis_imagenet_6_class_augmentation_2D_CNN_custom_ch_32_DO_075_DO_7_conv_checkpoint/005-0.1596.hdf5\n",
      "81/81 [==============================] - 36s 450ms/step - loss: 0.3075 - acc: 0.8762 - val_loss: 0.1596 - val_acc: 0.9459\n",
      "Epoch 6/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.2426 - acc: 0.9087WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.2285 - acc: 0.9200\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.15961\n",
      "81/81 [==============================] - 25s 308ms/step - loss: 0.2406 - acc: 0.9091 - val_loss: 0.2285 - val_acc: 0.9200\n",
      "Epoch 7/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.2256 - acc: 0.9208WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 15s 5ms/sample - loss: 0.1738 - acc: 0.9350\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.15961\n",
      "81/81 [==============================] - 23s 285ms/step - loss: 0.2262 - acc: 0.9209 - val_loss: 0.1738 - val_acc: 0.9350\n",
      "Epoch 8/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.1977 - acc: 0.9236WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 24s 8ms/sample - loss: 0.0605 - acc: 0.9844\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.15961 to 0.06048, saving model to model/checkpoint/vis_imagenet_6_class_augmentation_2D_CNN_custom_ch_32_DO_075_DO_7_conv_checkpoint/008-0.0605.hdf5\n",
      "81/81 [==============================] - 32s 396ms/step - loss: 0.1988 - acc: 0.9230 - val_loss: 0.0605 - val_acc: 0.9844\n",
      "Epoch 9/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.1752 - acc: 0.9340WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0872 - acc: 0.9684\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.06048\n",
      "81/81 [==============================] - 22s 265ms/step - loss: 0.1740 - acc: 0.9348 - val_loss: 0.0872 - val_acc: 0.9684\n",
      "Epoch 10/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.1520 - acc: 0.9465WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.1355 - acc: 0.9525\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.06048\n",
      "81/81 [==============================] - 23s 282ms/step - loss: 0.1491 - acc: 0.9479 - val_loss: 0.1355 - val_acc: 0.9525\n",
      "Epoch 11/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.1530 - acc: 0.9444WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0706 - acc: 0.9722\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.06048\n",
      "81/81 [==============================] - 25s 314ms/step - loss: 0.1527 - acc: 0.9444 - val_loss: 0.0706 - val_acc: 0.9722\n",
      "Epoch 12/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.1842 - acc: 0.9274WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.1002 - acc: 0.9650\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.06048\n",
      "81/81 [==============================] - 22s 276ms/step - loss: 0.1816 - acc: 0.9286 - val_loss: 0.1002 - val_acc: 0.9650\n",
      "Epoch 13/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.1334 - acc: 0.9478WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 25s 8ms/sample - loss: 0.1883 - acc: 0.9200\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.06048\n",
      "81/81 [==============================] - 35s 435ms/step - loss: 0.1337 - acc: 0.9479 - val_loss: 0.1883 - val_acc: 0.9200\n",
      "Epoch 14/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.1429 - acc: 0.9528WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3190/3183 [==============================] - 15s 5ms/sample - loss: 0.2217 - acc: 0.9135\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.06048\n",
      "81/81 [==============================] - 24s 296ms/step - loss: 0.1426 - acc: 0.9528 - val_loss: 0.2217 - val_acc: 0.9135\n",
      "Epoch 15/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/81 [============================>.] - ETA: 0s - loss: 0.1386 - acc: 0.9504WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0878 - acc: 0.9688\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.06048\n",
      "81/81 [==============================] - 23s 286ms/step - loss: 0.1391 - acc: 0.9500 - val_loss: 0.0878 - val_acc: 0.9688\n",
      "Epoch 16/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.1203 - acc: 0.9557WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.1276 - acc: 0.9425\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.06048\n",
      "81/81 [==============================] - 33s 406ms/step - loss: 0.1200 - acc: 0.9556 - val_loss: 0.1276 - val_acc: 0.9425\n",
      "Epoch 17/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.1132 - acc: 0.9582WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0798 - acc: 0.9700\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.06048\n",
      "81/81 [==============================] - 25s 308ms/step - loss: 0.1135 - acc: 0.9581 - val_loss: 0.0798 - val_acc: 0.9700\n",
      "Epoch 18/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.1034 - acc: 0.9609WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 37s 12ms/sample - loss: 0.1266 - acc: 0.9481\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.06048\n",
      "81/81 [==============================] - 41s 503ms/step - loss: 0.1033 - acc: 0.9612 - val_loss: 0.1266 - val_acc: 0.9481\n",
      "Epoch 19/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.1172 - acc: 0.9554WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.1583 - acc: 0.9294\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.06048\n",
      "81/81 [==============================] - 26s 320ms/step - loss: 0.1160 - acc: 0.9556 - val_loss: 0.1583 - val_acc: 0.9294\n",
      "Epoch 20/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.1069 - acc: 0.9650WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0987 - acc: 0.9625\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.06048\n",
      "81/81 [==============================] - 25s 313ms/step - loss: 0.1066 - acc: 0.9652 - val_loss: 0.0987 - val_acc: 0.9625\n",
      "Epoch 21/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.1031 - acc: 0.9642WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0880 - acc: 0.9603\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.06048\n",
      "81/81 [==============================] - 27s 331ms/step - loss: 0.1022 - acc: 0.9646 - val_loss: 0.0880 - val_acc: 0.9603\n",
      "Epoch 22/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.1077 - acc: 0.9585WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0646 - acc: 0.9787\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.06048\n",
      "81/81 [==============================] - 24s 297ms/step - loss: 0.1078 - acc: 0.9584 - val_loss: 0.0646 - val_acc: 0.9787\n",
      "Epoch 23/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0953 - acc: 0.9685WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 24s 7ms/sample - loss: 0.0613 - acc: 0.9725\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.06048\n",
      "81/81 [==============================] - 28s 348ms/step - loss: 0.0958 - acc: 0.9677 - val_loss: 0.0613 - val_acc: 0.9725\n",
      "Epoch 24/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0942 - acc: 0.9659WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0681 - acc: 0.9781\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.06048\n",
      "81/81 [==============================] - 24s 300ms/step - loss: 0.0932 - acc: 0.9665 - val_loss: 0.0681 - val_acc: 0.9781\n",
      "Epoch 25/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.1001 - acc: 0.9651WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0631 - acc: 0.9791\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.06048\n",
      "81/81 [==============================] - 23s 282ms/step - loss: 0.1008 - acc: 0.9649 - val_loss: 0.0631 - val_acc: 0.9791\n",
      "Epoch 26/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0739 - acc: 0.9755WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 26s 8ms/sample - loss: 0.1863 - acc: 0.9350\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.06048\n",
      "81/81 [==============================] - 31s 379ms/step - loss: 0.0735 - acc: 0.9758 - val_loss: 0.1863 - val_acc: 0.9350\n",
      "Epoch 27/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0824 - acc: 0.9726WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 20s 6ms/sample - loss: 0.0623 - acc: 0.9712\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.06048\n",
      "81/81 [==============================] - 26s 320ms/step - loss: 0.0822 - acc: 0.9727 - val_loss: 0.0623 - val_acc: 0.9712\n",
      "Epoch 28/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0674 - acc: 0.9761WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0630 - acc: 0.9825\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.06048\n",
      "81/81 [==============================] - 27s 333ms/step - loss: 0.0670 - acc: 0.9764 - val_loss: 0.0630 - val_acc: 0.9825\n",
      "Epoch 29/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0731 - acc: 0.9758WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 25s 8ms/sample - loss: 0.0577 - acc: 0.9831\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.06048 to 0.05766, saving model to model/checkpoint/vis_imagenet_6_class_augmentation_2D_CNN_custom_ch_32_DO_075_DO_7_conv_checkpoint/029-0.0577.hdf5\n",
      "81/81 [==============================] - 33s 407ms/step - loss: 0.0732 - acc: 0.9755 - val_loss: 0.0577 - val_acc: 0.9831\n",
      "Epoch 30/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.1085 - acc: 0.9637WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.1125 - acc: 0.9503\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.05766\n",
      "81/81 [==============================] - 25s 307ms/step - loss: 0.1086 - acc: 0.9634 - val_loss: 0.1125 - val_acc: 0.9503\n",
      "Epoch 31/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0840 - acc: 0.9733WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 25s 8ms/sample - loss: 0.0799 - acc: 0.9600\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.05766\n",
      "81/81 [==============================] - 47s 580ms/step - loss: 0.0848 - acc: 0.9727 - val_loss: 0.0799 - val_acc: 0.9600\n",
      "Epoch 32/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0695 - acc: 0.9777WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.2255 - acc: 0.9100 53s - loss: 0.2699\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.05766\n",
      "81/81 [==============================] - 24s 300ms/step - loss: 0.0687 - acc: 0.9780 - val_loss: 0.2255 - val_acc: 0.9100\n",
      "Epoch 33/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0878 - acc: 0.9701WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0839 - acc: 0.9500\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.05766\n",
      "81/81 [==============================] - 25s 311ms/step - loss: 0.0884 - acc: 0.9699 - val_loss: 0.0839 - val_acc: 0.9500\n",
      "Epoch 34/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0590 - acc: 0.9821WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 23s 7ms/sample - loss: 0.0841 - acc: 0.9575\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.05766\n",
      "81/81 [==============================] - 32s 397ms/step - loss: 0.0586 - acc: 0.9823 - val_loss: 0.0841 - val_acc: 0.9575\n",
      "Epoch 35/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0582 - acc: 0.9824WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0495 - acc: 0.9816\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.05766 to 0.04954, saving model to model/checkpoint/vis_imagenet_6_class_augmentation_2D_CNN_custom_ch_32_DO_075_DO_7_conv_checkpoint/035-0.0495.hdf5\n",
      "81/81 [==============================] - 26s 316ms/step - loss: 0.0586 - acc: 0.9820 - val_loss: 0.0495 - val_acc: 0.9816\n",
      "Epoch 36/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0837 - acc: 0.9675WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0470 - acc: 0.982516s\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.04954 to 0.04701, saving model to model/checkpoint/vis_imagenet_6_class_augmentation_2D_CNN_custom_ch_32_DO_075_DO_7_conv_checkpoint/036-0.0470.hdf5\n",
      "81/81 [==============================] - 24s 301ms/step - loss: 0.0835 - acc: 0.9677 - val_loss: 0.0470 - val_acc: 0.9825\n",
      "Epoch 37/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0534 - acc: 0.9828WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 24s 7ms/sample - loss: 0.0419 - acc: 0.9800\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.04701 to 0.04190, saving model to model/checkpoint/vis_imagenet_6_class_augmentation_2D_CNN_custom_ch_32_DO_075_DO_7_conv_checkpoint/037-0.0419.hdf5\n",
      "81/81 [==============================] - 29s 352ms/step - loss: 0.0545 - acc: 0.9829 - val_loss: 0.0419 - val_acc: 0.9800\n",
      "Epoch 38/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0610 - acc: 0.9799WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 20s 6ms/sample - loss: 0.0465 - acc: 0.9825\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.04190\n",
      "81/81 [==============================] - 25s 309ms/step - loss: 0.0629 - acc: 0.9789 - val_loss: 0.0465 - val_acc: 0.9825\n",
      "Epoch 39/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0493 - acc: 0.9852WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 22s 7ms/sample - loss: 0.0428 - acc: 0.9875\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.04190\n",
      "81/81 [==============================] - 26s 320ms/step - loss: 0.0491 - acc: 0.9851 - val_loss: 0.0428 - val_acc: 0.9875\n",
      "Epoch 40/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0411 - acc: 0.9870WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 25s 8ms/sample - loss: 0.0763 - acc: 0.9663\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.04190\n",
      "81/81 [==============================] - 30s 372ms/step - loss: 0.0417 - acc: 0.9867 - val_loss: 0.0763 - val_acc: 0.9663\n",
      "Epoch 41/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0441 - acc: 0.9876WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0627 - acc: 0.9800\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.04190\n",
      "81/81 [==============================] - 24s 297ms/step - loss: 0.0435 - acc: 0.9879 - val_loss: 0.0627 - val_acc: 0.9800\n",
      "Epoch 42/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0513 - acc: 0.9837WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0430 - acc: 0.9800\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.04190\n",
      "81/81 [==============================] - 27s 338ms/step - loss: 0.0517 - acc: 0.9836 - val_loss: 0.0430 - val_acc: 0.9800\n",
      "Epoch 43/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0548 - acc: 0.9812WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 27s 8ms/sample - loss: 0.0390 - acc: 0.9875\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.04190 to 0.03903, saving model to model/checkpoint/vis_imagenet_6_class_augmentation_2D_CNN_custom_ch_32_DO_075_DO_7_conv_checkpoint/043-0.0390.hdf5\n",
      "81/81 [==============================] - 32s 394ms/step - loss: 0.0540 - acc: 0.9817 - val_loss: 0.0390 - val_acc: 0.9875\n",
      "Epoch 44/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0421 - acc: 0.9850WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 32s 10ms/sample - loss: 0.0260 - acc: 0.9925\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.03903 to 0.02595, saving model to model/checkpoint/vis_imagenet_6_class_augmentation_2D_CNN_custom_ch_32_DO_075_DO_7_conv_checkpoint/044-0.0260.hdf5\n",
      "81/81 [==============================] - 37s 458ms/step - loss: 0.0418 - acc: 0.9854 - val_loss: 0.0260 - val_acc: 0.9925\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0515 - acc: 0.9808WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0507 - acc: 0.9850\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.02595\n",
      "81/81 [==============================] - 24s 297ms/step - loss: 0.0513 - acc: 0.9811 - val_loss: 0.0507 - val_acc: 0.9850\n",
      "Epoch 46/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0466 - acc: 0.9825WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 22s 7ms/sample - loss: 0.0336 - acc: 0.9900\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.02595\n",
      "81/81 [==============================] - 28s 343ms/step - loss: 0.0465 - acc: 0.9826 - val_loss: 0.0336 - val_acc: 0.9900\n",
      "Epoch 47/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0438 - acc: 0.9863WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0691 - acc: 0.9778\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.02595\n",
      "81/81 [==============================] - 24s 295ms/step - loss: 0.0432 - acc: 0.9867 - val_loss: 0.0691 - val_acc: 0.9778\n",
      "Epoch 48/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0395 - acc: 0.9892WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 29s 9ms/sample - loss: 0.1482 - acc: 0.9419\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.02595\n",
      "81/81 [==============================] - 34s 414ms/step - loss: 0.0404 - acc: 0.9888 - val_loss: 0.1482 - val_acc: 0.9419\n",
      "Epoch 49/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0299 - acc: 0.9920WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0614 - acc: 0.9716\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.02595\n",
      "81/81 [==============================] - 25s 307ms/step - loss: 0.0292 - acc: 0.9922 - val_loss: 0.0614 - val_acc: 0.9716\n",
      "Epoch 50/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0344 - acc: 0.9899WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0842 - acc: 0.9681\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.02595\n",
      "81/81 [==============================] - 26s 323ms/step - loss: 0.0347 - acc: 0.9898 - val_loss: 0.0842 - val_acc: 0.9681\n",
      "Epoch 51/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0405 - acc: 0.9882WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 20s 6ms/sample - loss: 0.0299 - acc: 0.9862\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.02595\n",
      "81/81 [==============================] - 25s 303ms/step - loss: 0.0400 - acc: 0.9885 - val_loss: 0.0299 - val_acc: 0.9862\n",
      "Epoch 52/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0458 - acc: 0.9850WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.0492 - acc: 0.9887\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.02595\n",
      "81/81 [==============================] - 24s 297ms/step - loss: 0.0457 - acc: 0.9851 - val_loss: 0.0492 - val_acc: 0.9887\n",
      "Epoch 53/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0505 - acc: 0.9827WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 20s 6ms/sample - loss: 0.0535 - acc: 0.9825\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.02595\n",
      "81/81 [==============================] - 25s 309ms/step - loss: 0.0499 - acc: 0.9829 - val_loss: 0.0535 - val_acc: 0.9825\n",
      "Epoch 54/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0426 - acc: 0.9859WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 21s 6ms/sample - loss: 0.1869 - acc: 0.9309\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.02595\n",
      "81/81 [==============================] - 29s 356ms/step - loss: 0.0421 - acc: 0.9860 - val_loss: 0.1869 - val_acc: 0.9309\n",
      "Epoch 55/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0489 - acc: 0.9841WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0308 - acc: 0.9916\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.02595\n",
      "81/81 [==============================] - 23s 285ms/step - loss: 0.0481 - acc: 0.9845 - val_loss: 0.0308 - val_acc: 0.9916\n",
      "Epoch 56/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0447 - acc: 0.9862WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 27s 8ms/sample - loss: 0.0272 - acc: 0.9916\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.02595\n",
      "81/81 [==============================] - 34s 419ms/step - loss: 0.0446 - acc: 0.9860 - val_loss: 0.0272 - val_acc: 0.9916\n",
      "Epoch 57/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0340 - acc: 0.9887WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.0501 - acc: 0.9875\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.02595\n",
      "81/81 [==============================] - 26s 317ms/step - loss: 0.0339 - acc: 0.9888 - val_loss: 0.0501 - val_acc: 0.9875\n",
      "Epoch 58/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0359 - acc: 0.9876WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0352 - acc: 0.9875\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.02595\n",
      "81/81 [==============================] - 23s 283ms/step - loss: 0.0359 - acc: 0.9873 - val_loss: 0.0352 - val_acc: 0.9875\n",
      "Epoch 59/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0381 - acc: 0.9859WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 21s 7ms/sample - loss: 0.0324 - acc: 0.9866\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.02595\n",
      "81/81 [==============================] - 34s 420ms/step - loss: 0.0400 - acc: 0.9857 - val_loss: 0.0324 - val_acc: 0.9866\n",
      "Epoch 60/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0348 - acc: 0.9896WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0268 - acc: 0.9925s may duplicate \n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.02595\n",
      "81/81 [==============================] - 24s 290ms/step - loss: 0.0344 - acc: 0.9898 - val_loss: 0.0268 - val_acc: 0.9925\n",
      "Epoch 61/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0376 - acc: 0.9884WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 34s 11ms/sample - loss: 0.0301 - acc: 0.9875\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.02595\n",
      "81/81 [==============================] - 39s 488ms/step - loss: 0.0373 - acc: 0.9885 - val_loss: 0.0301 - val_acc: 0.9875\n",
      "Epoch 62/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0315 - acc: 0.9890WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 14s 4ms/sample - loss: 0.0225 - acc: 0.9900\n",
      "\n",
      "Epoch 00062: val_loss improved from 0.02595 to 0.02252, saving model to model/checkpoint/vis_imagenet_6_class_augmentation_2D_CNN_custom_ch_32_DO_075_DO_7_conv_checkpoint/062-0.0225.hdf5\n",
      "81/81 [==============================] - 24s 300ms/step - loss: 0.0318 - acc: 0.9888 - val_loss: 0.0225 - val_acc: 0.9900\n",
      "Epoch 63/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0228 - acc: 0.9917WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 14s 4ms/sample - loss: 0.0353 - acc: 0.9856\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.02252\n",
      "81/81 [==============================] - 24s 294ms/step - loss: 0.0225 - acc: 0.9919 - val_loss: 0.0353 - val_acc: 0.9856\n",
      "Epoch 64/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0345 - acc: 0.9886WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3190/3183 [==============================] - 20s 6ms/sample - loss: 0.0586 - acc: 0.9768\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.02252\n",
      "81/81 [==============================] - 25s 315ms/step - loss: 0.0340 - acc: 0.9888 - val_loss: 0.0586 - val_acc: 0.9768\n",
      "Epoch 65/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0305 - acc: 0.9893WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0756 - acc: 0.9675\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.02252\n",
      "81/81 [==============================] - 23s 289ms/step - loss: 0.0301 - acc: 0.9894 - val_loss: 0.0756 - val_acc: 0.9675\n",
      "Epoch 66/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0385 - acc: 0.9877WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 24s 7ms/sample - loss: 0.0381 - acc: 0.9825\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.02252\n",
      "81/81 [==============================] - 29s 356ms/step - loss: 0.0392 - acc: 0.9876 - val_loss: 0.0381 - val_acc: 0.9825\n",
      "Epoch 67/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0334 - acc: 0.9884WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 22s 7ms/sample - loss: 0.0263 - acc: 0.9900\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.02252\n",
      "81/81 [==============================] - 29s 363ms/step - loss: 0.0345 - acc: 0.9882 - val_loss: 0.0263 - val_acc: 0.9900\n",
      "Epoch 68/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0220 - acc: 0.9937WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 29s 9ms/sample - loss: 0.0291 - acc: 0.9900\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.02252\n",
      "81/81 [==============================] - 42s 521ms/step - loss: 0.0218 - acc: 0.9938 - val_loss: 0.0291 - val_acc: 0.9900\n",
      "Epoch 69/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0182 - acc: 0.9937WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 24s 7ms/sample - loss: 0.0488 - acc: 0.9900\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.02252\n",
      "81/81 [==============================] - 29s 358ms/step - loss: 0.0184 - acc: 0.9935 - val_loss: 0.0488 - val_acc: 0.9900\n",
      "Epoch 70/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0282 - acc: 0.9917WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0272 - acc: 0.9900\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.02252\n",
      "81/81 [==============================] - 25s 305ms/step - loss: 0.0281 - acc: 0.9916 - val_loss: 0.0272 - val_acc: 0.9900\n",
      "Epoch 71/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0293 - acc: 0.9901WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0354 - acc: 0.9900\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.02252\n",
      "81/81 [==============================] - 25s 304ms/step - loss: 0.0289 - acc: 0.9904 - val_loss: 0.0354 - val_acc: 0.9900\n",
      "Epoch 72/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0361 - acc: 0.9877WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 24s 7ms/sample - loss: 0.0403 - acc: 0.9869\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.02252\n",
      "81/81 [==============================] - 30s 369ms/step - loss: 0.0357 - acc: 0.9879 - val_loss: 0.0403 - val_acc: 0.9869\n",
      "Epoch 73/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0239 - acc: 0.9917WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 14s 4ms/sample - loss: 0.0443 - acc: 0.9850\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.02252\n",
      "81/81 [==============================] - 22s 277ms/step - loss: 0.0240 - acc: 0.9913 - val_loss: 0.0443 - val_acc: 0.9850\n",
      "Epoch 74/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0236 - acc: 0.9930WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 25s 8ms/sample - loss: 0.0602 - acc: 0.9875\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.02252\n",
      "81/81 [==============================] - 30s 371ms/step - loss: 0.0242 - acc: 0.9926 - val_loss: 0.0602 - val_acc: 0.9875\n",
      "Epoch 75/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0203 - acc: 0.9943WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0499 - acc: 0.9825\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.02252\n",
      "81/81 [==============================] - 24s 292ms/step - loss: 0.0204 - acc: 0.9941 - val_loss: 0.0499 - val_acc: 0.9825\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0352 - acc: 0.9885WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0499 - acc: 0.9806\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.02252\n",
      "81/81 [==============================] - 24s 297ms/step - loss: 0.0344 - acc: 0.9888 - val_loss: 0.0499 - val_acc: 0.9806\n",
      "Epoch 77/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0319 - acc: 0.9901WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 24s 8ms/sample - loss: 0.0273 - acc: 0.9916\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.02252\n",
      "81/81 [==============================] - 35s 432ms/step - loss: 0.0313 - acc: 0.9904 - val_loss: 0.0273 - val_acc: 0.9916\n",
      "Epoch 78/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0154 - acc: 0.9955WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 20s 6ms/sample - loss: 0.0424 - acc: 0.9922\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.02252\n",
      "81/81 [==============================] - 26s 319ms/step - loss: 0.0151 - acc: 0.9957 - val_loss: 0.0424 - val_acc: 0.9922\n",
      "Epoch 79/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0229 - acc: 0.9917WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 26s 8ms/sample - loss: 0.0603 - acc: 0.9750\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.02252\n",
      "81/81 [==============================] - 30s 373ms/step - loss: 0.0254 - acc: 0.9913 - val_loss: 0.0603 - val_acc: 0.9750\n",
      "Epoch 80/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0286 - acc: 0.9903WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 20s 6ms/sample - loss: 0.0407 - acc: 0.9881\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.02252\n",
      "81/81 [==============================] - 25s 306ms/step - loss: 0.0283 - acc: 0.9904 - val_loss: 0.0407 - val_acc: 0.9881\n",
      "Epoch 81/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0215 - acc: 0.9933WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 24s 8ms/sample - loss: 0.0254 - acc: 0.9925\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.02252\n",
      "81/81 [==============================] - 38s 464ms/step - loss: 0.0212 - acc: 0.9935 - val_loss: 0.0254 - val_acc: 0.9925\n",
      "Epoch 82/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0134 - acc: 0.9968WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 24s 7ms/sample - loss: 0.0237 - acc: 0.9925\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.02252\n",
      "81/81 [==============================] - 30s 371ms/step - loss: 0.0131 - acc: 0.9969 - val_loss: 0.0237 - val_acc: 0.9925\n",
      "Epoch 83/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0129 - acc: 0.9955WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 24s 7ms/sample - loss: 0.0525 - acc: 0.9775\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.02252\n",
      "81/81 [==============================] - 28s 351ms/step - loss: 0.0127 - acc: 0.9957 - val_loss: 0.0525 - val_acc: 0.9775\n",
      "Epoch 84/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0205 - acc: 0.9933WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0223 - acc: 0.9925\n",
      "\n",
      "Epoch 00084: val_loss improved from 0.02252 to 0.02231, saving model to model/checkpoint/vis_imagenet_6_class_augmentation_2D_CNN_custom_ch_32_DO_075_DO_7_conv_checkpoint/084-0.0223.hdf5\n",
      "81/81 [==============================] - 24s 296ms/step - loss: 0.0201 - acc: 0.9935 - val_loss: 0.0223 - val_acc: 0.9925\n",
      "Epoch 85/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0158 - acc: 0.9962WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0256 - acc: 0.9881\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.02231\n",
      "81/81 [==============================] - 22s 275ms/step - loss: 0.0157 - acc: 0.9963 - val_loss: 0.0256 - val_acc: 0.9881\n",
      "Epoch 86/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0178 - acc: 0.9953WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 31s 10ms/sample - loss: 0.0339 - acc: 0.9925\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.02231\n",
      "81/81 [==============================] - 38s 473ms/step - loss: 0.0181 - acc: 0.9950 - val_loss: 0.0339 - val_acc: 0.9925\n",
      "Epoch 87/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0281 - acc: 0.9925WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0429 - acc: 0.9947\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.02231\n",
      "81/81 [==============================] - 25s 303ms/step - loss: 0.0278 - acc: 0.9926 - val_loss: 0.0429 - val_acc: 0.9947\n",
      "Epoch 88/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0192 - acc: 0.9936WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 25s 8ms/sample - loss: 0.0390 - acc: 0.9862\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.02231\n",
      "81/81 [==============================] - 36s 442ms/step - loss: 0.0195 - acc: 0.9935 - val_loss: 0.0390 - val_acc: 0.9862\n",
      "Epoch 89/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0172 - acc: 0.9950WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 20s 6ms/sample - loss: 0.0263 - acc: 0.9912\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.02231\n",
      "81/81 [==============================] - 27s 334ms/step - loss: 0.0170 - acc: 0.9950 - val_loss: 0.0263 - val_acc: 0.9912\n",
      "Epoch 90/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0219 - acc: 0.9933WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 27s 9ms/sample - loss: 0.0369 - acc: 0.9881\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.02231\n",
      "81/81 [==============================] - 31s 388ms/step - loss: 0.0215 - acc: 0.9935 - val_loss: 0.0369 - val_acc: 0.9881\n",
      "Epoch 91/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0150 - acc: 0.9956WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3200/3183 [==============================] - 27s 8ms/sample - loss: 0.0461 - acc: 0.9875\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.02231\n",
      "81/81 [==============================] - 34s 421ms/step - loss: 0.0160 - acc: 0.9953 - val_loss: 0.0461 - val_acc: 0.9875\n",
      "Epoch 92/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0330 - acc: 0.9896WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3190/3183 [==============================] - 18s 5ms/sample - loss: 0.0387 - acc: 0.9850\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.02231\n",
      "81/81 [==============================] - 28s 340ms/step - loss: 0.0330 - acc: 0.9894 - val_loss: 0.0387 - val_acc: 0.9850\n",
      "Epoch 93/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0179 - acc: 0.9953WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 38s 12ms/sample - loss: 0.0325 - acc: 0.9894\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.02231\n",
      "81/81 [==============================] - 44s 540ms/step - loss: 0.0177 - acc: 0.9953 - val_loss: 0.0325 - val_acc: 0.9894\n",
      "Epoch 94/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0237 - acc: 0.9909WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 14s 4ms/sample - loss: 0.0478 - acc: 0.9756\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.02231\n",
      "81/81 [==============================] - 25s 315ms/step - loss: 0.0234 - acc: 0.9910 - val_loss: 0.0478 - val_acc: 0.9756\n",
      "Epoch 95/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0202 - acc: 0.9943WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0462 - acc: 0.9900\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.02231\n",
      "81/81 [==============================] - 28s 342ms/step - loss: 0.0203 - acc: 0.9941 - val_loss: 0.0462 - val_acc: 0.9900\n",
      "Epoch 96/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0269 - acc: 0.9903WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 22s 7ms/sample - loss: 0.0723 - acc: 0.9706\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.02231\n",
      "81/81 [==============================] - 26s 327ms/step - loss: 0.0266 - acc: 0.9904 - val_loss: 0.0723 - val_acc: 0.9706\n",
      "Epoch 97/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0191 - acc: 0.9936WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 39s 12ms/sample - loss: 0.0327 - acc: 0.9900\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.02231\n",
      "81/81 [==============================] - 46s 564ms/step - loss: 0.0188 - acc: 0.9938 - val_loss: 0.0327 - val_acc: 0.9900\n",
      "Epoch 98/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0186 - acc: 0.9931WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0195 - acc: 0.9950\n",
      "\n",
      "Epoch 00098: val_loss improved from 0.02231 to 0.01947, saving model to model/checkpoint/vis_imagenet_6_class_augmentation_2D_CNN_custom_ch_32_DO_075_DO_7_conv_checkpoint/098-0.0195.hdf5\n",
      "81/81 [==============================] - 26s 322ms/step - loss: 0.0184 - acc: 0.9932 - val_loss: 0.0195 - val_acc: 0.9950\n",
      "Epoch 99/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0120 - acc: 0.9959WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 26s 8ms/sample - loss: 0.0374 - acc: 0.9919\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.01947\n",
      "81/81 [==============================] - 31s 382ms/step - loss: 0.0120 - acc: 0.9960 - val_loss: 0.0374 - val_acc: 0.9919\n",
      "Epoch 100/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0352 - acc: 0.9877WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 20s 6ms/sample - loss: 0.0211 - acc: 0.9900\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.01947\n",
      "81/81 [==============================] - 25s 314ms/step - loss: 0.0348 - acc: 0.9879 - val_loss: 0.0211 - val_acc: 0.9900\n",
      "Epoch 101/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0119 - acc: 0.9972WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 13s 4ms/sample - loss: 0.0314 - acc: 0.9925\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 0.01947\n",
      "81/81 [==============================] - 24s 292ms/step - loss: 0.0145 - acc: 0.9969 - val_loss: 0.0314 - val_acc: 0.9925\n",
      "Epoch 102/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0255 - acc: 0.9917- ETA: 1s - loss: WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 40s 13ms/sample - loss: 0.0364 - acc: 0.9850\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 0.01947\n",
      "81/81 [==============================] - 46s 565ms/step - loss: 0.0260 - acc: 0.9916 - val_loss: 0.0364 - val_acc: 0.9850\n",
      "Epoch 103/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0220 - acc: 0.9930WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3190/3183 [==============================] - 19s 6ms/sample - loss: 0.0247 - acc: 0.9950\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 0.01947\n",
      "81/81 [==============================] - 26s 315ms/step - loss: 0.0214 - acc: 0.9932 - val_loss: 0.0247 - val_acc: 0.9950\n",
      "Epoch 104/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0131 - acc: 0.9947WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 28s 9ms/sample - loss: 0.0181 - acc: 0.9950\n",
      "\n",
      "Epoch 00104: val_loss improved from 0.01947 to 0.01807, saving model to model/checkpoint/vis_imagenet_6_class_augmentation_2D_CNN_custom_ch_32_DO_075_DO_7_conv_checkpoint/104-0.0181.hdf5\n",
      "81/81 [==============================] - 35s 431ms/step - loss: 0.0130 - acc: 0.9947 - val_loss: 0.0181 - val_acc: 0.9950\n",
      "Epoch 105/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0171 - acc: 0.9946WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0227 - acc: 0.9894\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 0.01807\n",
      "81/81 [==============================] - 23s 289ms/step - loss: 0.0170 - acc: 0.9944 - val_loss: 0.0227 - val_acc: 0.9894\n",
      "Epoch 106/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0075 - acc: 0.9978WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0694 - acc: 0.989410s - loss: 0\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 0.01807\n",
      "81/81 [==============================] - 24s 301ms/step - loss: 0.0074 - acc: 0.9978 - val_loss: 0.0694 - val_acc: 0.9894\n",
      "Epoch 107/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0233 - acc: 0.9933WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.0411 - acc: 0.9844\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 0.01807\n",
      "81/81 [==============================] - 26s 323ms/step - loss: 0.0229 - acc: 0.9935 - val_loss: 0.0411 - val_acc: 0.9844\n",
      "Epoch 108/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0171 - acc: 0.9937WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 21s 7ms/sample - loss: 0.0564 - acc: 0.9794\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 0.01807\n",
      "81/81 [==============================] - 43s 536ms/step - loss: 0.0173 - acc: 0.9935 - val_loss: 0.0564 - val_acc: 0.9794\n",
      "Epoch 109/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0191 - acc: 0.9927WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 28s 9ms/sample - loss: 0.0239 - acc: 0.9900\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 0.01807\n",
      "81/81 [==============================] - 34s 414ms/step - loss: 0.0187 - acc: 0.9929 - val_loss: 0.0239 - val_acc: 0.9900\n",
      "Epoch 110/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0201 - acc: 0.9933WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0220 - acc: 0.9916\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 0.01807\n",
      "81/81 [==============================] - 24s 301ms/step - loss: 0.0196 - acc: 0.9935 - val_loss: 0.0220 - val_acc: 0.9916\n",
      "Epoch 111/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0064 - acc: 0.9975WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0286 - acc: 0.9900\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 0.01807\n",
      "81/81 [==============================] - 24s 302ms/step - loss: 0.0063 - acc: 0.9975 - val_loss: 0.0286 - val_acc: 0.9900\n",
      "Epoch 112/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0199 - acc: 0.9950WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 28s 9ms/sample - loss: 0.0395 - acc: 0.9812\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 0.01807\n",
      "81/81 [==============================] - 32s 399ms/step - loss: 0.0208 - acc: 0.9947 - val_loss: 0.0395 - val_acc: 0.9812\n",
      "Epoch 113/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0105 - acc: 0.9968WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0344 - acc: 0.9912\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 0.01807\n",
      "81/81 [==============================] - 25s 312ms/step - loss: 0.0102 - acc: 0.9969 - val_loss: 0.0344 - val_acc: 0.9912\n",
      "Epoch 114/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0092 - acc: 0.9968WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 20s 6ms/sample - loss: 0.0076 - acc: 0.9969\n",
      "\n",
      "Epoch 00114: val_loss improved from 0.01807 to 0.00763, saving model to model/checkpoint/vis_imagenet_6_class_augmentation_2D_CNN_custom_ch_32_DO_075_DO_7_conv_checkpoint/114-0.0076.hdf5\n",
      "81/81 [==============================] - 24s 300ms/step - loss: 0.0091 - acc: 0.9969 - val_loss: 0.0076 - val_acc: 0.9969\n",
      "Epoch 115/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0113 - acc: 0.9968- WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 24s 7ms/sample - loss: 0.0267 - acc: 0.9922\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 0.00763\n",
      "81/81 [==============================] - 29s 362ms/step - loss: 0.0113 - acc: 0.9969 - val_loss: 0.0267 - val_acc: 0.9922\n",
      "Epoch 116/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0172 - acc: 0.9940WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 22s 7ms/sample - loss: 0.0337 - acc: 0.99190s - loss: 0.0337 - acc: 0.992\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 0.00763\n",
      "81/81 [==============================] - 26s 323ms/step - loss: 0.0169 - acc: 0.9941 - val_loss: 0.0337 - val_acc: 0.9919\n",
      "Epoch 117/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0087 - acc: 0.9972WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 21s 7ms/sample - loss: 0.0209 - acc: 0.9950\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 0.00763\n",
      "81/81 [==============================] - 34s 417ms/step - loss: 0.0086 - acc: 0.9972 - val_loss: 0.0209 - val_acc: 0.9950\n",
      "Epoch 118/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0194 - acc: 0.9950WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0276 - acc: 0.9900\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 0.00763\n",
      "81/81 [==============================] - 25s 309ms/step - loss: 0.0197 - acc: 0.9947 - val_loss: 0.0276 - val_acc: 0.9900\n",
      "Epoch 119/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0173 - acc: 0.9943WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0293 - acc: 0.9919\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 0.00763\n",
      "81/81 [==============================] - 23s 285ms/step - loss: 0.0172 - acc: 0.9944 - val_loss: 0.0293 - val_acc: 0.9919\n",
      "Epoch 120/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0048 - acc: 0.9987WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 31s 10ms/sample - loss: 0.0150 - acc: 0.9919\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 0.00763\n",
      "81/81 [==============================] - 35s 431ms/step - loss: 0.0047 - acc: 0.9988 - val_loss: 0.0150 - val_acc: 0.9919\n",
      "Epoch 121/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0058 - acc: 0.9984WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0155 - acc: 0.9909\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 0.00763\n",
      "81/81 [==============================] - 24s 301ms/step - loss: 0.0058 - acc: 0.9984 - val_loss: 0.0155 - val_acc: 0.9909\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 122/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0130 - acc: 0.9965WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 41s 13ms/sample - loss: 0.0189 - acc: 0.9975\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 0.00763\n",
      "81/81 [==============================] - 45s 558ms/step - loss: 0.0127 - acc: 0.9966 - val_loss: 0.0189 - val_acc: 0.9975\n",
      "Epoch 123/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0068 - acc: 0.9987WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0393 - acc: 0.9925\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 0.00763\n",
      "81/81 [==============================] - 25s 307ms/step - loss: 0.0068 - acc: 0.9988 - val_loss: 0.0393 - val_acc: 0.9925\n",
      "Epoch 124/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0122 - acc: 0.9950WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 20s 6ms/sample - loss: 0.0317 - acc: 0.9950\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 0.00763\n",
      "81/81 [==============================] - 24s 293ms/step - loss: 0.0121 - acc: 0.9950 - val_loss: 0.0317 - val_acc: 0.9950\n",
      "Epoch 125/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0202 - acc: 0.9925WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 24s 7ms/sample - loss: 0.0278 - acc: 0.9975\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 0.00763\n",
      "81/81 [==============================] - 32s 399ms/step - loss: 0.0200 - acc: 0.9926 - val_loss: 0.0278 - val_acc: 0.9975\n",
      "Epoch 126/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0131 - acc: 0.9965WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.0556 - acc: 0.9844\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 0.00763\n",
      "81/81 [==============================] - 22s 274ms/step - loss: 0.0129 - acc: 0.9966 - val_loss: 0.0556 - val_acc: 0.9844\n",
      "Epoch 127/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0178 - acc: 0.9953WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 25s 8ms/sample - loss: 0.0212 - acc: 0.9944\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 0.00763\n",
      "81/81 [==============================] - 30s 376ms/step - loss: 0.0177 - acc: 0.9953 - val_loss: 0.0212 - val_acc: 0.9944\n",
      "Epoch 128/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0153 - acc: 0.9949WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 21s 7ms/sample - loss: 0.0271 - acc: 0.9891\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 0.00763\n",
      "81/81 [==============================] - 27s 339ms/step - loss: 0.0150 - acc: 0.9950 - val_loss: 0.0271 - val_acc: 0.9891\n",
      "Epoch 129/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0081 - acc: 0.9975WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 20s 6ms/sample - loss: 0.0318 - acc: 0.9841\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 0.00763\n",
      "81/81 [==============================] - 25s 306ms/step - loss: 0.0080 - acc: 0.9975 - val_loss: 0.0318 - val_acc: 0.9841\n",
      "Epoch 130/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0189 - acc: 0.9953WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.0223 - acc: 0.9941\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 0.00763\n",
      "81/81 [==============================] - 26s 324ms/step - loss: 0.0187 - acc: 0.9953 - val_loss: 0.0223 - val_acc: 0.9941\n",
      "Epoch 131/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0093 - acc: 0.9975WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 23s 7ms/sample - loss: 0.0155 - acc: 0.9916\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 0.00763\n",
      "81/81 [==============================] - 27s 338ms/step - loss: 0.0092 - acc: 0.9975 - val_loss: 0.0155 - val_acc: 0.9916\n",
      "Epoch 132/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0149 - acc: 0.9940WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 21s 6ms/sample - loss: 0.0506 - acc: 0.9925\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 0.00763\n",
      "81/81 [==============================] - 30s 375ms/step - loss: 0.0147 - acc: 0.9941 - val_loss: 0.0506 - val_acc: 0.9925\n",
      "Epoch 133/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0091 - acc: 0.9969WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.0210 - acc: 0.9931\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 0.00763\n",
      "81/81 [==============================] - 27s 329ms/step - loss: 0.0090 - acc: 0.9969 - val_loss: 0.0210 - val_acc: 0.9931\n",
      "Epoch 134/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0123 - acc: 0.9962WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0181 - acc: 0.9900\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 0.00763\n",
      "81/81 [==============================] - 26s 315ms/step - loss: 0.0121 - acc: 0.9963 - val_loss: 0.0181 - val_acc: 0.9900\n",
      "Epoch 135/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0182 - acc: 0.9949WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 20s 6ms/sample - loss: 0.0264 - acc: 0.9884\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 0.00763\n",
      "81/81 [==============================] - 26s 322ms/step - loss: 0.0178 - acc: 0.9950 - val_loss: 0.0264 - val_acc: 0.9884\n",
      "Epoch 136/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0078 - acc: 0.9978WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 20s 6ms/sample - loss: 0.0241 - acc: 0.9869\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 0.00763\n",
      "81/81 [==============================] - 30s 373ms/step - loss: 0.0077 - acc: 0.9978 - val_loss: 0.0241 - val_acc: 0.9869\n",
      "Epoch 137/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0192 - acc: 0.9952WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3200/3183 [==============================] - 41s 13ms/sample - loss: 0.0478 - acc: 0.9875\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 0.00763\n",
      "81/81 [==============================] - 48s 589ms/step - loss: 0.0188 - acc: 0.9953 - val_loss: 0.0478 - val_acc: 0.9875\n",
      "Epoch 138/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0140 - acc: 0.9962WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0434 - acc: 0.9800\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 0.00763\n",
      "81/81 [==============================] - 27s 335ms/step - loss: 0.0138 - acc: 0.9963 - val_loss: 0.0434 - val_acc: 0.9800\n",
      "Epoch 139/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0079 - acc: 0.9987WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 21s 6ms/sample - loss: 0.0283 - acc: 0.9972\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 0.00763\n",
      "81/81 [==============================] - 25s 303ms/step - loss: 0.0078 - acc: 0.9988 - val_loss: 0.0283 - val_acc: 0.9972\n",
      "Epoch 140/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0027 - acc: 0.9994WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0467 - acc: 0.9919\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 0.00763\n",
      "81/81 [==============================] - 22s 274ms/step - loss: 0.0030 - acc: 0.9991 - val_loss: 0.0467 - val_acc: 0.9919\n",
      "Epoch 141/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0147 - acc: 0.9950WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 30s 9ms/sample - loss: 0.0318 - acc: 0.9900\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 0.00763\n",
      "81/81 [==============================] - 36s 444ms/step - loss: 0.0151 - acc: 0.9947 - val_loss: 0.0318 - val_acc: 0.9900\n",
      "Epoch 142/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0133 - acc: 0.9965WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0098 - acc: 0.9969\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 0.00763\n",
      "81/81 [==============================] - 25s 305ms/step - loss: 0.0130 - acc: 0.9966 - val_loss: 0.0098 - val_acc: 0.9969\n",
      "Epoch 143/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0124 - acc: 0.9962WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0270 - acc: 0.9922\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 0.00763\n",
      "81/81 [==============================] - 22s 276ms/step - loss: 0.0121 - acc: 0.9963 - val_loss: 0.0270 - val_acc: 0.9922\n",
      "Epoch 144/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0092 - acc: 0.9984WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 33s 10ms/sample - loss: 0.0189 - acc: 0.9950\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 0.00763\n",
      "81/81 [==============================] - 41s 507ms/step - loss: 0.0091 - acc: 0.9984 - val_loss: 0.0189 - val_acc: 0.9950\n",
      "Epoch 145/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0076 - acc: 0.9981WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 23s 7ms/sample - loss: 0.0383 - acc: 0.9900\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 0.00763\n",
      "81/81 [==============================] - 35s 437ms/step - loss: 0.0078 - acc: 0.9978 - val_loss: 0.0383 - val_acc: 0.9900\n",
      "Epoch 146/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0165 - acc: 0.9940WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 22s 7ms/sample - loss: 0.0180 - acc: 0.9937s may d\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 0.00763\n",
      "81/81 [==============================] - 28s 342ms/step - loss: 0.0163 - acc: 0.9941 - val_loss: 0.0180 - val_acc: 0.9937\n",
      "Epoch 147/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0074 - acc: 0.9981WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.0200 - acc: 0.9925\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 0.00763\n",
      "81/81 [==============================] - 21s 259ms/step - loss: 0.0072 - acc: 0.9981 - val_loss: 0.0200 - val_acc: 0.9925\n",
      "Epoch 148/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0069 - acc: 0.9984WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0257 - acc: 0.9922\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 0.00763\n",
      "81/81 [==============================] - 24s 295ms/step - loss: 0.0068 - acc: 0.9984 - val_loss: 0.0257 - val_acc: 0.9922\n",
      "Epoch 149/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0093 - acc: 0.9978WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 26s 8ms/sample - loss: 0.0280 - acc: 0.9922\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 0.00763\n",
      "81/81 [==============================] - 30s 372ms/step - loss: 0.0096 - acc: 0.9975 - val_loss: 0.0280 - val_acc: 0.9922\n",
      "Epoch 150/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0175 - acc: 0.9952WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 30s 9ms/sample - loss: 0.0165 - acc: 0.9925\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 0.00763\n",
      "81/81 [==============================] - 35s 430ms/step - loss: 0.0171 - acc: 0.9953 - val_loss: 0.0165 - val_acc: 0.9925\n",
      "Epoch 151/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0112 - acc: 0.9968WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0284 - acc: 0.9925\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 0.00763\n",
      "81/81 [==============================] - 26s 316ms/step - loss: 0.0110 - acc: 0.9969 - val_loss: 0.0284 - val_acc: 0.9925\n",
      "Epoch 152/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0620 - acc: 0.9796WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0264 - acc: 0.9922\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 0.00763\n",
      "81/81 [==============================] - 24s 301ms/step - loss: 0.0616 - acc: 0.9798 - val_loss: 0.0264 - val_acc: 0.9922\n",
      "Epoch 153/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/81 [============================>.] - ETA: 0s - loss: 0.0129 - acc: 0.9959WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0329 - acc: 0.9925\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 0.00763\n",
      "81/81 [==============================] - 24s 299ms/step - loss: 0.0127 - acc: 0.9960 - val_loss: 0.0329 - val_acc: 0.9925\n",
      "Epoch 154/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0151 - acc: 0.9952WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 20s 6ms/sample - loss: 0.0256 - acc: 0.9925\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 0.00763\n",
      "81/81 [==============================] - 28s 341ms/step - loss: 0.0147 - acc: 0.9953 - val_loss: 0.0256 - val_acc: 0.9925\n",
      "Epoch 155/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0027 - acc: 0.9994WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0381 - acc: 0.9925\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 0.00763\n",
      "81/81 [==============================] - 27s 334ms/step - loss: 0.0027 - acc: 0.9994 - val_loss: 0.0381 - val_acc: 0.9925\n",
      "Epoch 156/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0108 - acc: 0.9975WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 5ms/sample - loss: 0.0380 - acc: 0.9950\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 0.00763\n",
      "81/81 [==============================] - 24s 300ms/step - loss: 0.0105 - acc: 0.9975 - val_loss: 0.0380 - val_acc: 0.9950\n",
      "Epoch 157/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0067 - acc: 0.9981WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 21s 7ms/sample - loss: 0.0434 - acc: 0.9900\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 0.00763\n",
      "81/81 [==============================] - 25s 311ms/step - loss: 0.0066 - acc: 0.9981 - val_loss: 0.0434 - val_acc: 0.9900\n",
      "Epoch 158/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0201 - acc: 0.9931WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0447 - acc: 0.9925\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 0.00763\n",
      "81/81 [==============================] - 28s 350ms/step - loss: 0.0199 - acc: 0.9932 - val_loss: 0.0447 - val_acc: 0.9925\n",
      "Epoch 159/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0144 - acc: 0.9953WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0140 - acc: 0.9912\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 0.00763\n",
      "81/81 [==============================] - 26s 320ms/step - loss: 0.0142 - acc: 0.9953 - val_loss: 0.0140 - val_acc: 0.9912\n",
      "Epoch 160/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0024 - acc: 0.9997WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 29s 9ms/sample - loss: 0.0231 - acc: 0.9925\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 0.00763\n",
      "81/81 [==============================] - 38s 466ms/step - loss: 0.0025 - acc: 0.9997 - val_loss: 0.0231 - val_acc: 0.9925\n",
      "Epoch 161/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0121 - acc: 0.9968WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 31s 10ms/sample - loss: 0.0343 - acc: 0.9950\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 0.00763\n",
      "81/81 [==============================] - 37s 452ms/step - loss: 0.0119 - acc: 0.9969 - val_loss: 0.0343 - val_acc: 0.9950\n",
      "Epoch 162/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0129 - acc: 0.9952WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0485 - acc: 0.9925\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 0.00763\n",
      "81/81 [==============================] - 27s 335ms/step - loss: 0.0128 - acc: 0.9953 - val_loss: 0.0485 - val_acc: 0.9925\n",
      "Epoch 163/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0143 - acc: 0.9962WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 32s 10ms/sample - loss: 0.0395 - acc: 0.9900\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 0.00763\n",
      "81/81 [==============================] - 37s 458ms/step - loss: 0.0141 - acc: 0.9963 - val_loss: 0.0395 - val_acc: 0.9900\n",
      "Epoch 164/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0144 - acc: 0.9959WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0346 - acc: 0.9900\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 0.00763\n",
      "81/81 [==============================] - 25s 313ms/step - loss: 0.0142 - acc: 0.9960 - val_loss: 0.0346 - val_acc: 0.9900\n",
      "Epoch 165/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0029 - acc: 0.9994WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0526 - acc: 0.9900\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 0.00763\n",
      "81/81 [==============================] - 24s 290ms/step - loss: 0.0029 - acc: 0.9994 - val_loss: 0.0526 - val_acc: 0.9900\n",
      "Epoch 166/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0012 - acc: 0.9997WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0455 - acc: 0.9887\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 0.00763\n",
      "81/81 [==============================] - 23s 289ms/step - loss: 0.0012 - acc: 0.9997 - val_loss: 0.0455 - val_acc: 0.9887\n",
      "Epoch 167/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0048 - acc: 0.9991WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0509 - acc: 0.98871\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 0.00763\n",
      "81/81 [==============================] - 27s 327ms/step - loss: 0.0048 - acc: 0.9991 - val_loss: 0.0509 - val_acc: 0.9887\n",
      "Epoch 168/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0095 - acc: 0.9978WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3200/3183 [==============================] - 31s 10ms/sample - loss: 0.0531 - acc: 0.9950\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 0.00763\n",
      "81/81 [==============================] - 35s 432ms/step - loss: 0.0093 - acc: 0.9978 - val_loss: 0.0531 - val_acc: 0.9950\n",
      "Epoch 169/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0094 - acc: 0.9978WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0456 - acc: 0.9950\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 0.00763\n",
      "81/81 [==============================] - 25s 307ms/step - loss: 0.0094 - acc: 0.9975 - val_loss: 0.0456 - val_acc: 0.9950\n",
      "Epoch 170/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0026 - acc: 0.9997WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 30s 9ms/sample - loss: 0.0538 - acc: 0.9925\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 0.00763\n",
      "81/81 [==============================] - 40s 497ms/step - loss: 0.0026 - acc: 0.9997 - val_loss: 0.0538 - val_acc: 0.9925\n",
      "Epoch 171/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0039 - acc: 0.9978WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0331 - acc: 0.9975\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 0.00763\n",
      "81/81 [==============================] - 28s 343ms/step - loss: 0.0039 - acc: 0.9978 - val_loss: 0.0331 - val_acc: 0.9975\n",
      "Epoch 172/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0216 - acc: 0.9940WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 29s 9ms/sample - loss: 0.0514 - acc: 0.9900\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 0.00763\n",
      "81/81 [==============================] - 34s 419ms/step - loss: 0.0213 - acc: 0.9941 - val_loss: 0.0514 - val_acc: 0.9900\n",
      "Epoch 173/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0104 - acc: 0.9971WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0305 - acc: 0.9950\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 0.00763\n",
      "81/81 [==============================] - 25s 305ms/step - loss: 0.0102 - acc: 0.9972 - val_loss: 0.0305 - val_acc: 0.9950\n",
      "Epoch 174/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0136 - acc: 0.9952WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 20s 6ms/sample - loss: 0.0322 - acc: 0.9894\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 0.00763\n",
      "81/81 [==============================] - 25s 303ms/step - loss: 0.0155 - acc: 0.9947 - val_loss: 0.0322 - val_acc: 0.9894\n",
      "Epoch 175/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0105 - acc: 0.9962WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.0444 - acc: 0.9875\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 0.00763\n",
      "81/81 [==============================] - 23s 285ms/step - loss: 0.0126 - acc: 0.9960 - val_loss: 0.0444 - val_acc: 0.9875\n",
      "Epoch 176/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0068 - acc: 0.9978WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 25s 8ms/sample - loss: 0.0345 - acc: 0.9947\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 0.00763\n",
      "81/81 [==============================] - 39s 482ms/step - loss: 0.0066 - acc: 0.9978 - val_loss: 0.0345 - val_acc: 0.9947\n",
      "Epoch 177/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0083 - acc: 0.9975WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0239 - acc: 0.9975\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 0.00763\n",
      "81/81 [==============================] - 30s 367ms/step - loss: 0.0083 - acc: 0.9975 - val_loss: 0.0239 - val_acc: 0.9975\n",
      "Epoch 178/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0067 - acc: 0.9975WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 29s 9ms/sample - loss: 0.0275 - acc: 0.9975\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 0.00763\n",
      "81/81 [==============================] - 34s 423ms/step - loss: 0.0066 - acc: 0.9975 - val_loss: 0.0275 - val_acc: 0.9975\n",
      "Epoch 179/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0059 - acc: 0.9981WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0544 - acc: 0.9900\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 0.00763\n",
      "81/81 [==============================] - 25s 311ms/step - loss: 0.0059 - acc: 0.9981 - val_loss: 0.0544 - val_acc: 0.9900\n",
      "Epoch 180/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0059 - acc: 0.9987WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 21s 7ms/sample - loss: 0.0387 - acc: 0.9925\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 0.00763\n",
      "81/81 [==============================] - 27s 330ms/step - loss: 0.0058 - acc: 0.9988 - val_loss: 0.0387 - val_acc: 0.9925\n",
      "Epoch 181/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0119 - acc: 0.9952WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0729 - acc: 0.9866\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 0.00763\n",
      "81/81 [==============================] - 22s 272ms/step - loss: 0.0117 - acc: 0.9953 - val_loss: 0.0729 - val_acc: 0.9866\n",
      "Epoch 182/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0118 - acc: 0.9959WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0331 - acc: 0.9925\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 0.00763\n",
      "81/81 [==============================] - 23s 285ms/step - loss: 0.0117 - acc: 0.9960 - val_loss: 0.0331 - val_acc: 0.9925\n",
      "Epoch 183/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0122 - acc: 0.9962WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0784 - acc: 0.9844\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 0.00763\n",
      "81/81 [==============================] - 26s 316ms/step - loss: 0.0120 - acc: 0.9963 - val_loss: 0.0784 - val_acc: 0.9844\n",
      "Epoch 184/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/81 [============================>.] - ETA: 0s - loss: 0.0261 - acc: 0.9928WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 24s 7ms/sample - loss: 0.0234 - acc: 0.9944\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 0.00763\n",
      "81/81 [==============================] - 30s 376ms/step - loss: 0.0259 - acc: 0.9929 - val_loss: 0.0234 - val_acc: 0.9944\n",
      "Epoch 185/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0074 - acc: 0.9984WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0360 - acc: 0.9919\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 0.00763\n",
      "81/81 [==============================] - 26s 315ms/step - loss: 0.0073 - acc: 0.9984 - val_loss: 0.0360 - val_acc: 0.9919\n",
      "Epoch 186/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0020 - acc: 0.9997WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 20s 6ms/sample - loss: 0.0402 - acc: 0.9947\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 0.00763\n",
      "81/81 [==============================] - 24s 299ms/step - loss: 0.0020 - acc: 0.9997 - val_loss: 0.0402 - val_acc: 0.9947\n",
      "Epoch 187/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0013 - acc: 0.9994WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 25s 8ms/sample - loss: 0.0290 - acc: 0.9969\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 0.00763\n",
      "81/81 [==============================] - 34s 418ms/step - loss: 0.0012 - acc: 0.9994 - val_loss: 0.0290 - val_acc: 0.9969\n",
      "Epoch 188/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0087 - acc: 0.9965WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 23s 7ms/sample - loss: 0.0312 - acc: 0.9950\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 0.00763\n",
      "81/81 [==============================] - 31s 385ms/step - loss: 0.0086 - acc: 0.9966 - val_loss: 0.0312 - val_acc: 0.9950\n",
      "Epoch 189/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0063 - acc: 0.9975WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0543 - acc: 0.9875\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 0.00763\n",
      "81/81 [==============================] - 29s 355ms/step - loss: 0.0062 - acc: 0.9975 - val_loss: 0.0543 - val_acc: 0.9875\n",
      "Epoch 190/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0050 - acc: 0.9994WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 28s 9ms/sample - loss: 0.0764 - acc: 0.9875\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 0.00763\n",
      "81/81 [==============================] - 33s 406ms/step - loss: 0.0053 - acc: 0.9991 - val_loss: 0.0764 - val_acc: 0.9875\n",
      "Epoch 191/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0016 - acc: 0.9997WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 20s 6ms/sample - loss: 0.0525 - acc: 0.9912\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 0.00763\n",
      "81/81 [==============================] - 26s 324ms/step - loss: 0.0020 - acc: 0.9994 - val_loss: 0.0525 - val_acc: 0.9912\n",
      "Epoch 192/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0179 - acc: 0.9940WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0324 - acc: 0.9875\n",
      "\n",
      "Epoch 00192: val_loss did not improve from 0.00763\n",
      "81/81 [==============================] - 24s 301ms/step - loss: 0.0177 - acc: 0.9941 - val_loss: 0.0324 - val_acc: 0.9875\n",
      "Epoch 193/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0183 - acc: 0.9943WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0757 - acc: 0.9919\n",
      "\n",
      "Epoch 00193: val_loss did not improve from 0.00763\n",
      "81/81 [==============================] - 23s 285ms/step - loss: 0.0179 - acc: 0.9944 - val_loss: 0.0757 - val_acc: 0.9919\n",
      "Epoch 194/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0061 - acc: 0.9972WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 29s 9ms/sample - loss: 0.0698 - acc: 0.9850\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 0.00763\n",
      "81/81 [==============================] - 33s 404ms/step - loss: 0.0066 - acc: 0.9969 - val_loss: 0.0698 - val_acc: 0.9850\n",
      "Epoch 195/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0134 - acc: 0.9965WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 26s 8ms/sample - loss: 0.0353 - acc: 0.9950\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 0.00763\n",
      "81/81 [==============================] - 31s 383ms/step - loss: 0.0132 - acc: 0.9966 - val_loss: 0.0353 - val_acc: 0.9950\n",
      "Epoch 196/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0116 - acc: 0.9959WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0367 - acc: 0.9925\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 0.00763\n",
      "81/81 [==============================] - 24s 297ms/step - loss: 0.0115 - acc: 0.9960 - val_loss: 0.0367 - val_acc: 0.9925\n",
      "Epoch 197/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0051 - acc: 0.9978WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0314 - acc: 0.9919\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 0.00763\n",
      "81/81 [==============================] - 23s 278ms/step - loss: 0.0050 - acc: 0.9978 - val_loss: 0.0314 - val_acc: 0.9919\n",
      "Epoch 198/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0088 - acc: 0.9971WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0404 - acc: 0.9900\n",
      "\n",
      "Epoch 00198: val_loss did not improve from 0.00763\n",
      "81/81 [==============================] - 23s 285ms/step - loss: 0.0089 - acc: 0.9969 - val_loss: 0.0404 - val_acc: 0.9900\n",
      "Epoch 199/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0032 - acc: 0.9997WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0458 - acc: 0.9947\n",
      "\n",
      "Epoch 00199: val_loss did not improve from 0.00763\n",
      "81/81 [==============================] - 26s 316ms/step - loss: 0.0031 - acc: 0.9997 - val_loss: 0.0458 - val_acc: 0.9947\n",
      "Epoch 200/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0140 - acc: 0.9959WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 34s 11ms/sample - loss: 0.0606 - acc: 0.9875\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 0.00763\n",
      "81/81 [==============================] - 38s 471ms/step - loss: 0.0137 - acc: 0.9960 - val_loss: 0.0606 - val_acc: 0.9875\n",
      "Epoch 201/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0035 - acc: 0.9990WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 26s 8ms/sample - loss: 0.0492 - acc: 0.9925\n",
      "\n",
      "Epoch 00201: val_loss did not improve from 0.00763\n",
      "81/81 [==============================] - 37s 455ms/step - loss: 0.0034 - acc: 0.9991 - val_loss: 0.0492 - val_acc: 0.9925\n",
      "Epoch 202/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 5.2149e-04 - acc: 1.0000WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0508 - acc: 0.9925\n",
      "\n",
      "Epoch 00202: val_loss did not improve from 0.00763\n",
      "81/81 [==============================] - 26s 317ms/step - loss: 5.1287e-04 - acc: 1.0000 - val_loss: 0.0508 - val_acc: 0.9925\n",
      "Epoch 203/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0042 - acc: 0.9984WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 20s 6ms/sample - loss: 0.0704 - acc: 0.9894\n",
      "\n",
      "Epoch 00203: val_loss did not improve from 0.00763\n",
      "81/81 [==============================] - 27s 334ms/step - loss: 0.0041 - acc: 0.9984 - val_loss: 0.0704 - val_acc: 0.9894\n",
      "Epoch 204/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0089 - acc: 0.9975WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.0687 - acc: 0.9875\n",
      "\n",
      "Epoch 00204: val_loss did not improve from 0.00763\n",
      "81/81 [==============================] - 29s 361ms/step - loss: 0.0088 - acc: 0.9975 - val_loss: 0.0687 - val_acc: 0.9875\n",
      "Epoch 205/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0077 - acc: 0.9968WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 20s 6ms/sample - loss: 0.0688 - acc: 0.9925\n",
      "\n",
      "Epoch 00205: val_loss did not improve from 0.00763\n",
      "81/81 [==============================] - 25s 304ms/step - loss: 0.0087 - acc: 0.9966 - val_loss: 0.0688 - val_acc: 0.9925\n",
      "Epoch 206/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0060 - acc: 0.9981WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0549 - acc: 0.9869\n",
      "\n",
      "Epoch 00206: val_loss did not improve from 0.00763\n",
      "81/81 [==============================] - 27s 330ms/step - loss: 0.0061 - acc: 0.9981 - val_loss: 0.0549 - val_acc: 0.9869\n",
      "Epoch 207/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0154 - acc: 0.9962WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 20s 6ms/sample - loss: 0.0543 - acc: 0.9950\n",
      "\n",
      "Epoch 00207: val_loss did not improve from 0.00763\n",
      "81/81 [==============================] - 25s 304ms/step - loss: 0.0150 - acc: 0.9963 - val_loss: 0.0543 - val_acc: 0.9950\n",
      "Epoch 208/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0133 - acc: 0.9972WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0293 - acc: 0.9925\n",
      "\n",
      "Epoch 00208: val_loss did not improve from 0.00763\n",
      "81/81 [==============================] - 23s 278ms/step - loss: 0.0131 - acc: 0.9972 - val_loss: 0.0293 - val_acc: 0.9925\n",
      "Epoch 209/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0145 - acc: 0.9965WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 20s 6ms/sample - loss: 0.0325 - acc: 0.9950\n",
      "\n",
      "Epoch 00209: val_loss did not improve from 0.00763\n",
      "81/81 [==============================] - 24s 300ms/step - loss: 0.0144 - acc: 0.9966 - val_loss: 0.0325 - val_acc: 0.9950\n",
      "Epoch 210/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0155 - acc: 0.9949WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0305 - acc: 0.9950\n",
      "\n",
      "Epoch 00210: val_loss did not improve from 0.00763\n",
      "81/81 [==============================] - 22s 277ms/step - loss: 0.0153 - acc: 0.9950 - val_loss: 0.0305 - val_acc: 0.9950\n",
      "Epoch 211/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0038 - acc: 0.9991WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.0423 - acc: 0.9950\n",
      "\n",
      "Epoch 00211: val_loss did not improve from 0.00763\n",
      "81/81 [==============================] - 24s 295ms/step - loss: 0.0038 - acc: 0.9991 - val_loss: 0.0423 - val_acc: 0.9950\n",
      "Epoch 212/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0038 - acc: 0.9981WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 21s 6ms/sample - loss: 0.0766 - acc: 0.9900\n",
      "\n",
      "Epoch 00212: val_loss did not improve from 0.00763\n",
      "81/81 [==============================] - 32s 398ms/step - loss: 0.0037 - acc: 0.9981 - val_loss: 0.0766 - val_acc: 0.9900\n",
      "Epoch 213/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0049 - acc: 0.9984WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.0595 - acc: 0.9869\n",
      "\n",
      "Epoch 00213: val_loss did not improve from 0.00763\n",
      "81/81 [==============================] - 24s 296ms/step - loss: 0.0049 - acc: 0.9984 - val_loss: 0.0595 - val_acc: 0.9869\n",
      "Epoch 214/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0087 - acc: 0.9965WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0444 - acc: 0.9944\n",
      "\n",
      "Epoch 00214: val_loss did not improve from 0.00763\n",
      "81/81 [==============================] - 23s 286ms/step - loss: 0.0086 - acc: 0.9966 - val_loss: 0.0444 - val_acc: 0.9944\n",
      "\n",
      "vis_imagenet_6_class_augmentation_2D_CNN_custom_ch_32_DO_075_DO_7_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3183/3183 [==============================] - 3s 1ms/sample - loss: 10.0830 - acc: 0.3371\n",
      "Loss: 10.082969008030192 Accuracy: 0.33710337\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(3, 8):\n",
    "    base = 'vis_imagenet_6_class_augmentation_2D_CNN_custom_ch_32_DO_075_DO'\n",
    "    model_name = base+'_{}_conv'.format(i)\n",
    "    \n",
    "#     with tf.device('/cpu:1'):\n",
    "    model = build_2d_cnn_custom_ch_32_DO(conv_num=i)\n",
    "#     model = multi_gpu_model(model, gpus=2)    \n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=1e-4),\n",
    "          metrics=['accuracy'])\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    os.makedirs(model_path, exist_ok=True)\n",
    "    model_filename = model_path+'{epoch:03d}-{val_loss:.4f}.hdf5'\n",
    "    checkpointer = ModelCheckpoint(filepath = model_filename, monitor = \"val_loss\", \n",
    "                                   verbose=1, save_best_only=True)\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=100)\n",
    "    hist = model.fit_generator(data_generator,\n",
    "            steps_per_epoch=len(x_train)//batch_size,\n",
    "            epochs=10000,\n",
    "            validation_data=(x_val, y_val),\n",
    "            callbacks = [checkpointer, early_stopping],\n",
    "            workers=8, \n",
    "            use_multiprocessing=True\n",
    "    )\n",
    "    \n",
    "    print()\n",
    "    print(model_name, 'Model')\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "    ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
    "    ax.plot(hist.history['acc'], 'b', label='train acc')\n",
    "    ax.plot(hist.history['val_acc'], 'g', label='val acc')\n",
    "    ax.set_xlabel('epoch')\n",
    "    ax.set_ylabel('loss')\n",
    "    ax.legend(loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    png_path = 'visualization/learning_curve/'\n",
    "    filename = model_name+'.png'\n",
    "    os.makedirs(png_path, exist_ok=True)\n",
    "    fig.savefig(png_path+filename, transparent=True)\n",
    "\n",
    "    model.save(model_path+'000_last.hdf5')\n",
    "    del(model)\n",
    "\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    model_filename = model_path + sorted(os.listdir(model_path))[-1]\n",
    "    model = load_model(model_filename)\n",
    "    [loss, accuracy] = model.evaluate(x_test, y_test)\n",
    "    print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "    print()\n",
    "\n",
    "    del(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "vis_imagenet_6_class_augmentation_2D_CNN_custom_ch_32_DO_075_DO_3_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_8 (InputLayer)         (None, 172, 172, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_28 (Conv2D)           (None, 172, 172, 32)      2432      \n",
      "_________________________________________________________________\n",
      "activation_28 (Activation)   (None, 172, 172, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_28 (MaxPooling (None, 86, 86, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_29 (Conv2D)           (None, 86, 86, 32)        25632     \n",
      "_________________________________________________________________\n",
      "activation_29 (Activation)   (None, 86, 86, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_29 (MaxPooling (None, 43, 43, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_30 (Conv2D)           (None, 43, 43, 64)        51264     \n",
      "_________________________________________________________________\n",
      "activation_30 (Activation)   (None, 43, 43, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_30 (MaxPooling (None, 22, 22, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 30976)             0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 30976)             0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 6)                 185862    \n",
      "=================================================================\n",
      "Total params: 265,190\n",
      "Trainable params: 265,190\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3183/3183 [==============================] - 3s 996us/sample - loss: 10.6577 - acc: 0.3358\n",
      "Loss: 10.65774965957938 Accuracy: 0.3358467\n",
      "\n",
      "vis_imagenet_6_class_augmentation_2D_CNN_custom_ch_32_DO_075_DO_4_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_9 (InputLayer)         (None, 172, 172, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_31 (Conv2D)           (None, 172, 172, 32)      2432      \n",
      "_________________________________________________________________\n",
      "activation_31 (Activation)   (None, 172, 172, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_31 (MaxPooling (None, 86, 86, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_32 (Conv2D)           (None, 86, 86, 32)        25632     \n",
      "_________________________________________________________________\n",
      "activation_32 (Activation)   (None, 86, 86, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_32 (MaxPooling (None, 43, 43, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_33 (Conv2D)           (None, 43, 43, 64)        51264     \n",
      "_________________________________________________________________\n",
      "activation_33 (Activation)   (None, 43, 43, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_33 (MaxPooling (None, 22, 22, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_34 (Conv2D)           (None, 22, 22, 64)        102464    \n",
      "_________________________________________________________________\n",
      "activation_34 (Activation)   (None, 22, 22, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_34 (MaxPooling (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 7744)              0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 7744)              0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 6)                 46470     \n",
      "=================================================================\n",
      "Total params: 228,262\n",
      "Trainable params: 228,262\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3183/3183 [==============================] - 3s 1ms/sample - loss: 10.6451 - acc: 0.3380\n",
      "Loss: 10.645130489546318 Accuracy: 0.33804587\n",
      "\n",
      "vis_imagenet_6_class_augmentation_2D_CNN_custom_ch_32_DO_075_DO_5_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_10 (InputLayer)        (None, 172, 172, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_35 (Conv2D)           (None, 172, 172, 32)      2432      \n",
      "_________________________________________________________________\n",
      "activation_35 (Activation)   (None, 172, 172, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_35 (MaxPooling (None, 86, 86, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_36 (Conv2D)           (None, 86, 86, 32)        25632     \n",
      "_________________________________________________________________\n",
      "activation_36 (Activation)   (None, 86, 86, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_36 (MaxPooling (None, 43, 43, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_37 (Conv2D)           (None, 43, 43, 64)        51264     \n",
      "_________________________________________________________________\n",
      "activation_37 (Activation)   (None, 43, 43, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_37 (MaxPooling (None, 22, 22, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_38 (Conv2D)           (None, 22, 22, 64)        102464    \n",
      "_________________________________________________________________\n",
      "activation_38 (Activation)   (None, 22, 22, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_38 (MaxPooling (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_39 (Conv2D)           (None, 11, 11, 128)       204928    \n",
      "_________________________________________________________________\n",
      "activation_39 (Activation)   (None, 11, 11, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_39 (MaxPooling (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 6)                 27654     \n",
      "=================================================================\n",
      "Total params: 414,374\n",
      "Trainable params: 414,374\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3183/3183 [==============================] - 3s 1ms/sample - loss: 10.6499 - acc: 0.3374\n",
      "Loss: 10.649943708605003 Accuracy: 0.33741754\n",
      "\n",
      "vis_imagenet_6_class_augmentation_2D_CNN_custom_ch_32_DO_075_DO_6_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_11 (InputLayer)        (None, 172, 172, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_40 (Conv2D)           (None, 172, 172, 32)      2432      \n",
      "_________________________________________________________________\n",
      "activation_40 (Activation)   (None, 172, 172, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_40 (MaxPooling (None, 86, 86, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_41 (Conv2D)           (None, 86, 86, 32)        25632     \n",
      "_________________________________________________________________\n",
      "activation_41 (Activation)   (None, 86, 86, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_41 (MaxPooling (None, 43, 43, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_42 (Conv2D)           (None, 43, 43, 64)        51264     \n",
      "_________________________________________________________________\n",
      "activation_42 (Activation)   (None, 43, 43, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_42 (MaxPooling (None, 22, 22, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_43 (Conv2D)           (None, 22, 22, 64)        102464    \n",
      "_________________________________________________________________\n",
      "activation_43 (Activation)   (None, 22, 22, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_43 (MaxPooling (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_44 (Conv2D)           (None, 11, 11, 128)       204928    \n",
      "_________________________________________________________________\n",
      "activation_44 (Activation)   (None, 11, 11, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_44 (MaxPooling (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_45 (Conv2D)           (None, 6, 6, 128)         409728    \n",
      "_________________________________________________________________\n",
      "activation_45 (Activation)   (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_45 (MaxPooling (None, 3, 3, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 6)                 6918      \n",
      "=================================================================\n",
      "Total params: 803,366\n",
      "Trainable params: 803,366\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3183/3183 [==============================] - 4s 1ms/sample - loss: 10.5307 - acc: 0.3384\n",
      "Loss: 10.530664003067498 Accuracy: 0.33836004\n",
      "\n",
      "vis_imagenet_6_class_augmentation_2D_CNN_custom_ch_32_DO_075_DO_7_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_12 (InputLayer)        (None, 172, 172, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_46 (Conv2D)           (None, 172, 172, 32)      2432      \n",
      "_________________________________________________________________\n",
      "activation_46 (Activation)   (None, 172, 172, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_46 (MaxPooling (None, 86, 86, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_47 (Conv2D)           (None, 86, 86, 32)        25632     \n",
      "_________________________________________________________________\n",
      "activation_47 (Activation)   (None, 86, 86, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_47 (MaxPooling (None, 43, 43, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_48 (Conv2D)           (None, 43, 43, 64)        51264     \n",
      "_________________________________________________________________\n",
      "activation_48 (Activation)   (None, 43, 43, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_48 (MaxPooling (None, 22, 22, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_49 (Conv2D)           (None, 22, 22, 64)        102464    \n",
      "_________________________________________________________________\n",
      "activation_49 (Activation)   (None, 22, 22, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_49 (MaxPooling (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_50 (Conv2D)           (None, 11, 11, 128)       204928    \n",
      "_________________________________________________________________\n",
      "activation_50 (Activation)   (None, 11, 11, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_50 (MaxPooling (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_51 (Conv2D)           (None, 6, 6, 128)         409728    \n",
      "_________________________________________________________________\n",
      "activation_51 (Activation)   (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_51 (MaxPooling (None, 3, 3, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_52 (Conv2D)           (None, 3, 3, 256)         819456    \n",
      "_________________________________________________________________\n",
      "activation_52 (Activation)   (None, 3, 3, 256)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_52 (MaxPooling (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 6)                 6150      \n",
      "=================================================================\n",
      "Total params: 1,622,054\n",
      "Trainable params: 1,622,054\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3183/3183 [==============================] - 4s 1ms/sample - loss: 10.0830 - acc: 0.3371\n",
      "Loss: 10.082969008030192 Accuracy: 0.33710337\n"
     ]
    }
   ],
   "source": [
    "log_dir = 'log'\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "base = 'vis_imagenet_6_class_augmentation_2D_CNN_custom_ch_32_DO_075_DO'\n",
    "\n",
    "with open(path.join(log_dir, base), 'w') as log_file:\n",
    "    for i in range(3, 8):\n",
    "        model_name = base+'_{}_conv'.format(i)\n",
    "        print()\n",
    "        print(model_name, 'Model')\n",
    "        model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "        model_filename = model_path + sorted(os.listdir(model_path))[-1]\n",
    "\n",
    "        model = load_model(model_filename)\n",
    "        model.summary()\n",
    "\n",
    "        [loss, accuracy] = model.evaluate(x_val, y_val)\n",
    "        print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "\n",
    "        del(model)\n",
    "\n",
    "        log_file.write('\\t'.join([model_name, str(accuracy), str(loss)])+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "vis_imagenet_6_class_augmentation_2D_CNN_custom_ch_32_DO_075_DO_3_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_8 (InputLayer)         (None, 172, 172, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_28 (Conv2D)           (None, 172, 172, 32)      2432      \n",
      "_________________________________________________________________\n",
      "activation_28 (Activation)   (None, 172, 172, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_28 (MaxPooling (None, 86, 86, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_29 (Conv2D)           (None, 86, 86, 32)        25632     \n",
      "_________________________________________________________________\n",
      "activation_29 (Activation)   (None, 86, 86, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_29 (MaxPooling (None, 43, 43, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_30 (Conv2D)           (None, 43, 43, 64)        51264     \n",
      "_________________________________________________________________\n",
      "activation_30 (Activation)   (None, 43, 43, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_30 (MaxPooling (None, 22, 22, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 30976)             0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 30976)             0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 6)                 185862    \n",
      "=================================================================\n",
      "Total params: 265,190\n",
      "Trainable params: 265,190\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3183/3183 [==============================] - 3s 1ms/sample - loss: 10.6589 - acc: 0.3358\n",
      "Loss: 10.658858283987875 Accuracy: 0.3358467\n",
      "\n",
      "vis_imagenet_6_class_augmentation_2D_CNN_custom_ch_32_DO_075_DO_4_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_9 (InputLayer)         (None, 172, 172, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_31 (Conv2D)           (None, 172, 172, 32)      2432      \n",
      "_________________________________________________________________\n",
      "activation_31 (Activation)   (None, 172, 172, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_31 (MaxPooling (None, 86, 86, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_32 (Conv2D)           (None, 86, 86, 32)        25632     \n",
      "_________________________________________________________________\n",
      "activation_32 (Activation)   (None, 86, 86, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_32 (MaxPooling (None, 43, 43, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_33 (Conv2D)           (None, 43, 43, 64)        51264     \n",
      "_________________________________________________________________\n",
      "activation_33 (Activation)   (None, 43, 43, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_33 (MaxPooling (None, 22, 22, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_34 (Conv2D)           (None, 22, 22, 64)        102464    \n",
      "_________________________________________________________________\n",
      "activation_34 (Activation)   (None, 22, 22, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_34 (MaxPooling (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 7744)              0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 7744)              0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 6)                 46470     \n",
      "=================================================================\n",
      "Total params: 228,262\n",
      "Trainable params: 228,262\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3183/3183 [==============================] - 3s 1ms/sample - loss: 10.6552 - acc: 0.3377\n",
      "Loss: 10.655174890089391 Accuracy: 0.3377317\n",
      "\n",
      "vis_imagenet_6_class_augmentation_2D_CNN_custom_ch_32_DO_075_DO_5_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_10 (InputLayer)        (None, 172, 172, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_35 (Conv2D)           (None, 172, 172, 32)      2432      \n",
      "_________________________________________________________________\n",
      "activation_35 (Activation)   (None, 172, 172, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_35 (MaxPooling (None, 86, 86, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_36 (Conv2D)           (None, 86, 86, 32)        25632     \n",
      "_________________________________________________________________\n",
      "activation_36 (Activation)   (None, 86, 86, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_36 (MaxPooling (None, 43, 43, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_37 (Conv2D)           (None, 43, 43, 64)        51264     \n",
      "_________________________________________________________________\n",
      "activation_37 (Activation)   (None, 43, 43, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_37 (MaxPooling (None, 22, 22, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_38 (Conv2D)           (None, 22, 22, 64)        102464    \n",
      "_________________________________________________________________\n",
      "activation_38 (Activation)   (None, 22, 22, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_38 (MaxPooling (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_39 (Conv2D)           (None, 11, 11, 128)       204928    \n",
      "_________________________________________________________________\n",
      "activation_39 (Activation)   (None, 11, 11, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_39 (MaxPooling (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 6)                 27654     \n",
      "=================================================================\n",
      "Total params: 414,374\n",
      "Trainable params: 414,374\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3183/3183 [==============================] - 3s 1ms/sample - loss: 10.6566 - acc: 0.3380\n",
      "Loss: 10.656612129999756 Accuracy: 0.33804587\n",
      "\n",
      "vis_imagenet_6_class_augmentation_2D_CNN_custom_ch_32_DO_075_DO_6_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_11 (InputLayer)        (None, 172, 172, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_40 (Conv2D)           (None, 172, 172, 32)      2432      \n",
      "_________________________________________________________________\n",
      "activation_40 (Activation)   (None, 172, 172, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_40 (MaxPooling (None, 86, 86, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_41 (Conv2D)           (None, 86, 86, 32)        25632     \n",
      "_________________________________________________________________\n",
      "activation_41 (Activation)   (None, 86, 86, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_41 (MaxPooling (None, 43, 43, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_42 (Conv2D)           (None, 43, 43, 64)        51264     \n",
      "_________________________________________________________________\n",
      "activation_42 (Activation)   (None, 43, 43, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_42 (MaxPooling (None, 22, 22, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_43 (Conv2D)           (None, 22, 22, 64)        102464    \n",
      "_________________________________________________________________\n",
      "activation_43 (Activation)   (None, 22, 22, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_43 (MaxPooling (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_44 (Conv2D)           (None, 11, 11, 128)       204928    \n",
      "_________________________________________________________________\n",
      "activation_44 (Activation)   (None, 11, 11, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_44 (MaxPooling (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_45 (Conv2D)           (None, 6, 6, 128)         409728    \n",
      "_________________________________________________________________\n",
      "activation_45 (Activation)   (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_45 (MaxPooling (None, 3, 3, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 6)                 6918      \n",
      "=================================================================\n",
      "Total params: 803,366\n",
      "Trainable params: 803,366\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3183/3183 [==============================] - 4s 1ms/sample - loss: 10.5985 - acc: 0.3384\n",
      "Loss: 10.598501925748865 Accuracy: 0.33836004\n",
      "\n",
      "vis_imagenet_6_class_augmentation_2D_CNN_custom_ch_32_DO_075_DO_7_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_12 (InputLayer)        (None, 172, 172, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_46 (Conv2D)           (None, 172, 172, 32)      2432      \n",
      "_________________________________________________________________\n",
      "activation_46 (Activation)   (None, 172, 172, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_46 (MaxPooling (None, 86, 86, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_47 (Conv2D)           (None, 86, 86, 32)        25632     \n",
      "_________________________________________________________________\n",
      "activation_47 (Activation)   (None, 86, 86, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_47 (MaxPooling (None, 43, 43, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_48 (Conv2D)           (None, 43, 43, 64)        51264     \n",
      "_________________________________________________________________\n",
      "activation_48 (Activation)   (None, 43, 43, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_48 (MaxPooling (None, 22, 22, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_49 (Conv2D)           (None, 22, 22, 64)        102464    \n",
      "_________________________________________________________________\n",
      "activation_49 (Activation)   (None, 22, 22, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_49 (MaxPooling (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_50 (Conv2D)           (None, 11, 11, 128)       204928    \n",
      "_________________________________________________________________\n",
      "activation_50 (Activation)   (None, 11, 11, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_50 (MaxPooling (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_51 (Conv2D)           (None, 6, 6, 128)         409728    \n",
      "_________________________________________________________________\n",
      "activation_51 (Activation)   (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_51 (MaxPooling (None, 3, 3, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_52 (Conv2D)           (None, 3, 3, 256)         819456    \n",
      "_________________________________________________________________\n",
      "activation_52 (Activation)   (None, 3, 3, 256)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_52 (MaxPooling (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 6)                 6150      \n",
      "=================================================================\n",
      "Total params: 1,622,054\n",
      "Trainable params: 1,622,054\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3183/3183 [==============================] - 3s 1ms/sample - loss: 10.5670 - acc: 0.3374\n",
      "Loss: 10.567010301282796 Accuracy: 0.33741754\n"
     ]
    }
   ],
   "source": [
    "for i in range(3, 8):\n",
    "    model_name = base+'_{}_conv'.format(i)\n",
    "    print()\n",
    "    print(model_name, 'Model')\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    model_filename = model_path + '000_last.hdf5'\n",
    "\n",
    "    model = load_model(model_filename)\n",
    "    model.summary()\n",
    "\n",
    "    [loss, accuracy] = model.evaluate(x_test, y_test)\n",
    "    print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "\n",
    "    del(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "vis_imagenet_6_class_augmentation_2D_CNN_custom_ch_32_DO_075_DO_7_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_12 (InputLayer)        (None, 172, 172, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_46 (Conv2D)           (None, 172, 172, 32)      2432      \n",
      "_________________________________________________________________\n",
      "activation_46 (Activation)   (None, 172, 172, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_46 (MaxPooling (None, 86, 86, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_47 (Conv2D)           (None, 86, 86, 32)        25632     \n",
      "_________________________________________________________________\n",
      "activation_47 (Activation)   (None, 86, 86, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_47 (MaxPooling (None, 43, 43, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_48 (Conv2D)           (None, 43, 43, 64)        51264     \n",
      "_________________________________________________________________\n",
      "activation_48 (Activation)   (None, 43, 43, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_48 (MaxPooling (None, 22, 22, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_49 (Conv2D)           (None, 22, 22, 64)        102464    \n",
      "_________________________________________________________________\n",
      "activation_49 (Activation)   (None, 22, 22, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_49 (MaxPooling (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_50 (Conv2D)           (None, 11, 11, 128)       204928    \n",
      "_________________________________________________________________\n",
      "activation_50 (Activation)   (None, 11, 11, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_50 (MaxPooling (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_51 (Conv2D)           (None, 6, 6, 128)         409728    \n",
      "_________________________________________________________________\n",
      "activation_51 (Activation)   (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_51 (MaxPooling (None, 3, 3, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_52 (Conv2D)           (None, 3, 3, 256)         819456    \n",
      "_________________________________________________________________\n",
      "activation_52 (Activation)   (None, 3, 3, 256)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_52 (MaxPooling (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 6)                 6150      \n",
      "=================================================================\n",
      "Total params: 1,622,054\n",
      "Trainable params: 1,622,054\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3183/3183 [==============================] - 4s 1ms/sample - loss: 10.0830 - acc: 0.3371\n",
      "Loss: 10.082969008030192 Accuracy: 0.33710337\n"
     ]
    }
   ],
   "source": [
    "i = 7\n",
    "model_name = base+'_{}_conv'.format(i)\n",
    "print()\n",
    "print(model_name, 'Model')\n",
    "model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "model_filename = model_path + sorted(os.listdir(model_path))[-1]\n",
    "\n",
    "model = load_model(model_filename)\n",
    "model.summary()\n",
    "\n",
    "[loss, accuracy] = model.evaluate(x_val, y_val)\n",
    "print('Loss:', loss, 'Accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 1, 1])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "[[  29    1    0    0    0    0]\n",
      " [   6 1044    0    0    0    0]\n",
      " [  14   64    0    0    0    0]\n",
      " [ 145 1795    0    0    0    0]\n",
      " [   8   26    0    0    0    0]\n",
      " [   1   50    0    0    0    0]]\n",
      "\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.14      0.97      0.25        30\n",
      "           1       0.35      0.99      0.52      1050\n",
      "           2       0.00      0.00      0.00        78\n",
      "           3       0.00      0.00      0.00      1940\n",
      "           4       0.00      0.00      0.00        34\n",
      "           5       0.00      0.00      0.00        51\n",
      "\n",
      "   micro avg       0.34      0.34      0.34      3183\n",
      "   macro avg       0.08      0.33      0.13      3183\n",
      "weighted avg       0.12      0.34      0.17      3183\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f7270188518>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "Y_pred = model.predict(x_test)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "y_real = np.argmax(y_test, axis=1)\n",
    "confusion_mat = confusion_matrix(y_real, y_pred)\n",
    "print('Confusion Matrix')\n",
    "print(confusion_mat)\n",
    "print()\n",
    "\n",
    "print('Classification Report')\n",
    "print(classification_report(y_real, y_pred))\n",
    "print()\n",
    "\n",
    "# labels = y_table.T[0]\n",
    "plt.figure(figsize=(4,4), dpi=100)\n",
    "plt.xticks(np.arange(len(y_list)), y_list)\n",
    "plt.yticks(np.arange(len(y_list)), y_list)\n",
    "plt.imshow(confusion_mat, interpolation='nearest', cmap=plt.cm.bone_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

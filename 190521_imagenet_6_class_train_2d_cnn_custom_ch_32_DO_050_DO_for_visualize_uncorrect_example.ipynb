{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import os.path as path\n",
    "import itertools\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.layers import Input,InputLayer, Dense, Activation, BatchNormalization, Flatten, Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D, Dropout\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,LearningRateScheduler, \\\n",
    "                                        EarlyStopping\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.utils import to_categorical, multi_gpu_model, Sequence\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data = np.load(path.join(data_dir, 'imagenet_6_class_172_train_data.npz'))\n",
    "# val_data = np.load(path.join(data_dir, 'imagenet_6_class_172_val_data.npz'))\n",
    "\n",
    "x_train = np.load(path.join(data_dir, 'imagenet_6_class_172_x_train.npy'))\n",
    "y_train = np.load(path.join(data_dir, 'imagenet_6_class_172_y_train.npy'))\n",
    "x_val = np.load(path.join(data_dir, 'imagenet_6_class_172_x_val.npy'))\n",
    "y_val = np.load(path.join(data_dir, 'imagenet_6_class_172_y_val.npy'))\n",
    "y_list = np.load(path.join(data_dir, 'imagenet_6_class_172_y_list.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((235111, 172, 172, 3),\n",
       " (235111,),\n",
       " (3183, 172, 172, 3),\n",
       " (3183,),\n",
       " (3183, 172, 172, 3),\n",
       " (3183,),\n",
       " (6,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# x_train = train_data['x_data']\n",
    "# y_train = train_data['y_data']\n",
    "# x_val = val_data['x_data']\n",
    "# y_val = val_data['y_data']\n",
    "x_test = x_val\n",
    "y_test = y_val\n",
    "# y_list = val_data['y_list']\n",
    "\n",
    "x_train.shape, y_train.shape, x_val.shape, y_val.shape, x_test.shape, y_test.shape, y_list.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((235111, 172, 172, 3),\n",
       " (235111, 6),\n",
       " (3183, 172, 172, 3),\n",
       " (3183, 6),\n",
       " (3183, 172, 172, 3),\n",
       " (3183, 6))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = to_categorical(y_train)\n",
    "y_val = to_categorical(y_val)\n",
    "y_test = y_val\n",
    "\n",
    "x_train.shape, y_train.shape, x_val.shape, y_val.shape, x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = x_train[0].shape\n",
    "output_size = len(y_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_2d_cnn_custom_ch_32_DO(conv_num=1):\n",
    "    input_layer = Input(shape=input_shape)\n",
    "    x = input_layer\n",
    "\n",
    "    for i in range(conv_num):\n",
    "        x = Conv2D(kernel_size=5, filters=32*(2**(i//2)), strides=(1,1), padding='same')(x)\n",
    "#         x = BatchNormalization()(x)\n",
    "        x = Activation('relu')(x)\n",
    "        x = MaxPooling2D(pool_size=3, strides=(2,2), padding='same')(x)\n",
    "\n",
    "    x = Flatten()(x)\n",
    "  \n",
    "    x = Dropout(0.5)(x)\n",
    "    output_layer = Dense(output_size, activation='softmax')(x)\n",
    "    \n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 172, 172, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 172, 172, 32)      2432      \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 172, 172, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 86, 86, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 236672)            0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 236672)            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 6)                 1420038   \n",
      "=================================================================\n",
      "Total params: 1,422,470\n",
      "Trainable params: 1,422,470\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 172, 172, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 172, 172, 32)      2432      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 172, 172, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 86, 86, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 86, 86, 32)        25632     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 86, 86, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 43, 43, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 59168)             0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 59168)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 6)                 355014    \n",
      "=================================================================\n",
      "Total params: 383,078\n",
      "Trainable params: 383,078\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 172, 172, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 172, 172, 32)      2432      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 172, 172, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 86, 86, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 86, 86, 32)        25632     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 86, 86, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 43, 43, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 43, 43, 64)        51264     \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 43, 43, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 22, 22, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 30976)             0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 30976)             0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 6)                 185862    \n",
      "=================================================================\n",
      "Total params: 265,190\n",
      "Trainable params: 265,190\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, 172, 172, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 172, 172, 32)      2432      \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 172, 172, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 86, 86, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 86, 86, 32)        25632     \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 86, 86, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 43, 43, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 43, 43, 64)        51264     \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 43, 43, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 22, 22, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 22, 22, 64)        102464    \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 22, 22, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 7744)              0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 7744)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 6)                 46470     \n",
      "=================================================================\n",
      "Total params: 228,262\n",
      "Trainable params: 228,262\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         (None, 172, 172, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 172, 172, 32)      2432      \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 172, 172, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 86, 86, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 86, 86, 32)        25632     \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 86, 86, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 43, 43, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 43, 43, 64)        51264     \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 43, 43, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 22, 22, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 22, 22, 64)        102464    \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 22, 22, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 11, 11, 128)       204928    \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 11, 11, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 6)                 27654     \n",
      "=================================================================\n",
      "Total params: 414,374\n",
      "Trainable params: 414,374\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         (None, 172, 172, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 172, 172, 32)      2432      \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 172, 172, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling (None, 86, 86, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 86, 86, 32)        25632     \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 86, 86, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling (None, 43, 43, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 43, 43, 64)        51264     \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 43, 43, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_17 (MaxPooling (None, 22, 22, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 22, 22, 64)        102464    \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 22, 22, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_18 (MaxPooling (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 11, 11, 128)       204928    \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 11, 11, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_19 (MaxPooling (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 6, 6, 128)         409728    \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_20 (MaxPooling (None, 3, 3, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 6)                 6918      \n",
      "=================================================================\n",
      "Total params: 803,366\n",
      "Trainable params: 803,366\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_7 (InputLayer)         (None, 172, 172, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 172, 172, 32)      2432      \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 172, 172, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_21 (MaxPooling (None, 86, 86, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_22 (Conv2D)           (None, 86, 86, 32)        25632     \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 86, 86, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_22 (MaxPooling (None, 43, 43, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 43, 43, 64)        51264     \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 43, 43, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_23 (MaxPooling (None, 22, 22, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_24 (Conv2D)           (None, 22, 22, 64)        102464    \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 22, 22, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_24 (MaxPooling (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_25 (Conv2D)           (None, 11, 11, 128)       204928    \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 11, 11, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_25 (MaxPooling (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_26 (Conv2D)           (None, 6, 6, 128)         409728    \n",
      "_________________________________________________________________\n",
      "activation_26 (Activation)   (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_26 (MaxPooling (None, 3, 3, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_27 (Conv2D)           (None, 3, 3, 256)         819456    \n",
      "_________________________________________________________________\n",
      "activation_27 (Activation)   (None, 3, 3, 256)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_27 (MaxPooling (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 6)                 6150      \n",
      "=================================================================\n",
      "Total params: 1,622,054\n",
      "Trainable params: 1,622,054\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 8):\n",
    "    model = build_2d_cnn_custom_ch_32_DO(conv_num=i)\n",
    "    model.summary()\n",
    "    del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BalanceDataGenerator(Sequence):\n",
    "    def __init__(self, x_data, y_data, batch_size, shuffle=True):\n",
    "        self.x_data = x_data\n",
    "        self.y_data = y_data\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.sample_size = int(np.sum(y_data, axis=0).min())\n",
    "        self.data_shape = x_data.shape[1:]\n",
    "        self.y_labels = np.unique(y_data)\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.y_labels) * self.sample_size / self.batch_size))\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        self.indexes = np.zeros((len(self.y_labels), self.sample_size))\n",
    "        for i, label in enumerate(self.y_labels):\n",
    "            y_temp = self.y_data.argmax(axis=1)\n",
    "            y_index = np.argwhere(y_temp==label).squeeze()\n",
    "            if self.shuffle == True:\n",
    "                self.indexes[i] = np.random.choice(y_index, \n",
    "                                   self.sample_size, \n",
    "                                   replace=False)\n",
    "            else:\n",
    "                self.indexes[i] = y_index[:self.sample_size]\n",
    "                \n",
    "        self.indexes = self.indexes.flatten().astype(np.int32)\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "                \n",
    "    def __getitem__(self, batch_idx):\n",
    "        indices = self.indexes[batch_idx*self.batch_size: (batch_idx+1)*self.batch_size]\n",
    "        return self.x_data[indices], self.y_data[indices]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch_size = 40\n",
    "data_generator = BalanceDataGenerator(x_train, y_train,\n",
    "                                      batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.7179 - acc: 0.5921WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 12s 4ms/sample - loss: 0.7330 - acc: 0.4625\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.73301, saving model to model/checkpoint/vis_imagenet_6_class_augmentation_2D_CNN_custom_ch_32_DO_050_DO_3_conv_checkpoint/001-0.7330.hdf5\n",
      "81/81 [==============================] - 17s 208ms/step - loss: 0.7156 - acc: 0.5940 - val_loss: 0.7330 - val_acc: 0.4625\n",
      "Epoch 2/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.5113 - acc: 0.7518WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 12s 4ms/sample - loss: 0.3026 - acc: 0.9191\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.73301 to 0.30255, saving model to model/checkpoint/vis_imagenet_6_class_augmentation_2D_CNN_custom_ch_32_DO_050_DO_3_conv_checkpoint/002-0.3026.hdf5\n",
      "81/81 [==============================] - 17s 210ms/step - loss: 0.5105 - acc: 0.7517 - val_loss: 0.3026 - val_acc: 0.9191\n",
      "Epoch 3/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.4079 - acc: 0.8291WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3190/3183 [==============================] - 11s 4ms/sample - loss: 0.4351 - acc: 0.7950\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.30255\n",
      "81/81 [==============================] - 16s 192ms/step - loss: 0.4071 - acc: 0.8296 - val_loss: 0.4351 - val_acc: 0.7950\n",
      "Epoch 4/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.3763 - acc: 0.8405WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 12s 4ms/sample - loss: 0.3215 - acc: 0.8700\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.30255\n",
      "81/81 [==============================] - 16s 199ms/step - loss: 0.3757 - acc: 0.8414 - val_loss: 0.3215 - val_acc: 0.8700\n",
      "Epoch 5/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.3321 - acc: 0.8606WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 13s 4ms/sample - loss: 0.3446 - acc: 0.8550\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.30255\n",
      "81/81 [==============================] - 17s 207ms/step - loss: 0.3333 - acc: 0.8600 - val_loss: 0.3446 - val_acc: 0.8550\n",
      "Epoch 6/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.2958 - acc: 0.8797WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 15s 5ms/sample - loss: 0.1925 - acc: 0.9341\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.30255 to 0.19249, saving model to model/checkpoint/vis_imagenet_6_class_augmentation_2D_CNN_custom_ch_32_DO_050_DO_3_conv_checkpoint/006-0.1925.hdf5\n",
      "81/81 [==============================] - 20s 242ms/step - loss: 0.2940 - acc: 0.8805 - val_loss: 0.1925 - val_acc: 0.9341\n",
      "Epoch 7/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.3044 - acc: 0.8702WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.2765 - acc: 0.8906\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.19249\n",
      "81/81 [==============================] - 23s 279ms/step - loss: 0.3045 - acc: 0.8703 - val_loss: 0.2765 - val_acc: 0.8906\n",
      "Epoch 8/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.2721 - acc: 0.8877WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 10s 3ms/sample - loss: 0.3501 - acc: 0.8494\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.19249\n",
      "81/81 [==============================] - 21s 253ms/step - loss: 0.2706 - acc: 0.8880 - val_loss: 0.3501 - val_acc: 0.8494\n",
      "Epoch 9/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.2390 - acc: 0.9102- ETA: WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 14s 4ms/sample - loss: 0.3512 - acc: 0.8400\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.19249\n",
      "81/81 [==============================] - 21s 259ms/step - loss: 0.2377 - acc: 0.9106 - val_loss: 0.3512 - val_acc: 0.8400\n",
      "Epoch 10/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.2607 - acc: 0.8972WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 14s 4ms/sample - loss: 0.1264 - acc: 0.9544\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.19249 to 0.12641, saving model to model/checkpoint/vis_imagenet_6_class_augmentation_2D_CNN_custom_ch_32_DO_050_DO_3_conv_checkpoint/010-0.1264.hdf5\n",
      "81/81 [==============================] - 20s 245ms/step - loss: 0.2611 - acc: 0.8970 - val_loss: 0.1264 - val_acc: 0.9544\n",
      "Epoch 11/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.2306 - acc: 0.9070WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 15s 5ms/sample - loss: 0.3824 - acc: 0.8344\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.12641\n",
      "81/81 [==============================] - 19s 234ms/step - loss: 0.2298 - acc: 0.9075 - val_loss: 0.3824 - val_acc: 0.8344\n",
      "Epoch 12/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.2166 - acc: 0.9142WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 15s 5ms/sample - loss: 0.2068 - acc: 0.9262\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.12641\n",
      "81/81 [==============================] - 20s 244ms/step - loss: 0.2170 - acc: 0.9143 - val_loss: 0.2068 - val_acc: 0.9262\n",
      "Epoch 13/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.2006 - acc: 0.9204WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 13s 4ms/sample - loss: 0.1541 - acc: 0.9509\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.12641\n",
      "81/81 [==============================] - 18s 228ms/step - loss: 0.2015 - acc: 0.9202 - val_loss: 0.1541 - val_acc: 0.9509\n",
      "Epoch 14/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.2063 - acc: 0.9164WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 12s 4ms/sample - loss: 0.0985 - acc: 0.9656\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.12641 to 0.09849, saving model to model/checkpoint/vis_imagenet_6_class_augmentation_2D_CNN_custom_ch_32_DO_050_DO_3_conv_checkpoint/014-0.0985.hdf5\n",
      "81/81 [==============================] - 18s 221ms/step - loss: 0.2058 - acc: 0.9165 - val_loss: 0.0985 - val_acc: 0.9656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.2035 - acc: 0.9221WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 13s 4ms/sample - loss: 0.0978 - acc: 0.9700\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.09849 to 0.09783, saving model to model/checkpoint/vis_imagenet_6_class_augmentation_2D_CNN_custom_ch_32_DO_050_DO_3_conv_checkpoint/015-0.0978.hdf5\n",
      "81/81 [==============================] - 22s 270ms/step - loss: 0.2026 - acc: 0.9224 - val_loss: 0.0978 - val_acc: 0.9700\n",
      "Epoch 16/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.1710 - acc: 0.9340WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 12s 4ms/sample - loss: 0.1416 - acc: 0.9575\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.09783\n",
      "81/81 [==============================] - 18s 221ms/step - loss: 0.1704 - acc: 0.9342 - val_loss: 0.1416 - val_acc: 0.9575\n",
      "Epoch 17/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.1598 - acc: 0.9403WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 13s 4ms/sample - loss: 0.1107 - acc: 0.9600\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.09783\n",
      "81/81 [==============================] - 20s 243ms/step - loss: 0.1594 - acc: 0.9407 - val_loss: 0.1107 - val_acc: 0.9600\n",
      "Epoch 18/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.1696 - acc: 0.9375WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 12s 4ms/sample - loss: 0.1258 - acc: 0.9625\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.09783\n",
      "81/81 [==============================] - 18s 217ms/step - loss: 0.1685 - acc: 0.9379 - val_loss: 0.1258 - val_acc: 0.9625\n",
      "Epoch 19/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.1566 - acc: 0.9422WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 12s 4ms/sample - loss: 0.0874 - acc: 0.9706\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.09783 to 0.08744, saving model to model/checkpoint/vis_imagenet_6_class_augmentation_2D_CNN_custom_ch_32_DO_050_DO_3_conv_checkpoint/019-0.0874.hdf5\n",
      "81/81 [==============================] - 17s 210ms/step - loss: 0.1555 - acc: 0.9429 - val_loss: 0.0874 - val_acc: 0.9706\n",
      "Epoch 20/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.1554 - acc: 0.9422WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 13s 4ms/sample - loss: 0.1270 - acc: 0.9506\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.08744\n",
      "81/81 [==============================] - 19s 240ms/step - loss: 0.1546 - acc: 0.9429 - val_loss: 0.1270 - val_acc: 0.9506\n",
      "Epoch 21/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.1515 - acc: 0.9456WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 21s 7ms/sample - loss: 0.1838 - acc: 0.9312\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.08744\n",
      "81/81 [==============================] - 30s 365ms/step - loss: 0.1510 - acc: 0.9460 - val_loss: 0.1838 - val_acc: 0.9312\n",
      "Epoch 22/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.1390 - acc: 0.9472WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 27s 9ms/sample - loss: 0.1556 - acc: 0.9466\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.08744\n",
      "81/81 [==============================] - 37s 453ms/step - loss: 0.1372 - acc: 0.9482 - val_loss: 0.1556 - val_acc: 0.9466\n",
      "Epoch 23/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.1453 - acc: 0.9481WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 32s 10ms/sample - loss: 0.0899 - acc: 0.9638\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.08744\n",
      "81/81 [==============================] - 39s 479ms/step - loss: 0.1452 - acc: 0.9479 - val_loss: 0.0899 - val_acc: 0.9638\n",
      "Epoch 24/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.1404 - acc: 0.9500WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 35s 11ms/sample - loss: 0.2388 - acc: 0.9109\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.08744\n",
      "81/81 [==============================] - 49s 608ms/step - loss: 0.1405 - acc: 0.9500 - val_loss: 0.2388 - val_acc: 0.9109\n",
      "Epoch 25/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.1476 - acc: 0.9418WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 14s 4ms/sample - loss: 0.2143 - acc: 0.9175\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.08744\n",
      "81/81 [==============================] - 53s 653ms/step - loss: 0.1493 - acc: 0.9410 - val_loss: 0.2143 - val_acc: 0.9175\n",
      "Epoch 26/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.1169 - acc: 0.9585WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 40s 13ms/sample - loss: 0.0658 - acc: 0.9675\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.08744 to 0.06584, saving model to model/checkpoint/vis_imagenet_6_class_augmentation_2D_CNN_custom_ch_32_DO_050_DO_3_conv_checkpoint/026-0.0658.hdf5\n",
      "81/81 [==============================] - 68s 838ms/step - loss: 0.1192 - acc: 0.9575 - val_loss: 0.0658 - val_acc: 0.9675\n",
      "Epoch 27/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.1234 - acc: 0.9566WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 63s 20ms/sample - loss: 0.0631 - acc: 0.9725\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.06584 to 0.06307, saving model to model/checkpoint/vis_imagenet_6_class_augmentation_2D_CNN_custom_ch_32_DO_050_DO_3_conv_checkpoint/027-0.0631.hdf5\n",
      "81/81 [==============================] - 66s 820ms/step - loss: 0.1234 - acc: 0.9569 - val_loss: 0.0631 - val_acc: 0.9725\n",
      "Epoch 28/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.1223 - acc: 0.9577WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 68s 21ms/sample - loss: 0.1223 - acc: 0.9625\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.06307\n",
      "81/81 [==============================] - 72s 890ms/step - loss: 0.1222 - acc: 0.9578 - val_loss: 0.1223 - val_acc: 0.9625\n",
      "Epoch 29/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.1305 - acc: 0.9519WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3200/3183 [==============================] - 66s 21ms/sample - loss: 0.0853 - acc: 0.9659\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.06307\n",
      "81/81 [==============================] - 71s 872ms/step - loss: 0.1298 - acc: 0.9525 - val_loss: 0.0853 - val_acc: 0.9659\n",
      "Epoch 30/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.1174 - acc: 0.9610WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 63s 20ms/sample - loss: 0.0639 - acc: 0.9681\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.06307\n",
      "81/81 [==============================] - 69s 857ms/step - loss: 0.1177 - acc: 0.9609 - val_loss: 0.0639 - val_acc: 0.9681\n",
      "Epoch 31/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.1241 - acc: 0.9554WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 65s 20ms/sample - loss: 0.0678 - acc: 0.9669\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.06307\n",
      "81/81 [==============================] - 71s 876ms/step - loss: 0.1232 - acc: 0.9559 - val_loss: 0.0678 - val_acc: 0.9669\n",
      "Epoch 32/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.1098 - acc: 0.9621WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 64s 20ms/sample - loss: 0.0563 - acc: 0.9834\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.06307 to 0.05626, saving model to model/checkpoint/vis_imagenet_6_class_augmentation_2D_CNN_custom_ch_32_DO_050_DO_3_conv_checkpoint/032-0.0563.hdf5\n",
      "81/81 [==============================] - 69s 850ms/step - loss: 0.1087 - acc: 0.9621 - val_loss: 0.0563 - val_acc: 0.9834\n",
      "Epoch 33/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.1109 - acc: 0.9631WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.1929 - acc: 0.9162\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.05626\n",
      "81/81 [==============================] - 70s 864ms/step - loss: 0.1109 - acc: 0.9631 - val_loss: 0.1929 - val_acc: 0.9162\n",
      "Epoch 34/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.1084 - acc: 0.9634WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 41s 13ms/sample - loss: 0.0975 - acc: 0.9700\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.05626\n",
      "81/81 [==============================] - 69s 849ms/step - loss: 0.1090 - acc: 0.9631 - val_loss: 0.0975 - val_acc: 0.9700\n",
      "Epoch 35/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.1251 - acc: 0.9599WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 15s 5ms/sample - loss: 0.0981 - acc: 0.9644\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.05626\n",
      "81/81 [==============================] - 67s 830ms/step - loss: 0.1239 - acc: 0.9606 - val_loss: 0.0981 - val_acc: 0.9644\n",
      "Epoch 36/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.1212 - acc: 0.9585WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 65s 20ms/sample - loss: 0.2554 - acc: 0.8975\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.05626\n",
      "81/81 [==============================] - 69s 847ms/step - loss: 0.1211 - acc: 0.9584 - val_loss: 0.2554 - val_acc: 0.8975\n",
      "Epoch 37/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.1132 - acc: 0.9583WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 15s 5ms/sample - loss: 0.0714 - acc: 0.9669\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.05626\n",
      "81/81 [==============================] - 70s 866ms/step - loss: 0.1123 - acc: 0.9587 - val_loss: 0.0714 - val_acc: 0.9669\n",
      "Epoch 38/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.1000 - acc: 0.9654WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 64s 20ms/sample - loss: 0.1001 - acc: 0.9575\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.05626\n",
      "81/81 [==============================] - 68s 838ms/step - loss: 0.0999 - acc: 0.9652 - val_loss: 0.1001 - val_acc: 0.9575\n",
      "Epoch 39/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.1063 - acc: 0.9615WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 70s 22ms/sample - loss: 0.1509 - acc: 0.9441\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.05626\n",
      "81/81 [==============================] - 74s 910ms/step - loss: 0.1062 - acc: 0.9612 - val_loss: 0.1509 - val_acc: 0.9441\n",
      "Epoch 40/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.1176 - acc: 0.9591WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 15s 5ms/sample - loss: 0.1176 - acc: 0.9553\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.05626\n",
      "81/81 [==============================] - 72s 886ms/step - loss: 0.1178 - acc: 0.9590 - val_loss: 0.1176 - val_acc: 0.9553\n",
      "Epoch 41/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.1102 - acc: 0.9645WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 67s 21ms/sample - loss: 0.1411 - acc: 0.9444\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.05626\n",
      "81/81 [==============================] - 72s 889ms/step - loss: 0.1103 - acc: 0.9646 - val_loss: 0.1411 - val_acc: 0.9444\n",
      "Epoch 42/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.1128 - acc: 0.9632WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 65s 20ms/sample - loss: 0.0762 - acc: 0.9688\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.05626\n",
      "81/81 [==============================] - 70s 862ms/step - loss: 0.1118 - acc: 0.9637 - val_loss: 0.0762 - val_acc: 0.9688\n",
      "Epoch 43/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0968 - acc: 0.9667WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 64s 20ms/sample - loss: 0.0538 - acc: 0.9869\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.05626 to 0.05384, saving model to model/checkpoint/vis_imagenet_6_class_augmentation_2D_CNN_custom_ch_32_DO_050_DO_3_conv_checkpoint/043-0.0538.hdf5\n",
      "81/81 [==============================] - 68s 843ms/step - loss: 0.0961 - acc: 0.9668 - val_loss: 0.0538 - val_acc: 0.9869\n",
      "Epoch 44/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.1023 - acc: 0.9659WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3200/3183 [==============================] - 15s 5ms/sample - loss: 0.0855 - acc: 0.9663\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.05384\n",
      "81/81 [==============================] - 72s 885ms/step - loss: 0.1015 - acc: 0.9665 - val_loss: 0.0855 - val_acc: 0.9663\n",
      "Epoch 45/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.1011 - acc: 0.9640WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 68s 21ms/sample - loss: 0.0805 - acc: 0.9675\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.05384\n",
      "81/81 [==============================] - 73s 902ms/step - loss: 0.1014 - acc: 0.9637 - val_loss: 0.0805 - val_acc: 0.9675\n",
      "Epoch 46/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.1078 - acc: 0.9613WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 68s 21ms/sample - loss: 0.0508 - acc: 0.9825\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.05384 to 0.05080, saving model to model/checkpoint/vis_imagenet_6_class_augmentation_2D_CNN_custom_ch_32_DO_050_DO_3_conv_checkpoint/046-0.0508.hdf5\n",
      "81/81 [==============================] - 72s 890ms/step - loss: 0.1068 - acc: 0.9618 - val_loss: 0.0508 - val_acc: 0.9825\n",
      "Epoch 47/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.1038 - acc: 0.9617WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 68s 21ms/sample - loss: 0.0647 - acc: 0.9775\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.05080\n",
      "81/81 [==============================] - 72s 884ms/step - loss: 0.1032 - acc: 0.9621 - val_loss: 0.0647 - val_acc: 0.9775\n",
      "Epoch 48/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.1180 - acc: 0.9605WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 15s 5ms/sample - loss: 0.1545 - acc: 0.9469\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.05080\n",
      "81/81 [==============================] - 72s 886ms/step - loss: 0.1169 - acc: 0.9609 - val_loss: 0.1545 - val_acc: 0.9469\n",
      "Epoch 49/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0933 - acc: 0.9675WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 14s 4ms/sample - loss: 0.1020 - acc: 0.9625\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.05080\n",
      "81/81 [==============================] - 71s 874ms/step - loss: 0.0951 - acc: 0.9668 - val_loss: 0.1020 - val_acc: 0.9625\n",
      "Epoch 50/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0840 - acc: 0.9739WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 67s 21ms/sample - loss: 0.0986 - acc: 0.9647\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.05080\n",
      "81/81 [==============================] - 71s 878ms/step - loss: 0.0839 - acc: 0.9736 - val_loss: 0.0986 - val_acc: 0.9647\n",
      "Epoch 51/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.1069 - acc: 0.9612WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 43s 13ms/sample - loss: 0.0787 - acc: 0.9700\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.05080\n",
      "81/81 [==============================] - 71s 873ms/step - loss: 0.1054 - acc: 0.9618 - val_loss: 0.0787 - val_acc: 0.9700\n",
      "Epoch 52/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.1057 - acc: 0.9628WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 68s 21ms/sample - loss: 0.0472 - acc: 0.9850\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.05080 to 0.04722, saving model to model/checkpoint/vis_imagenet_6_class_augmentation_2D_CNN_custom_ch_32_DO_050_DO_3_conv_checkpoint/052-0.0472.hdf5\n",
      "81/81 [==============================] - 72s 889ms/step - loss: 0.1066 - acc: 0.9624 - val_loss: 0.0472 - val_acc: 0.9850\n",
      "Epoch 53/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.1007 - acc: 0.9637WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 43s 13ms/sample - loss: 0.1495 - acc: 0.9556\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.04722\n",
      "81/81 [==============================] - 72s 883ms/step - loss: 0.1011 - acc: 0.9637 - val_loss: 0.1495 - val_acc: 0.9556\n",
      "Epoch 54/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0946 - acc: 0.9659WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 69s 22ms/sample - loss: 0.1039 - acc: 0.9566\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.04722\n",
      "81/81 [==============================] - 73s 904ms/step - loss: 0.0942 - acc: 0.9659 - val_loss: 0.1039 - val_acc: 0.9566\n",
      "Epoch 55/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0846 - acc: 0.9723WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 67s 21ms/sample - loss: 0.0660 - acc: 0.9719\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.04722\n",
      "81/81 [==============================] - 72s 894ms/step - loss: 0.0851 - acc: 0.9721 - val_loss: 0.0660 - val_acc: 0.9719\n",
      "Epoch 56/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0921 - acc: 0.9698WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 70s 22ms/sample - loss: 0.0660 - acc: 0.9684\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.04722\n",
      "81/81 [==============================] - 76s 933ms/step - loss: 0.0927 - acc: 0.9696 - val_loss: 0.0660 - val_acc: 0.9684\n",
      "Epoch 57/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0885 - acc: 0.9701WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 69s 21ms/sample - loss: 0.0686 - acc: 0.9706\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.04722\n",
      "81/81 [==============================] - 73s 897ms/step - loss: 0.0882 - acc: 0.9702 - val_loss: 0.0686 - val_acc: 0.9706\n",
      "Epoch 58/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0776 - acc: 0.9729WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 70s 22ms/sample - loss: 0.0791 - acc: 0.9675\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.04722\n",
      "81/81 [==============================] - 74s 909ms/step - loss: 0.0775 - acc: 0.9730 - val_loss: 0.0791 - val_acc: 0.9675\n",
      "Epoch 59/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0814 - acc: 0.9710WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3200/3183 [==============================] - 67s 21ms/sample - loss: 0.1136 - acc: 0.9591\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.04722\n",
      "81/81 [==============================] - 73s 897ms/step - loss: 0.0831 - acc: 0.9708 - val_loss: 0.1136 - val_acc: 0.9591\n",
      "Epoch 60/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0874 - acc: 0.9686WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 70s 22ms/sample - loss: 0.0415 - acc: 0.9850\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.04722 to 0.04153, saving model to model/checkpoint/vis_imagenet_6_class_augmentation_2D_CNN_custom_ch_32_DO_050_DO_3_conv_checkpoint/060-0.0415.hdf5\n",
      "81/81 [==============================] - 74s 917ms/step - loss: 0.0876 - acc: 0.9683 - val_loss: 0.0415 - val_acc: 0.9850\n",
      "Epoch 61/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0814 - acc: 0.9723WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 68s 21ms/sample - loss: 0.0795 - acc: 0.9675\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.04153\n",
      "81/81 [==============================] - 77s 948ms/step - loss: 0.0805 - acc: 0.9724 - val_loss: 0.0795 - val_acc: 0.9675\n",
      "Epoch 62/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0818 - acc: 0.9764WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 63s 20ms/sample - loss: 0.0603 - acc: 0.9725\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.04153\n",
      "81/81 [==============================] - 68s 839ms/step - loss: 0.0815 - acc: 0.9764 - val_loss: 0.0603 - val_acc: 0.9725\n",
      "Epoch 63/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0947 - acc: 0.9639WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 72s 22ms/sample - loss: 0.0904 - acc: 0.9644\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.04153\n",
      "81/81 [==============================] - 79s 970ms/step - loss: 0.0952 - acc: 0.9637 - val_loss: 0.0904 - val_acc: 0.9644\n",
      "Epoch 64/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0832 - acc: 0.9698WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 14s 4ms/sample - loss: 0.0591 - acc: 0.9731\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.04153\n",
      "81/81 [==============================] - 68s 842ms/step - loss: 0.0831 - acc: 0.9696 - val_loss: 0.0591 - val_acc: 0.9731\n",
      "Epoch 65/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0736 - acc: 0.9764WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 69s 22ms/sample - loss: 0.0477 - acc: 0.97661s - loss: \n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.04153\n",
      "81/81 [==============================] - 74s 912ms/step - loss: 0.0742 - acc: 0.9758 - val_loss: 0.0477 - val_acc: 0.9766\n",
      "Epoch 66/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0793 - acc: 0.9733WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 15s 5ms/sample - loss: 0.0675 - acc: 0.9725\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.04153\n",
      "81/81 [==============================] - 73s 901ms/step - loss: 0.0786 - acc: 0.9736 - val_loss: 0.0675 - val_acc: 0.9725\n",
      "Epoch 67/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0768 - acc: 0.9727WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0841 - acc: 0.9656\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.04153\n",
      "81/81 [==============================] - 77s 947ms/step - loss: 0.0769 - acc: 0.9727 - val_loss: 0.0841 - val_acc: 0.9656\n",
      "Epoch 68/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0777 - acc: 0.9747WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3190/3183 [==============================] - 70s 22ms/sample - loss: 0.0581 - acc: 0.9749\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.04153\n",
      "81/81 [==============================] - 74s 917ms/step - loss: 0.0770 - acc: 0.9749 - val_loss: 0.0581 - val_acc: 0.9749\n",
      "Epoch 69/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0760 - acc: 0.9755WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 68s 21ms/sample - loss: 0.0515 - acc: 0.9816\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.04153\n",
      "81/81 [==============================] - 72s 894ms/step - loss: 0.0757 - acc: 0.9758 - val_loss: 0.0515 - val_acc: 0.9816\n",
      "Epoch 70/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0775 - acc: 0.9758WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0550 - acc: 0.9794\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.04153\n",
      "81/81 [==============================] - 75s 921ms/step - loss: 0.0766 - acc: 0.9764 - val_loss: 0.0550 - val_acc: 0.9794\n",
      "Epoch 71/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0760 - acc: 0.9755WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 72s 22ms/sample - loss: 0.1404 - acc: 0.9500\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.04153\n",
      "81/81 [==============================] - 77s 954ms/step - loss: 0.0773 - acc: 0.9749 - val_loss: 0.1404 - val_acc: 0.9500\n",
      "Epoch 72/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0650 - acc: 0.9793WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 63s 20ms/sample - loss: 0.0485 - acc: 0.9812\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.04153\n",
      "81/81 [==============================] - 71s 871ms/step - loss: 0.0645 - acc: 0.9795 - val_loss: 0.0485 - val_acc: 0.9812\n",
      "Epoch 73/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0719 - acc: 0.9761WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 47s 15ms/sample - loss: 0.0489 - acc: 0.9856\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.04153\n",
      "81/81 [==============================] - 77s 949ms/step - loss: 0.0726 - acc: 0.9758 - val_loss: 0.0489 - val_acc: 0.9856\n",
      "Epoch 74/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0746 - acc: 0.9711WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 71s 22ms/sample - loss: 0.1058 - acc: 0.9563\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.04153\n",
      "81/81 [==============================] - 76s 936ms/step - loss: 0.0740 - acc: 0.9714 - val_loss: 0.1058 - val_acc: 0.9563\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0667 - acc: 0.9774WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 68s 21ms/sample - loss: 0.0681 - acc: 0.9700\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.04153\n",
      "81/81 [==============================] - 75s 922ms/step - loss: 0.0662 - acc: 0.9777 - val_loss: 0.0681 - val_acc: 0.9700\n",
      "Epoch 76/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0784 - acc: 0.9723WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 44s 14ms/sample - loss: 0.0639 - acc: 0.9787\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.04153\n",
      "81/81 [==============================] - 74s 914ms/step - loss: 0.0775 - acc: 0.9727 - val_loss: 0.0639 - val_acc: 0.9787\n",
      "Epoch 77/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0671 - acc: 0.9818WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 69s 22ms/sample - loss: 0.0517 - acc: 0.9837\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.04153\n",
      "81/81 [==============================] - 74s 912ms/step - loss: 0.0674 - acc: 0.9814 - val_loss: 0.0517 - val_acc: 0.9837\n",
      "Epoch 78/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0601 - acc: 0.9799WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 67s 21ms/sample - loss: 0.0975 - acc: 0.9628\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.04153\n",
      "81/81 [==============================] - 75s 929ms/step - loss: 0.0599 - acc: 0.9798 - val_loss: 0.0975 - val_acc: 0.9628\n",
      "Epoch 79/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0634 - acc: 0.9799WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 64s 20ms/sample - loss: 0.0751 - acc: 0.9681\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.04153\n",
      "81/81 [==============================] - 73s 903ms/step - loss: 0.0631 - acc: 0.9801 - val_loss: 0.0751 - val_acc: 0.9681\n",
      "Epoch 80/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0682 - acc: 0.9755WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 65s 20ms/sample - loss: 0.0598 - acc: 0.9772\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.04153\n",
      "81/81 [==============================] - 74s 916ms/step - loss: 0.0684 - acc: 0.9755 - val_loss: 0.0598 - val_acc: 0.9772\n",
      "Epoch 81/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0641 - acc: 0.9805WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 67s 21ms/sample - loss: 0.0799 - acc: 0.9631\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.04153\n",
      "81/81 [==============================] - 74s 914ms/step - loss: 0.0638 - acc: 0.9804 - val_loss: 0.0799 - val_acc: 0.9631\n",
      "Epoch 82/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0718 - acc: 0.9755WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - ETA: 0s - loss: 0.0535 - acc: 0.983 - 43s 13ms/sample - loss: 0.0568 - acc: 0.9819\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.04153\n",
      "81/81 [==============================] - 73s 905ms/step - loss: 0.0722 - acc: 0.9755 - val_loss: 0.0568 - val_acc: 0.9819\n",
      "Epoch 83/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0664 - acc: 0.9783WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 15s 5ms/sample - loss: 0.0516 - acc: 0.9819\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.04153\n",
      "81/81 [==============================] - 71s 881ms/step - loss: 0.0658 - acc: 0.9786 - val_loss: 0.0516 - val_acc: 0.9819\n",
      "Epoch 84/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0599 - acc: 0.9793WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 47s 15ms/sample - loss: 0.0660 - acc: 0.9725\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.04153\n",
      "81/81 [==============================] - 77s 950ms/step - loss: 0.0604 - acc: 0.9789 - val_loss: 0.0660 - val_acc: 0.9725\n",
      "Epoch 85/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0541 - acc: 0.9844WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 62s 20ms/sample - loss: 0.0419 - acc: 0.9875\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.04153\n",
      "81/81 [==============================] - 72s 894ms/step - loss: 0.0555 - acc: 0.9836 - val_loss: 0.0419 - val_acc: 0.9875\n",
      "Epoch 86/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0680 - acc: 0.9791WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 66s 21ms/sample - loss: 0.0783 - acc: 0.9725\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.04153\n",
      "81/81 [==============================] - 71s 872ms/step - loss: 0.0668 - acc: 0.9795 - val_loss: 0.0783 - val_acc: 0.9725\n",
      "Epoch 87/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0707 - acc: 0.9758WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 68s 21ms/sample - loss: 0.0427 - acc: 0.9850\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.04153\n",
      "81/81 [==============================] - 73s 901ms/step - loss: 0.0702 - acc: 0.9761 - val_loss: 0.0427 - val_acc: 0.9850\n",
      "Epoch 88/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0671 - acc: 0.9787WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 64s 20ms/sample - loss: 0.1011 - acc: 0.9650\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.04153\n",
      "81/81 [==============================] - 73s 903ms/step - loss: 0.0674 - acc: 0.9786 - val_loss: 0.1011 - val_acc: 0.9650\n",
      "Epoch 89/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0558 - acc: 0.9854WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 70s 22ms/sample - loss: 0.0801 - acc: 0.9700\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.04153\n",
      "81/81 [==============================] - 74s 918ms/step - loss: 0.0551 - acc: 0.9857 - val_loss: 0.0801 - val_acc: 0.9700\n",
      "Epoch 90/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0604 - acc: 0.9789WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3200/3183 [==============================] - 14s 4ms/sample - loss: 0.1437 - acc: 0.9491\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.04153\n",
      "81/81 [==============================] - 73s 903ms/step - loss: 0.0602 - acc: 0.9792 - val_loss: 0.1437 - val_acc: 0.9491\n",
      "Epoch 91/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0608 - acc: 0.9803WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 70s 22ms/sample - loss: 0.0454 - acc: 0.9819\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.04153\n",
      "81/81 [==============================] - 74s 917ms/step - loss: 0.0601 - acc: 0.9808 - val_loss: 0.0454 - val_acc: 0.9819\n",
      "Epoch 92/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0607 - acc: 0.9824WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0562 - acc: 0.9812\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.04153\n",
      "81/81 [==============================] - 72s 886ms/step - loss: 0.0606 - acc: 0.9823 - val_loss: 0.0562 - val_acc: 0.9812\n",
      "Epoch 93/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0719 - acc: 0.9774WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 68s 21ms/sample - loss: 0.0463 - acc: 0.9834\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.04153\n",
      "81/81 [==============================] - 72s 895ms/step - loss: 0.0711 - acc: 0.9777 - val_loss: 0.0463 - val_acc: 0.9834\n",
      "Epoch 94/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0482 - acc: 0.9846WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 69s 22ms/sample - loss: 0.0550 - acc: 0.9787\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.04153\n",
      "81/81 [==============================] - 74s 908ms/step - loss: 0.0480 - acc: 0.9848 - val_loss: 0.0550 - val_acc: 0.9787\n",
      "Epoch 95/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0416 - acc: 0.9868WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 67s 21ms/sample - loss: 0.0676 - acc: 0.9762\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.04153\n",
      "81/81 [==============================] - 76s 941ms/step - loss: 0.0416 - acc: 0.9870 - val_loss: 0.0676 - val_acc: 0.9762\n",
      "Epoch 96/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0552 - acc: 0.9827WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 70s 22ms/sample - loss: 0.1157 - acc: 0.9569\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.04153\n",
      "81/81 [==============================] - 75s 924ms/step - loss: 0.0549 - acc: 0.9829 - val_loss: 0.1157 - val_acc: 0.9569\n",
      "Epoch 97/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0507 - acc: 0.9833WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 71s 22ms/sample - loss: 0.0420 - acc: 0.9891\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.04153\n",
      "81/81 [==============================] - 75s 929ms/step - loss: 0.0503 - acc: 0.9836 - val_loss: 0.0420 - val_acc: 0.9891\n",
      "Epoch 98/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0479 - acc: 0.9889WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.0656 - acc: 0.9725\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.04153\n",
      "81/81 [==============================] - 73s 897ms/step - loss: 0.0481 - acc: 0.9888 - val_loss: 0.0656 - val_acc: 0.9725\n",
      "Epoch 99/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0629 - acc: 0.9818WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 74s 23ms/sample - loss: 0.0496 - acc: 0.9850\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.04153\n",
      "81/81 [==============================] - 78s 958ms/step - loss: 0.0628 - acc: 0.9820 - val_loss: 0.0496 - val_acc: 0.9850\n",
      "Epoch 100/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0716 - acc: 0.9815WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.0534 - acc: 0.9825\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.04153\n",
      "81/81 [==============================] - 72s 887ms/step - loss: 0.0710 - acc: 0.9817 - val_loss: 0.0534 - val_acc: 0.9825\n",
      "Epoch 101/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0588 - acc: 0.9818WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 15s 5ms/sample - loss: 0.0438 - acc: 0.9875\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 0.04153\n",
      "81/81 [==============================] - 72s 883ms/step - loss: 0.0594 - acc: 0.9814 - val_loss: 0.0438 - val_acc: 0.9875\n",
      "Epoch 102/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0514 - acc: 0.9849WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 67s 21ms/sample - loss: 0.0846 - acc: 0.9678\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 0.04153\n",
      "81/81 [==============================] - 74s 913ms/step - loss: 0.0508 - acc: 0.9851 - val_loss: 0.0846 - val_acc: 0.9678\n",
      "Epoch 103/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0651 - acc: 0.9808WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 71s 22ms/sample - loss: 0.0651 - acc: 0.9750\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 0.04153\n",
      "81/81 [==============================] - 76s 933ms/step - loss: 0.0645 - acc: 0.9811 - val_loss: 0.0651 - val_acc: 0.9750\n",
      "Epoch 104/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0495 - acc: 0.9812WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 70s 22ms/sample - loss: 0.0443 - acc: 0.9837\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 0.04153\n",
      "81/81 [==============================] - 75s 924ms/step - loss: 0.0491 - acc: 0.9814 - val_loss: 0.0443 - val_acc: 0.9837\n",
      "Epoch 105/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0559 - acc: 0.9828WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 44s 14ms/sample - loss: 0.0578 - acc: 0.9834\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 0.04153\n",
      "81/81 [==============================] - 75s 923ms/step - loss: 0.0553 - acc: 0.9832 - val_loss: 0.0578 - val_acc: 0.9834\n",
      "Epoch 106/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/81 [============================>.] - ETA: 0s - loss: 0.0529 - acc: 0.9811WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 70s 22ms/sample - loss: 0.0613 - acc: 0.9737\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 0.04153\n",
      "81/81 [==============================] - 75s 923ms/step - loss: 0.0529 - acc: 0.9811 - val_loss: 0.0613 - val_acc: 0.9737\n",
      "Epoch 107/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0538 - acc: 0.9811WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 65s 20ms/sample - loss: 0.0437 - acc: 0.9816\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 0.04153\n",
      "81/81 [==============================] - 74s 918ms/step - loss: 0.0532 - acc: 0.9814 - val_loss: 0.0437 - val_acc: 0.9816\n",
      "Epoch 108/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0594 - acc: 0.9799WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 74s 23ms/sample - loss: 0.0710 - acc: 0.9725\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 0.04153\n",
      "81/81 [==============================] - 79s 978ms/step - loss: 0.0585 - acc: 0.9804 - val_loss: 0.0710 - val_acc: 0.9725\n",
      "Epoch 109/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0410 - acc: 0.9882WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 20s 6ms/sample - loss: 0.0495 - acc: 0.9806\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 0.04153\n",
      "81/81 [==============================] - 79s 974ms/step - loss: 0.0406 - acc: 0.9885 - val_loss: 0.0495 - val_acc: 0.9806\n",
      "Epoch 110/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0480 - acc: 0.9870WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 69s 22ms/sample - loss: 0.0855 - acc: 0.9728\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 0.04153\n",
      "81/81 [==============================] - 76s 939ms/step - loss: 0.0473 - acc: 0.9870 - val_loss: 0.0855 - val_acc: 0.9728\n",
      "Epoch 111/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0545 - acc: 0.9835WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 66s 21ms/sample - loss: 0.0489 - acc: 0.9850\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 0.04153\n",
      "81/81 [==============================] - 74s 915ms/step - loss: 0.0534 - acc: 0.9839 - val_loss: 0.0489 - val_acc: 0.9850\n",
      "Epoch 112/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0494 - acc: 0.9862WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 45s 14ms/sample - loss: 0.1118 - acc: 0.9572\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 0.04153\n",
      "81/81 [==============================] - 75s 928ms/step - loss: 0.0492 - acc: 0.9860 - val_loss: 0.1118 - val_acc: 0.9572\n",
      "Epoch 113/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0579 - acc: 0.9803WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.0678 - acc: 0.9725\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 0.04153\n",
      "81/81 [==============================] - 73s 897ms/step - loss: 0.0588 - acc: 0.9798 - val_loss: 0.0678 - val_acc: 0.9725\n",
      "Epoch 114/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0545 - acc: 0.9825WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.0648 - acc: 0.9787\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 0.04153\n",
      "81/81 [==============================] - 77s 951ms/step - loss: 0.0553 - acc: 0.9823 - val_loss: 0.0648 - val_acc: 0.9787\n",
      "Epoch 115/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0435 - acc: 0.9876WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 46s 14ms/sample - loss: 0.0405 - acc: 0.9862\n",
      "\n",
      "Epoch 00115: val_loss improved from 0.04153 to 0.04053, saving model to model/checkpoint/vis_imagenet_6_class_augmentation_2D_CNN_custom_ch_32_DO_050_DO_3_conv_checkpoint/115-0.0405.hdf5\n",
      "81/81 [==============================] - 76s 934ms/step - loss: 0.0442 - acc: 0.9876 - val_loss: 0.0405 - val_acc: 0.9862\n",
      "Epoch 116/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0380 - acc: 0.9887WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 67s 21ms/sample - loss: 0.0385 - acc: 0.9894\n",
      "\n",
      "Epoch 00116: val_loss improved from 0.04053 to 0.03852, saving model to model/checkpoint/vis_imagenet_6_class_augmentation_2D_CNN_custom_ch_32_DO_050_DO_3_conv_checkpoint/116-0.0385.hdf5\n",
      "81/81 [==============================] - 75s 926ms/step - loss: 0.0385 - acc: 0.9882 - val_loss: 0.0385 - val_acc: 0.9894\n",
      "Epoch 117/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0436 - acc: 0.9871WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 72s 23ms/sample - loss: 0.0443 - acc: 0.9850\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 0.03852\n",
      "81/81 [==============================] - 76s 935ms/step - loss: 0.0438 - acc: 0.9870 - val_loss: 0.0443 - val_acc: 0.9850\n",
      "Epoch 118/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0436 - acc: 0.9889WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.0386 - acc: 0.9875\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 0.03852\n",
      "81/81 [==============================] - 77s 945ms/step - loss: 0.0441 - acc: 0.9888 - val_loss: 0.0386 - val_acc: 0.9875\n",
      "Epoch 119/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0528 - acc: 0.9846WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 76s 24ms/sample - loss: 0.0445 - acc: 0.9841\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 0.03852\n",
      "81/81 [==============================] - 79s 980ms/step - loss: 0.0523 - acc: 0.9848 - val_loss: 0.0445 - val_acc: 0.9841\n",
      "Epoch 120/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0422 - acc: 0.9882WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 14s 4ms/sample - loss: 0.0509 - acc: 0.9816\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 0.03852\n",
      "81/81 [==============================] - 71s 883ms/step - loss: 0.0448 - acc: 0.9876 - val_loss: 0.0509 - val_acc: 0.9816\n",
      "Epoch 121/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/81 [============================>.] - ETA: 0s - loss: 0.0476 - acc: 0.9854WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 72s 23ms/sample - loss: 0.0584 - acc: 0.9822\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 0.03852\n",
      "81/81 [==============================] - 76s 937ms/step - loss: 0.0477 - acc: 0.9851 - val_loss: 0.0584 - val_acc: 0.9822\n",
      "Epoch 122/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0478 - acc: 0.9855WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 71s 22ms/sample - loss: 0.0575 - acc: 0.9787\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 0.03852\n",
      "81/81 [==============================] - 75s 927ms/step - loss: 0.0476 - acc: 0.9854 - val_loss: 0.0575 - val_acc: 0.9787\n",
      "Epoch 123/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0318 - acc: 0.9903WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 72s 22ms/sample - loss: 0.0624 - acc: 0.9825\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 0.03852\n",
      "81/81 [==============================] - 76s 942ms/step - loss: 0.0315 - acc: 0.9904 - val_loss: 0.0624 - val_acc: 0.9825\n",
      "Epoch 124/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0486 - acc: 0.9862WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 71s 22ms/sample - loss: 0.0468 - acc: 0.9825\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 0.03852\n",
      "81/81 [==============================] - 75s 931ms/step - loss: 0.0484 - acc: 0.9863 - val_loss: 0.0468 - val_acc: 0.9825\n",
      "Epoch 125/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0470 - acc: 0.9866WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0543 - acc: 0.9875\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 0.03852\n",
      "81/81 [==============================] - 77s 955ms/step - loss: 0.0481 - acc: 0.9863 - val_loss: 0.0543 - val_acc: 0.9875\n",
      "Epoch 126/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0402 - acc: 0.9870WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 75s 23ms/sample - loss: 0.0586 - acc: 0.9750\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 0.03852\n",
      "81/81 [==============================] - 81s 996ms/step - loss: 0.0401 - acc: 0.9870 - val_loss: 0.0586 - val_acc: 0.9750\n",
      "Epoch 127/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0414 - acc: 0.9893WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 14s 4ms/sample - loss: 0.0560 - acc: 0.9812\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 0.03852\n",
      "81/81 [==============================] - 71s 873ms/step - loss: 0.0416 - acc: 0.9891 - val_loss: 0.0560 - val_acc: 0.9812\n",
      "Epoch 128/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0368 - acc: 0.9878WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3190/3183 [==============================] - 70s 22ms/sample - loss: 0.0580 - acc: 0.9774\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 0.03852\n",
      "81/81 [==============================] - 75s 921ms/step - loss: 0.0368 - acc: 0.9876 - val_loss: 0.0580 - val_acc: 0.9774\n",
      "Epoch 129/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0447 - acc: 0.9857WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 66s 21ms/sample - loss: 0.0535 - acc: 0.9812\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 0.03852\n",
      "81/81 [==============================] - 71s 877ms/step - loss: 0.0443 - acc: 0.9860 - val_loss: 0.0535 - val_acc: 0.9812\n",
      "Epoch 130/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0455 - acc: 0.9860WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 67s 21ms/sample - loss: 0.0431 - acc: 0.9900\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 0.03852\n",
      "81/81 [==============================] - 71s 881ms/step - loss: 0.0447 - acc: 0.9863 - val_loss: 0.0431 - val_acc: 0.9900\n",
      "Epoch 131/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0377 - acc: 0.9889WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 71s 22ms/sample - loss: 0.0865 - acc: 0.9675\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 0.03852\n",
      "81/81 [==============================] - 75s 930ms/step - loss: 0.0379 - acc: 0.9888 - val_loss: 0.0865 - val_acc: 0.9675\n",
      "Epoch 132/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0489 - acc: 0.9855WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 70s 22ms/sample - loss: 0.0439 - acc: 0.9850\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 0.03852\n",
      "81/81 [==============================] - 74s 914ms/step - loss: 0.0486 - acc: 0.9857 - val_loss: 0.0439 - val_acc: 0.9850\n",
      "Epoch 133/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0458 - acc: 0.9871WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 72s 23ms/sample - loss: 0.0470 - acc: 0.9825\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 0.03852\n",
      "81/81 [==============================] - 76s 937ms/step - loss: 0.0455 - acc: 0.9873 - val_loss: 0.0470 - val_acc: 0.9825\n",
      "Epoch 134/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0405 - acc: 0.9854WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 15s 5ms/sample - loss: 0.0578 - acc: 0.9825\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 0.03852\n",
      "81/81 [==============================] - 75s 932ms/step - loss: 0.0401 - acc: 0.9857 - val_loss: 0.0578 - val_acc: 0.9825\n",
      "Epoch 135/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0352 - acc: 0.9912WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 73s 23ms/sample - loss: 0.0424 - acc: 0.9862\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 0.03852\n",
      "81/81 [==============================] - 77s 956ms/step - loss: 0.0349 - acc: 0.9913 - val_loss: 0.0424 - val_acc: 0.9862\n",
      "Epoch 136/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0323 - acc: 0.9903WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3200/3183 [==============================] - 15s 5ms/sample - loss: 0.0460 - acc: 0.9806\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 0.03852\n",
      "81/81 [==============================] - 73s 895ms/step - loss: 0.0320 - acc: 0.9904 - val_loss: 0.0460 - val_acc: 0.9806\n",
      "Epoch 137/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0423 - acc: 0.9865WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 76s 24ms/sample - loss: 0.0451 - acc: 0.9875\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 0.03852\n",
      "81/81 [==============================] - 79s 981ms/step - loss: 0.0420 - acc: 0.9867 - val_loss: 0.0451 - val_acc: 0.9875\n",
      "Epoch 138/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0290 - acc: 0.9908WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 73s 23ms/sample - loss: 0.0407 - acc: 0.9900\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 0.03852\n",
      "81/81 [==============================] - 77s 948ms/step - loss: 0.0288 - acc: 0.9910 - val_loss: 0.0407 - val_acc: 0.9900\n",
      "Epoch 139/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0275 - acc: 0.9921WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 72s 22ms/sample - loss: 0.0594 - acc: 0.9775\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 0.03852\n",
      "81/81 [==============================] - 75s 930ms/step - loss: 0.0272 - acc: 0.9922 - val_loss: 0.0594 - val_acc: 0.9775\n",
      "Epoch 140/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0377 - acc: 0.9887WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 15s 5ms/sample - loss: 0.0461 - acc: 0.9900\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 0.03852\n",
      "81/81 [==============================] - 73s 906ms/step - loss: 0.0377 - acc: 0.9888 - val_loss: 0.0461 - val_acc: 0.9900\n",
      "Epoch 141/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0462 - acc: 0.9876WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 69s 22ms/sample - loss: 0.0454 - acc: 0.9875\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 0.03852\n",
      "81/81 [==============================] - 74s 917ms/step - loss: 0.0453 - acc: 0.9879 - val_loss: 0.0454 - val_acc: 0.9875\n",
      "Epoch 142/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0463 - acc: 0.9841WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 73s 23ms/sample - loss: 0.0440 - acc: 0.9875\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 0.03852\n",
      "81/81 [==============================] - 76s 944ms/step - loss: 0.0459 - acc: 0.9842 - val_loss: 0.0440 - val_acc: 0.9875\n",
      "Epoch 143/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0351 - acc: 0.9892WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0739 - acc: 0.9688\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 0.03852\n",
      "81/81 [==============================] - 78s 966ms/step - loss: 0.0346 - acc: 0.9894 - val_loss: 0.0739 - val_acc: 0.9688\n",
      "Epoch 144/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0411 - acc: 0.9898WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 72s 22ms/sample - loss: 0.0894 - acc: 0.9650\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 0.03852\n",
      "81/81 [==============================] - 76s 938ms/step - loss: 0.0403 - acc: 0.9901 - val_loss: 0.0894 - val_acc: 0.9650\n",
      "Epoch 145/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0369 - acc: 0.9895WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 67s 21ms/sample - loss: 0.0488 - acc: 0.9859\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 0.03852\n",
      "81/81 [==============================] - 72s 885ms/step - loss: 0.0383 - acc: 0.9894 - val_loss: 0.0488 - val_acc: 0.9859\n",
      "Epoch 146/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0331 - acc: 0.9905WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.0637 - acc: 0.9775\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 0.03852\n",
      "81/81 [==============================] - 73s 902ms/step - loss: 0.0338 - acc: 0.9904 - val_loss: 0.0637 - val_acc: 0.9775\n",
      "Epoch 147/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0308 - acc: 0.9909WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 70s 22ms/sample - loss: 0.0498 - acc: 0.9900\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 0.03852\n",
      "81/81 [==============================] - 74s 919ms/step - loss: 0.0306 - acc: 0.9910 - val_loss: 0.0498 - val_acc: 0.9900\n",
      "Epoch 148/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0446 - acc: 0.9873WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 70s 22ms/sample - loss: 0.0473 - acc: 0.9875\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 0.03852\n",
      "81/81 [==============================] - 74s 915ms/step - loss: 0.0458 - acc: 0.9867 - val_loss: 0.0473 - val_acc: 0.9875\n",
      "Epoch 149/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0437 - acc: 0.9873WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 44s 14ms/sample - loss: 0.0416 - acc: 0.9850\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 0.03852\n",
      "81/81 [==============================] - 74s 909ms/step - loss: 0.0429 - acc: 0.9876 - val_loss: 0.0416 - val_acc: 0.9850\n",
      "Epoch 150/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0407 - acc: 0.9881WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 44s 14ms/sample - loss: 0.0462 - acc: 0.9850\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 0.03852\n",
      "81/81 [==============================] - 76s 933ms/step - loss: 0.0407 - acc: 0.9882 - val_loss: 0.0462 - val_acc: 0.9850\n",
      "Epoch 151/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0380 - acc: 0.9846WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 15s 5ms/sample - loss: 0.0403 - acc: 0.9862\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 0.03852\n",
      "81/81 [==============================] - 72s 895ms/step - loss: 0.0382 - acc: 0.9845 - val_loss: 0.0403 - val_acc: 0.9862\n",
      "Epoch 152/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/81 [============================>.] - ETA: 0s - loss: 0.0353 - acc: 0.9920WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 69s 22ms/sample - loss: 0.0482 - acc: 0.9837\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 0.03852\n",
      "81/81 [==============================] - 73s 903ms/step - loss: 0.0348 - acc: 0.9922 - val_loss: 0.0482 - val_acc: 0.9837\n",
      "Epoch 153/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0261 - acc: 0.9936WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 71s 22ms/sample - loss: 0.0785 - acc: 0.9737\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 0.03852\n",
      "81/81 [==============================] - 75s 930ms/step - loss: 0.0262 - acc: 0.9932 - val_loss: 0.0785 - val_acc: 0.9737\n",
      "Epoch 154/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0333 - acc: 0.9896WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 72s 22ms/sample - loss: 0.0567 - acc: 0.9725\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 0.03852\n",
      "81/81 [==============================] - 75s 928ms/step - loss: 0.0329 - acc: 0.9898 - val_loss: 0.0567 - val_acc: 0.9725\n",
      "Epoch 155/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0304 - acc: 0.9890WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 70s 22ms/sample - loss: 0.0486 - acc: 0.9800\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 0.03852\n",
      "81/81 [==============================] - 73s 904ms/step - loss: 0.0302 - acc: 0.9891 - val_loss: 0.0486 - val_acc: 0.9800\n",
      "Epoch 156/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0339 - acc: 0.9896WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 69s 21ms/sample - loss: 0.0783 - acc: 0.9725\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 0.03852\n",
      "81/81 [==============================] - 73s 901ms/step - loss: 0.0373 - acc: 0.9888 - val_loss: 0.0783 - val_acc: 0.9725\n",
      "Epoch 157/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0329 - acc: 0.9887WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 46s 14ms/sample - loss: 0.0665 - acc: 0.9809\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 0.03852\n",
      "81/81 [==============================] - 76s 940ms/step - loss: 0.0327 - acc: 0.9888 - val_loss: 0.0665 - val_acc: 0.9809\n",
      "Epoch 158/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0363 - acc: 0.9889WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 73s 23ms/sample - loss: 0.0448 - acc: 0.9925\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 0.03852\n",
      "81/81 [==============================] - 77s 948ms/step - loss: 0.0358 - acc: 0.9891 - val_loss: 0.0448 - val_acc: 0.9925\n",
      "Epoch 159/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0315 - acc: 0.9898WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 45s 14ms/sample - loss: 0.0487 - acc: 0.9916\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 0.03852\n",
      "81/81 [==============================] - 76s 944ms/step - loss: 0.0316 - acc: 0.9898 - val_loss: 0.0487 - val_acc: 0.9916\n",
      "Epoch 160/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0249 - acc: 0.9928WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 69s 22ms/sample - loss: 0.0492 - acc: 0.9859\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 0.03852\n",
      "81/81 [==============================] - 74s 912ms/step - loss: 0.0246 - acc: 0.9929 - val_loss: 0.0492 - val_acc: 0.9859\n",
      "Epoch 161/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0286 - acc: 0.9890WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 46s 14ms/sample - loss: 0.0389 - acc: 0.9850\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 0.03852\n",
      "81/81 [==============================] - 76s 944ms/step - loss: 0.0285 - acc: 0.9891 - val_loss: 0.0389 - val_acc: 0.9850\n",
      "Epoch 162/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0264 - acc: 0.9921WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 66s 21ms/sample - loss: 0.0631 - acc: 0.9775\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 0.03852\n",
      "81/81 [==============================] - 72s 891ms/step - loss: 0.0265 - acc: 0.9919 - val_loss: 0.0631 - val_acc: 0.9775\n",
      "Epoch 163/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0358 - acc: 0.9889WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 72s 22ms/sample - loss: 0.0431 - acc: 0.9934\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 0.03852\n",
      "81/81 [==============================] - 76s 936ms/step - loss: 0.0354 - acc: 0.9891 - val_loss: 0.0431 - val_acc: 0.9934\n",
      "Epoch 164/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0221 - acc: 0.9925WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 73s 23ms/sample - loss: 0.0518 - acc: 0.9875\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 0.03852\n",
      "81/81 [==============================] - 77s 952ms/step - loss: 0.0219 - acc: 0.9926 - val_loss: 0.0518 - val_acc: 0.9875\n",
      "Epoch 165/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0468 - acc: 0.9846WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 15s 5ms/sample - loss: 0.0525 - acc: 0.9925\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 0.03852\n",
      "81/81 [==============================] - 73s 905ms/step - loss: 0.0465 - acc: 0.9848 - val_loss: 0.0525 - val_acc: 0.9925\n",
      "Epoch 166/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0240 - acc: 0.9924WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0415 - acc: 0.9866\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 0.03852\n",
      "81/81 [==============================] - 74s 916ms/step - loss: 0.0240 - acc: 0.9926 - val_loss: 0.0415 - val_acc: 0.9866\n",
      "Epoch 167/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0306 - acc: 0.9918WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3200/3183 [==============================] - 47s 15ms/sample - loss: 0.0618 - acc: 0.9850\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 0.03852\n",
      "81/81 [==============================] - 78s 959ms/step - loss: 0.0305 - acc: 0.9919 - val_loss: 0.0618 - val_acc: 0.9850\n",
      "Epoch 168/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0281 - acc: 0.9930WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 75s 23ms/sample - loss: 0.0448 - acc: 0.9900\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 0.03852\n",
      "81/81 [==============================] - 79s 977ms/step - loss: 0.0276 - acc: 0.9932 - val_loss: 0.0448 - val_acc: 0.9900\n",
      "Epoch 169/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0234 - acc: 0.9947WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 74s 23ms/sample - loss: 0.0522 - acc: 0.9906\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 0.03852\n",
      "81/81 [==============================] - 79s 972ms/step - loss: 0.0232 - acc: 0.9947 - val_loss: 0.0522 - val_acc: 0.9906\n",
      "Epoch 170/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0343 - acc: 0.9925WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 47s 15ms/sample - loss: 0.0580 - acc: 0.9850\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 0.03852\n",
      "81/81 [==============================] - 79s 977ms/step - loss: 0.0339 - acc: 0.9926 - val_loss: 0.0580 - val_acc: 0.9850\n",
      "Epoch 171/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0202 - acc: 0.9934WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 78s 24ms/sample - loss: 0.0461 - acc: 0.9825\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 0.03852\n",
      "81/81 [==============================] - 84s 1s/step - loss: 0.0215 - acc: 0.9932 - val_loss: 0.0461 - val_acc: 0.9825\n",
      "Epoch 172/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0378 - acc: 0.9870WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 73s 23ms/sample - loss: 0.0529 - acc: 0.9894\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 0.03852\n",
      "81/81 [==============================] - 77s 953ms/step - loss: 0.0373 - acc: 0.9873 - val_loss: 0.0529 - val_acc: 0.9894\n",
      "Epoch 173/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0328 - acc: 0.9898WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 73s 23ms/sample - loss: 0.0577 - acc: 0.9831\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 0.03852\n",
      "81/81 [==============================] - 77s 954ms/step - loss: 0.0322 - acc: 0.9901 - val_loss: 0.0577 - val_acc: 0.9831\n",
      "Epoch 174/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0264 - acc: 0.9914WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 67s 21ms/sample - loss: 0.0426 - acc: 0.9850\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 0.03852\n",
      "81/81 [==============================] - 76s 941ms/step - loss: 0.0259 - acc: 0.9916 - val_loss: 0.0426 - val_acc: 0.9850\n",
      "Epoch 175/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0267 - acc: 0.9925WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 69s 22ms/sample - loss: 0.0622 - acc: 0.9809\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 0.03852\n",
      "81/81 [==============================] - 73s 897ms/step - loss: 0.0275 - acc: 0.9919 - val_loss: 0.0622 - val_acc: 0.9809\n",
      "Epoch 176/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0265 - acc: 0.9918WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 73s 23ms/sample - loss: 0.0537 - acc: 0.9825\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 0.03852\n",
      "81/81 [==============================] - 77s 951ms/step - loss: 0.0264 - acc: 0.9919 - val_loss: 0.0537 - val_acc: 0.9825\n",
      "Epoch 177/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0218 - acc: 0.9940WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 71s 22ms/sample - loss: 0.0741 - acc: 0.9775\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 0.03852\n",
      "81/81 [==============================] - 78s 968ms/step - loss: 0.0215 - acc: 0.9941 - val_loss: 0.0741 - val_acc: 0.9775\n",
      "Epoch 178/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0258 - acc: 0.9914WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0974 - acc: 0.9678\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 0.03852\n",
      "81/81 [==============================] - 75s 930ms/step - loss: 0.0256 - acc: 0.9916 - val_loss: 0.0974 - val_acc: 0.9678\n",
      "Epoch 179/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0176 - acc: 0.9952WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 73s 23ms/sample - loss: 0.0515 - acc: 0.9869\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 0.03852\n",
      "81/81 [==============================] - 77s 950ms/step - loss: 0.0175 - acc: 0.9953 - val_loss: 0.0515 - val_acc: 0.9869\n",
      "Epoch 180/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0304 - acc: 0.9909WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 71s 22ms/sample - loss: 0.0612 - acc: 0.9809\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 0.03852\n",
      "81/81 [==============================] - 76s 934ms/step - loss: 0.0302 - acc: 0.9910 - val_loss: 0.0612 - val_acc: 0.9809\n",
      "Epoch 181/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0278 - acc: 0.9915WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 70s 22ms/sample - loss: 0.0479 - acc: 0.9859\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 0.03852\n",
      "81/81 [==============================] - 77s 955ms/step - loss: 0.0275 - acc: 0.9916 - val_loss: 0.0479 - val_acc: 0.9859\n",
      "Epoch 182/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0240 - acc: 0.9911WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0599 - acc: 0.9837\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 0.03852\n",
      "81/81 [==============================] - 74s 917ms/step - loss: 0.0235 - acc: 0.9913 - val_loss: 0.0599 - val_acc: 0.9837\n",
      "Epoch 183/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/81 [============================>.] - ETA: 0s - loss: 0.0288 - acc: 0.9925WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 72s 22ms/sample - loss: 0.0466 - acc: 0.9906\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 0.03852\n",
      "81/81 [==============================] - 78s 960ms/step - loss: 0.0285 - acc: 0.9926 - val_loss: 0.0466 - val_acc: 0.9906\n",
      "Epoch 184/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0386 - acc: 0.9865WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 74s 23ms/sample - loss: 0.0887 - acc: 0.9787\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 0.03852\n",
      "81/81 [==============================] - 78s 964ms/step - loss: 0.0386 - acc: 0.9863 - val_loss: 0.0887 - val_acc: 0.9787\n",
      "Epoch 185/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0260 - acc: 0.9905WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 72s 23ms/sample - loss: 0.0515 - acc: 0.9850\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 0.03852\n",
      "81/81 [==============================] - 76s 938ms/step - loss: 0.0265 - acc: 0.9904 - val_loss: 0.0515 - val_acc: 0.9850\n",
      "Epoch 186/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0377 - acc: 0.9877WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 72s 22ms/sample - loss: 0.0607 - acc: 0.9809\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 0.03852\n",
      "81/81 [==============================] - 76s 933ms/step - loss: 0.0374 - acc: 0.9879 - val_loss: 0.0607 - val_acc: 0.9809\n",
      "Epoch 187/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0268 - acc: 0.9924WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 73s 23ms/sample - loss: 0.0576 - acc: 0.9862\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 0.03852\n",
      "81/81 [==============================] - 77s 948ms/step - loss: 0.0264 - acc: 0.9926 - val_loss: 0.0576 - val_acc: 0.9862\n",
      "Epoch 188/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0260 - acc: 0.9946WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.0456 - acc: 0.9916\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 0.03852\n",
      "81/81 [==============================] - 73s 899ms/step - loss: 0.0256 - acc: 0.9947 - val_loss: 0.0456 - val_acc: 0.9916\n",
      "Epoch 189/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0192 - acc: 0.9956WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 47s 15ms/sample - loss: 0.0497 - acc: 0.9875\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 0.03852\n",
      "81/81 [==============================] - 78s 961ms/step - loss: 0.0191 - acc: 0.9957 - val_loss: 0.0497 - val_acc: 0.9875\n",
      "Epoch 190/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0387 - acc: 0.9899WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 73s 23ms/sample - loss: 0.0529 - acc: 0.9881\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 0.03852\n",
      "81/81 [==============================] - 77s 948ms/step - loss: 0.0391 - acc: 0.9894 - val_loss: 0.0529 - val_acc: 0.9881\n",
      "Epoch 191/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0284 - acc: 0.9906WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 68s 21ms/sample - loss: 0.0529 - acc: 0.9875\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 0.03852\n",
      "81/81 [==============================] - 75s 924ms/step - loss: 0.0299 - acc: 0.9901 - val_loss: 0.0529 - val_acc: 0.9875\n",
      "Epoch 192/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0138 - acc: 0.9972WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.0622 - acc: 0.9825\n",
      "\n",
      "Epoch 00192: val_loss did not improve from 0.03852\n",
      "81/81 [==============================] - 73s 897ms/step - loss: 0.0137 - acc: 0.9972 - val_loss: 0.0622 - val_acc: 0.9825\n",
      "Epoch 193/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0190 - acc: 0.9950WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 72s 23ms/sample - loss: 0.0532 - acc: 0.9891\n",
      "\n",
      "Epoch 00193: val_loss did not improve from 0.03852\n",
      "81/81 [==============================] - 76s 940ms/step - loss: 0.0188 - acc: 0.9950 - val_loss: 0.0532 - val_acc: 0.9891\n",
      "Epoch 194/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0235 - acc: 0.9924WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 68s 21ms/sample - loss: 0.0473 - acc: 0.9862\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 0.03852\n",
      "81/81 [==============================] - 76s 935ms/step - loss: 0.0235 - acc: 0.9922 - val_loss: 0.0473 - val_acc: 0.9862\n",
      "Epoch 195/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0197 - acc: 0.9934WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 74s 23ms/sample - loss: 0.0499 - acc: 0.9875\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 0.03852\n",
      "81/81 [==============================] - 77s 955ms/step - loss: 0.0195 - acc: 0.9935 - val_loss: 0.0499 - val_acc: 0.9875\n",
      "Epoch 196/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0274 - acc: 0.9914WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 47s 15ms/sample - loss: 0.1288 - acc: 0.9534\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 0.03852\n",
      "81/81 [==============================] - 78s 962ms/step - loss: 0.0269 - acc: 0.9916 - val_loss: 0.1288 - val_acc: 0.9534\n",
      "Epoch 197/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0273 - acc: 0.9908WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 71s 22ms/sample - loss: 0.0564 - acc: 0.9900\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 0.03852\n",
      "81/81 [==============================] - 76s 941ms/step - loss: 0.0270 - acc: 0.9910 - val_loss: 0.0564 - val_acc: 0.9900\n",
      "Epoch 198/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0212 - acc: 0.9959WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3200/3183 [==============================] - 44s 14ms/sample - loss: 0.0608 - acc: 0.9850\n",
      "\n",
      "Epoch 00198: val_loss did not improve from 0.03852\n",
      "81/81 [==============================] - 76s 942ms/step - loss: 0.0208 - acc: 0.9960 - val_loss: 0.0608 - val_acc: 0.9850\n",
      "Epoch 199/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0231 - acc: 0.9936WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 15s 5ms/sample - loss: 0.0571 - acc: 0.9847\n",
      "\n",
      "Epoch 00199: val_loss did not improve from 0.03852\n",
      "81/81 [==============================] - 76s 943ms/step - loss: 0.0239 - acc: 0.9935 - val_loss: 0.0571 - val_acc: 0.9847\n",
      "Epoch 200/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0234 - acc: 0.9952WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 73s 23ms/sample - loss: 0.0464 - acc: 0.9891\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 0.03852\n",
      "81/81 [==============================] - 77s 955ms/step - loss: 0.0239 - acc: 0.9950 - val_loss: 0.0464 - val_acc: 0.9891\n",
      "Epoch 201/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0239 - acc: 0.9930WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 73s 23ms/sample - loss: 0.0498 - acc: 0.9894\n",
      "\n",
      "Epoch 00201: val_loss did not improve from 0.03852\n",
      "81/81 [==============================] - 78s 962ms/step - loss: 0.0234 - acc: 0.9932 - val_loss: 0.0498 - val_acc: 0.9894\n",
      "Epoch 202/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0200 - acc: 0.9950WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 48s 15ms/sample - loss: 0.0504 - acc: 0.9919\n",
      "\n",
      "Epoch 00202: val_loss did not improve from 0.03852\n",
      "81/81 [==============================] - 78s 964ms/step - loss: 0.0197 - acc: 0.9950 - val_loss: 0.0504 - val_acc: 0.9919\n",
      "Epoch 203/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0244 - acc: 0.9920WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 73s 23ms/sample - loss: 0.0493 - acc: 0.9834\n",
      "\n",
      "Epoch 00203: val_loss did not improve from 0.03852\n",
      "81/81 [==============================] - 77s 950ms/step - loss: 0.0245 - acc: 0.9919 - val_loss: 0.0493 - val_acc: 0.9834\n",
      "Epoch 204/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0282 - acc: 0.9914WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 74s 23ms/sample - loss: 0.0434 - acc: 0.9900\n",
      "\n",
      "Epoch 00204: val_loss did not improve from 0.03852\n",
      "81/81 [==============================] - 78s 969ms/step - loss: 0.0275 - acc: 0.9916 - val_loss: 0.0434 - val_acc: 0.9900\n",
      "Epoch 205/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0342 - acc: 0.9903WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 14s 4ms/sample - loss: 0.0541 - acc: 0.9809\n",
      "\n",
      "Epoch 00205: val_loss did not improve from 0.03852\n",
      "81/81 [==============================] - 76s 937ms/step - loss: 0.0339 - acc: 0.9904 - val_loss: 0.0541 - val_acc: 0.9809\n",
      "Epoch 206/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0253 - acc: 0.9920WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 72s 23ms/sample - loss: 0.0525 - acc: 0.9900\n",
      "\n",
      "Epoch 00206: val_loss did not improve from 0.03852\n",
      "81/81 [==============================] - 76s 935ms/step - loss: 0.0248 - acc: 0.9922 - val_loss: 0.0525 - val_acc: 0.9900\n",
      "Epoch 207/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0221 - acc: 0.9931WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 72s 22ms/sample - loss: 0.0409 - acc: 0.9875\n",
      "\n",
      "Epoch 00207: val_loss did not improve from 0.03852\n",
      "81/81 [==============================] - 77s 955ms/step - loss: 0.0219 - acc: 0.9932 - val_loss: 0.0409 - val_acc: 0.9875\n",
      "Epoch 208/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0182 - acc: 0.9950WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 72s 23ms/sample - loss: 0.0519 - acc: 0.9897\n",
      "\n",
      "Epoch 00208: val_loss did not improve from 0.03852\n",
      "81/81 [==============================] - 76s 944ms/step - loss: 0.0185 - acc: 0.9947 - val_loss: 0.0519 - val_acc: 0.9897\n",
      "Epoch 209/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0195 - acc: 0.9943WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 70s 22ms/sample - loss: 0.0406 - acc: 0.9900\n",
      "\n",
      "Epoch 00209: val_loss did not improve from 0.03852\n",
      "81/81 [==============================] - 75s 928ms/step - loss: 0.0193 - acc: 0.9944 - val_loss: 0.0406 - val_acc: 0.9900\n",
      "Epoch 210/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0181 - acc: 0.9946WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 74s 23ms/sample - loss: 0.0657 - acc: 0.9853\n",
      "\n",
      "Epoch 00210: val_loss did not improve from 0.03852\n",
      "81/81 [==============================] - 79s 972ms/step - loss: 0.0179 - acc: 0.9947 - val_loss: 0.0657 - val_acc: 0.9853\n",
      "Epoch 211/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0204 - acc: 0.9953WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 47s 15ms/sample - loss: 0.0603 - acc: 0.9897\n",
      "\n",
      "Epoch 00211: val_loss did not improve from 0.03852\n",
      "81/81 [==============================] - 78s 960ms/step - loss: 0.0202 - acc: 0.9953 - val_loss: 0.0603 - val_acc: 0.9897\n",
      "Epoch 212/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0240 - acc: 0.9936WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 69s 22ms/sample - loss: 0.0586 - acc: 0.9822\n",
      "\n",
      "Epoch 00212: val_loss did not improve from 0.03852\n",
      "81/81 [==============================] - 76s 938ms/step - loss: 0.0237 - acc: 0.9938 - val_loss: 0.0586 - val_acc: 0.9822\n",
      "Epoch 213/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0272 - acc: 0.9934WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 71s 22ms/sample - loss: 0.0699 - acc: 0.9834\n",
      "\n",
      "Epoch 00213: val_loss did not improve from 0.03852\n",
      "81/81 [==============================] - 75s 931ms/step - loss: 0.0271 - acc: 0.9935 - val_loss: 0.0699 - val_acc: 0.9834\n",
      "Epoch 214/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/81 [============================>.] - ETA: 0s - loss: 0.0208 - acc: 0.9950WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 74s 23ms/sample - loss: 0.0526 - acc: 0.9875\n",
      "\n",
      "Epoch 00214: val_loss did not improve from 0.03852\n",
      "81/81 [==============================] - 77s 955ms/step - loss: 0.0206 - acc: 0.9950 - val_loss: 0.0526 - val_acc: 0.9875\n",
      "Epoch 215/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0295 - acc: 0.9917WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 15s 5ms/sample - loss: 0.0761 - acc: 0.9753\n",
      "\n",
      "Epoch 00215: val_loss did not improve from 0.03852\n",
      "81/81 [==============================] - 75s 920ms/step - loss: 0.0290 - acc: 0.9919 - val_loss: 0.0761 - val_acc: 0.9753\n",
      "Epoch 216/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0268 - acc: 0.9934WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0510 - acc: 0.9894\n",
      "\n",
      "Epoch 00216: val_loss did not improve from 0.03852\n",
      "81/81 [==============================] - 78s 957ms/step - loss: 0.0269 - acc: 0.9935 - val_loss: 0.0510 - val_acc: 0.9894\n",
      "\n",
      "vis_imagenet_6_class_augmentation_2D_CNN_custom_ch_32_DO_050_DO_3_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3183/3183 [==============================] - 3s 1ms/sample - loss: 10.6577 - acc: 0.3365\n",
      "Loss: 10.657696457540672 Accuracy: 0.336475\n",
      "\n",
      "Epoch 1/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.8211 - acc: 0.5292WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 47s 15ms/sample - loss: 0.7991 - acc: 0.2084\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.79913, saving model to model/checkpoint/vis_imagenet_6_class_augmentation_2D_CNN_custom_ch_32_DO_050_DO_4_conv_checkpoint/001-0.7991.hdf5\n",
      "81/81 [==============================] - 54s 666ms/step - loss: 0.8186 - acc: 0.5317 - val_loss: 0.7991 - val_acc: 0.2084\n",
      "Epoch 2/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.6135 - acc: 0.6715WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 70s 22ms/sample - loss: 0.3795 - acc: 0.8794\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.79913 to 0.37954, saving model to model/checkpoint/vis_imagenet_6_class_augmentation_2D_CNN_custom_ch_32_DO_050_DO_4_conv_checkpoint/002-0.3795.hdf5\n",
      "81/81 [==============================] - 75s 923ms/step - loss: 0.6112 - acc: 0.6747 - val_loss: 0.3795 - val_acc: 0.8794\n",
      "Epoch 3/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.4584 - acc: 0.7987WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3190/3183 [==============================] - 67s 21ms/sample - loss: 0.4340 - acc: 0.8154\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.37954\n",
      "81/81 [==============================] - 78s 957ms/step - loss: 0.4579 - acc: 0.7989 - val_loss: 0.4340 - val_acc: 0.8154\n",
      "Epoch 4/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.3767 - acc: 0.8435WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 49s 15ms/sample - loss: 0.4914 - acc: 0.73783s - los\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.37954\n",
      "81/81 [==============================] - 80s 984ms/step - loss: 0.3767 - acc: 0.8436 - val_loss: 0.4914 - val_acc: 0.7378\n",
      "Epoch 5/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.3207 - acc: 0.8737WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 71s 22ms/sample - loss: 0.3457 - acc: 0.8469\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.37954 to 0.34571, saving model to model/checkpoint/vis_imagenet_6_class_augmentation_2D_CNN_custom_ch_32_DO_050_DO_4_conv_checkpoint/005-0.3457.hdf5\n",
      "81/81 [==============================] - 79s 973ms/step - loss: 0.3195 - acc: 0.8749 - val_loss: 0.3457 - val_acc: 0.8469\n",
      "Epoch 6/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.3004 - acc: 0.8740WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 67s 21ms/sample - loss: 0.4805 - acc: 0.7375\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.34571\n",
      "81/81 [==============================] - 73s 899ms/step - loss: 0.3013 - acc: 0.8727 - val_loss: 0.4805 - val_acc: 0.7375\n",
      "Epoch 7/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.2775 - acc: 0.8934WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 70s 22ms/sample - loss: 0.2264 - acc: 0.9106\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.34571 to 0.22637, saving model to model/checkpoint/vis_imagenet_6_class_augmentation_2D_CNN_custom_ch_32_DO_050_DO_4_conv_checkpoint/007-0.2264.hdf5\n",
      "81/81 [==============================] - 81s 1s/step - loss: 0.2752 - acc: 0.8942 - val_loss: 0.2264 - val_acc: 0.9106\n",
      "Epoch 8/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.2426 - acc: 0.9059WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3190/3183 [==============================] - 73s 23ms/sample - loss: 0.2606 - acc: 0.8840\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.22637\n",
      "81/81 [==============================] - 78s 966ms/step - loss: 0.2420 - acc: 0.9066 - val_loss: 0.2606 - val_acc: 0.8840\n",
      "Epoch 9/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.2116 - acc: 0.9208WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 73s 23ms/sample - loss: 0.0815 - acc: 0.9691\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.22637 to 0.08147, saving model to model/checkpoint/vis_imagenet_6_class_augmentation_2D_CNN_custom_ch_32_DO_050_DO_4_conv_checkpoint/009-0.0815.hdf5\n",
      "81/81 [==============================] - 78s 968ms/step - loss: 0.2116 - acc: 0.9205 - val_loss: 0.0815 - val_acc: 0.9691\n",
      "Epoch 10/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.2343 - acc: 0.9079WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 73s 23ms/sample - loss: 0.3012 - acc: 0.8872\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.08147\n",
      "81/81 [==============================] - 78s 963ms/step - loss: 0.2339 - acc: 0.9081 - val_loss: 0.3012 - val_acc: 0.8872\n",
      "Epoch 11/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.2137 - acc: 0.9185WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 79s 25ms/sample - loss: 0.1472 - acc: 0.9450\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.08147\n",
      "81/81 [==============================] - 85s 1s/step - loss: 0.2127 - acc: 0.9190 - val_loss: 0.1472 - val_acc: 0.9450\n",
      "Epoch 12/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.2064 - acc: 0.9177WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 73s 23ms/sample - loss: 0.1738 - acc: 0.9450\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.08147\n",
      "81/81 [==============================] - 79s 973ms/step - loss: 0.2048 - acc: 0.9184 - val_loss: 0.1738 - val_acc: 0.9450\n",
      "Epoch 13/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.1825 - acc: 0.9281WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 47s 15ms/sample - loss: 0.2696 - acc: 0.8900\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.08147\n",
      "81/81 [==============================] - 76s 937ms/step - loss: 0.1840 - acc: 0.9277 - val_loss: 0.2696 - val_acc: 0.8900\n",
      "Epoch 14/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.1543 - acc: 0.9412WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 71s 22ms/sample - loss: 0.1219 - acc: 0.9500\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.08147\n",
      "81/81 [==============================] - 77s 953ms/step - loss: 0.1541 - acc: 0.9407 - val_loss: 0.1219 - val_acc: 0.9500\n",
      "Epoch 15/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/81 [============================>.] - ETA: 0s - loss: 0.1672 - acc: 0.9375WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 72s 23ms/sample - loss: 0.2152 - acc: 0.9109\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.08147\n",
      "81/81 [==============================] - 78s 957ms/step - loss: 0.1677 - acc: 0.9373 - val_loss: 0.2152 - val_acc: 0.9109\n",
      "Epoch 16/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.1442 - acc: 0.9491WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 56s 18ms/sample - loss: 0.1158 - acc: 0.9600\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.08147\n",
      "81/81 [==============================] - 86s 1s/step - loss: 0.1452 - acc: 0.9488 - val_loss: 0.1158 - val_acc: 0.9600\n",
      "Epoch 17/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.1592 - acc: 0.9444WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 70s 22ms/sample - loss: 0.1878 - acc: 0.9306\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.08147\n",
      "81/81 [==============================] - 78s 968ms/step - loss: 0.1606 - acc: 0.9438 - val_loss: 0.1878 - val_acc: 0.9306\n",
      "Epoch 18/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.1306 - acc: 0.9516WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 72s 23ms/sample - loss: 0.0648 - acc: 0.9778\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.08147 to 0.06484, saving model to model/checkpoint/vis_imagenet_6_class_augmentation_2D_CNN_custom_ch_32_DO_050_DO_4_conv_checkpoint/018-0.0648.hdf5\n",
      "81/81 [==============================] - 81s 1s/step - loss: 0.1308 - acc: 0.9510 - val_loss: 0.0648 - val_acc: 0.9778\n",
      "Epoch 19/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.1146 - acc: 0.9604WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 72s 23ms/sample - loss: 0.0949 - acc: 0.9684\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.06484\n",
      "81/81 [==============================] - 76s 942ms/step - loss: 0.1146 - acc: 0.9606 - val_loss: 0.0949 - val_acc: 0.9684\n",
      "Epoch 20/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.1370 - acc: 0.9478WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 50s 16ms/sample - loss: 0.2430 - acc: 0.9125\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.06484\n",
      "81/81 [==============================] - 80s 985ms/step - loss: 0.1371 - acc: 0.9475 - val_loss: 0.2430 - val_acc: 0.9125\n",
      "Epoch 21/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.1304 - acc: 0.9548WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 74s 23ms/sample - loss: 0.0862 - acc: 0.9737\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.06484\n",
      "81/81 [==============================] - 81s 996ms/step - loss: 0.1297 - acc: 0.9553 - val_loss: 0.0862 - val_acc: 0.9737\n",
      "Epoch 22/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.1593 - acc: 0.9418WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 72s 22ms/sample - loss: 0.1367 - acc: 0.9494\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.06484\n",
      "81/81 [==============================] - 77s 945ms/step - loss: 0.1570 - acc: 0.9429 - val_loss: 0.1367 - val_acc: 0.9494\n",
      "Epoch 23/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.1333 - acc: 0.9570WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 74s 23ms/sample - loss: 0.0906 - acc: 0.9675\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.06484\n",
      "81/81 [==============================] - 80s 985ms/step - loss: 0.1324 - acc: 0.9572 - val_loss: 0.0906 - val_acc: 0.9675\n",
      "Epoch 24/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.1317 - acc: 0.9500WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 47s 15ms/sample - loss: 0.2267 - acc: 0.9128\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.06484\n",
      "81/81 [==============================] - 80s 983ms/step - loss: 0.1323 - acc: 0.9503 - val_loss: 0.2267 - val_acc: 0.9128\n",
      "Epoch 25/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.1131 - acc: 0.9613WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.0651 - acc: 0.9831\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.06484\n",
      "81/81 [==============================] - 79s 972ms/step - loss: 0.1149 - acc: 0.9603 - val_loss: 0.0651 - val_acc: 0.9831\n",
      "Epoch 26/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.1108 - acc: 0.9601WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 70s 22ms/sample - loss: 0.1210 - acc: 0.9588\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.06484\n",
      "81/81 [==============================] - 76s 934ms/step - loss: 0.1124 - acc: 0.9593 - val_loss: 0.1210 - val_acc: 0.9588\n",
      "Epoch 27/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.1271 - acc: 0.9560WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 73s 23ms/sample - loss: 0.1127 - acc: 0.9644\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.06484\n",
      "81/81 [==============================] - 78s 964ms/step - loss: 0.1264 - acc: 0.9562 - val_loss: 0.1127 - val_acc: 0.9644\n",
      "Epoch 28/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.1288 - acc: 0.9544WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 20s 6ms/sample - loss: 0.0764 - acc: 0.9762\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.06484\n",
      "81/81 [==============================] - 77s 946ms/step - loss: 0.1292 - acc: 0.9538 - val_loss: 0.0764 - val_acc: 0.9762\n",
      "Epoch 29/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.1368 - acc: 0.9484WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 69s 21ms/sample - loss: 0.0902 - acc: 0.9775\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.06484\n",
      "81/81 [==============================] - 73s 903ms/step - loss: 0.1372 - acc: 0.9485 - val_loss: 0.0902 - val_acc: 0.9775\n",
      "Epoch 30/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.1357 - acc: 0.9491WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3200/3183 [==============================] - 73s 23ms/sample - loss: 0.0571 - acc: 0.9800\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.06484 to 0.05710, saving model to model/checkpoint/vis_imagenet_6_class_augmentation_2D_CNN_custom_ch_32_DO_050_DO_4_conv_checkpoint/030-0.0571.hdf5\n",
      "81/81 [==============================] - 77s 948ms/step - loss: 0.1346 - acc: 0.9491 - val_loss: 0.0571 - val_acc: 0.9800\n",
      "Epoch 31/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.1280 - acc: 0.9544WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 71s 22ms/sample - loss: 0.1012 - acc: 0.9619\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.05710\n",
      "81/81 [==============================] - 77s 949ms/step - loss: 0.1270 - acc: 0.9550 - val_loss: 0.1012 - val_acc: 0.9619\n",
      "Epoch 32/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.1133 - acc: 0.9576WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.1748 - acc: 0.9269\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.05710\n",
      "81/81 [==============================] - 74s 916ms/step - loss: 0.1129 - acc: 0.9578 - val_loss: 0.1748 - val_acc: 0.9269\n",
      "Epoch 33/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0986 - acc: 0.9621WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 70s 22ms/sample - loss: 0.1305 - acc: 0.9450\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.05710\n",
      "81/81 [==============================] - 74s 914ms/step - loss: 0.1004 - acc: 0.9615 - val_loss: 0.1305 - val_acc: 0.9450\n",
      "Epoch 34/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0930 - acc: 0.9632WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 73s 23ms/sample - loss: 0.0913 - acc: 0.9712\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.05710\n",
      "81/81 [==============================] - 76s 940ms/step - loss: 0.0922 - acc: 0.9637 - val_loss: 0.0913 - val_acc: 0.9712\n",
      "Epoch 35/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.1042 - acc: 0.9620WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.1761 - acc: 0.9347\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.05710\n",
      "81/81 [==============================] - 78s 967ms/step - loss: 0.1042 - acc: 0.9618 - val_loss: 0.1761 - val_acc: 0.9347\n",
      "Epoch 36/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.1204 - acc: 0.9525WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 71s 22ms/sample - loss: 0.1339 - acc: 0.9453\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.05710\n",
      "81/81 [==============================] - 76s 934ms/step - loss: 0.1199 - acc: 0.9528 - val_loss: 0.1339 - val_acc: 0.9453\n",
      "Epoch 37/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.1145 - acc: 0.9570WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 66s 21ms/sample - loss: 0.0822 - acc: 0.9744\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.05710\n",
      "81/81 [==============================] - 73s 899ms/step - loss: 0.1182 - acc: 0.9562 - val_loss: 0.0822 - val_acc: 0.9744\n",
      "Epoch 38/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.1122 - acc: 0.9593WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 72s 22ms/sample - loss: 0.0729 - acc: 0.9759\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.05710\n",
      "81/81 [==============================] - 77s 945ms/step - loss: 0.1122 - acc: 0.9590 - val_loss: 0.0729 - val_acc: 0.9759\n",
      "Epoch 39/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.1016 - acc: 0.9683WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 46s 14ms/sample - loss: 0.1996 - acc: 0.9200\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.05710\n",
      "81/81 [==============================] - 77s 952ms/step - loss: 0.1025 - acc: 0.9680 - val_loss: 0.1996 - val_acc: 0.9200\n",
      "Epoch 40/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.1036 - acc: 0.9623WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 15s 5ms/sample - loss: 0.0695 - acc: 0.9737\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.05710\n",
      "81/81 [==============================] - 78s 962ms/step - loss: 0.1038 - acc: 0.9624 - val_loss: 0.0695 - val_acc: 0.9737\n",
      "Epoch 41/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.1053 - acc: 0.9623WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 72s 22ms/sample - loss: 0.0998 - acc: 0.9681\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.05710\n",
      "81/81 [==============================] - 77s 957ms/step - loss: 0.1044 - acc: 0.9628 - val_loss: 0.0998 - val_acc: 0.9681\n",
      "Epoch 42/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0904 - acc: 0.9673WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 73s 23ms/sample - loss: 0.1096 - acc: 0.9566\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.05710\n",
      "81/81 [==============================] - 77s 947ms/step - loss: 0.0903 - acc: 0.9671 - val_loss: 0.1096 - val_acc: 0.9566\n",
      "Epoch 43/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0980 - acc: 0.9657WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 73s 23ms/sample - loss: 0.0750 - acc: 0.9638\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.05710\n",
      "81/81 [==============================] - 78s 963ms/step - loss: 0.0974 - acc: 0.9662 - val_loss: 0.0750 - val_acc: 0.9638\n",
      "Epoch 44/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0994 - acc: 0.9689WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 70s 22ms/sample - loss: 0.0640 - acc: 0.9750\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.05710\n",
      "81/81 [==============================] - 76s 940ms/step - loss: 0.0986 - acc: 0.9693 - val_loss: 0.0640 - val_acc: 0.9750\n",
      "Epoch 45/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0895 - acc: 0.9667WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 75s 24ms/sample - loss: 0.0455 - acc: 0.9869\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.05710 to 0.04549, saving model to model/checkpoint/vis_imagenet_6_class_augmentation_2D_CNN_custom_ch_32_DO_050_DO_4_conv_checkpoint/045-0.0455.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81/81 [==============================] - 79s 979ms/step - loss: 0.0893 - acc: 0.9668 - val_loss: 0.0455 - val_acc: 0.9869\n",
      "Epoch 46/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0834 - acc: 0.9726WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0987 - acc: 0.9688\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.04549\n",
      "81/81 [==============================] - 76s 941ms/step - loss: 0.0832 - acc: 0.9718 - val_loss: 0.0987 - val_acc: 0.9688\n",
      "Epoch 47/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0875 - acc: 0.9711WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.1234 - acc: 0.9513\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.04549\n",
      "81/81 [==============================] - 80s 982ms/step - loss: 0.0867 - acc: 0.9714 - val_loss: 0.1234 - val_acc: 0.9513\n",
      "Epoch 48/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0932 - acc: 0.9618WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 75s 23ms/sample - loss: 0.0741 - acc: 0.9706\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.04549\n",
      "81/81 [==============================] - 80s 984ms/step - loss: 0.0938 - acc: 0.9618 - val_loss: 0.0741 - val_acc: 0.9706\n",
      "Epoch 49/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.1091 - acc: 0.9637WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 73s 23ms/sample - loss: 0.0650 - acc: 0.9725\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.04549\n",
      "81/81 [==============================] - 77s 949ms/step - loss: 0.1070 - acc: 0.9646 - val_loss: 0.0650 - val_acc: 0.9725\n",
      "Epoch 50/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0844 - acc: 0.9720WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 75s 24ms/sample - loss: 0.1202 - acc: 0.9528\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.04549\n",
      "81/81 [==============================] - 79s 981ms/step - loss: 0.0838 - acc: 0.9724 - val_loss: 0.1202 - val_acc: 0.9528\n",
      "Epoch 51/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0900 - acc: 0.9650WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - ETA: 0s - loss: 0.1709 - acc: 0.9294  ETA: 10s - loss: 0.1684 - a - 52s 16ms/sample - loss: 0.1697 - acc: 0.9300\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.04549\n",
      "81/81 [==============================] - 83s 1s/step - loss: 0.0913 - acc: 0.9649 - val_loss: 0.1697 - val_acc: 0.9300\n",
      "Epoch 52/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0793 - acc: 0.9701WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - ETA: 0s - loss: 0.1722 - acc: 0.941 - 18s 6ms/sample - loss: 0.1693 - acc: 0.9425\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.04549\n",
      "81/81 [==============================] - 78s 957ms/step - loss: 0.0800 - acc: 0.9699 - val_loss: 0.1693 - val_acc: 0.9425\n",
      "Epoch 53/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0871 - acc: 0.9691WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0514 - acc: 0.9822\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.04549\n",
      "81/81 [==============================] - 75s 928ms/step - loss: 0.0868 - acc: 0.9690 - val_loss: 0.0514 - val_acc: 0.9822\n",
      "Epoch 54/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0796 - acc: 0.9723WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 72s 22ms/sample - loss: 0.2217 - acc: 0.9156\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.04549\n",
      "81/81 [==============================] - 77s 956ms/step - loss: 0.0805 - acc: 0.9727 - val_loss: 0.2217 - val_acc: 0.9156\n",
      "Epoch 55/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0979 - acc: 0.9656WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 67s 21ms/sample - loss: 0.1247 - acc: 0.9475\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.04549\n",
      "81/81 [==============================] - 75s 931ms/step - loss: 0.0964 - acc: 0.9665 - val_loss: 0.1247 - val_acc: 0.9475\n",
      "Epoch 56/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0856 - acc: 0.9679WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 83s 26ms/sample - loss: 0.0958 - acc: 0.9600\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.04549\n",
      "81/81 [==============================] - 87s 1s/step - loss: 0.0856 - acc: 0.9680 - val_loss: 0.0958 - val_acc: 0.9600\n",
      "Epoch 57/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.1091 - acc: 0.9624WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 47s 15ms/sample - loss: 0.0546 - acc: 0.9841\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.04549\n",
      "81/81 [==============================] - 79s 978ms/step - loss: 0.1074 - acc: 0.9634 - val_loss: 0.0546 - val_acc: 0.9841\n",
      "Epoch 58/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0962 - acc: 0.9664WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 73s 23ms/sample - loss: 0.0763 - acc: 0.9681\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.04549\n",
      "81/81 [==============================] - 78s 957ms/step - loss: 0.0957 - acc: 0.9665 - val_loss: 0.0763 - val_acc: 0.9681\n",
      "Epoch 59/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0763 - acc: 0.9729WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 72s 23ms/sample - loss: 0.0603 - acc: 0.9806\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.04549\n",
      "81/81 [==============================] - 78s 959ms/step - loss: 0.0762 - acc: 0.9733 - val_loss: 0.0603 - val_acc: 0.9806\n",
      "Epoch 60/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0796 - acc: 0.9698WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 15s 5ms/sample - loss: 0.0667 - acc: 0.9688\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.04549\n",
      "81/81 [==============================] - 76s 944ms/step - loss: 0.0792 - acc: 0.9702 - val_loss: 0.0667 - val_acc: 0.9688\n",
      "Epoch 61/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/81 [============================>.] - ETA: 0s - loss: 0.0783 - acc: 0.9730WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 50s 16ms/sample - loss: 0.0905 - acc: 0.9700\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.04549\n",
      "81/81 [==============================] - 82s 1s/step - loss: 0.0783 - acc: 0.9727 - val_loss: 0.0905 - val_acc: 0.9700\n",
      "Epoch 62/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0858 - acc: 0.9695WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 72s 22ms/sample - loss: 0.1004 - acc: 0.9609\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.04549\n",
      "81/81 [==============================] - 77s 945ms/step - loss: 0.0852 - acc: 0.9699 - val_loss: 0.1004 - val_acc: 0.9609\n",
      "Epoch 63/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0750 - acc: 0.9771WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 78s 24ms/sample - loss: 0.0689 - acc: 0.97723s - loss: 0.0616 - ac\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.04549\n",
      "81/81 [==============================] - 82s 1s/step - loss: 0.0739 - acc: 0.9777 - val_loss: 0.0689 - val_acc: 0.9772\n",
      "Epoch 64/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0745 - acc: 0.9730WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 20s 6ms/sample - loss: 0.0430 - acc: 0.9887\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.04549 to 0.04303, saving model to model/checkpoint/vis_imagenet_6_class_augmentation_2D_CNN_custom_ch_32_DO_050_DO_4_conv_checkpoint/064-0.0430.hdf5\n",
      "81/81 [==============================] - 82s 1s/step - loss: 0.0744 - acc: 0.9730 - val_loss: 0.0430 - val_acc: 0.9887\n",
      "Epoch 65/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0996 - acc: 0.9659WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 74s 23ms/sample - loss: 0.0553 - acc: 0.9800\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.04303\n",
      "81/81 [==============================] - 79s 970ms/step - loss: 0.1001 - acc: 0.9652 - val_loss: 0.0553 - val_acc: 0.9800\n",
      "Epoch 66/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0931 - acc: 0.9632WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 80s 25ms/sample - loss: 0.0593 - acc: 0.9750\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.04303\n",
      "81/81 [==============================] - 85s 1s/step - loss: 0.0942 - acc: 0.9634 - val_loss: 0.0593 - val_acc: 0.9750\n",
      "Epoch 67/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0834 - acc: 0.9736WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 74s 23ms/sample - loss: 0.1044 - acc: 0.9606\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.04303\n",
      "81/81 [==============================] - 79s 971ms/step - loss: 0.0841 - acc: 0.9733 - val_loss: 0.1044 - val_acc: 0.9606\n",
      "Epoch 68/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0820 - acc: 0.9701WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 73s 23ms/sample - loss: 0.0555 - acc: 0.9825\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.04303\n",
      "81/81 [==============================] - 77s 951ms/step - loss: 0.0815 - acc: 0.9705 - val_loss: 0.0555 - val_acc: 0.9825\n",
      "Epoch 69/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0791 - acc: 0.9739WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 73s 23ms/sample - loss: 0.0383 - acc: 0.9875\n",
      "\n",
      "Epoch 00069: val_loss improved from 0.04303 to 0.03826, saving model to model/checkpoint/vis_imagenet_6_class_augmentation_2D_CNN_custom_ch_32_DO_050_DO_4_conv_checkpoint/069-0.0383.hdf5\n",
      "81/81 [==============================] - 78s 967ms/step - loss: 0.0784 - acc: 0.9742 - val_loss: 0.0383 - val_acc: 0.9875\n",
      "Epoch 70/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0740 - acc: 0.9726WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 15s 5ms/sample - loss: 0.1329 - acc: 0.9459\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.03826\n",
      "81/81 [==============================] - 77s 949ms/step - loss: 0.0734 - acc: 0.9730 - val_loss: 0.1329 - val_acc: 0.9459\n",
      "Epoch 71/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0857 - acc: 0.9742WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.1801 - acc: 0.9291\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.03826\n",
      "81/81 [==============================] - 79s 975ms/step - loss: 0.0862 - acc: 0.9739 - val_loss: 0.1801 - val_acc: 0.9291\n",
      "Epoch 72/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0869 - acc: 0.9708WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 72s 23ms/sample - loss: 0.0487 - acc: 0.9875\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.03826\n",
      "81/81 [==============================] - 77s 949ms/step - loss: 0.0866 - acc: 0.9711 - val_loss: 0.0487 - val_acc: 0.9875\n",
      "Epoch 73/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0854 - acc: 0.9689WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 71s 22ms/sample - loss: 0.0525 - acc: 0.9800\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.03826\n",
      "81/81 [==============================] - 77s 954ms/step - loss: 0.0853 - acc: 0.9690 - val_loss: 0.0525 - val_acc: 0.9800\n",
      "Epoch 74/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0682 - acc: 0.9761WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 73s 23ms/sample - loss: 0.1443 - acc: 0.9450\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.03826\n",
      "81/81 [==============================] - 77s 946ms/step - loss: 0.0676 - acc: 0.9761 - val_loss: 0.1443 - val_acc: 0.9450\n",
      "Epoch 75/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0723 - acc: 0.9755WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 72s 23ms/sample - loss: 0.0525 - acc: 0.9837\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.03826\n",
      "81/81 [==============================] - 76s 935ms/step - loss: 0.0723 - acc: 0.9755 - val_loss: 0.0525 - val_acc: 0.9837\n",
      "Epoch 76/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/81 [============================>.] - ETA: 0s - loss: 0.0629 - acc: 0.9780WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 74s 23ms/sample - loss: 0.0607 - acc: 0.9816\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.03826\n",
      "81/81 [==============================] - 77s 957ms/step - loss: 0.0636 - acc: 0.9780 - val_loss: 0.0607 - val_acc: 0.9816\n",
      "Epoch 77/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0630 - acc: 0.9774WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 75s 23ms/sample - loss: 0.0507 - acc: 0.9834\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.03826\n",
      "81/81 [==============================] - 79s 970ms/step - loss: 0.0631 - acc: 0.9773 - val_loss: 0.0507 - val_acc: 0.9834\n",
      "Epoch 78/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0704 - acc: 0.9761WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 73s 23ms/sample - loss: 0.0579 - acc: 0.9775\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.03826\n",
      "81/81 [==============================] - 77s 951ms/step - loss: 0.0696 - acc: 0.9764 - val_loss: 0.0579 - val_acc: 0.9775\n",
      "Epoch 79/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0640 - acc: 0.9789WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 74s 23ms/sample - loss: 0.0587 - acc: 0.9809\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.03826\n",
      "81/81 [==============================] - 78s 958ms/step - loss: 0.0637 - acc: 0.9789 - val_loss: 0.0587 - val_acc: 0.9809\n",
      "Epoch 80/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0745 - acc: 0.9758WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 75s 23ms/sample - loss: 0.0649 - acc: 0.9769\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.03826\n",
      "81/81 [==============================] - 79s 974ms/step - loss: 0.0737 - acc: 0.9761 - val_loss: 0.0649 - val_acc: 0.9769\n",
      "Epoch 81/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0710 - acc: 0.9752WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.0616 - acc: 0.9800\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.03826\n",
      "81/81 [==============================] - 78s 964ms/step - loss: 0.0725 - acc: 0.9752 - val_loss: 0.0616 - val_acc: 0.9800\n",
      "Epoch 82/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0590 - acc: 0.9796WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 72s 23ms/sample - loss: 0.0511 - acc: 0.9844\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.03826\n",
      "81/81 [==============================] - 77s 952ms/step - loss: 0.0585 - acc: 0.9798 - val_loss: 0.0511 - val_acc: 0.9844\n",
      "Epoch 83/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0526 - acc: 0.9849WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 72s 22ms/sample - loss: 0.0373 - acc: 0.9900\n",
      "\n",
      "Epoch 00083: val_loss improved from 0.03826 to 0.03729, saving model to model/checkpoint/vis_imagenet_6_class_augmentation_2D_CNN_custom_ch_32_DO_050_DO_4_conv_checkpoint/083-0.0373.hdf5\n",
      "81/81 [==============================] - 76s 934ms/step - loss: 0.0522 - acc: 0.9851 - val_loss: 0.0373 - val_acc: 0.9900\n",
      "Epoch 84/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0575 - acc: 0.9835WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 72s 22ms/sample - loss: 0.0748 - acc: 0.9663\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.03729\n",
      "81/81 [==============================] - 76s 934ms/step - loss: 0.0568 - acc: 0.9839 - val_loss: 0.0748 - val_acc: 0.9663\n",
      "Epoch 85/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0745 - acc: 0.9739WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 46s 14ms/sample - loss: 0.1322 - acc: 0.9466\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.03729\n",
      "81/81 [==============================] - 78s 963ms/step - loss: 0.0746 - acc: 0.9736 - val_loss: 0.1322 - val_acc: 0.9466\n",
      "Epoch 86/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0604 - acc: 0.9802WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 73s 23ms/sample - loss: 0.0421 - acc: 0.9919\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.03729\n",
      "81/81 [==============================] - 78s 963ms/step - loss: 0.0600 - acc: 0.9804 - val_loss: 0.0421 - val_acc: 0.9919\n",
      "Epoch 87/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0672 - acc: 0.9742WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 70s 22ms/sample - loss: 0.0447 - acc: 0.9853\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.03729\n",
      "81/81 [==============================] - 78s 963ms/step - loss: 0.0672 - acc: 0.9742 - val_loss: 0.0447 - val_acc: 0.9853\n",
      "Epoch 88/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0552 - acc: 0.9854WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 72s 23ms/sample - loss: 0.0597 - acc: 0.9862\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.03729\n",
      "81/81 [==============================] - 79s 979ms/step - loss: 0.0559 - acc: 0.9848 - val_loss: 0.0597 - val_acc: 0.9862\n",
      "Epoch 89/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0549 - acc: 0.9824WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 79s 25ms/sample - loss: 0.0731 - acc: 0.9650\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.03729\n",
      "81/81 [==============================] - 87s 1s/step - loss: 0.0556 - acc: 0.9823 - val_loss: 0.0731 - val_acc: 0.9650\n",
      "Epoch 90/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0581 - acc: 0.9818WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 74s 23ms/sample - loss: 0.0842 - acc: 0.9631\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.03729\n",
      "81/81 [==============================] - 78s 967ms/step - loss: 0.0580 - acc: 0.9817 - val_loss: 0.0842 - val_acc: 0.9631\n",
      "Epoch 91/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0521 - acc: 0.9850WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3200/3183 [==============================] - 74s 23ms/sample - loss: 0.0457 - acc: 0.9831\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.03729\n",
      "81/81 [==============================] - 78s 961ms/step - loss: 0.0549 - acc: 0.9836 - val_loss: 0.0457 - val_acc: 0.9831\n",
      "Epoch 92/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0539 - acc: 0.9827WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 74s 23ms/sample - loss: 0.0480 - acc: 0.9850\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.03729\n",
      "81/81 [==============================] - 88s 1s/step - loss: 0.0542 - acc: 0.9823 - val_loss: 0.0480 - val_acc: 0.9850\n",
      "Epoch 93/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0523 - acc: 0.9844WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 68s 21ms/sample - loss: 0.0440 - acc: 0.9850\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.03729\n",
      "81/81 [==============================] - 77s 949ms/step - loss: 0.0533 - acc: 0.9842 - val_loss: 0.0440 - val_acc: 0.9850\n",
      "Epoch 94/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0626 - acc: 0.9787WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 72s 22ms/sample - loss: 0.0425 - acc: 0.9912\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.03729\n",
      "81/81 [==============================] - 76s 938ms/step - loss: 0.0616 - acc: 0.9792 - val_loss: 0.0425 - val_acc: 0.9912\n",
      "Epoch 95/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0447 - acc: 0.9849WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 69s 22ms/sample - loss: 0.0448 - acc: 0.9900\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.03729\n",
      "81/81 [==============================] - 77s 954ms/step - loss: 0.0446 - acc: 0.9851 - val_loss: 0.0448 - val_acc: 0.9900\n",
      "Epoch 96/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0543 - acc: 0.9818WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 5ms/sample - loss: 0.0487 - acc: 0.9869\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.03729\n",
      "81/81 [==============================] - 78s 963ms/step - loss: 0.0537 - acc: 0.9820 - val_loss: 0.0487 - val_acc: 0.9869\n",
      "Epoch 97/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0574 - acc: 0.9815WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 19s 6ms/sample - loss: 0.0394 - acc: 0.9894\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.03729\n",
      "81/81 [==============================] - 78s 957ms/step - loss: 0.0567 - acc: 0.9817 - val_loss: 0.0394 - val_acc: 0.9894\n",
      "Epoch 98/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0511 - acc: 0.9825WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 72s 23ms/sample - loss: 0.0343 - acc: 0.9875\n",
      "\n",
      "Epoch 00098: val_loss improved from 0.03729 to 0.03430, saving model to model/checkpoint/vis_imagenet_6_class_augmentation_2D_CNN_custom_ch_32_DO_050_DO_4_conv_checkpoint/098-0.0343.hdf5\n",
      "81/81 [==============================] - 78s 968ms/step - loss: 0.0505 - acc: 0.9829 - val_loss: 0.0343 - val_acc: 0.9875\n",
      "Epoch 99/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0718 - acc: 0.9720WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 72s 22ms/sample - loss: 0.0493 - acc: 0.9800\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.03430\n",
      "81/81 [==============================] - 80s 982ms/step - loss: 0.0706 - acc: 0.9727 - val_loss: 0.0493 - val_acc: 0.9800\n",
      "Epoch 100/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0516 - acc: 0.9850WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 74s 23ms/sample - loss: 0.0649 - acc: 0.9750\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.03430\n",
      "81/81 [==============================] - 79s 973ms/step - loss: 0.0515 - acc: 0.9851 - val_loss: 0.0649 - val_acc: 0.9750\n",
      "Epoch 101/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0425 - acc: 0.9857WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 74s 23ms/sample - loss: 0.0445 - acc: 0.9800\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 0.03430\n",
      "81/81 [==============================] - 80s 990ms/step - loss: 0.0433 - acc: 0.9851 - val_loss: 0.0445 - val_acc: 0.9800\n",
      "Epoch 102/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0525 - acc: 0.9840WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 74s 23ms/sample - loss: 0.0365 - acc: 0.9875\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 0.03430\n",
      "81/81 [==============================] - 78s 965ms/step - loss: 0.0526 - acc: 0.9839 - val_loss: 0.0365 - val_acc: 0.9875\n",
      "Epoch 103/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0448 - acc: 0.9860WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 46s 14ms/sample - loss: 0.0522 - acc: 0.9853\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 0.03430\n",
      "81/81 [==============================] - 77s 945ms/step - loss: 0.0446 - acc: 0.9860 - val_loss: 0.0522 - val_acc: 0.9853\n",
      "Epoch 104/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0537 - acc: 0.9849WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 72s 22ms/sample - loss: 0.0365 - acc: 0.9900\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 0.03430\n",
      "81/81 [==============================] - 76s 935ms/step - loss: 0.0534 - acc: 0.9851 - val_loss: 0.0365 - val_acc: 0.9900\n",
      "Epoch 105/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0590 - acc: 0.9796WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 69s 21ms/sample - loss: 0.0882 - acc: 0.9638\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 0.03430\n",
      "81/81 [==============================] - 73s 901ms/step - loss: 0.0595 - acc: 0.9789 - val_loss: 0.0882 - val_acc: 0.9638\n",
      "Epoch 106/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0525 - acc: 0.9831WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 63s 20ms/sample - loss: 0.0508 - acc: 0.9875\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 0.03430\n",
      "81/81 [==============================] - 77s 949ms/step - loss: 0.0521 - acc: 0.9836 - val_loss: 0.0508 - val_acc: 0.9875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 107/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0562 - acc: 0.9815WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.0723 - acc: 0.9700\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 0.03430\n",
      "81/81 [==============================] - 75s 920ms/step - loss: 0.0553 - acc: 0.9820 - val_loss: 0.0723 - val_acc: 0.9700\n",
      "Epoch 108/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0493 - acc: 0.9835WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 75s 23ms/sample - loss: 0.0490 - acc: 0.9850\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 0.03430\n",
      "81/81 [==============================] - 80s 983ms/step - loss: 0.0487 - acc: 0.9836 - val_loss: 0.0490 - val_acc: 0.9850\n",
      "Epoch 109/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0455 - acc: 0.9850WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 78s 24ms/sample - loss: 0.0478 - acc: 0.9875\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 0.03430\n",
      "81/81 [==============================] - 83s 1s/step - loss: 0.0471 - acc: 0.9851 - val_loss: 0.0478 - val_acc: 0.9875\n",
      "Epoch 110/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0419 - acc: 0.9859WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 77s 24ms/sample - loss: 0.0408 - acc: 0.9862\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 0.03430\n",
      "81/81 [==============================] - 82s 1s/step - loss: 0.0417 - acc: 0.9860 - val_loss: 0.0408 - val_acc: 0.9862\n",
      "Epoch 111/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0520 - acc: 0.9830WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 74s 23ms/sample - loss: 0.0613 - acc: 0.9756\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 0.03430\n",
      "81/81 [==============================] - 78s 966ms/step - loss: 0.0514 - acc: 0.9832 - val_loss: 0.0613 - val_acc: 0.9756\n",
      "Epoch 112/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0415 - acc: 0.9874WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 77s 24ms/sample - loss: 0.0391 - acc: 0.9894\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 0.03430\n",
      "81/81 [==============================] - 81s 1s/step - loss: 0.0412 - acc: 0.9876 - val_loss: 0.0391 - val_acc: 0.9894\n",
      "Epoch 113/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0501 - acc: 0.9841WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 73s 23ms/sample - loss: 0.0892 - acc: 0.96007s - loss: 0.0948 - acc:\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 0.03430\n",
      "81/81 [==============================] - 77s 956ms/step - loss: 0.0540 - acc: 0.9836 - val_loss: 0.0892 - val_acc: 0.9600\n",
      "Epoch 114/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0529 - acc: 0.9831WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 5ms/sample - loss: 0.0405 - acc: 0.9847\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 0.03430\n",
      "81/81 [==============================] - 79s 977ms/step - loss: 0.0526 - acc: 0.9832 - val_loss: 0.0405 - val_acc: 0.9847\n",
      "Epoch 115/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0344 - acc: 0.9893WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 47s 15ms/sample - loss: 0.0384 - acc: 0.9916\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 0.03430\n",
      "81/81 [==============================] - 76s 944ms/step - loss: 0.0341 - acc: 0.9894 - val_loss: 0.0384 - val_acc: 0.9916\n",
      "Epoch 116/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0416 - acc: 0.9866WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 69s 21ms/sample - loss: 0.0507 - acc: 0.9806\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 0.03430\n",
      "81/81 [==============================] - 76s 934ms/step - loss: 0.0425 - acc: 0.9867 - val_loss: 0.0507 - val_acc: 0.9806\n",
      "Epoch 117/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0507 - acc: 0.9826WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3190/3183 [==============================] - 73s 23ms/sample - loss: 0.0527 - acc: 0.9740\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 0.03430\n",
      "81/81 [==============================] - 77s 957ms/step - loss: 0.0550 - acc: 0.9808 - val_loss: 0.0527 - val_acc: 0.9740\n",
      "Epoch 118/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0580 - acc: 0.9811WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 74s 23ms/sample - loss: 0.0301 - acc: 0.9925\n",
      "\n",
      "Epoch 00118: val_loss improved from 0.03430 to 0.03009, saving model to model/checkpoint/vis_imagenet_6_class_augmentation_2D_CNN_custom_ch_32_DO_050_DO_4_conv_checkpoint/118-0.0301.hdf5\n",
      "81/81 [==============================] - 79s 975ms/step - loss: 0.0576 - acc: 0.9814 - val_loss: 0.0301 - val_acc: 0.9925\n",
      "Epoch 119/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0433 - acc: 0.9868WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 48s 15ms/sample - loss: 0.0348 - acc: 0.9881\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 0.03009\n",
      "81/81 [==============================] - 79s 978ms/step - loss: 0.0434 - acc: 0.9867 - val_loss: 0.0348 - val_acc: 0.9881\n",
      "Epoch 120/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0351 - acc: 0.9862WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0371 - acc: 0.9887\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 0.03009\n",
      "81/81 [==============================] - 81s 999ms/step - loss: 0.0348 - acc: 0.9863 - val_loss: 0.0371 - val_acc: 0.9887\n",
      "Epoch 121/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0413 - acc: 0.9866WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 15s 5ms/sample - loss: 0.0529 - acc: 0.981910s - los\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 0.03009\n",
      "81/81 [==============================] - 77s 945ms/step - loss: 0.0405 - acc: 0.9870 - val_loss: 0.0529 - val_acc: 0.9819\n",
      "Epoch 122/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0333 - acc: 0.9899WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3200/3183 [==============================] - 72s 22ms/sample - loss: 0.0453 - acc: 0.9825\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 0.03009\n",
      "81/81 [==============================] - 76s 936ms/step - loss: 0.0330 - acc: 0.9901 - val_loss: 0.0453 - val_acc: 0.9825\n",
      "Epoch 123/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0448 - acc: 0.9884WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 14s 4ms/sample - loss: 0.0427 - acc: 0.9887\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 0.03009\n",
      "81/81 [==============================] - 76s 941ms/step - loss: 0.0447 - acc: 0.9885 - val_loss: 0.0427 - val_acc: 0.9887\n",
      "Epoch 124/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0345 - acc: 0.9866WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 25s 8ms/sample - loss: 0.0359 - acc: 0.9916\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 0.03009\n",
      "81/81 [==============================] - 83s 1s/step - loss: 0.0353 - acc: 0.9863 - val_loss: 0.0359 - val_acc: 0.9916\n",
      "Epoch 125/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0429 - acc: 0.9837WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 78s 24ms/sample - loss: 0.0437 - acc: 0.9875\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 0.03009\n",
      "81/81 [==============================] - 84s 1s/step - loss: 0.0426 - acc: 0.9839 - val_loss: 0.0437 - val_acc: 0.9875\n",
      "Epoch 126/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0325 - acc: 0.9895WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 78s 24ms/sample - loss: 0.0382 - acc: 0.9887\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 0.03009\n",
      "81/81 [==============================] - 82s 1s/step - loss: 0.0328 - acc: 0.9894 - val_loss: 0.0382 - val_acc: 0.9887\n",
      "Epoch 127/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0331 - acc: 0.9908WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 71s 22ms/sample - loss: 0.0358 - acc: 0.9925\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 0.03009\n",
      "81/81 [==============================] - 77s 949ms/step - loss: 0.0324 - acc: 0.9910 - val_loss: 0.0358 - val_acc: 0.9925\n",
      "Epoch 128/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0503 - acc: 0.9831WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 78s 25ms/sample - loss: 0.0427 - acc: 0.9906\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 0.03009\n",
      "81/81 [==============================] - 83s 1s/step - loss: 0.0495 - acc: 0.9836 - val_loss: 0.0427 - val_acc: 0.9906\n",
      "Epoch 129/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0322 - acc: 0.9903WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 75s 23ms/sample - loss: 0.0321 - acc: 0.9894\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 0.03009\n",
      "81/81 [==============================] - 79s 981ms/step - loss: 0.0320 - acc: 0.9904 - val_loss: 0.0321 - val_acc: 0.9894\n",
      "Epoch 130/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0267 - acc: 0.9917WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 47s 15ms/sample - loss: 0.0312 - acc: 0.9922\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 0.03009\n",
      "81/81 [==============================] - 78s 963ms/step - loss: 0.0269 - acc: 0.9916 - val_loss: 0.0312 - val_acc: 0.9922\n",
      "Epoch 131/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0488 - acc: 0.9833WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 23s 7ms/sample - loss: 0.0363 - acc: 0.9912\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 0.03009\n",
      "81/81 [==============================] - 81s 994ms/step - loss: 0.0486 - acc: 0.9832 - val_loss: 0.0363 - val_acc: 0.9912\n",
      "Epoch 132/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0420 - acc: 0.9892WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 75s 23ms/sample - loss: 0.0561 - acc: 0.9816\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 0.03009\n",
      "81/81 [==============================] - 80s 983ms/step - loss: 0.0412 - acc: 0.9894 - val_loss: 0.0561 - val_acc: 0.9816\n",
      "Epoch 133/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0346 - acc: 0.9885WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 71s 22ms/sample - loss: 0.0464 - acc: 0.9825\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 0.03009\n",
      "81/81 [==============================] - 76s 943ms/step - loss: 0.0348 - acc: 0.9879 - val_loss: 0.0464 - val_acc: 0.9825\n",
      "Epoch 134/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0360 - acc: 0.9893WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 45s 14ms/sample - loss: 0.0433 - acc: 0.9891\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 0.03009\n",
      "81/81 [==============================] - 75s 924ms/step - loss: 0.0361 - acc: 0.9891 - val_loss: 0.0433 - val_acc: 0.9891\n",
      "Epoch 135/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0323 - acc: 0.9898WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 71s 22ms/sample - loss: 0.0268 - acc: 0.9925\n",
      "\n",
      "Epoch 00135: val_loss improved from 0.03009 to 0.02680, saving model to model/checkpoint/vis_imagenet_6_class_augmentation_2D_CNN_custom_ch_32_DO_050_DO_4_conv_checkpoint/135-0.0268.hdf5\n",
      "81/81 [==============================] - 76s 944ms/step - loss: 0.0321 - acc: 0.9901 - val_loss: 0.0268 - val_acc: 0.9925\n",
      "Epoch 136/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0320 - acc: 0.9892WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0486 - acc: 0.9847\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 0.02680\n",
      "81/81 [==============================] - 80s 982ms/step - loss: 0.0324 - acc: 0.9888 - val_loss: 0.0486 - val_acc: 0.9847\n",
      "Epoch 137/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0348 - acc: 0.9896WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 24s 7ms/sample - loss: 0.0394 - acc: 0.9837\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 0.02680\n",
      "81/81 [==============================] - 82s 1s/step - loss: 0.0345 - acc: 0.9898 - val_loss: 0.0394 - val_acc: 0.9837\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 138/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0317 - acc: 0.9892WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 70s 22ms/sample - loss: 0.0416 - acc: 0.9819\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 0.02680\n",
      "81/81 [==============================] - 79s 978ms/step - loss: 0.0313 - acc: 0.9894 - val_loss: 0.0416 - val_acc: 0.9819\n",
      "Epoch 139/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0230 - acc: 0.9937WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 70s 22ms/sample - loss: 0.0486 - acc: 0.9809\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 0.02680\n",
      "81/81 [==============================] - 75s 923ms/step - loss: 0.0228 - acc: 0.9938 - val_loss: 0.0486 - val_acc: 0.9809\n",
      "Epoch 140/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0319 - acc: 0.9895WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 68s 21ms/sample - loss: 0.0350 - acc: 0.9922\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 0.02680\n",
      "81/81 [==============================] - 74s 907ms/step - loss: 0.0334 - acc: 0.9891 - val_loss: 0.0350 - val_acc: 0.9922\n",
      "Epoch 141/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0543 - acc: 0.9805WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 73s 23ms/sample - loss: 0.0514 - acc: 0.9875\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 0.02680\n",
      "81/81 [==============================] - 78s 966ms/step - loss: 0.0540 - acc: 0.9808 - val_loss: 0.0514 - val_acc: 0.9875\n",
      "Epoch 142/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0325 - acc: 0.9898WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0402 - acc: 0.9837\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 0.02680\n",
      "81/81 [==============================] - 76s 940ms/step - loss: 0.0320 - acc: 0.9901 - val_loss: 0.0402 - val_acc: 0.9837\n",
      "Epoch 143/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0354 - acc: 0.9899WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 61s 19ms/sample - loss: 0.0461 - acc: 0.9825\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 0.02680\n",
      "81/81 [==============================] - 75s 927ms/step - loss: 0.0350 - acc: 0.9901 - val_loss: 0.0461 - val_acc: 0.9825\n",
      "Epoch 144/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0254 - acc: 0.9906WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 68s 21ms/sample - loss: 0.0262 - acc: 0.9925\n",
      "\n",
      "Epoch 00144: val_loss improved from 0.02680 to 0.02617, saving model to model/checkpoint/vis_imagenet_6_class_augmentation_2D_CNN_custom_ch_32_DO_050_DO_4_conv_checkpoint/144-0.0262.hdf5\n",
      "81/81 [==============================] - 74s 914ms/step - loss: 0.0260 - acc: 0.9904 - val_loss: 0.0262 - val_acc: 0.9925\n",
      "Epoch 145/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0425 - acc: 0.9860WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 75s 23ms/sample - loss: 0.0340 - acc: 0.9922\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 0.02617\n",
      "81/81 [==============================] - 80s 989ms/step - loss: 0.0422 - acc: 0.9863 - val_loss: 0.0340 - val_acc: 0.9922\n",
      "Epoch 146/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0299 - acc: 0.9912WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 80s 25ms/sample - loss: 0.0353 - acc: 0.9900\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 0.02617\n",
      "81/81 [==============================] - 85s 1s/step - loss: 0.0296 - acc: 0.9913 - val_loss: 0.0353 - val_acc: 0.9900\n",
      "Epoch 147/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0318 - acc: 0.9893WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 15s 5ms/sample - loss: 0.0276 - acc: 0.9922\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 0.02617\n",
      "81/81 [==============================] - 75s 927ms/step - loss: 0.0316 - acc: 0.9894 - val_loss: 0.0276 - val_acc: 0.9922\n",
      "Epoch 148/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0407 - acc: 0.9859WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 72s 22ms/sample - loss: 0.0699 - acc: 0.9787\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 0.02617\n",
      "81/81 [==============================] - 77s 950ms/step - loss: 0.0402 - acc: 0.9860 - val_loss: 0.0699 - val_acc: 0.9787\n",
      "Epoch 149/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0497 - acc: 0.9857WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 73s 23ms/sample - loss: 0.0284 - acc: 0.9919\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 0.02617\n",
      "81/81 [==============================] - 78s 965ms/step - loss: 0.0510 - acc: 0.9857 - val_loss: 0.0284 - val_acc: 0.9919\n",
      "Epoch 150/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0318 - acc: 0.9905WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 45s 14ms/sample - loss: 0.0327 - acc: 0.9919\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 0.02617\n",
      "81/81 [==============================] - 76s 932ms/step - loss: 0.0326 - acc: 0.9901 - val_loss: 0.0327 - val_acc: 0.9919\n",
      "Epoch 151/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0265 - acc: 0.9906WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 73s 23ms/sample - loss: 0.0325 - acc: 0.9916\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 0.02617\n",
      "81/81 [==============================] - 77s 955ms/step - loss: 0.0265 - acc: 0.9904 - val_loss: 0.0325 - val_acc: 0.9916\n",
      "Epoch 152/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0286 - acc: 0.9925WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 72s 22ms/sample - loss: 0.0287 - acc: 0.9897\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 0.02617\n",
      "81/81 [==============================] - 77s 951ms/step - loss: 0.0301 - acc: 0.9922 - val_loss: 0.0287 - val_acc: 0.9897\n",
      "Epoch 153/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0370 - acc: 0.9886WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3190/3183 [==============================] - 44s 14ms/sample - loss: 0.0380 - acc: 0.9922\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 0.02617\n",
      "81/81 [==============================] - 75s 922ms/step - loss: 0.0387 - acc: 0.9876 - val_loss: 0.0380 - val_acc: 0.9922\n",
      "Epoch 154/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0306 - acc: 0.9908WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 20s 6ms/sample - loss: 0.0333 - acc: 0.9900\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 0.02617\n",
      "81/81 [==============================] - 82s 1s/step - loss: 0.0301 - acc: 0.9910 - val_loss: 0.0333 - val_acc: 0.9900\n",
      "Epoch 155/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0242 - acc: 0.9955WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 71s 22ms/sample - loss: 0.0387 - acc: 0.9891\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 0.02617\n",
      "81/81 [==============================] - 82s 1s/step - loss: 0.0242 - acc: 0.9953 - val_loss: 0.0387 - val_acc: 0.9891\n",
      "Epoch 156/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0209 - acc: 0.9936WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 72s 23ms/sample - loss: 0.0391 - acc: 0.9925\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 0.02617\n",
      "81/81 [==============================] - 80s 985ms/step - loss: 0.0205 - acc: 0.9938 - val_loss: 0.0391 - val_acc: 0.9925\n",
      "Epoch 157/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0268 - acc: 0.9908WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 73s 23ms/sample - loss: 0.0459 - acc: 0.9925\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 0.02617\n",
      "81/81 [==============================] - 81s 995ms/step - loss: 0.0279 - acc: 0.9898 - val_loss: 0.0459 - val_acc: 0.9925\n",
      "Epoch 158/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0268 - acc: 0.9933WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 49s 15ms/sample - loss: 0.0412 - acc: 0.9922\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 0.02617\n",
      "81/81 [==============================] - 80s 992ms/step - loss: 0.0266 - acc: 0.9935 - val_loss: 0.0412 - val_acc: 0.9922\n",
      "Epoch 159/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0245 - acc: 0.9934WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 73s 23ms/sample - loss: 0.0304 - acc: 0.9925\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 0.02617\n",
      "81/81 [==============================] - 78s 963ms/step - loss: 0.0246 - acc: 0.9932 - val_loss: 0.0304 - val_acc: 0.9925\n",
      "Epoch 160/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0344 - acc: 0.9882WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 74s 23ms/sample - loss: 0.0522 - acc: 0.9947\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 0.02617\n",
      "81/81 [==============================] - 83s 1s/step - loss: 0.0352 - acc: 0.9879 - val_loss: 0.0522 - val_acc: 0.9947\n",
      "Epoch 161/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0422 - acc: 0.9852WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 74s 23ms/sample - loss: 0.0526 - acc: 0.9753\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 0.02617\n",
      "81/81 [==============================] - 81s 1s/step - loss: 0.0418 - acc: 0.9854 - val_loss: 0.0526 - val_acc: 0.9753\n",
      "Epoch 162/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0262 - acc: 0.9918WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 76s 24ms/sample - loss: 0.0396 - acc: 0.9909\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 0.02617\n",
      "81/81 [==============================] - 82s 1s/step - loss: 0.0260 - acc: 0.9919 - val_loss: 0.0396 - val_acc: 0.9909\n",
      "Epoch 163/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0390 - acc: 0.9882WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.0365 - acc: 0.9894\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 0.02617\n",
      "81/81 [==============================] - 75s 927ms/step - loss: 0.0382 - acc: 0.9885 - val_loss: 0.0365 - val_acc: 0.9894\n",
      "Epoch 164/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0197 - acc: 0.9955WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 51s 16ms/sample - loss: 0.0716 - acc: 0.9694\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 0.02617\n",
      "81/81 [==============================] - 82s 1s/step - loss: 0.0208 - acc: 0.9950 - val_loss: 0.0716 - val_acc: 0.9694\n",
      "Epoch 165/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0211 - acc: 0.9940WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 49s 15ms/sample - loss: 0.0477 - acc: 0.9887\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 0.02617\n",
      "81/81 [==============================] - 82s 1s/step - loss: 0.0210 - acc: 0.9941 - val_loss: 0.0477 - val_acc: 0.9887\n",
      "Epoch 166/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0236 - acc: 0.9925WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 47s 15ms/sample - loss: 0.0493 - acc: 0.9950\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 0.02617\n",
      "81/81 [==============================] - 78s 965ms/step - loss: 0.0235 - acc: 0.9926 - val_loss: 0.0493 - val_acc: 0.9950\n",
      "Epoch 167/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0339 - acc: 0.9895WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 71s 22ms/sample - loss: 0.0370 - acc: 0.9909\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 0.02617\n",
      "81/81 [==============================] - 79s 976ms/step - loss: 0.0335 - acc: 0.9894 - val_loss: 0.0370 - val_acc: 0.9909\n",
      "Epoch 168/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0265 - acc: 0.9925WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 70s 22ms/sample - loss: 0.0373 - acc: 0.9912\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 0.02617\n",
      "81/81 [==============================] - 75s 927ms/step - loss: 0.0263 - acc: 0.9926 - val_loss: 0.0373 - val_acc: 0.9912\n",
      "Epoch 169/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/81 [============================>.] - ETA: 0s - loss: 0.0374 - acc: 0.9871WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 74s 23ms/sample - loss: 0.0274 - acc: 0.9925\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 0.02617\n",
      "81/81 [==============================] - 83s 1s/step - loss: 0.0371 - acc: 0.9873 - val_loss: 0.0274 - val_acc: 0.9925\n",
      "Epoch 170/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0180 - acc: 0.9950WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 71s 22ms/sample - loss: 0.0397 - acc: 0.9872\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 0.02617\n",
      "81/81 [==============================] - 78s 963ms/step - loss: 0.0179 - acc: 0.9950 - val_loss: 0.0397 - val_acc: 0.9872\n",
      "Epoch 171/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0219 - acc: 0.9921WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 71s 22ms/sample - loss: 0.0437 - acc: 0.9837\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 0.02617\n",
      "81/81 [==============================] - 77s 946ms/step - loss: 0.0219 - acc: 0.9922 - val_loss: 0.0437 - val_acc: 0.9837\n",
      "Epoch 172/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0246 - acc: 0.9918WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 74s 23ms/sample - loss: 0.0351 - acc: 0.9891\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 0.02617\n",
      "81/81 [==============================] - 78s 963ms/step - loss: 0.0260 - acc: 0.9916 - val_loss: 0.0351 - val_acc: 0.9891\n",
      "Epoch 173/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0248 - acc: 0.9936WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 72s 22ms/sample - loss: 0.0456 - acc: 0.9887\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 0.02617\n",
      "81/81 [==============================] - 78s 958ms/step - loss: 0.0248 - acc: 0.9935 - val_loss: 0.0456 - val_acc: 0.9887\n",
      "Epoch 174/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0313 - acc: 0.9905WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 80s 25ms/sample - loss: 0.0334 - acc: 0.9900\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 0.02617\n",
      "81/81 [==============================] - 86s 1s/step - loss: 0.0311 - acc: 0.9907 - val_loss: 0.0334 - val_acc: 0.9900\n",
      "Epoch 175/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0167 - acc: 0.9956WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 73s 23ms/sample - loss: 0.0445 - acc: 0.9891\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 0.02617\n",
      "81/81 [==============================] - 79s 976ms/step - loss: 0.0172 - acc: 0.9950 - val_loss: 0.0445 - val_acc: 0.9891\n",
      "Epoch 176/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0270 - acc: 0.9947WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 74s 23ms/sample - loss: 0.0389 - acc: 0.9866\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 0.02617\n",
      "81/81 [==============================] - 79s 981ms/step - loss: 0.0269 - acc: 0.9947 - val_loss: 0.0389 - val_acc: 0.9866\n",
      "Epoch 177/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0287 - acc: 0.9911WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 68s 21ms/sample - loss: 0.0340 - acc: 0.9922\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 0.02617\n",
      "81/81 [==============================] - 76s 943ms/step - loss: 0.0283 - acc: 0.9913 - val_loss: 0.0340 - val_acc: 0.9922\n",
      "Epoch 178/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0296 - acc: 0.9915WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.0578 - acc: 0.9769\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 0.02617\n",
      "81/81 [==============================] - 75s 922ms/step - loss: 0.0297 - acc: 0.9913 - val_loss: 0.0578 - val_acc: 0.9769\n",
      "Epoch 179/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0258 - acc: 0.9933WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 67s 21ms/sample - loss: 0.0303 - acc: 0.9897\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 0.02617\n",
      "81/81 [==============================] - 74s 908ms/step - loss: 0.0262 - acc: 0.9932 - val_loss: 0.0303 - val_acc: 0.9897\n",
      "Epoch 180/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0178 - acc: 0.9959WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 69s 22ms/sample - loss: 0.0382 - acc: 0.9944\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 0.02617\n",
      "81/81 [==============================] - 75s 923ms/step - loss: 0.0177 - acc: 0.9960 - val_loss: 0.0382 - val_acc: 0.9944\n",
      "Epoch 181/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0233 - acc: 0.9928WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 74s 23ms/sample - loss: 0.0342 - acc: 0.9891\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 0.02617\n",
      "81/81 [==============================] - 80s 982ms/step - loss: 0.0232 - acc: 0.9929 - val_loss: 0.0342 - val_acc: 0.9891\n",
      "Epoch 182/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0182 - acc: 0.9949WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 70s 22ms/sample - loss: 0.0391 - acc: 0.9897\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 0.02617\n",
      "81/81 [==============================] - 74s 915ms/step - loss: 0.0182 - acc: 0.9950 - val_loss: 0.0391 - val_acc: 0.9897\n",
      "Epoch 183/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0233 - acc: 0.9927WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 72s 23ms/sample - loss: 0.0360 - acc: 0.9856\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 0.02617\n",
      "81/81 [==============================] - 78s 966ms/step - loss: 0.0237 - acc: 0.9926 - val_loss: 0.0360 - val_acc: 0.9856\n",
      "Epoch 184/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0309 - acc: 0.9899WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3200/3183 [==============================] - 22s 7ms/sample - loss: 0.0255 - acc: 0.9894\n",
      "\n",
      "Epoch 00184: val_loss improved from 0.02617 to 0.02549, saving model to model/checkpoint/vis_imagenet_6_class_augmentation_2D_CNN_custom_ch_32_DO_050_DO_4_conv_checkpoint/184-0.0255.hdf5\n",
      "81/81 [==============================] - 78s 959ms/step - loss: 0.0306 - acc: 0.9901 - val_loss: 0.0255 - val_acc: 0.9894\n",
      "Epoch 185/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0276 - acc: 0.9905WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0388 - acc: 0.9944\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 0.02549\n",
      "81/81 [==============================] - 76s 938ms/step - loss: 0.0281 - acc: 0.9904 - val_loss: 0.0388 - val_acc: 0.9944\n",
      "Epoch 186/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0226 - acc: 0.9934WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 67s 21ms/sample - loss: 0.0250 - acc: 0.9900\n",
      "\n",
      "Epoch 00186: val_loss improved from 0.02549 to 0.02502, saving model to model/checkpoint/vis_imagenet_6_class_augmentation_2D_CNN_custom_ch_32_DO_050_DO_4_conv_checkpoint/186-0.0250.hdf5\n",
      "81/81 [==============================] - 76s 935ms/step - loss: 0.0229 - acc: 0.9935 - val_loss: 0.0250 - val_acc: 0.9900\n",
      "Epoch 187/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0213 - acc: 0.9940WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0394 - acc: 0.9912\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 0.02502\n",
      "81/81 [==============================] - 79s 976ms/step - loss: 0.0210 - acc: 0.9941 - val_loss: 0.0394 - val_acc: 0.9912\n",
      "Epoch 188/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0262 - acc: 0.9918WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 71s 22ms/sample - loss: 0.0357 - acc: 0.9875\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 0.02502\n",
      "81/81 [==============================] - 76s 942ms/step - loss: 0.0260 - acc: 0.9919 - val_loss: 0.0357 - val_acc: 0.9875\n",
      "Epoch 189/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0241 - acc: 0.9925WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 76s 24ms/sample - loss: 0.0291 - acc: 0.9875\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 0.02502\n",
      "81/81 [==============================] - 85s 1s/step - loss: 0.0239 - acc: 0.9926 - val_loss: 0.0291 - val_acc: 0.9875\n",
      "Epoch 190/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0181 - acc: 0.9940WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 77s 24ms/sample - loss: 0.0423 - acc: 0.9853\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 0.02502\n",
      "81/81 [==============================] - 84s 1s/step - loss: 0.0186 - acc: 0.9938 - val_loss: 0.0423 - val_acc: 0.9853\n",
      "Epoch 191/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0155 - acc: 0.9950WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 76s 24ms/sample - loss: 0.0328 - acc: 0.9916\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 0.02502\n",
      "81/81 [==============================] - 81s 995ms/step - loss: 0.0154 - acc: 0.9950 - val_loss: 0.0328 - val_acc: 0.9916\n",
      "Epoch 192/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0197 - acc: 0.9949WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 73s 23ms/sample - loss: 0.0352 - acc: 0.9903\n",
      "\n",
      "Epoch 00192: val_loss did not improve from 0.02502\n",
      "81/81 [==============================] - 80s 985ms/step - loss: 0.0200 - acc: 0.9947 - val_loss: 0.0352 - val_acc: 0.9903\n",
      "Epoch 193/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0164 - acc: 0.9962WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.0293 - acc: 0.9872\n",
      "\n",
      "Epoch 00193: val_loss did not improve from 0.02502\n",
      "81/81 [==============================] - 74s 910ms/step - loss: 0.0162 - acc: 0.9963 - val_loss: 0.0293 - val_acc: 0.9872\n",
      "Epoch 194/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0249 - acc: 0.9924WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 75s 24ms/sample - loss: 0.0387 - acc: 0.9916\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 0.02502\n",
      "81/81 [==============================] - 81s 1s/step - loss: 0.0245 - acc: 0.9926 - val_loss: 0.0387 - val_acc: 0.9916\n",
      "Epoch 195/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0126 - acc: 0.9962WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 69s 22ms/sample - loss: 0.0330 - acc: 0.9900\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 0.02502\n",
      "81/81 [==============================] - 73s 898ms/step - loss: 0.0126 - acc: 0.9963 - val_loss: 0.0330 - val_acc: 0.9900\n",
      "Epoch 196/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0231 - acc: 0.9931WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 75s 23ms/sample - loss: 0.0444 - acc: 0.9916\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 0.02502\n",
      "81/81 [==============================] - 79s 973ms/step - loss: 0.0230 - acc: 0.9932 - val_loss: 0.0444 - val_acc: 0.9916\n",
      "Epoch 197/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0255 - acc: 0.9930WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0341 - acc: 0.9941\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 0.02502\n",
      "81/81 [==============================] - 73s 903ms/step - loss: 0.0253 - acc: 0.9932 - val_loss: 0.0341 - val_acc: 0.9941\n",
      "Epoch 198/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0200 - acc: 0.9937WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 66s 21ms/sample - loss: 0.0166 - acc: 0.9944\n",
      "\n",
      "Epoch 00198: val_loss improved from 0.02502 to 0.01660, saving model to model/checkpoint/vis_imagenet_6_class_augmentation_2D_CNN_custom_ch_32_DO_050_DO_4_conv_checkpoint/198-0.0166.hdf5\n",
      "81/81 [==============================] - 74s 919ms/step - loss: 0.0197 - acc: 0.9938 - val_loss: 0.0166 - val_acc: 0.9944\n",
      "Epoch 199/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0263 - acc: 0.9908WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3200/3183 [==============================] - 73s 23ms/sample - loss: 0.0341 - acc: 0.9875\n",
      "\n",
      "Epoch 00199: val_loss did not improve from 0.01660\n",
      "81/81 [==============================] - 79s 978ms/step - loss: 0.0258 - acc: 0.9910 - val_loss: 0.0341 - val_acc: 0.9875\n",
      "Epoch 200/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0185 - acc: 0.9946WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 45s 14ms/sample - loss: 0.0222 - acc: 0.9925\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 0.01660\n",
      "81/81 [==============================] - 76s 938ms/step - loss: 0.0182 - acc: 0.9947 - val_loss: 0.0222 - val_acc: 0.9925\n",
      "Epoch 201/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0218 - acc: 0.9940WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 5ms/sample - loss: 0.0313 - acc: 0.9897\n",
      "\n",
      "Epoch 00201: val_loss did not improve from 0.01660\n",
      "81/81 [==============================] - 76s 943ms/step - loss: 0.0214 - acc: 0.9941 - val_loss: 0.0313 - val_acc: 0.9897\n",
      "Epoch 202/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0179 - acc: 0.9950WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 65s 20ms/sample - loss: 0.0461 - acc: 0.9950\n",
      "\n",
      "Epoch 00202: val_loss did not improve from 0.01660\n",
      "81/81 [==============================] - 76s 936ms/step - loss: 0.0178 - acc: 0.9950 - val_loss: 0.0461 - val_acc: 0.9950\n",
      "Epoch 203/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0191 - acc: 0.9937WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 72s 22ms/sample - loss: 0.0252 - acc: 0.9925\n",
      "\n",
      "Epoch 00203: val_loss did not improve from 0.01660\n",
      "81/81 [==============================] - 79s 979ms/step - loss: 0.0191 - acc: 0.9938 - val_loss: 0.0252 - val_acc: 0.9925\n",
      "Epoch 204/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0282 - acc: 0.9906WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 22s 7ms/sample - loss: 0.0322 - acc: 0.9862\n",
      "\n",
      "Epoch 00204: val_loss did not improve from 0.01660\n",
      "81/81 [==============================] - 81s 994ms/step - loss: 0.0280 - acc: 0.9907 - val_loss: 0.0322 - val_acc: 0.9862\n",
      "Epoch 205/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0192 - acc: 0.9947WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 79s 25ms/sample - loss: 0.0289 - acc: 0.9900\n",
      "\n",
      "Epoch 00205: val_loss did not improve from 0.01660\n",
      "81/81 [==============================] - 84s 1s/step - loss: 0.0191 - acc: 0.9947 - val_loss: 0.0289 - val_acc: 0.9900\n",
      "Epoch 206/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0165 - acc: 0.9965WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 73s 23ms/sample - loss: 0.0320 - acc: 0.9903\n",
      "\n",
      "Epoch 00206: val_loss did not improve from 0.01660\n",
      "81/81 [==============================] - 80s 991ms/step - loss: 0.0161 - acc: 0.9966 - val_loss: 0.0320 - val_acc: 0.9903\n",
      "Epoch 207/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0183 - acc: 0.9943WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 47s 15ms/sample - loss: 0.0258 - acc: 0.9897\n",
      "\n",
      "Epoch 00207: val_loss did not improve from 0.01660\n",
      "81/81 [==============================] - 77s 955ms/step - loss: 0.0186 - acc: 0.9941 - val_loss: 0.0258 - val_acc: 0.9897\n",
      "Epoch 208/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0201 - acc: 0.9937WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 72s 23ms/sample - loss: 0.0313 - acc: 0.9912\n",
      "\n",
      "Epoch 00208: val_loss did not improve from 0.01660\n",
      "81/81 [==============================] - 77s 947ms/step - loss: 0.0199 - acc: 0.9938 - val_loss: 0.0313 - val_acc: 0.9912\n",
      "Epoch 209/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0248 - acc: 0.9924WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 71s 22ms/sample - loss: 0.0583 - acc: 0.9775\n",
      "\n",
      "Epoch 00209: val_loss did not improve from 0.01660\n",
      "81/81 [==============================] - 75s 927ms/step - loss: 0.0246 - acc: 0.9926 - val_loss: 0.0583 - val_acc: 0.9775\n",
      "Epoch 210/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0192 - acc: 0.9940WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 70s 22ms/sample - loss: 0.0474 - acc: 0.9822\n",
      "\n",
      "Epoch 00210: val_loss did not improve from 0.01660\n",
      "81/81 [==============================] - 77s 946ms/step - loss: 0.0195 - acc: 0.9938 - val_loss: 0.0474 - val_acc: 0.9822\n",
      "Epoch 211/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0138 - acc: 0.9959WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 86s 27ms/sample - loss: 0.0348 - acc: 0.9897\n",
      "\n",
      "Epoch 00211: val_loss did not improve from 0.01660\n",
      "81/81 [==============================] - 92s 1s/step - loss: 0.0136 - acc: 0.9960 - val_loss: 0.0348 - val_acc: 0.9897\n",
      "Epoch 212/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0178 - acc: 0.9950WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 48s 15ms/sample - loss: 0.0372 - acc: 0.9925\n",
      "\n",
      "Epoch 00212: val_loss did not improve from 0.01660\n",
      "81/81 [==============================] - 80s 982ms/step - loss: 0.0178 - acc: 0.9950 - val_loss: 0.0372 - val_acc: 0.9925\n",
      "Epoch 213/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0134 - acc: 0.9949WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 82s 26ms/sample - loss: 0.0382 - acc: 0.9950\n",
      "\n",
      "Epoch 00213: val_loss did not improve from 0.01660\n",
      "81/81 [==============================] - 91s 1s/step - loss: 0.0134 - acc: 0.9947 - val_loss: 0.0382 - val_acc: 0.9950\n",
      "Epoch 214/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0134 - acc: 0.9968WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 49s 15ms/sample - loss: 0.0289 - acc: 0.9897\n",
      "\n",
      "Epoch 00214: val_loss did not improve from 0.01660\n",
      "81/81 [==============================] - 81s 1s/step - loss: 0.0131 - acc: 0.9969 - val_loss: 0.0289 - val_acc: 0.9897\n",
      "Epoch 215/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/81 [============================>.] - ETA: 0s - loss: 0.0144 - acc: 0.9955WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 72s 22ms/sample - loss: 0.0316 - acc: 0.9947\n",
      "\n",
      "Epoch 00215: val_loss did not improve from 0.01660\n",
      "81/81 [==============================] - 76s 944ms/step - loss: 0.0142 - acc: 0.9957 - val_loss: 0.0316 - val_acc: 0.9947\n",
      "Epoch 216/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0259 - acc: 0.9921WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 72s 22ms/sample - loss: 0.0351 - acc: 0.9922\n",
      "\n",
      "Epoch 00216: val_loss did not improve from 0.01660\n",
      "81/81 [==============================] - 80s 986ms/step - loss: 0.0258 - acc: 0.9922 - val_loss: 0.0351 - val_acc: 0.9922\n",
      "Epoch 217/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0160 - acc: 0.9947WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 14s 4ms/sample - loss: 0.0353 - acc: 0.9887\n",
      "\n",
      "Epoch 00217: val_loss did not improve from 0.01660\n",
      "81/81 [==============================] - 75s 930ms/step - loss: 0.0160 - acc: 0.9947 - val_loss: 0.0353 - val_acc: 0.9887\n",
      "Epoch 218/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0205 - acc: 0.9940WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 74s 23ms/sample - loss: 0.0501 - acc: 0.9887\n",
      "\n",
      "Epoch 00218: val_loss did not improve from 0.01660\n",
      "81/81 [==============================] - 78s 966ms/step - loss: 0.0203 - acc: 0.9941 - val_loss: 0.0501 - val_acc: 0.9887\n",
      "Epoch 219/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0196 - acc: 0.9937WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3190/3183 [==============================] - 45s 14ms/sample - loss: 0.0305 - acc: 0.9925\n",
      "\n",
      "Epoch 00219: val_loss did not improve from 0.01660\n",
      "81/81 [==============================] - 77s 948ms/step - loss: 0.0202 - acc: 0.9935 - val_loss: 0.0305 - val_acc: 0.9925\n",
      "Epoch 220/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0107 - acc: 0.9968WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 71s 22ms/sample - loss: 0.0455 - acc: 0.9922\n",
      "\n",
      "Epoch 00220: val_loss did not improve from 0.01660\n",
      "81/81 [==============================] - 76s 944ms/step - loss: 0.0114 - acc: 0.9966 - val_loss: 0.0455 - val_acc: 0.9922\n",
      "Epoch 221/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0162 - acc: 0.9952WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 70s 22ms/sample - loss: 0.0397 - acc: 0.99120s -\n",
      "\n",
      "Epoch 00221: val_loss did not improve from 0.01660\n",
      "81/81 [==============================] - 74s 914ms/step - loss: 0.0160 - acc: 0.9953 - val_loss: 0.0397 - val_acc: 0.9912\n",
      "Epoch 222/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0161 - acc: 0.9952WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 70s 22ms/sample - loss: 0.0379 - acc: 0.9925\n",
      "\n",
      "Epoch 00222: val_loss did not improve from 0.01660\n",
      "81/81 [==============================] - 74s 919ms/step - loss: 0.0157 - acc: 0.9953 - val_loss: 0.0379 - val_acc: 0.9925\n",
      "Epoch 223/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0328 - acc: 0.9915WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 67s 21ms/sample - loss: 0.0479 - acc: 0.9950\n",
      "\n",
      "Epoch 00223: val_loss did not improve from 0.01660\n",
      "81/81 [==============================] - 75s 927ms/step - loss: 0.0328 - acc: 0.9916 - val_loss: 0.0479 - val_acc: 0.9950\n",
      "Epoch 224/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0184 - acc: 0.9949WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 45s 14ms/sample - loss: 0.0409 - acc: 0.9919\n",
      "\n",
      "Epoch 00224: val_loss did not improve from 0.01660\n",
      "81/81 [==============================] - 77s 945ms/step - loss: 0.0181 - acc: 0.9950 - val_loss: 0.0409 - val_acc: 0.9919\n",
      "Epoch 225/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0272 - acc: 0.9915- ETWARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 72s 22ms/sample - loss: 0.0341 - acc: 0.9925\n",
      "\n",
      "Epoch 00225: val_loss did not improve from 0.01660\n",
      "81/81 [==============================] - 76s 942ms/step - loss: 0.0274 - acc: 0.9913 - val_loss: 0.0341 - val_acc: 0.9925\n",
      "Epoch 226/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0135 - acc: 0.9959WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 71s 22ms/sample - loss: 0.0257 - acc: 0.9919\n",
      "\n",
      "Epoch 00226: val_loss did not improve from 0.01660\n",
      "81/81 [==============================] - 76s 944ms/step - loss: 0.0133 - acc: 0.9960 - val_loss: 0.0257 - val_acc: 0.9919\n",
      "Epoch 227/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0099 - acc: 0.9965WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 75s 23ms/sample - loss: 0.0332 - acc: 0.9897\n",
      "\n",
      "Epoch 00227: val_loss did not improve from 0.01660\n",
      "81/81 [==============================] - 81s 1s/step - loss: 0.0098 - acc: 0.9966 - val_loss: 0.0332 - val_acc: 0.9897\n",
      "Epoch 228/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0222 - acc: 0.9959WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 75s 23ms/sample - loss: 0.0253 - acc: 0.9922\n",
      "\n",
      "Epoch 00228: val_loss did not improve from 0.01660\n",
      "81/81 [==============================] - 80s 984ms/step - loss: 0.0219 - acc: 0.9960 - val_loss: 0.0253 - val_acc: 0.9922\n",
      "Epoch 229/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0379 - acc: 0.9899WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 66s 21ms/sample - loss: 0.0210 - acc: 0.9941\n",
      "\n",
      "Epoch 00229: val_loss did not improve from 0.01660\n",
      "81/81 [==============================] - 74s 914ms/step - loss: 0.0376 - acc: 0.9901 - val_loss: 0.0210 - val_acc: 0.9941\n",
      "Epoch 230/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0235 - acc: 0.9928WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3200/3183 [==============================] - 68s 21ms/sample - loss: 0.0245 - acc: 0.9919\n",
      "\n",
      "Epoch 00230: val_loss did not improve from 0.01660\n",
      "81/81 [==============================] - 76s 934ms/step - loss: 0.0233 - acc: 0.9929 - val_loss: 0.0245 - val_acc: 0.9919\n",
      "Epoch 231/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0146 - acc: 0.9959WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 75s 23ms/sample - loss: 0.0242 - acc: 0.9922\n",
      "\n",
      "Epoch 00231: val_loss did not improve from 0.01660\n",
      "81/81 [==============================] - 80s 985ms/step - loss: 0.0147 - acc: 0.9957 - val_loss: 0.0242 - val_acc: 0.9922\n",
      "Epoch 232/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0282 - acc: 0.9905- EWARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 46s 14ms/sample - loss: 0.0340 - acc: 0.9922\n",
      "\n",
      "Epoch 00232: val_loss did not improve from 0.01660\n",
      "81/81 [==============================] - 77s 957ms/step - loss: 0.0283 - acc: 0.9904 - val_loss: 0.0340 - val_acc: 0.9922\n",
      "Epoch 233/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0210 - acc: 0.9943WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 72s 22ms/sample - loss: 0.0198 - acc: 0.9944\n",
      "\n",
      "Epoch 00233: val_loss did not improve from 0.01660\n",
      "81/81 [==============================] - 79s 971ms/step - loss: 0.0209 - acc: 0.9944 - val_loss: 0.0198 - val_acc: 0.9944\n",
      "Epoch 234/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0090 - acc: 0.9987WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 48s 15ms/sample - loss: 0.0315 - acc: 0.9947\n",
      "\n",
      "Epoch 00234: val_loss did not improve from 0.01660\n",
      "81/81 [==============================] - 80s 985ms/step - loss: 0.0091 - acc: 0.9988 - val_loss: 0.0315 - val_acc: 0.9947\n",
      "Epoch 235/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0255 - acc: 0.9921WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 73s 23ms/sample - loss: 0.0298 - acc: 0.9887\n",
      "\n",
      "Epoch 00235: val_loss did not improve from 0.01660\n",
      "81/81 [==============================] - 84s 1s/step - loss: 0.0253 - acc: 0.9922 - val_loss: 0.0298 - val_acc: 0.9887\n",
      "Epoch 236/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0198 - acc: 0.9940WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.0324 - acc: 0.9909\n",
      "\n",
      "Epoch 00236: val_loss did not improve from 0.01660\n",
      "81/81 [==============================] - 74s 914ms/step - loss: 0.0203 - acc: 0.9938 - val_loss: 0.0324 - val_acc: 0.9909\n",
      "Epoch 237/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0091 - acc: 0.9969WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 74s 23ms/sample - loss: 0.0316 - acc: 0.9916\n",
      "\n",
      "Epoch 00237: val_loss did not improve from 0.01660\n",
      "81/81 [==============================] - 78s 964ms/step - loss: 0.0105 - acc: 0.9966 - val_loss: 0.0316 - val_acc: 0.9916\n",
      "Epoch 238/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0189 - acc: 0.9934WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 47s 15ms/sample - loss: 0.0365 - acc: 0.9950\n",
      "\n",
      "Epoch 00238: val_loss did not improve from 0.01660\n",
      "81/81 [==============================] - 76s 932ms/step - loss: 0.0187 - acc: 0.9935 - val_loss: 0.0365 - val_acc: 0.9950\n",
      "Epoch 239/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0120 - acc: 0.9965WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 73s 23ms/sample - loss: 0.0360 - acc: 0.9912\n",
      "\n",
      "Epoch 00239: val_loss did not improve from 0.01660\n",
      "81/81 [==============================] - 79s 971ms/step - loss: 0.0120 - acc: 0.9966 - val_loss: 0.0360 - val_acc: 0.9912\n",
      "Epoch 240/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0133 - acc: 0.9955WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 74s 23ms/sample - loss: 0.0271 - acc: 0.9916\n",
      "\n",
      "Epoch 00240: val_loss did not improve from 0.01660\n",
      "81/81 [==============================] - 84s 1s/step - loss: 0.0130 - acc: 0.9957 - val_loss: 0.0271 - val_acc: 0.9916\n",
      "Epoch 241/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0242 - acc: 0.9931WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 62s 19ms/sample - loss: 0.0345 - acc: 0.9909\n",
      "\n",
      "Epoch 00241: val_loss did not improve from 0.01660\n",
      "81/81 [==============================] - 78s 966ms/step - loss: 0.0241 - acc: 0.9932 - val_loss: 0.0345 - val_acc: 0.9909\n",
      "Epoch 242/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0075 - acc: 0.9987WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 78s 24ms/sample - loss: 0.0367 - acc: 0.9925\n",
      "\n",
      "Epoch 00242: val_loss did not improve from 0.01660\n",
      "81/81 [==============================] - 83s 1s/step - loss: 0.0075 - acc: 0.9988 - val_loss: 0.0367 - val_acc: 0.9925\n",
      "Epoch 243/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0182 - acc: 0.9943WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 15s 5ms/sample - loss: 0.0395 - acc: 0.9919\n",
      "\n",
      "Epoch 00243: val_loss did not improve from 0.01660\n",
      "81/81 [==============================] - 78s 963ms/step - loss: 0.0181 - acc: 0.9944 - val_loss: 0.0395 - val_acc: 0.9919\n",
      "Epoch 244/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0188 - acc: 0.9955WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 46s 14ms/sample - loss: 0.0340 - acc: 0.9909\n",
      "\n",
      "Epoch 00244: val_loss did not improve from 0.01660\n",
      "81/81 [==============================] - 77s 947ms/step - loss: 0.0199 - acc: 0.9950 - val_loss: 0.0340 - val_acc: 0.9909\n",
      "Epoch 245/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0155 - acc: 0.9953WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 66s 21ms/sample - loss: 0.0415 - acc: 0.9866\n",
      "\n",
      "Epoch 00245: val_loss did not improve from 0.01660\n",
      "81/81 [==============================] - 78s 966ms/step - loss: 0.0153 - acc: 0.9953 - val_loss: 0.0415 - val_acc: 0.9866\n",
      "Epoch 246/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/81 [============================>.] - ETA: 0s - loss: 0.0163 - acc: 0.9956WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 66s 21ms/sample - loss: 0.0494 - acc: 0.9841\n",
      "\n",
      "Epoch 00246: val_loss did not improve from 0.01660\n",
      "81/81 [==============================] - 75s 931ms/step - loss: 0.0163 - acc: 0.9957 - val_loss: 0.0494 - val_acc: 0.9841\n",
      "Epoch 247/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0108 - acc: 0.9969WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 67s 21ms/sample - loss: 0.0539 - acc: 0.9950\n",
      "\n",
      "Epoch 00247: val_loss did not improve from 0.01660\n",
      "81/81 [==============================] - 77s 952ms/step - loss: 0.0107 - acc: 0.9969 - val_loss: 0.0539 - val_acc: 0.9950\n",
      "Epoch 248/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0208 - acc: 0.9931WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 73s 23ms/sample - loss: 0.0313 - acc: 0.9925\n",
      "\n",
      "Epoch 00248: val_loss did not improve from 0.01660\n",
      "81/81 [==============================] - 77s 951ms/step - loss: 0.0212 - acc: 0.9929 - val_loss: 0.0313 - val_acc: 0.9925\n",
      "Epoch 249/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0115 - acc: 0.9962WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 71s 22ms/sample - loss: 0.0396 - acc: 0.9900\n",
      "\n",
      "Epoch 00249: val_loss did not improve from 0.01660\n",
      "81/81 [==============================] - 79s 973ms/step - loss: 0.0114 - acc: 0.9963 - val_loss: 0.0396 - val_acc: 0.9900\n",
      "Epoch 250/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0152 - acc: 0.9956WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0326 - acc: 0.9878\n",
      "\n",
      "Epoch 00250: val_loss did not improve from 0.01660\n",
      "81/81 [==============================] - 75s 926ms/step - loss: 0.0150 - acc: 0.9957 - val_loss: 0.0326 - val_acc: 0.9878\n",
      "Epoch 251/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0068 - acc: 0.9990WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 73s 23ms/sample - loss: 0.0425 - acc: 0.9909\n",
      "\n",
      "Epoch 00251: val_loss did not improve from 0.01660\n",
      "81/81 [==============================] - 79s 969ms/step - loss: 0.0067 - acc: 0.9991 - val_loss: 0.0425 - val_acc: 0.9909\n",
      "Epoch 252/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0092 - acc: 0.9972WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 47s 15ms/sample - loss: 0.0337 - acc: 0.9919\n",
      "\n",
      "Epoch 00252: val_loss did not improve from 0.01660\n",
      "81/81 [==============================] - 78s 957ms/step - loss: 0.0092 - acc: 0.9972 - val_loss: 0.0337 - val_acc: 0.9919\n",
      "Epoch 253/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0188 - acc: 0.9943WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 70s 22ms/sample - loss: 0.0336 - acc: 0.9922\n",
      "\n",
      "Epoch 00253: val_loss did not improve from 0.01660\n",
      "81/81 [==============================] - 75s 925ms/step - loss: 0.0186 - acc: 0.9944 - val_loss: 0.0336 - val_acc: 0.9922\n",
      "Epoch 254/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0135 - acc: 0.9952WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.0248 - acc: 0.9947\n",
      "\n",
      "Epoch 00254: val_loss did not improve from 0.01660\n",
      "81/81 [==============================] - 77s 945ms/step - loss: 0.0132 - acc: 0.9953 - val_loss: 0.0248 - val_acc: 0.9947\n",
      "Epoch 255/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0233 - acc: 0.9933WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.0412 - acc: 0.9869\n",
      "\n",
      "Epoch 00255: val_loss did not improve from 0.01660\n",
      "81/81 [==============================] - 79s 973ms/step - loss: 0.0237 - acc: 0.9929 - val_loss: 0.0412 - val_acc: 0.9869\n",
      "Epoch 256/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0137 - acc: 0.9965WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 73s 23ms/sample - loss: 0.0426 - acc: 0.9866\n",
      "\n",
      "Epoch 00256: val_loss did not improve from 0.01660\n",
      "81/81 [==============================] - 77s 952ms/step - loss: 0.0136 - acc: 0.9966 - val_loss: 0.0426 - val_acc: 0.9866\n",
      "Epoch 257/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0156 - acc: 0.9940WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 45s 14ms/sample - loss: 0.0390 - acc: 0.9925\n",
      "\n",
      "Epoch 00257: val_loss did not improve from 0.01660\n",
      "81/81 [==============================] - 76s 937ms/step - loss: 0.0158 - acc: 0.9938 - val_loss: 0.0390 - val_acc: 0.9925\n",
      "Epoch 258/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0199 - acc: 0.9943WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.0276 - acc: 0.9919\n",
      "\n",
      "Epoch 00258: val_loss did not improve from 0.01660\n",
      "81/81 [==============================] - 77s 948ms/step - loss: 0.0196 - acc: 0.9944 - val_loss: 0.0276 - val_acc: 0.9919\n",
      "Epoch 259/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0180 - acc: 0.9949WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 67s 21ms/sample - loss: 0.0203 - acc: 0.9925\n",
      "\n",
      "Epoch 00259: val_loss did not improve from 0.01660\n",
      "81/81 [==============================] - 75s 926ms/step - loss: 0.0176 - acc: 0.9950 - val_loss: 0.0203 - val_acc: 0.9925\n",
      "Epoch 260/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0128 - acc: 0.9943WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 72s 23ms/sample - loss: 0.0341 - acc: 0.9944\n",
      "\n",
      "Epoch 00260: val_loss did not improve from 0.01660\n",
      "81/81 [==============================] - 78s 961ms/step - loss: 0.0127 - acc: 0.9944 - val_loss: 0.0341 - val_acc: 0.9944\n",
      "Epoch 261/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0081 - acc: 0.9971WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3200/3183 [==============================] - 73s 23ms/sample - loss: 0.0272 - acc: 0.9897\n",
      "\n",
      "Epoch 00261: val_loss did not improve from 0.01660\n",
      "81/81 [==============================] - 78s 962ms/step - loss: 0.0080 - acc: 0.9972 - val_loss: 0.0272 - val_acc: 0.9897\n",
      "Epoch 262/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0238 - acc: 0.9949WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.0216 - acc: 0.9922\n",
      "\n",
      "Epoch 00262: val_loss did not improve from 0.01660\n",
      "81/81 [==============================] - 73s 906ms/step - loss: 0.0233 - acc: 0.9950 - val_loss: 0.0216 - val_acc: 0.9922\n",
      "Epoch 263/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0133 - acc: 0.9953WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 57s 18ms/sample - loss: 0.0247 - acc: 0.9922\n",
      "\n",
      "Epoch 00263: val_loss did not improve from 0.01660\n",
      "81/81 [==============================] - 76s 940ms/step - loss: 0.0131 - acc: 0.9953 - val_loss: 0.0247 - val_acc: 0.9922\n",
      "Epoch 264/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0100 - acc: 0.9975WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0388 - acc: 0.9919\n",
      "\n",
      "Epoch 00264: val_loss did not improve from 0.01660\n",
      "81/81 [==============================] - 74s 916ms/step - loss: 0.0101 - acc: 0.9975 - val_loss: 0.0388 - val_acc: 0.9919\n",
      "Epoch 265/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0169 - acc: 0.9953WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 71s 22ms/sample - loss: 0.0224 - acc: 0.9919\n",
      "\n",
      "Epoch 00265: val_loss did not improve from 0.01660\n",
      "81/81 [==============================] - 76s 940ms/step - loss: 0.0168 - acc: 0.9953 - val_loss: 0.0224 - val_acc: 0.9919\n",
      "Epoch 266/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0188 - acc: 0.9947WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 68s 21ms/sample - loss: 0.0366 - acc: 0.9916\n",
      "\n",
      "Epoch 00266: val_loss did not improve from 0.01660\n",
      "81/81 [==============================] - 85s 1s/step - loss: 0.0186 - acc: 0.9947 - val_loss: 0.0366 - val_acc: 0.9916\n",
      "Epoch 267/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0106 - acc: 0.9959WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 72s 22ms/sample - loss: 0.0222 - acc: 0.9909\n",
      "\n",
      "Epoch 00267: val_loss did not improve from 0.01660\n",
      "81/81 [==============================] - 76s 942ms/step - loss: 0.0107 - acc: 0.9957 - val_loss: 0.0222 - val_acc: 0.9909\n",
      "Epoch 268/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0169 - acc: 0.9950WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 82s 26ms/sample - loss: 0.0253 - acc: 0.9900\n",
      "\n",
      "Epoch 00268: val_loss did not improve from 0.01660\n",
      "81/81 [==============================] - 86s 1s/step - loss: 0.0167 - acc: 0.9950 - val_loss: 0.0253 - val_acc: 0.9900\n",
      "Epoch 269/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0151 - acc: 0.9962WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 69s 22ms/sample - loss: 0.0335 - acc: 0.9922\n",
      "\n",
      "Epoch 00269: val_loss did not improve from 0.01660\n",
      "81/81 [==============================] - 77s 952ms/step - loss: 0.0147 - acc: 0.9963 - val_loss: 0.0335 - val_acc: 0.9922\n",
      "Epoch 270/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0283 - acc: 0.9914WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 67s 21ms/sample - loss: 0.0475 - acc: 0.99003s - loss: 0.0\n",
      "\n",
      "Epoch 00270: val_loss did not improve from 0.01660\n",
      "81/81 [==============================] - 72s 888ms/step - loss: 0.0278 - acc: 0.9916 - val_loss: 0.0475 - val_acc: 0.9900\n",
      "Epoch 271/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0118 - acc: 0.9959WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 72s 23ms/sample - loss: 0.0388 - acc: 0.9922\n",
      "\n",
      "Epoch 00271: val_loss did not improve from 0.01660\n",
      "81/81 [==============================] - 77s 951ms/step - loss: 0.0125 - acc: 0.9957 - val_loss: 0.0388 - val_acc: 0.9922\n",
      "Epoch 272/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0149 - acc: 0.9969WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 73s 23ms/sample - loss: 0.0212 - acc: 0.9950\n",
      "\n",
      "Epoch 00272: val_loss did not improve from 0.01660\n",
      "81/81 [==============================] - 78s 957ms/step - loss: 0.0148 - acc: 0.9969 - val_loss: 0.0212 - val_acc: 0.9950\n",
      "Epoch 273/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0055 - acc: 0.9990WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 70s 22ms/sample - loss: 0.0159 - acc: 0.9925\n",
      "\n",
      "Epoch 00273: val_loss improved from 0.01660 to 0.01588, saving model to model/checkpoint/vis_imagenet_6_class_augmentation_2D_CNN_custom_ch_32_DO_050_DO_4_conv_checkpoint/273-0.0159.hdf5\n",
      "81/81 [==============================] - 76s 933ms/step - loss: 0.0056 - acc: 0.9988 - val_loss: 0.0159 - val_acc: 0.9925\n",
      "Epoch 274/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0169 - acc: 0.9965WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 52s 16ms/sample - loss: 0.0317 - acc: 0.9950\n",
      "\n",
      "Epoch 00274: val_loss did not improve from 0.01588\n",
      "81/81 [==============================] - 82s 1s/step - loss: 0.0168 - acc: 0.9966 - val_loss: 0.0317 - val_acc: 0.9950\n",
      "Epoch 275/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0105 - acc: 0.9978WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 71s 22ms/sample - loss: 0.0225 - acc: 0.9931\n",
      "\n",
      "Epoch 00275: val_loss did not improve from 0.01588\n",
      "81/81 [==============================] - 77s 951ms/step - loss: 0.0104 - acc: 0.9978 - val_loss: 0.0225 - val_acc: 0.9931\n",
      "Epoch 276/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0194 - acc: 0.9940WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 88s 27ms/sample - loss: 0.0623 - acc: 0.9900\n",
      "\n",
      "Epoch 00276: val_loss did not improve from 0.01588\n",
      "81/81 [==============================] - 92s 1s/step - loss: 0.0196 - acc: 0.9938 - val_loss: 0.0623 - val_acc: 0.9900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 277/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0175 - acc: 0.9930WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 69s 21ms/sample - loss: 0.0313 - acc: 0.9937\n",
      "\n",
      "Epoch 00277: val_loss did not improve from 0.01588\n",
      "81/81 [==============================] - 81s 1s/step - loss: 0.0176 - acc: 0.9929 - val_loss: 0.0313 - val_acc: 0.9937\n",
      "Epoch 278/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0098 - acc: 0.9978WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - ETA: 0s - loss: 0.0263 - acc: 0.991 - 16s 5ms/sample - loss: 0.0260 - acc: 0.9912\n",
      "\n",
      "Epoch 00278: val_loss did not improve from 0.01588\n",
      "81/81 [==============================] - 77s 956ms/step - loss: 0.0097 - acc: 0.9978 - val_loss: 0.0260 - val_acc: 0.9912\n",
      "Epoch 279/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0174 - acc: 0.9978WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 74s 23ms/sample - loss: 0.0472 - acc: 0.9931\n",
      "\n",
      "Epoch 00279: val_loss did not improve from 0.01588\n",
      "81/81 [==============================] - 79s 976ms/step - loss: 0.0172 - acc: 0.9978 - val_loss: 0.0472 - val_acc: 0.9931\n",
      "Epoch 280/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0111 - acc: 0.9972WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 66s 20ms/sample - loss: 0.0347 - acc: 0.9947\n",
      "\n",
      "Epoch 00280: val_loss did not improve from 0.01588\n",
      "81/81 [==============================] - 77s 956ms/step - loss: 0.0112 - acc: 0.9972 - val_loss: 0.0347 - val_acc: 0.9947\n",
      "Epoch 281/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0155 - acc: 0.9962WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 76s 24ms/sample - loss: 0.0323 - acc: 0.9950\n",
      "\n",
      "Epoch 00281: val_loss did not improve from 0.01588\n",
      "81/81 [==============================] - 84s 1s/step - loss: 0.0154 - acc: 0.9963 - val_loss: 0.0323 - val_acc: 0.9950\n",
      "Epoch 282/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0070 - acc: 0.9987WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 73s 23ms/sample - loss: 0.0286 - acc: 0.9944\n",
      "\n",
      "Epoch 00282: val_loss did not improve from 0.01588\n",
      "81/81 [==============================] - 80s 982ms/step - loss: 0.0068 - acc: 0.9988 - val_loss: 0.0286 - val_acc: 0.9944\n",
      "Epoch 283/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0141 - acc: 0.9959WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 66s 21ms/sample - loss: 0.0234 - acc: 0.9947\n",
      "\n",
      "Epoch 00283: val_loss did not improve from 0.01588\n",
      "81/81 [==============================] - 77s 953ms/step - loss: 0.0149 - acc: 0.9953 - val_loss: 0.0234 - val_acc: 0.9947\n",
      "Epoch 284/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0284 - acc: 0.9918WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 70s 22ms/sample - loss: 0.0311 - acc: 0.9947\n",
      "\n",
      "Epoch 00284: val_loss did not improve from 0.01588\n",
      "81/81 [==============================] - 74s 918ms/step - loss: 0.0281 - acc: 0.9919 - val_loss: 0.0311 - val_acc: 0.9947\n",
      "Epoch 285/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0102 - acc: 0.9978WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 71s 22ms/sample - loss: 0.0362 - acc: 0.9947\n",
      "\n",
      "Epoch 00285: val_loss did not improve from 0.01588\n",
      "81/81 [==============================] - 79s 975ms/step - loss: 0.0100 - acc: 0.9978 - val_loss: 0.0362 - val_acc: 0.9947\n",
      "Epoch 286/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0123 - acc: 0.9965WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 72s 23ms/sample - loss: 0.0379 - acc: 0.9944\n",
      "\n",
      "Epoch 00286: val_loss did not improve from 0.01588\n",
      "81/81 [==============================] - 79s 978ms/step - loss: 0.0122 - acc: 0.9966 - val_loss: 0.0379 - val_acc: 0.9944\n",
      "Epoch 287/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0137 - acc: 0.9962WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 71s 22ms/sample - loss: 0.0195 - acc: 0.9944\n",
      "\n",
      "Epoch 00287: val_loss did not improve from 0.01588\n",
      "81/81 [==============================] - 76s 938ms/step - loss: 0.0136 - acc: 0.9963 - val_loss: 0.0195 - val_acc: 0.9944\n",
      "Epoch 288/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0149 - acc: 0.9971WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 77s 24ms/sample - loss: 0.0318 - acc: 0.9881\n",
      "\n",
      "Epoch 00288: val_loss did not improve from 0.01588\n",
      "81/81 [==============================] - 81s 1s/step - loss: 0.0146 - acc: 0.9972 - val_loss: 0.0318 - val_acc: 0.9881\n",
      "Epoch 289/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0090 - acc: 0.9975WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 74s 23ms/sample - loss: 0.0275 - acc: 0.9919\n",
      "\n",
      "Epoch 00289: val_loss did not improve from 0.01588\n",
      "81/81 [==============================] - 78s 963ms/step - loss: 0.0089 - acc: 0.9975 - val_loss: 0.0275 - val_acc: 0.9919\n",
      "Epoch 290/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0138 - acc: 0.9962WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 76s 24ms/sample - loss: 0.0398 - acc: 0.9925\n",
      "\n",
      "Epoch 00290: val_loss did not improve from 0.01588\n",
      "81/81 [==============================] - 87s 1s/step - loss: 0.0138 - acc: 0.9963 - val_loss: 0.0398 - val_acc: 0.9925\n",
      "Epoch 291/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0165 - acc: 0.9959WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 75s 24ms/sample - loss: 0.0230 - acc: 0.9937\n",
      "\n",
      "Epoch 00291: val_loss did not improve from 0.01588\n",
      "81/81 [==============================] - 82s 1s/step - loss: 0.0164 - acc: 0.9960 - val_loss: 0.0230 - val_acc: 0.9937\n",
      "Epoch 292/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0220 - acc: 0.9928WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3200/3183 [==============================] - 22s 7ms/sample - loss: 0.0282 - acc: 0.9950\n",
      "\n",
      "Epoch 00292: val_loss did not improve from 0.01588\n",
      "81/81 [==============================] - 81s 1000ms/step - loss: 0.0217 - acc: 0.9929 - val_loss: 0.0282 - val_acc: 0.9950\n",
      "Epoch 293/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0147 - acc: 0.9953WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 67s 21ms/sample - loss: 0.0226 - acc: 0.9934\n",
      "\n",
      "Epoch 00293: val_loss did not improve from 0.01588\n",
      "81/81 [==============================] - 80s 988ms/step - loss: 0.0146 - acc: 0.9953 - val_loss: 0.0226 - val_acc: 0.9934\n",
      "Epoch 294/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0043 - acc: 0.9990WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 76s 24ms/sample - loss: 0.0332 - acc: 0.9941\n",
      "\n",
      "Epoch 00294: val_loss did not improve from 0.01588\n",
      "81/81 [==============================] - 82s 1s/step - loss: 0.0042 - acc: 0.9991 - val_loss: 0.0332 - val_acc: 0.9941\n",
      "Epoch 295/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0088 - acc: 0.9987WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 76s 24ms/sample - loss: 0.0375 - acc: 0.9947\n",
      "\n",
      "Epoch 00295: val_loss did not improve from 0.01588\n",
      "81/81 [==============================] - 83s 1s/step - loss: 0.0088 - acc: 0.9988 - val_loss: 0.0375 - val_acc: 0.9947\n",
      "Epoch 296/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0104 - acc: 0.9968WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 47s 15ms/sample - loss: 0.0382 - acc: 0.9941\n",
      "\n",
      "Epoch 00296: val_loss did not improve from 0.01588\n",
      "81/81 [==============================] - 77s 947ms/step - loss: 0.0103 - acc: 0.9969 - val_loss: 0.0382 - val_acc: 0.9941\n",
      "Epoch 297/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0122 - acc: 0.9959WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 79s 25ms/sample - loss: 0.0290 - acc: 0.99508s - loss: 0\n",
      "\n",
      "Epoch 00297: val_loss did not improve from 0.01588\n",
      "81/81 [==============================] - 84s 1s/step - loss: 0.0124 - acc: 0.9957 - val_loss: 0.0290 - val_acc: 0.9950\n",
      "Epoch 298/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0059 - acc: 0.9984WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 64s 20ms/sample - loss: 0.0365 - acc: 0.9950\n",
      "\n",
      "Epoch 00298: val_loss did not improve from 0.01588\n",
      "81/81 [==============================] - 73s 900ms/step - loss: 0.0058 - acc: 0.9984 - val_loss: 0.0365 - val_acc: 0.9950\n",
      "Epoch 299/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0145 - acc: 0.9968WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 75s 23ms/sample - loss: 0.0302 - acc: 0.9937\n",
      "\n",
      "Epoch 00299: val_loss did not improve from 0.01588\n",
      "81/81 [==============================] - 82s 1s/step - loss: 0.0159 - acc: 0.9966 - val_loss: 0.0302 - val_acc: 0.9937\n",
      "Epoch 300/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0104 - acc: 0.9978WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 73s 23ms/sample - loss: 0.0315 - acc: 0.99507s - loss: 0.0392 -\n",
      "\n",
      "Epoch 00300: val_loss did not improve from 0.01588\n",
      "81/81 [==============================] - 81s 1s/step - loss: 0.0101 - acc: 0.9978 - val_loss: 0.0315 - val_acc: 0.9950\n",
      "Epoch 301/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0098 - acc: 0.9969WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 65s 20ms/sample - loss: 0.0359 - acc: 0.99376s - los\n",
      "\n",
      "Epoch 00301: val_loss did not improve from 0.01588\n",
      "81/81 [==============================] - 76s 943ms/step - loss: 0.0106 - acc: 0.9966 - val_loss: 0.0359 - val_acc: 0.9937\n",
      "Epoch 302/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0077 - acc: 0.9972WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0231 - acc: 0.99254s - loss: 0.0298 - a\n",
      "\n",
      "Epoch 00302: val_loss did not improve from 0.01588\n",
      "81/81 [==============================] - 75s 928ms/step - loss: 0.0076 - acc: 0.9972 - val_loss: 0.0231 - val_acc: 0.9925\n",
      "Epoch 303/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0145 - acc: 0.9962WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 72s 23ms/sample - loss: 0.0472 - acc: 0.9950\n",
      "\n",
      "Epoch 00303: val_loss did not improve from 0.01588\n",
      "81/81 [==============================] - 82s 1s/step - loss: 0.0145 - acc: 0.9960 - val_loss: 0.0472 - val_acc: 0.9950\n",
      "Epoch 304/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0121 - acc: 0.9965WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.0428 - acc: 0.9941\n",
      "\n",
      "Epoch 00304: val_loss did not improve from 0.01588\n",
      "81/81 [==============================] - 78s 962ms/step - loss: 0.0119 - acc: 0.9966 - val_loss: 0.0428 - val_acc: 0.9941\n",
      "Epoch 305/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0095 - acc: 0.9972WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.0316 - acc: 0.9937\n",
      "\n",
      "Epoch 00305: val_loss did not improve from 0.01588\n",
      "81/81 [==============================] - 74s 909ms/step - loss: 0.0094 - acc: 0.9972 - val_loss: 0.0316 - val_acc: 0.9937\n",
      "Epoch 306/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0101 - acc: 0.9975WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.0256 - acc: 0.9869\n",
      "\n",
      "Epoch 00306: val_loss did not improve from 0.01588\n",
      "81/81 [==============================] - 78s 963ms/step - loss: 0.0108 - acc: 0.9972 - val_loss: 0.0256 - val_acc: 0.9869\n",
      "Epoch 307/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0121 - acc: 0.9962WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 77s 24ms/sample - loss: 0.0394 - acc: 0.9950\n",
      "\n",
      "Epoch 00307: val_loss did not improve from 0.01588\n",
      "81/81 [==============================] - 82s 1s/step - loss: 0.0122 - acc: 0.9963 - val_loss: 0.0394 - val_acc: 0.9950\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 308/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0108 - acc: 0.9971WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 67s 21ms/sample - loss: 0.0318 - acc: 0.9944\n",
      "\n",
      "Epoch 00308: val_loss did not improve from 0.01588\n",
      "81/81 [==============================] - 77s 953ms/step - loss: 0.0116 - acc: 0.9969 - val_loss: 0.0318 - val_acc: 0.9944\n",
      "Epoch 309/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0160 - acc: 0.9950WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 48s 15ms/sample - loss: 0.0290 - acc: 0.9934\n",
      "\n",
      "Epoch 00309: val_loss did not improve from 0.01588\n",
      "81/81 [==============================] - 80s 986ms/step - loss: 0.0158 - acc: 0.9950 - val_loss: 0.0290 - val_acc: 0.9934\n",
      "Epoch 310/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0094 - acc: 0.9972WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3190/3183 [==============================] - 16s 5ms/sample - loss: 0.0234 - acc: 0.9925\n",
      "\n",
      "Epoch 00310: val_loss did not improve from 0.01588\n",
      "81/81 [==============================] - 74s 920ms/step - loss: 0.0093 - acc: 0.9972 - val_loss: 0.0234 - val_acc: 0.9925\n",
      "Epoch 311/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0101 - acc: 0.9968WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 68s 21ms/sample - loss: 0.0286 - acc: 0.9925\n",
      "\n",
      "Epoch 00311: val_loss did not improve from 0.01588\n",
      "81/81 [==============================] - 77s 947ms/step - loss: 0.0123 - acc: 0.9963 - val_loss: 0.0286 - val_acc: 0.9925\n",
      "Epoch 312/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0166 - acc: 0.9946WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 80s 25ms/sample - loss: 0.0273 - acc: 0.9925\n",
      "\n",
      "Epoch 00312: val_loss did not improve from 0.01588\n",
      "81/81 [==============================] - 87s 1s/step - loss: 0.0201 - acc: 0.9938 - val_loss: 0.0273 - val_acc: 0.9925\n",
      "Epoch 313/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0146 - acc: 0.9934WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 14s 4ms/sample - loss: 0.0141 - acc: 0.9944\n",
      "\n",
      "Epoch 00313: val_loss improved from 0.01588 to 0.01410, saving model to model/checkpoint/vis_imagenet_6_class_augmentation_2D_CNN_custom_ch_32_DO_050_DO_4_conv_checkpoint/313-0.0141.hdf5\n",
      "81/81 [==============================] - 77s 946ms/step - loss: 0.0145 - acc: 0.9935 - val_loss: 0.0141 - val_acc: 0.9944\n",
      "Epoch 314/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0133 - acc: 0.9971WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 70s 22ms/sample - loss: 0.0211 - acc: 0.9900\n",
      "\n",
      "Epoch 00314: val_loss did not improve from 0.01410\n",
      "81/81 [==============================] - 75s 924ms/step - loss: 0.0132 - acc: 0.9972 - val_loss: 0.0211 - val_acc: 0.9900\n",
      "Epoch 315/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0135 - acc: 0.9981WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 73s 23ms/sample - loss: 0.0300 - acc: 0.9900\n",
      "\n",
      "Epoch 00315: val_loss did not improve from 0.01410\n",
      "81/81 [==============================] - 78s 961ms/step - loss: 0.0135 - acc: 0.9978 - val_loss: 0.0300 - val_acc: 0.9900\n",
      "Epoch 316/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0129 - acc: 0.9955WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 71s 22ms/sample - loss: 0.0339 - acc: 0.9950\n",
      "\n",
      "Epoch 00316: val_loss did not improve from 0.01410\n",
      "81/81 [==============================] - 78s 962ms/step - loss: 0.0130 - acc: 0.9957 - val_loss: 0.0339 - val_acc: 0.9950\n",
      "Epoch 317/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0135 - acc: 0.9959WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 15s 5ms/sample - loss: 0.0147 - acc: 0.9950\n",
      "\n",
      "Epoch 00317: val_loss did not improve from 0.01410\n",
      "81/81 [==============================] - 75s 926ms/step - loss: 0.0149 - acc: 0.9953 - val_loss: 0.0147 - val_acc: 0.9950\n",
      "Epoch 318/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0106 - acc: 0.9965WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 69s 21ms/sample - loss: 0.0459 - acc: 0.9925\n",
      "\n",
      "Epoch 00318: val_loss did not improve from 0.01410\n",
      "81/81 [==============================] - 73s 905ms/step - loss: 0.0104 - acc: 0.9966 - val_loss: 0.0459 - val_acc: 0.9925\n",
      "Epoch 319/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0111 - acc: 0.9962WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 13s 4ms/sample - loss: 0.0194 - acc: 0.9922\n",
      "\n",
      "Epoch 00319: val_loss did not improve from 0.01410\n",
      "81/81 [==============================] - 73s 898ms/step - loss: 0.0111 - acc: 0.9960 - val_loss: 0.0194 - val_acc: 0.9922\n",
      "Epoch 320/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0071 - acc: 0.9981WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 15s 5ms/sample - loss: 0.0427 - acc: 0.9922\n",
      "\n",
      "Epoch 00320: val_loss did not improve from 0.01410\n",
      "81/81 [==============================] - 72s 886ms/step - loss: 0.0070 - acc: 0.9981 - val_loss: 0.0427 - val_acc: 0.9922\n",
      "Epoch 321/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0075 - acc: 0.9972WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 65s 20ms/sample - loss: 0.0439 - acc: 0.9925\n",
      "\n",
      "Epoch 00321: val_loss did not improve from 0.01410\n",
      "81/81 [==============================] - 79s 972ms/step - loss: 0.0077 - acc: 0.9969 - val_loss: 0.0439 - val_acc: 0.9925\n",
      "Epoch 322/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0086 - acc: 0.9978WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 46s 14ms/sample - loss: 0.0206 - acc: 0.9947\n",
      "\n",
      "Epoch 00322: val_loss did not improve from 0.01410\n",
      "81/81 [==============================] - 78s 967ms/step - loss: 0.0084 - acc: 0.9978 - val_loss: 0.0206 - val_acc: 0.9947\n",
      "Epoch 323/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0110 - acc: 0.9978WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3200/3183 [==============================] - 59s 18ms/sample - loss: 0.0349 - acc: 0.9950\n",
      "\n",
      "Epoch 00323: val_loss did not improve from 0.01410\n",
      "81/81 [==============================] - 89s 1s/step - loss: 0.0109 - acc: 0.9978 - val_loss: 0.0349 - val_acc: 0.9950\n",
      "Epoch 324/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0140 - acc: 0.9952WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 69s 22ms/sample - loss: 0.0250 - acc: 0.9887\n",
      "\n",
      "Epoch 00324: val_loss did not improve from 0.01410\n",
      "81/81 [==============================] - 79s 974ms/step - loss: 0.0138 - acc: 0.9953 - val_loss: 0.0250 - val_acc: 0.9887\n",
      "Epoch 325/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0143 - acc: 0.9955WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 74s 23ms/sample - loss: 0.0119 - acc: 0.9950\n",
      "\n",
      "Epoch 00325: val_loss improved from 0.01410 to 0.01195, saving model to model/checkpoint/vis_imagenet_6_class_augmentation_2D_CNN_custom_ch_32_DO_050_DO_4_conv_checkpoint/325-0.0119.hdf5\n",
      "81/81 [==============================] - 78s 960ms/step - loss: 0.0139 - acc: 0.9957 - val_loss: 0.0119 - val_acc: 0.9950\n",
      "Epoch 326/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0118 - acc: 0.9969WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 70s 22ms/sample - loss: 0.0220 - acc: 0.9950\n",
      "\n",
      "Epoch 00326: val_loss did not improve from 0.01195\n",
      "81/81 [==============================] - 81s 1s/step - loss: 0.0117 - acc: 0.9969 - val_loss: 0.0220 - val_acc: 0.9950\n",
      "Epoch 327/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0035 - acc: 0.9994WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 67s 21ms/sample - loss: 0.0262 - acc: 0.9944\n",
      "\n",
      "Epoch 00327: val_loss did not improve from 0.01195\n",
      "81/81 [==============================] - 79s 973ms/step - loss: 0.0035 - acc: 0.9994 - val_loss: 0.0262 - val_acc: 0.9944\n",
      "Epoch 328/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0182 - acc: 0.9959WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 71s 22ms/sample - loss: 0.0493 - acc: 0.9925\n",
      "\n",
      "Epoch 00328: val_loss did not improve from 0.01195\n",
      "81/81 [==============================] - 75s 929ms/step - loss: 0.0184 - acc: 0.9957 - val_loss: 0.0493 - val_acc: 0.9925\n",
      "Epoch 329/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0128 - acc: 0.9965WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 63s 20ms/sample - loss: 0.0378 - acc: 0.9947\n",
      "\n",
      "Epoch 00329: val_loss did not improve from 0.01195\n",
      "81/81 [==============================] - 75s 930ms/step - loss: 0.0126 - acc: 0.9966 - val_loss: 0.0378 - val_acc: 0.9947\n",
      "Epoch 330/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0088 - acc: 0.9984WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 72s 22ms/sample - loss: 0.0256 - acc: 0.9922\n",
      "\n",
      "Epoch 00330: val_loss did not improve from 0.01195\n",
      "81/81 [==============================] - 79s 975ms/step - loss: 0.0087 - acc: 0.9984 - val_loss: 0.0256 - val_acc: 0.9922\n",
      "Epoch 331/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0060 - acc: 0.9978WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 46s 14ms/sample - loss: 0.0369 - acc: 0.9950\n",
      "\n",
      "Epoch 00331: val_loss did not improve from 0.01195\n",
      "81/81 [==============================] - 79s 975ms/step - loss: 0.0060 - acc: 0.9978 - val_loss: 0.0369 - val_acc: 0.9950\n",
      "Epoch 332/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0077 - acc: 0.9975WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 47s 15ms/sample - loss: 0.0249 - acc: 0.9919\n",
      "\n",
      "Epoch 00332: val_loss did not improve from 0.01195\n",
      "81/81 [==============================] - 77s 952ms/step - loss: 0.0076 - acc: 0.9975 - val_loss: 0.0249 - val_acc: 0.9919\n",
      "Epoch 333/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0122 - acc: 0.9962WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 72s 23ms/sample - loss: 0.0426 - acc: 0.9866\n",
      "\n",
      "Epoch 00333: val_loss did not improve from 0.01195\n",
      "81/81 [==============================] - 77s 949ms/step - loss: 0.0121 - acc: 0.9963 - val_loss: 0.0426 - val_acc: 0.9866\n",
      "Epoch 334/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0102 - acc: 0.9965WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 74s 23ms/sample - loss: 0.0688 - acc: 0.9950\n",
      "\n",
      "Epoch 00334: val_loss did not improve from 0.01195\n",
      "81/81 [==============================] - 79s 974ms/step - loss: 0.0101 - acc: 0.9966 - val_loss: 0.0688 - val_acc: 0.9950\n",
      "Epoch 335/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0069 - acc: 0.9981WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 15s 5ms/sample - loss: 0.0458 - acc: 0.9944\n",
      "\n",
      "Epoch 00335: val_loss did not improve from 0.01195\n",
      "81/81 [==============================] - 75s 920ms/step - loss: 0.0068 - acc: 0.9981 - val_loss: 0.0458 - val_acc: 0.9944\n",
      "Epoch 336/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0070 - acc: 0.9975WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 46s 14ms/sample - loss: 0.0371 - acc: 0.9925\n",
      "\n",
      "Epoch 00336: val_loss did not improve from 0.01195\n",
      "81/81 [==============================] - 76s 944ms/step - loss: 0.0068 - acc: 0.9975 - val_loss: 0.0371 - val_acc: 0.9925\n",
      "Epoch 337/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0080 - acc: 0.9984WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 66s 21ms/sample - loss: 0.0434 - acc: 0.9950\n",
      "\n",
      "Epoch 00337: val_loss did not improve from 0.01195\n",
      "81/81 [==============================] - 77s 948ms/step - loss: 0.0079 - acc: 0.9984 - val_loss: 0.0434 - val_acc: 0.9950\n",
      "Epoch 338/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0072 - acc: 0.9987WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 72s 22ms/sample - loss: 0.0255 - acc: 0.9900\n",
      "\n",
      "Epoch 00338: val_loss did not improve from 0.01195\n",
      "81/81 [==============================] - 85s 1s/step - loss: 0.0071 - acc: 0.9988 - val_loss: 0.0255 - val_acc: 0.9900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 339/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0079 - acc: 0.9978WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 73s 23ms/sample - loss: 0.0506 - acc: 0.9944\n",
      "\n",
      "Epoch 00339: val_loss did not improve from 0.01195\n",
      "81/81 [==============================] - 79s 975ms/step - loss: 0.0078 - acc: 0.9978 - val_loss: 0.0506 - val_acc: 0.9944\n",
      "Epoch 340/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0091 - acc: 0.9975WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 70s 22ms/sample - loss: 0.0493 - acc: 0.9925\n",
      "\n",
      "Epoch 00340: val_loss did not improve from 0.01195\n",
      "81/81 [==============================] - 78s 958ms/step - loss: 0.0089 - acc: 0.9975 - val_loss: 0.0493 - val_acc: 0.9925\n",
      "Epoch 341/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0039 - acc: 0.9994WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 15s 5ms/sample - loss: 0.0578 - acc: 0.9950\n",
      "\n",
      "Epoch 00341: val_loss did not improve from 0.01195\n",
      "81/81 [==============================] - 71s 876ms/step - loss: 0.0039 - acc: 0.9994 - val_loss: 0.0578 - val_acc: 0.9950\n",
      "Epoch 342/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0064 - acc: 0.9987WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 16s 5ms/sample - loss: 0.0360 - acc: 0.994711s - los\n",
      "\n",
      "Epoch 00342: val_loss did not improve from 0.01195\n",
      "81/81 [==============================] - 75s 926ms/step - loss: 0.0063 - acc: 0.9988 - val_loss: 0.0360 - val_acc: 0.9947\n",
      "Epoch 343/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0100 - acc: 0.9975WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 78s 24ms/sample - loss: 0.0345 - acc: 0.9950\n",
      "\n",
      "Epoch 00343: val_loss did not improve from 0.01195\n",
      "81/81 [==============================] - 83s 1s/step - loss: 0.0098 - acc: 0.9975 - val_loss: 0.0345 - val_acc: 0.9950\n",
      "Epoch 344/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0039 - acc: 0.9991WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 46s 14ms/sample - loss: 0.0583 - acc: 0.9947\n",
      "\n",
      "Epoch 00344: val_loss did not improve from 0.01195\n",
      "81/81 [==============================] - 79s 970ms/step - loss: 0.0039 - acc: 0.9991 - val_loss: 0.0583 - val_acc: 0.9947\n",
      "Epoch 345/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0137 - acc: 0.9965WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 73s 23ms/sample - loss: 0.0375 - acc: 0.9875\n",
      "\n",
      "Epoch 00345: val_loss did not improve from 0.01195\n",
      "81/81 [==============================] - 78s 958ms/step - loss: 0.0134 - acc: 0.9966 - val_loss: 0.0375 - val_acc: 0.9875\n",
      "Epoch 346/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0135 - acc: 0.9953WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 14s 4ms/sample - loss: 0.0258 - acc: 0.9900\n",
      "\n",
      "Epoch 00346: val_loss did not improve from 0.01195\n",
      "81/81 [==============================] - 73s 898ms/step - loss: 0.0133 - acc: 0.9953 - val_loss: 0.0258 - val_acc: 0.9900\n",
      "Epoch 347/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0090 - acc: 0.9965WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 15s 5ms/sample - loss: 0.0427 - acc: 0.9950\n",
      "\n",
      "Epoch 00347: val_loss did not improve from 0.01195\n",
      "81/81 [==============================] - 73s 898ms/step - loss: 0.0088 - acc: 0.9966 - val_loss: 0.0427 - val_acc: 0.9950\n",
      "Epoch 348/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0127 - acc: 0.9969WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3190/3183 [==============================] - 70s 22ms/sample - loss: 0.0603 - acc: 0.9950\n",
      "\n",
      "Epoch 00348: val_loss did not improve from 0.01195\n",
      "81/81 [==============================] - 76s 943ms/step - loss: 0.0128 - acc: 0.9969 - val_loss: 0.0603 - val_acc: 0.9950\n",
      "Epoch 349/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0062 - acc: 0.9984WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 15s 5ms/sample - loss: 0.0490 - acc: 0.9947\n",
      "\n",
      "Epoch 00349: val_loss did not improve from 0.01195\n",
      "81/81 [==============================] - 76s 936ms/step - loss: 0.0061 - acc: 0.9984 - val_loss: 0.0490 - val_acc: 0.9947\n",
      "Epoch 350/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0103 - acc: 0.9962WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 17s 5ms/sample - loss: 0.0478 - acc: 0.9950\n",
      "\n",
      "Epoch 00350: val_loss did not improve from 0.01195\n",
      "81/81 [==============================] - 78s 958ms/step - loss: 0.0102 - acc: 0.9963 - val_loss: 0.0478 - val_acc: 0.9950\n",
      "Epoch 351/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0087 - acc: 0.9981WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 63s 20ms/sample - loss: 0.0430 - acc: 0.9947\n",
      "\n",
      "Epoch 00351: val_loss did not improve from 0.01195\n",
      "81/81 [==============================] - 74s 912ms/step - loss: 0.0086 - acc: 0.9981 - val_loss: 0.0430 - val_acc: 0.9947\n",
      "Epoch 352/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0138 - acc: 0.9962WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 20s 6ms/sample - loss: 0.0467 - acc: 0.9950\n",
      "\n",
      "Epoch 00352: val_loss did not improve from 0.01195\n",
      "81/81 [==============================] - 82s 1s/step - loss: 0.0138 - acc: 0.9963 - val_loss: 0.0467 - val_acc: 0.9950\n",
      "Epoch 353/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0082 - acc: 0.9975WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3190/3183 [==============================] - 72s 22ms/sample - loss: 0.0391 - acc: 0.9900\n",
      "\n",
      "Epoch 00353: val_loss did not improve from 0.01195\n",
      "81/81 [==============================] - 76s 943ms/step - loss: 0.0082 - acc: 0.9975 - val_loss: 0.0391 - val_acc: 0.9900\n",
      "Epoch 354/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0078 - acc: 0.9987WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3200/3183 [==============================] - 74s 23ms/sample - loss: 0.0340 - acc: 0.9944\n",
      "\n",
      "Epoch 00354: val_loss did not improve from 0.01195\n",
      "81/81 [==============================] - 80s 987ms/step - loss: 0.0077 - acc: 0.9988 - val_loss: 0.0340 - val_acc: 0.9944\n",
      "Epoch 355/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0056 - acc: 0.9990WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 74s 23ms/sample - loss: 0.0464 - acc: 0.9950\n",
      "\n",
      "Epoch 00355: val_loss did not improve from 0.01195\n",
      "81/81 [==============================] - 77s 952ms/step - loss: 0.0055 - acc: 0.9991 - val_loss: 0.0464 - val_acc: 0.9950\n",
      "Epoch 356/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0178 - acc: 0.9959WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 70s 22ms/sample - loss: 0.0492 - acc: 0.9950\n",
      "\n",
      "Epoch 00356: val_loss did not improve from 0.01195\n",
      "81/81 [==============================] - 76s 935ms/step - loss: 0.0176 - acc: 0.9960 - val_loss: 0.0492 - val_acc: 0.9950\n",
      "Epoch 357/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0067 - acc: 0.9987WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3190/3183 [==============================] - 73s 23ms/sample - loss: 0.0434 - acc: 0.9950\n",
      "\n",
      "Epoch 00357: val_loss did not improve from 0.01195\n",
      "81/81 [==============================] - 76s 940ms/step - loss: 0.0067 - acc: 0.9988 - val_loss: 0.0434 - val_acc: 0.9950\n",
      "Epoch 358/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0034 - acc: 0.9990WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 73s 23ms/sample - loss: 0.0476 - acc: 0.9944\n",
      "\n",
      "Epoch 00358: val_loss did not improve from 0.01195\n",
      "81/81 [==============================] - 79s 971ms/step - loss: 0.0033 - acc: 0.9991 - val_loss: 0.0476 - val_acc: 0.9944\n",
      "Epoch 359/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0061 - acc: 0.9987WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 73s 23ms/sample - loss: 0.0677 - acc: 0.9950\n",
      "\n",
      "Epoch 00359: val_loss did not improve from 0.01195\n",
      "81/81 [==============================] - 78s 958ms/step - loss: 0.0061 - acc: 0.9988 - val_loss: 0.0677 - val_acc: 0.9950\n",
      "Epoch 360/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0123 - acc: 0.9971WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 20s 6ms/sample - loss: 0.0295 - acc: 0.9925\n",
      "\n",
      "Epoch 00360: val_loss did not improve from 0.01195\n",
      "81/81 [==============================] - 78s 959ms/step - loss: 0.0125 - acc: 0.9972 - val_loss: 0.0295 - val_acc: 0.9925\n",
      "Epoch 361/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0080 - acc: 0.9971WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 77s 24ms/sample - loss: 0.0360 - acc: 0.9925\n",
      "\n",
      "Epoch 00361: val_loss did not improve from 0.01195\n",
      "81/81 [==============================] - 81s 999ms/step - loss: 0.0086 - acc: 0.9969 - val_loss: 0.0360 - val_acc: 0.9925\n",
      "Epoch 362/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0108 - acc: 0.9975WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 72s 22ms/sample - loss: 0.0613 - acc: 0.9950\n",
      "\n",
      "Epoch 00362: val_loss did not improve from 0.01195\n",
      "81/81 [==============================] - 76s 936ms/step - loss: 0.0105 - acc: 0.9975 - val_loss: 0.0613 - val_acc: 0.9950\n",
      "Epoch 363/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0109 - acc: 0.9965WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 72s 22ms/sample - loss: 0.0509 - acc: 0.9947\n",
      "\n",
      "Epoch 00363: val_loss did not improve from 0.01195\n",
      "81/81 [==============================] - 76s 940ms/step - loss: 0.0106 - acc: 0.9966 - val_loss: 0.0509 - val_acc: 0.9947\n",
      "Epoch 364/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0147 - acc: 0.9953WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 74s 23ms/sample - loss: 0.0309 - acc: 0.9950\n",
      "\n",
      "Epoch 00364: val_loss did not improve from 0.01195\n",
      "81/81 [==============================] - 79s 976ms/step - loss: 0.0145 - acc: 0.9953 - val_loss: 0.0309 - val_acc: 0.9950\n",
      "Epoch 365/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0114 - acc: 0.9972WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 70s 22ms/sample - loss: 0.0249 - acc: 0.9950\n",
      "\n",
      "Epoch 00365: val_loss did not improve from 0.01195\n",
      "81/81 [==============================] - 78s 969ms/step - loss: 0.0113 - acc: 0.9972 - val_loss: 0.0249 - val_acc: 0.9950\n",
      "Epoch 366/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0058 - acc: 0.9991WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 45s 14ms/sample - loss: 0.0352 - acc: 0.9950\n",
      "\n",
      "Epoch 00366: val_loss did not improve from 0.01195\n",
      "81/81 [==============================] - 78s 959ms/step - loss: 0.0057 - acc: 0.9991 - val_loss: 0.0352 - val_acc: 0.9950\n",
      "Epoch 367/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0063 - acc: 0.9984WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 80s 25ms/sample - loss: 0.0435 - acc: 0.9947\n",
      "\n",
      "Epoch 00367: val_loss did not improve from 0.01195\n",
      "81/81 [==============================] - 84s 1s/step - loss: 0.0069 - acc: 0.9981 - val_loss: 0.0435 - val_acc: 0.9947\n",
      "Epoch 368/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0082 - acc: 0.9975WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 61s 19ms/sample - loss: 0.0153 - acc: 0.9947\n",
      "\n",
      "Epoch 00368: val_loss did not improve from 0.01195\n",
      "81/81 [==============================] - 94s 1s/step - loss: 0.0081 - acc: 0.9975 - val_loss: 0.0153 - val_acc: 0.9947\n",
      "Epoch 369/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0089 - acc: 0.9975WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 73s 23ms/sample - loss: 0.0274 - acc: 0.9950\n",
      "\n",
      "Epoch 00369: val_loss did not improve from 0.01195\n",
      "81/81 [==============================] - 79s 971ms/step - loss: 0.0093 - acc: 0.9969 - val_loss: 0.0274 - val_acc: 0.9950\n",
      "Epoch 370/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/81 [============================>.] - ETA: 0s - loss: 0.0109 - acc: 0.9966WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3190/3183 [==============================] - 74s 23ms/sample - loss: 0.0283 - acc: 0.9950\n",
      "\n",
      "Epoch 00370: val_loss did not improve from 0.01195\n",
      "81/81 [==============================] - 78s 961ms/step - loss: 0.0108 - acc: 0.9966 - val_loss: 0.0283 - val_acc: 0.9950\n",
      "Epoch 371/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0053 - acc: 0.9990WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 15s 5ms/sample - loss: 0.0332 - acc: 0.9947\n",
      "\n",
      "Epoch 00371: val_loss did not improve from 0.01195\n",
      "81/81 [==============================] - 73s 902ms/step - loss: 0.0052 - acc: 0.9991 - val_loss: 0.0332 - val_acc: 0.9947\n",
      "Epoch 372/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0104 - acc: 0.9965WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 68s 21ms/sample - loss: 0.0199 - acc: 0.9916\n",
      "\n",
      "Epoch 00372: val_loss did not improve from 0.01195\n",
      "81/81 [==============================] - 75s 926ms/step - loss: 0.0104 - acc: 0.9966 - val_loss: 0.0199 - val_acc: 0.9916\n",
      "Epoch 373/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0060 - acc: 0.9981WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 72s 22ms/sample - loss: 0.0332 - acc: 0.9947\n",
      "\n",
      "Epoch 00373: val_loss did not improve from 0.01195\n",
      "81/81 [==============================] - 76s 937ms/step - loss: 0.0059 - acc: 0.9981 - val_loss: 0.0332 - val_acc: 0.9947\n",
      "Epoch 374/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0083 - acc: 0.9978WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 28s 9ms/sample - loss: 0.0229 - acc: 0.9922\n",
      "\n",
      "Epoch 00374: val_loss did not improve from 0.01195\n",
      "81/81 [==============================] - 85s 1s/step - loss: 0.0082 - acc: 0.9978 - val_loss: 0.0229 - val_acc: 0.9922\n",
      "Epoch 375/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0070 - acc: 0.9972WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 49s 15ms/sample - loss: 0.0356 - acc: 0.9950\n",
      "\n",
      "Epoch 00375: val_loss did not improve from 0.01195\n",
      "81/81 [==============================] - 81s 998ms/step - loss: 0.0071 - acc: 0.9972 - val_loss: 0.0356 - val_acc: 0.9950\n",
      "Epoch 376/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0053 - acc: 0.9991WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 82s 26ms/sample - loss: 0.0413 - acc: 0.9944\n",
      "\n",
      "Epoch 00376: val_loss did not improve from 0.01195\n",
      "81/81 [==============================] - 86s 1s/step - loss: 0.0053 - acc: 0.9991 - val_loss: 0.0413 - val_acc: 0.9944\n",
      "Epoch 377/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0129 - acc: 0.9962WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 86s 27ms/sample - loss: 0.0178 - acc: 0.9950\n",
      "\n",
      "Epoch 00377: val_loss did not improve from 0.01195\n",
      "81/81 [==============================] - 92s 1s/step - loss: 0.0128 - acc: 0.9963 - val_loss: 0.0178 - val_acc: 0.9950\n",
      "Epoch 378/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0123 - acc: 0.9975WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 48s 15ms/sample - loss: 0.0185 - acc: 0.9947\n",
      "\n",
      "Epoch 00378: val_loss did not improve from 0.01195\n",
      "81/81 [==============================] - 81s 999ms/step - loss: 0.0122 - acc: 0.9975 - val_loss: 0.0185 - val_acc: 0.9947\n",
      "Epoch 379/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0067 - acc: 0.9987WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 72s 23ms/sample - loss: 0.0414 - acc: 0.9950\n",
      "\n",
      "Epoch 00379: val_loss did not improve from 0.01195\n",
      "81/81 [==============================] - 76s 944ms/step - loss: 0.0066 - acc: 0.9988 - val_loss: 0.0414 - val_acc: 0.9950\n",
      "Epoch 380/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0032 - acc: 0.9994WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 75s 23ms/sample - loss: 0.0294 - acc: 0.9950\n",
      "\n",
      "Epoch 00380: val_loss did not improve from 0.01195\n",
      "81/81 [==============================] - 81s 1s/step - loss: 0.0031 - acc: 0.9994 - val_loss: 0.0294 - val_acc: 0.9950\n",
      "Epoch 381/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0099 - acc: 0.9965WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 85s 26ms/sample - loss: 0.0248 - acc: 0.9950\n",
      "\n",
      "Epoch 00381: val_loss did not improve from 0.01195\n",
      "81/81 [==============================] - 90s 1s/step - loss: 0.0097 - acc: 0.9966 - val_loss: 0.0248 - val_acc: 0.9950\n",
      "Epoch 382/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0074 - acc: 0.9978WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 73s 23ms/sample - loss: 0.0354 - acc: 0.9944\n",
      "\n",
      "Epoch 00382: val_loss did not improve from 0.01195\n",
      "81/81 [==============================] - 79s 970ms/step - loss: 0.0072 - acc: 0.9978 - val_loss: 0.0354 - val_acc: 0.9944\n",
      "Epoch 383/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0181 - acc: 0.9975WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 70s 22ms/sample - loss: 0.0373 - acc: 0.9950\n",
      "\n",
      "Epoch 00383: val_loss did not improve from 0.01195\n",
      "81/81 [==============================] - 75s 922ms/step - loss: 0.0177 - acc: 0.9975 - val_loss: 0.0373 - val_acc: 0.9950\n",
      "Epoch 384/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0041 - acc: 0.9984WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 18s 6ms/sample - loss: 0.0306 - acc: 0.9947\n",
      "\n",
      "Epoch 00384: val_loss did not improve from 0.01195\n",
      "81/81 [==============================] - 79s 971ms/step - loss: 0.0041 - acc: 0.9984 - val_loss: 0.0306 - val_acc: 0.9947\n",
      "Epoch 385/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0064 - acc: 0.9981WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3200/3183 [==============================] - 72s 23ms/sample - loss: 0.0350 - acc: 0.9916\n",
      "\n",
      "Epoch 00385: val_loss did not improve from 0.01195\n",
      "81/81 [==============================] - 76s 944ms/step - loss: 0.0062 - acc: 0.9981 - val_loss: 0.0350 - val_acc: 0.9916\n",
      "Epoch 386/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0125 - acc: 0.9952WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 73s 23ms/sample - loss: 0.0505 - acc: 0.9950\n",
      "\n",
      "Epoch 00386: val_loss did not improve from 0.01195\n",
      "81/81 [==============================] - 77s 946ms/step - loss: 0.0123 - acc: 0.9953 - val_loss: 0.0505 - val_acc: 0.9950\n",
      "Epoch 387/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0119 - acc: 0.9953WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3190/3183 [==============================] - 14s 4ms/sample - loss: 0.0503 - acc: 0.9947\n",
      "\n",
      "Epoch 00387: val_loss did not improve from 0.01195\n",
      "81/81 [==============================] - 74s 916ms/step - loss: 0.0118 - acc: 0.9953 - val_loss: 0.0503 - val_acc: 0.9947\n",
      "Epoch 388/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0089 - acc: 0.9975WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 50s 16ms/sample - loss: 0.0346 - acc: 0.9944\n",
      "\n",
      "Epoch 00388: val_loss did not improve from 0.01195\n",
      "81/81 [==============================] - 81s 996ms/step - loss: 0.0088 - acc: 0.9975 - val_loss: 0.0346 - val_acc: 0.9944\n",
      "Epoch 389/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0058 - acc: 0.9978WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 74s 23ms/sample - loss: 0.0382 - acc: 0.9916\n",
      "\n",
      "Epoch 00389: val_loss did not improve from 0.01195\n",
      "81/81 [==============================] - 78s 958ms/step - loss: 0.0057 - acc: 0.9978 - val_loss: 0.0382 - val_acc: 0.9916\n",
      "Epoch 390/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0060 - acc: 0.9987WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 15s 5ms/sample - loss: 0.0350 - acc: 0.9944\n",
      "\n",
      "Epoch 00390: val_loss did not improve from 0.01195\n",
      "81/81 [==============================] - 78s 967ms/step - loss: 0.0059 - acc: 0.9988 - val_loss: 0.0350 - val_acc: 0.9944\n",
      "Epoch 391/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0072 - acc: 0.9971WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 49s 15ms/sample - loss: 0.0500 - acc: 0.9937\n",
      "\n",
      "Epoch 00391: val_loss did not improve from 0.01195\n",
      "81/81 [==============================] - 80s 986ms/step - loss: 0.0071 - acc: 0.9972 - val_loss: 0.0500 - val_acc: 0.9937\n",
      "Epoch 392/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0056 - acc: 0.9984WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 85s 27ms/sample - loss: 0.0496 - acc: 0.9950\n",
      "\n",
      "Epoch 00392: val_loss did not improve from 0.01195\n",
      "81/81 [==============================] - 90s 1s/step - loss: 0.0055 - acc: 0.9984 - val_loss: 0.0496 - val_acc: 0.9950\n",
      "Epoch 393/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0040 - acc: 0.9994WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 77s 24ms/sample - loss: 0.0296 - acc: 0.9916\n",
      "\n",
      "Epoch 00393: val_loss did not improve from 0.01195\n",
      "81/81 [==============================] - 82s 1s/step - loss: 0.0039 - acc: 0.9994 - val_loss: 0.0296 - val_acc: 0.9916\n",
      "Epoch 394/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0053 - acc: 0.9984WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 73s 23ms/sample - loss: 0.0185 - acc: 0.9934\n",
      "\n",
      "Epoch 00394: val_loss did not improve from 0.01195\n",
      "81/81 [==============================] - 79s 969ms/step - loss: 0.0052 - acc: 0.9984 - val_loss: 0.0185 - val_acc: 0.9934\n",
      "Epoch 395/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0123 - acc: 0.9971WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 75s 23ms/sample - loss: 0.0289 - acc: 0.9950\n",
      "\n",
      "Epoch 00395: val_loss did not improve from 0.01195\n",
      "81/81 [==============================] - 79s 972ms/step - loss: 0.0120 - acc: 0.9972 - val_loss: 0.0289 - val_acc: 0.9950\n",
      "Epoch 396/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0160 - acc: 0.9943WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 68s 21ms/sample - loss: 0.0241 - acc: 0.9887\n",
      "\n",
      "Epoch 00396: val_loss did not improve from 0.01195\n",
      "81/81 [==============================] - 73s 906ms/step - loss: 0.0158 - acc: 0.9944 - val_loss: 0.0241 - val_acc: 0.9887\n",
      "Epoch 397/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0158 - acc: 0.9965WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 71s 22ms/sample - loss: 0.0345 - acc: 0.9900\n",
      "\n",
      "Epoch 00397: val_loss did not improve from 0.01195\n",
      "81/81 [==============================] - 75s 922ms/step - loss: 0.0155 - acc: 0.9966 - val_loss: 0.0345 - val_acc: 0.9900\n",
      "Epoch 398/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0083 - acc: 0.9972WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3190/3183 [==============================] - 69s 22ms/sample - loss: 0.0485 - acc: 0.9931\n",
      "\n",
      "Epoch 00398: val_loss did not improve from 0.01195\n",
      "81/81 [==============================] - 73s 899ms/step - loss: 0.0083 - acc: 0.9972 - val_loss: 0.0485 - val_acc: 0.9931\n",
      "Epoch 399/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0088 - acc: 0.9971WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 72s 22ms/sample - loss: 0.0324 - acc: 0.9950\n",
      "\n",
      "Epoch 00399: val_loss did not improve from 0.01195\n",
      "81/81 [==============================] - 76s 938ms/step - loss: 0.0086 - acc: 0.9972 - val_loss: 0.0324 - val_acc: 0.9950\n",
      "Epoch 400/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0049 - acc: 0.9984WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 75s 24ms/sample - loss: 0.0251 - acc: 0.9922\n",
      "\n",
      "Epoch 00400: val_loss did not improve from 0.01195\n",
      "81/81 [==============================] - 80s 983ms/step - loss: 0.0049 - acc: 0.9984 - val_loss: 0.0251 - val_acc: 0.9922\n",
      "Epoch 401/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/81 [============================>.] - ETA: 0s - loss: 0.0079 - acc: 0.9978WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 73s 23ms/sample - loss: 0.0332 - acc: 0.9941\n",
      "\n",
      "Epoch 00401: val_loss did not improve from 0.01195\n",
      "81/81 [==============================] - 78s 964ms/step - loss: 0.0078 - acc: 0.9978 - val_loss: 0.0332 - val_acc: 0.9941\n",
      "Epoch 402/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0068 - acc: 0.9978WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 46s 15ms/sample - loss: 0.0302 - acc: 0.9944\n",
      "\n",
      "Epoch 00402: val_loss did not improve from 0.01195\n",
      "81/81 [==============================] - 76s 943ms/step - loss: 0.0069 - acc: 0.9975 - val_loss: 0.0302 - val_acc: 0.9944\n",
      "Epoch 403/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0111 - acc: 0.9971WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 69s 21ms/sample - loss: 0.0307 - acc: 0.9941\n",
      "\n",
      "Epoch 00403: val_loss did not improve from 0.01195\n",
      "81/81 [==============================] - 74s 908ms/step - loss: 0.0108 - acc: 0.9972 - val_loss: 0.0307 - val_acc: 0.9941\n",
      "Epoch 404/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0080 - acc: 0.9975WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 76s 24ms/sample - loss: 0.0262 - acc: 0.9941\n",
      "\n",
      "Epoch 00404: val_loss did not improve from 0.01195\n",
      "81/81 [==============================] - 80s 992ms/step - loss: 0.0079 - acc: 0.9975 - val_loss: 0.0262 - val_acc: 0.9941\n",
      "Epoch 405/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0060 - acc: 0.9987WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 72s 23ms/sample - loss: 0.0514 - acc: 0.9950\n",
      "\n",
      "Epoch 00405: val_loss did not improve from 0.01195\n",
      "81/81 [==============================] - 76s 934ms/step - loss: 0.0059 - acc: 0.9988 - val_loss: 0.0514 - val_acc: 0.9950\n",
      "Epoch 406/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0138 - acc: 0.9962WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 47s 15ms/sample - loss: 0.0246 - acc: 0.9944\n",
      "\n",
      "Epoch 00406: val_loss did not improve from 0.01195\n",
      "81/81 [==============================] - 78s 968ms/step - loss: 0.0138 - acc: 0.9963 - val_loss: 0.0246 - val_acc: 0.9944\n",
      "Epoch 407/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0194 - acc: 0.9925WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 72s 22ms/sample - loss: 0.0278 - acc: 0.9941\n",
      "\n",
      "Epoch 00407: val_loss did not improve from 0.01195\n",
      "81/81 [==============================] - 76s 933ms/step - loss: 0.0193 - acc: 0.9926 - val_loss: 0.0278 - val_acc: 0.9941\n",
      "Epoch 408/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0046 - acc: 0.9991WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 72s 23ms/sample - loss: 0.0363 - acc: 0.9950\n",
      "\n",
      "Epoch 00408: val_loss did not improve from 0.01195\n",
      "81/81 [==============================] - 76s 943ms/step - loss: 0.0046 - acc: 0.9991 - val_loss: 0.0363 - val_acc: 0.9950\n",
      "Epoch 409/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0038 - acc: 0.9994WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 48s 15ms/sample - loss: 0.0583 - acc: 0.9950\n",
      "\n",
      "Epoch 00409: val_loss did not improve from 0.01195\n",
      "81/81 [==============================] - 78s 969ms/step - loss: 0.0038 - acc: 0.9994 - val_loss: 0.0583 - val_acc: 0.9950\n",
      "Epoch 410/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0040 - acc: 0.9990WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 75s 23ms/sample - loss: 0.0512 - acc: 0.9950\n",
      "\n",
      "Epoch 00410: val_loss did not improve from 0.01195\n",
      "81/81 [==============================] - 79s 981ms/step - loss: 0.0040 - acc: 0.9991 - val_loss: 0.0512 - val_acc: 0.9950\n",
      "Epoch 411/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0122 - acc: 0.9975WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 74s 23ms/sample - loss: 0.0313 - acc: 0.9947\n",
      "\n",
      "Epoch 00411: val_loss did not improve from 0.01195\n",
      "81/81 [==============================] - 79s 974ms/step - loss: 0.0121 - acc: 0.9975 - val_loss: 0.0313 - val_acc: 0.9947\n",
      "Epoch 412/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0047 - acc: 0.9984WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 69s 22ms/sample - loss: 0.0451 - acc: 0.9941\n",
      "\n",
      "Epoch 00412: val_loss did not improve from 0.01195\n",
      "81/81 [==============================] - 73s 906ms/step - loss: 0.0047 - acc: 0.9984 - val_loss: 0.0451 - val_acc: 0.9941\n",
      "Epoch 413/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 1.0000WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 75s 23ms/sample - loss: 0.0660 - acc: 0.9944\n",
      "\n",
      "Epoch 00413: val_loss did not improve from 0.01195\n",
      "81/81 [==============================] - 79s 975ms/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.0660 - val_acc: 0.9944\n",
      "Epoch 414/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0028 - acc: 0.9994WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 74s 23ms/sample - loss: 0.0398 - acc: 0.9950\n",
      "\n",
      "Epoch 00414: val_loss did not improve from 0.01195\n",
      "81/81 [==============================] - 78s 959ms/step - loss: 0.0032 - acc: 0.9991 - val_loss: 0.0398 - val_acc: 0.9950\n",
      "Epoch 415/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0035 - acc: 0.9990WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 70s 22ms/sample - loss: 0.0243 - acc: 0.9944\n",
      "\n",
      "Epoch 00415: val_loss did not improve from 0.01195\n",
      "81/81 [==============================] - 73s 907ms/step - loss: 0.0034 - acc: 0.9991 - val_loss: 0.0243 - val_acc: 0.9944\n",
      "Epoch 416/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0053 - acc: 0.9978WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3200/3183 [==============================] - 47s 15ms/sample - loss: 0.0336 - acc: 0.9944\n",
      "\n",
      "Epoch 00416: val_loss did not improve from 0.01195\n",
      "81/81 [==============================] - 78s 960ms/step - loss: 0.0052 - acc: 0.9978 - val_loss: 0.0336 - val_acc: 0.9944\n",
      "Epoch 417/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0101 - acc: 0.9959WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 73s 23ms/sample - loss: 0.0453 - acc: 0.9922\n",
      "\n",
      "Epoch 00417: val_loss did not improve from 0.01195\n",
      "81/81 [==============================] - 78s 961ms/step - loss: 0.0100 - acc: 0.9960 - val_loss: 0.0453 - val_acc: 0.9922\n",
      "Epoch 418/10000\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0123 - acc: 0.9978WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 73s 23ms/sample - loss: 0.0286 - acc: 0.9947\n",
      "\n",
      "Epoch 00418: val_loss did not improve from 0.01195\n",
      "81/81 [==============================] - 76s 941ms/step - loss: 0.0124 - acc: 0.9975 - val_loss: 0.0286 - val_acc: 0.9947\n",
      "Epoch 419/10000\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0041 - acc: 0.9990WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-52e8544a4ac4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcheckpointer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearly_stopping\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     )\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1424\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1425\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1426\u001b[0;31m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1428\u001b[0m   def evaluate_generator(self,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, **kwargs)\u001b[0m\n\u001b[1;32m    223\u001b[0m           \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m           \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 225\u001b[0;31m           mode='test')\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_results\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, **kwargs)\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m       \u001b[0mbatch_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_next_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mbatch_data\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/engine/training_generator.py\u001b[0m in \u001b[0;36m_get_next_batch\u001b[0;34m(output_generator, mode)\u001b[0m\n\u001b[1;32m    256\u001b[0m   \u001b[0;34m\"\"\"Retrieves the next batch of input data.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m     \u001b[0mgenerator_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    259\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m     \u001b[0;31m# Returning `None` will trigger looping to stop.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    741\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    742\u001b[0m       \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_running\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 743\u001b[0;31m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    744\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask_done\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    745\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    162\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_qsize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"'timeout' must be a non-negative number\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    294\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(3, 8):\n",
    "    base = 'vis_imagenet_6_class_augmentation_2D_CNN_custom_ch_32_DO_050_DO'\n",
    "    model_name = base+'_{}_conv'.format(i)\n",
    "    \n",
    "#     with tf.device('/cpu:0'):\n",
    "    model = build_2d_cnn_custom_ch_32_DO(conv_num=i)\n",
    "#     model = multi_gpu_model(model, gpus=2)\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=1e-4),\n",
    "          metrics=['accuracy'])\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    os.makedirs(model_path, exist_ok=True)\n",
    "    model_filename = model_path+'{epoch:03d}-{val_loss:.4f}.hdf5'\n",
    "    checkpointer = ModelCheckpoint(filepath = model_filename, monitor = \"val_loss\", \n",
    "                                   verbose=1, save_best_only=True)\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=100)\n",
    "    hist = model.fit_generator(data_generator,\n",
    "            steps_per_epoch=len(x_train)//batch_size,\n",
    "            epochs=10000,\n",
    "            validation_data=(x_val, y_val),\n",
    "            callbacks = [checkpointer, early_stopping],\n",
    "            workers=8, \n",
    "            use_multiprocessing=True\n",
    "    )\n",
    "    \n",
    "    print()\n",
    "    print(model_name, 'Model')\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "    ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
    "    ax.plot(hist.history['acc'], 'b', label='train acc')\n",
    "    ax.plot(hist.history['val_acc'], 'g', label='val acc')\n",
    "    ax.set_xlabel('epoch')\n",
    "    ax.set_ylabel('loss')\n",
    "    ax.legend(loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    png_path = 'visualization/learning_curve/'\n",
    "    filename = model_name+'.png'\n",
    "    os.makedirs(png_path, exist_ok=True)\n",
    "    fig.savefig(png_path+filename, transparent=True)\n",
    "\n",
    "    model.save(model_path+'000_last.hdf5')\n",
    "    del(model)\n",
    "\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    model_filename = model_path + sorted(os.listdir(model_path))[-1]\n",
    "    model = load_model(model_filename)\n",
    "    [loss, accuracy] = model.evaluate(x_test, y_test)\n",
    "    print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "    print()\n",
    "\n",
    "    del(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = 'log'\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "base = 'vis_imagenet_6_class_augmentation_2D_CNN_custom_ch_32_DO_050_DO'\n",
    "\n",
    "with open(path.join(log_dir, base), 'w') as log_file:\n",
    "    for i in range(3, 8):\n",
    "        model_name = base+'_{}_conv'.format(i)\n",
    "        print()\n",
    "        print(model_name, 'Model')\n",
    "        model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "        model_filename = model_path + sorted(os.listdir(model_path))[-1]\n",
    "\n",
    "        model = load_model(model_filename)\n",
    "        model.summary()\n",
    "\n",
    "        [loss, accuracy] = model.evaluate(x_test, y_test)\n",
    "        print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "\n",
    "        del(model)\n",
    "\n",
    "        log_file.write('\\t'.join([model_name, str(accuracy), str(loss)])+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3, 8):\n",
    "    model_name = base+'_{}_conv'.format(i)\n",
    "    print()\n",
    "    print(model_name, 'Model')\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    model_filename = model_path + '000_last.hdf5'\n",
    "\n",
    "    model = load_model(model_filename)\n",
    "    model.summary()\n",
    "\n",
    "    [loss, accuracy] = model.evaluate(x_test, y_test)\n",
    "    print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "\n",
    "    del(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import os.path as path\n",
    "import itertools\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.layers import Input,InputLayer, Dense, Activation, BatchNormalization, Flatten, Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D, Dropout\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,LearningRateScheduler, \\\n",
    "                                        EarlyStopping\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.utils import to_categorical, multi_gpu_model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.load(path.join(data_dir, 'imagenet_6_class_train_data.npz'))\n",
    "val_data = np.load(path.join(data_dir, 'imagenet_6_class_val_data.npz'))\n",
    "test_data = np.load(path.join(data_dir, 'imagenet_6_class_val_data.npz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4680, 341, 341, 3),\n",
       " (4680,),\n",
       " (1560, 341, 341, 3),\n",
       " (1560,),\n",
       " (1560, 341, 341, 3),\n",
       " (1560,),\n",
       " (6, 2))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = train_data['x_data']\n",
    "y_train = train_data['y_data']\n",
    "x_val = val_data['x_data']\n",
    "y_val = val_data['y_data']\n",
    "x_test = test_data['x_data']\n",
    "y_test = test_data['y_data']\n",
    "y_table_array = test_data['y_table_array']\n",
    "\n",
    "x_train.shape, y_train.shape, x_val.shape, y_val.shape, x_test.shape, y_test.shape, y_table_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4680, 341, 341, 3),\n",
       " (4680, 6),\n",
       " (1560, 341, 341, 3),\n",
       " (1560, 6),\n",
       " (1560, 341, 341, 3),\n",
       " (1560, 6))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = to_categorical(y_train)\n",
    "y_val = to_categorical(y_val)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "x_train.shape, y_train.shape, x_val.shape, y_val.shape, x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bed', 'bird', 'cat', 'dog', 'house', 'tree']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_list = [text for _, text in y_table_array]\n",
    "y_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = x_train[0].shape\n",
    "output_size = len(y_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_2d_cnn_custom_ch_128_DO(conv_num=1):\n",
    "    input_layer = Input(shape=input_shape)\n",
    "    x = input_layer\n",
    "\n",
    "    for i in range(conv_num):\n",
    "        x = Conv2D(kernel_size=5, filters=128*(2**(i//2)), strides=(1,1), padding='same')(x)\n",
    "#         x = BatchNormalization()(x)\n",
    "        x = Activation('relu')(x)\n",
    "        x = MaxPooling2D(pool_size=3, strides=(3,3), padding='same')(x)\n",
    "\n",
    "    x = Flatten()(x)\n",
    "  \n",
    "    x = Dropout(0.75)(x)\n",
    "    output_layer = Dense(output_size, activation='softmax')(x)\n",
    "    \n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 341, 341, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 341, 341, 128)     9728      \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 341, 341, 128)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 114, 114, 128)     0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1663488)           0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1663488)           0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 6)                 9980934   \n",
      "=================================================================\n",
      "Total params: 9,990,662\n",
      "Trainable params: 9,990,662\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 341, 341, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 341, 341, 128)     9728      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 341, 341, 128)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 114, 114, 128)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 114, 114, 128)     409728    \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 114, 114, 128)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 38, 38, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 184832)            0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 184832)            0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 6)                 1108998   \n",
      "=================================================================\n",
      "Total params: 1,528,454\n",
      "Trainable params: 1,528,454\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 341, 341, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 341, 341, 128)     9728      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 341, 341, 128)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 114, 114, 128)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 114, 114, 128)     409728    \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 114, 114, 128)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 38, 38, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 38, 38, 256)       819456    \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 38, 38, 256)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 13, 13, 256)       0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 43264)             0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 43264)             0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 6)                 259590    \n",
      "=================================================================\n",
      "Total params: 1,498,502\n",
      "Trainable params: 1,498,502\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, 341, 341, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 341, 341, 128)     9728      \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 341, 341, 128)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 114, 114, 128)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 114, 114, 128)     409728    \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 114, 114, 128)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 38, 38, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 38, 38, 256)       819456    \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 38, 38, 256)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 13, 13, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 13, 13, 256)       1638656   \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 13, 13, 256)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 5, 5, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 6400)              0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 6400)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 6)                 38406     \n",
      "=================================================================\n",
      "Total params: 2,915,974\n",
      "Trainable params: 2,915,974\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         (None, 341, 341, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 341, 341, 128)     9728      \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 341, 341, 128)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 114, 114, 128)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 114, 114, 128)     409728    \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 114, 114, 128)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 38, 38, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 38, 38, 256)       819456    \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 38, 38, 256)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 13, 13, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 13, 13, 256)       1638656   \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 13, 13, 256)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 5, 5, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 5, 5, 512)         3277312   \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 5, 5, 512)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 6)                 12294     \n",
      "=================================================================\n",
      "Total params: 6,167,174\n",
      "Trainable params: 6,167,174\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 6):\n",
    "    model = build_2d_cnn_custom_ch_128_DO(conv_num=i)\n",
    "    model.summary()\n",
    "    del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_generator = ImageDataGenerator(\n",
    "                    rotation_range=30,\n",
    "                    width_shift_range=0.15,\n",
    "                    height_shift_range=0.15,\n",
    "                    shear_range=0.2,\n",
    "                    zoom_range=0.2,\n",
    "                    horizontal_flip=True,\n",
    "                    fill_mode='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/1000\n",
      "25/25 [==============================] - 13s 522ms/step - loss: 1.3519 - acc: 0.4596\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.35194, saving model to model/checkpoint/vis_imagenet_6_class_augumentation_2D_CNN_custom_ch_128_DO_075_DO_3_conv_checkpoint/001-1.3519.hdf5\n",
      "74/74 [==============================] - 50s 675ms/step - loss: 1.6047 - acc: 0.3188 - val_loss: 1.3519 - val_acc: 0.4596\n",
      "Epoch 2/1000\n",
      "25/25 [==============================] - 13s 512ms/step - loss: 1.2175 - acc: 0.5173\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.35194 to 1.21746, saving model to model/checkpoint/vis_imagenet_6_class_augumentation_2D_CNN_custom_ch_128_DO_075_DO_3_conv_checkpoint/002-1.2175.hdf5\n",
      "74/74 [==============================] - 45s 607ms/step - loss: 1.3236 - acc: 0.4667 - val_loss: 1.2175 - val_acc: 0.5173\n",
      "Epoch 3/1000\n",
      "25/25 [==============================] - 12s 499ms/step - loss: 1.1590 - acc: 0.5372\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.21746 to 1.15899, saving model to model/checkpoint/vis_imagenet_6_class_augumentation_2D_CNN_custom_ch_128_DO_075_DO_3_conv_checkpoint/003-1.1590.hdf5\n",
      "74/74 [==============================] - 45s 605ms/step - loss: 1.2165 - acc: 0.5233 - val_loss: 1.1590 - val_acc: 0.5372\n",
      "Epoch 4/1000\n",
      "25/25 [==============================] - 13s 502ms/step - loss: 1.0935 - acc: 0.6032\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.15899 to 1.09352, saving model to model/checkpoint/vis_imagenet_6_class_augumentation_2D_CNN_custom_ch_128_DO_075_DO_3_conv_checkpoint/004-1.0935.hdf5\n",
      "74/74 [==============================] - 45s 606ms/step - loss: 1.1461 - acc: 0.5709 - val_loss: 1.0935 - val_acc: 0.6032\n",
      "Epoch 5/1000\n",
      "25/25 [==============================] - 12s 496ms/step - loss: 1.0376 - acc: 0.6147\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.09352 to 1.03759, saving model to model/checkpoint/vis_imagenet_6_class_augumentation_2D_CNN_custom_ch_128_DO_075_DO_3_conv_checkpoint/005-1.0376.hdf5\n",
      "74/74 [==============================] - 45s 605ms/step - loss: 1.1172 - acc: 0.5810 - val_loss: 1.0376 - val_acc: 0.6147\n",
      "Epoch 6/1000\n",
      "25/25 [==============================] - 12s 483ms/step - loss: 1.0353 - acc: 0.6192\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.03759 to 1.03530, saving model to model/checkpoint/vis_imagenet_6_class_augumentation_2D_CNN_custom_ch_128_DO_075_DO_3_conv_checkpoint/006-1.0353.hdf5\n",
      "74/74 [==============================] - 44s 599ms/step - loss: 1.0652 - acc: 0.5949 - val_loss: 1.0353 - val_acc: 0.6192\n",
      "Epoch 7/1000\n",
      "25/25 [==============================] - 12s 495ms/step - loss: 0.9976 - acc: 0.6250\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.03530 to 0.99760, saving model to model/checkpoint/vis_imagenet_6_class_augumentation_2D_CNN_custom_ch_128_DO_075_DO_3_conv_checkpoint/007-0.9976.hdf5\n",
      "74/74 [==============================] - 44s 601ms/step - loss: 1.0336 - acc: 0.6154 - val_loss: 0.9976 - val_acc: 0.6250\n",
      "Epoch 8/1000\n",
      "25/25 [==============================] - 12s 485ms/step - loss: 0.9659 - acc: 0.6436 22s\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.99760 to 0.96587, saving model to model/checkpoint/vis_imagenet_6_class_augumentation_2D_CNN_custom_ch_128_DO_075_DO_3_conv_checkpoint/008-0.9659.hdf5\n",
      "74/74 [==============================] - 45s 605ms/step - loss: 0.9982 - acc: 0.6318 - val_loss: 0.9659 - val_acc: 0.6436\n",
      "Epoch 9/1000\n",
      "25/25 [==============================] - 13s 509ms/step - loss: 0.9495 - acc: 0.6474\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.96587 to 0.94954, saving model to model/checkpoint/vis_imagenet_6_class_augumentation_2D_CNN_custom_ch_128_DO_075_DO_3_conv_checkpoint/009-0.9495.hdf5\n",
      "74/74 [==============================] - 45s 609ms/step - loss: 0.9805 - acc: 0.6440 - val_loss: 0.9495 - val_acc: 0.6474\n",
      "Epoch 10/1000\n",
      "25/25 [==============================] - 12s 490ms/step - loss: 0.9066 - acc: 0.6686\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.94954 to 0.90659, saving model to model/checkpoint/vis_imagenet_6_class_augumentation_2D_CNN_custom_ch_128_DO_075_DO_3_conv_checkpoint/010-0.9066.hdf5\n",
      "74/74 [==============================] - 45s 604ms/step - loss: 0.9245 - acc: 0.6622 - val_loss: 0.9066 - val_acc: 0.6686\n",
      "Epoch 11/1000\n",
      "25/25 [==============================] - 13s 503ms/step - loss: 0.9442 - acc: 0.6487\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.90659\n",
      "74/74 [==============================] - 45s 610ms/step - loss: 0.9302 - acc: 0.6620 - val_loss: 0.9442 - val_acc: 0.6487\n",
      "Epoch 12/1000\n",
      "25/25 [==============================] - 12s 496ms/step - loss: 0.8890 - acc: 0.6724\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.90659 to 0.88905, saving model to model/checkpoint/vis_imagenet_6_class_augumentation_2D_CNN_custom_ch_128_DO_075_DO_3_conv_checkpoint/012-0.8890.hdf5\n",
      "74/74 [==============================] - 45s 605ms/step - loss: 0.9000 - acc: 0.6722 - val_loss: 0.8890 - val_acc: 0.6724\n",
      "Epoch 13/1000\n",
      "25/25 [==============================] - 12s 496ms/step - loss: 0.8742 - acc: 0.6865\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.88905 to 0.87420, saving model to model/checkpoint/vis_imagenet_6_class_augumentation_2D_CNN_custom_ch_128_DO_075_DO_3_conv_checkpoint/013-0.8742.hdf5\n",
      "74/74 [==============================] - 45s 609ms/step - loss: 0.8772 - acc: 0.6838 - val_loss: 0.8742 - val_acc: 0.6865\n",
      "Epoch 14/1000\n",
      "25/25 [==============================] - 13s 506ms/step - loss: 0.8463 - acc: 0.6974\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.87420 to 0.84629, saving model to model/checkpoint/vis_imagenet_6_class_augumentation_2D_CNN_custom_ch_128_DO_075_DO_3_conv_checkpoint/014-0.8463.hdf5\n",
      "74/74 [==============================] - 45s 606ms/step - loss: 0.8890 - acc: 0.6853 - val_loss: 0.8463 - val_acc: 0.6974\n",
      "Epoch 15/1000\n",
      "25/25 [==============================] - 13s 506ms/step - loss: 0.7852 - acc: 0.7167\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.84629 to 0.78524, saving model to model/checkpoint/vis_imagenet_6_class_augumentation_2D_CNN_custom_ch_128_DO_075_DO_3_conv_checkpoint/015-0.7852.hdf5\n",
      "74/74 [==============================] - 45s 607ms/step - loss: 0.8320 - acc: 0.7038 - val_loss: 0.7852 - val_acc: 0.7167\n",
      "Epoch 16/1000\n",
      "25/25 [==============================] - 13s 524ms/step - loss: 0.8138 - acc: 0.7122\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.78524\n",
      "74/74 [==============================] - 45s 614ms/step - loss: 0.8326 - acc: 0.6955 - val_loss: 0.8138 - val_acc: 0.7122\n",
      "Epoch 17/1000\n",
      "25/25 [==============================] - 12s 484ms/step - loss: 0.7567 - acc: 0.7282\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.78524 to 0.75671, saving model to model/checkpoint/vis_imagenet_6_class_augumentation_2D_CNN_custom_ch_128_DO_075_DO_3_conv_checkpoint/017-0.7567.hdf5\n",
      "74/74 [==============================] - 45s 603ms/step - loss: 0.7954 - acc: 0.7071 - val_loss: 0.7567 - val_acc: 0.7282\n",
      "Epoch 18/1000\n",
      "25/25 [==============================] - 12s 485ms/step - loss: 0.7935 - acc: 0.7160\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.75671\n",
      "74/74 [==============================] - 44s 596ms/step - loss: 0.7974 - acc: 0.7156 - val_loss: 0.7935 - val_acc: 0.7160\n",
      "Epoch 19/1000\n",
      "25/25 [==============================] - 12s 492ms/step - loss: 0.7843 - acc: 0.7212\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.75671\n",
      "74/74 [==============================] - 45s 602ms/step - loss: 0.7706 - acc: 0.7267 - val_loss: 0.7843 - val_acc: 0.7212\n",
      "Epoch 20/1000\n",
      "25/25 [==============================] - 12s 496ms/step - loss: 0.7336 - acc: 0.7436\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.75671 to 0.73364, saving model to model/checkpoint/vis_imagenet_6_class_augumentation_2D_CNN_custom_ch_128_DO_075_DO_3_conv_checkpoint/020-0.7336.hdf5\n",
      "74/74 [==============================] - 45s 611ms/step - loss: 0.7545 - acc: 0.7231 - val_loss: 0.7336 - val_acc: 0.7436\n",
      "Epoch 21/1000\n",
      "25/25 [==============================] - 12s 497ms/step - loss: 0.7276 - acc: 0.7468\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.73364 to 0.72759, saving model to model/checkpoint/vis_imagenet_6_class_augumentation_2D_CNN_custom_ch_128_DO_075_DO_3_conv_checkpoint/021-0.7276.hdf5\n",
      "74/74 [==============================] - 45s 607ms/step - loss: 0.7455 - acc: 0.7380 - val_loss: 0.7276 - val_acc: 0.7468\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/1000\n",
      "25/25 [==============================] - 12s 495ms/step - loss: 0.7464 - acc: 0.7378\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.72759\n",
      "74/74 [==============================] - 44s 601ms/step - loss: 0.7292 - acc: 0.7301 - val_loss: 0.7464 - val_acc: 0.7378\n",
      "Epoch 23/1000\n",
      "25/25 [==============================] - 13s 502ms/step - loss: 0.7255 - acc: 0.7423\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.72759 to 0.72552, saving model to model/checkpoint/vis_imagenet_6_class_augumentation_2D_CNN_custom_ch_128_DO_075_DO_3_conv_checkpoint/023-0.7255.hdf5\n",
      "74/74 [==============================] - 45s 606ms/step - loss: 0.7216 - acc: 0.7419 - val_loss: 0.7255 - val_acc: 0.7423\n",
      "Epoch 24/1000\n",
      "25/25 [==============================] - 12s 496ms/step - loss: 0.7366 - acc: 0.7365\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.72552\n",
      "74/74 [==============================] - 45s 603ms/step - loss: 0.7286 - acc: 0.7453 - val_loss: 0.7366 - val_acc: 0.7365\n",
      "Epoch 25/1000\n",
      "25/25 [==============================] - 12s 498ms/step - loss: 0.7238 - acc: 0.7404\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.72552 to 0.72383, saving model to model/checkpoint/vis_imagenet_6_class_augumentation_2D_CNN_custom_ch_128_DO_075_DO_3_conv_checkpoint/025-0.7238.hdf5\n",
      "74/74 [==============================] - 45s 605ms/step - loss: 0.7172 - acc: 0.7382 - val_loss: 0.7238 - val_acc: 0.7404\n",
      "Epoch 26/1000\n",
      "25/25 [==============================] - 12s 493ms/step - loss: 0.6923 - acc: 0.7577\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.72383 to 0.69226, saving model to model/checkpoint/vis_imagenet_6_class_augumentation_2D_CNN_custom_ch_128_DO_075_DO_3_conv_checkpoint/026-0.6923.hdf5\n",
      "74/74 [==============================] - 45s 605ms/step - loss: 0.6850 - acc: 0.7592 - val_loss: 0.6923 - val_acc: 0.7577\n",
      "Epoch 27/1000\n",
      "25/25 [==============================] - 13s 515ms/step - loss: 0.7234 - acc: 0.7404\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.69226\n",
      "74/74 [==============================] - 45s 610ms/step - loss: 0.6787 - acc: 0.7596 - val_loss: 0.7234 - val_acc: 0.7404\n",
      "Epoch 28/1000\n",
      "25/25 [==============================] - 13s 505ms/step - loss: 0.6932 - acc: 0.7583\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.69226\n",
      "74/74 [==============================] - 45s 608ms/step - loss: 0.6826 - acc: 0.7611 - val_loss: 0.6932 - val_acc: 0.7583\n",
      "Epoch 29/1000\n",
      "25/25 [==============================] - 12s 497ms/step - loss: 0.6752 - acc: 0.7622\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.69226 to 0.67519, saving model to model/checkpoint/vis_imagenet_6_class_augumentation_2D_CNN_custom_ch_128_DO_075_DO_3_conv_checkpoint/029-0.6752.hdf5\n",
      "74/74 [==============================] - 45s 606ms/step - loss: 0.6559 - acc: 0.7673 - val_loss: 0.6752 - val_acc: 0.7622\n",
      "Epoch 30/1000\n",
      "25/25 [==============================] - 12s 491ms/step - loss: 0.6804 - acc: 0.7635\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.67519\n",
      "74/74 [==============================] - 44s 601ms/step - loss: 0.6746 - acc: 0.7632 - val_loss: 0.6804 - val_acc: 0.7635\n",
      "Epoch 31/1000\n",
      "25/25 [==============================] - 12s 496ms/step - loss: 0.7221 - acc: 0.7494\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.67519\n",
      "74/74 [==============================] - 45s 606ms/step - loss: 0.6665 - acc: 0.7581 - val_loss: 0.7221 - val_acc: 0.7494\n",
      "Epoch 32/1000\n",
      "25/25 [==============================] - 13s 500ms/step - loss: 0.6614 - acc: 0.7705\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.67519 to 0.66140, saving model to model/checkpoint/vis_imagenet_6_class_augumentation_2D_CNN_custom_ch_128_DO_075_DO_3_conv_checkpoint/032-0.6614.hdf5\n",
      "74/74 [==============================] - 45s 609ms/step - loss: 0.6607 - acc: 0.7707 - val_loss: 0.6614 - val_acc: 0.7705\n",
      "Epoch 33/1000\n",
      "25/25 [==============================] - 12s 488ms/step - loss: 0.6306 - acc: 0.7788\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.66140 to 0.63056, saving model to model/checkpoint/vis_imagenet_6_class_augumentation_2D_CNN_custom_ch_128_DO_075_DO_3_conv_checkpoint/033-0.6306.hdf5\n",
      "74/74 [==============================] - 45s 603ms/step - loss: 0.6328 - acc: 0.7788 - val_loss: 0.6306 - val_acc: 0.7788\n",
      "Epoch 34/1000\n",
      "25/25 [==============================] - 12s 487ms/step - loss: 0.6890 - acc: 0.7615\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.63056\n",
      "74/74 [==============================] - 45s 605ms/step - loss: 0.6199 - acc: 0.7803 - val_loss: 0.6890 - val_acc: 0.7615\n",
      "Epoch 35/1000\n",
      "25/25 [==============================] - 12s 486ms/step - loss: 0.6589 - acc: 0.7673\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.63056\n",
      "74/74 [==============================] - 44s 601ms/step - loss: 0.6188 - acc: 0.7810 - val_loss: 0.6589 - val_acc: 0.7673\n",
      "Epoch 36/1000\n",
      "25/25 [==============================] - 12s 483ms/step - loss: 0.6517 - acc: 0.7692\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.63056\n",
      "74/74 [==============================] - 44s 600ms/step - loss: 0.6196 - acc: 0.7812 - val_loss: 0.6517 - val_acc: 0.7692\n",
      "Epoch 37/1000\n",
      "25/25 [==============================] - 13s 510ms/step - loss: 0.6366 - acc: 0.7724\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.63056\n",
      "74/74 [==============================] - 45s 608ms/step - loss: 0.6213 - acc: 0.7870 - val_loss: 0.6366 - val_acc: 0.7724\n",
      "Epoch 38/1000\n",
      "25/25 [==============================] - 12s 490ms/step - loss: 0.6665 - acc: 0.7788\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.63056\n",
      "74/74 [==============================] - 45s 603ms/step - loss: 0.5968 - acc: 0.7816 - val_loss: 0.6665 - val_acc: 0.7788\n",
      "Epoch 39/1000\n",
      "25/25 [==============================] - 12s 479ms/step - loss: 0.6223 - acc: 0.7865\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.63056 to 0.62230, saving model to model/checkpoint/vis_imagenet_6_class_augumentation_2D_CNN_custom_ch_128_DO_075_DO_3_conv_checkpoint/039-0.6223.hdf5\n",
      "74/74 [==============================] - 44s 595ms/step - loss: 0.6037 - acc: 0.7872 - val_loss: 0.6223 - val_acc: 0.7865\n",
      "Epoch 40/1000\n",
      "25/25 [==============================] - 12s 480ms/step - loss: 0.6030 - acc: 0.7955\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.62230 to 0.60300, saving model to model/checkpoint/vis_imagenet_6_class_augumentation_2D_CNN_custom_ch_128_DO_075_DO_3_conv_checkpoint/040-0.6030.hdf5\n",
      "74/74 [==============================] - 44s 598ms/step - loss: 0.5841 - acc: 0.7912 - val_loss: 0.6030 - val_acc: 0.7955\n",
      "Epoch 41/1000\n",
      "25/25 [==============================] - 12s 488ms/step - loss: 0.6400 - acc: 0.7756\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.60300\n",
      "74/74 [==============================] - 44s 599ms/step - loss: 0.5946 - acc: 0.7947 - val_loss: 0.6400 - val_acc: 0.7756\n",
      "Epoch 42/1000\n",
      "25/25 [==============================] - 12s 479ms/step - loss: 0.5795 - acc: 0.7949\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.60300 to 0.57949, saving model to model/checkpoint/vis_imagenet_6_class_augumentation_2D_CNN_custom_ch_128_DO_075_DO_3_conv_checkpoint/042-0.5795.hdf5\n",
      "74/74 [==============================] - 44s 596ms/step - loss: 0.5589 - acc: 0.7983 - val_loss: 0.5795 - val_acc: 0.7949\n",
      "Epoch 43/1000\n",
      "48/74 [==================>...........] - ETA: 11s - loss: 0.5707 - acc: 0.7905"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[64,128,341,341] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node training/Adam/gradients/max_pooling2d_15/MaxPool_grad/MaxPoolGrad}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-5c72f2bcf67f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcheckpointer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearly_stopping\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     )\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1424\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1425\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1426\u001b[0;31m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1428\u001b[0m   def evaluate_generator(self,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, **kwargs)\u001b[0m\n\u001b[1;32m    189\u001b[0m       \u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m       \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m   1189\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_fit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1191\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1193\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3074\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3075\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3076\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3077\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3078\u001b[0m     return nest.pack_sequence_as(self._outputs_structure,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    526\u001b[0m             \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 528\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    529\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m     \u001b[0;31m# as there is a reference to status from this from the traceback due to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[64,128,341,341] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node training/Adam/gradients/max_pooling2d_15/MaxPool_grad/MaxPoolGrad}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n"
     ]
    }
   ],
   "source": [
    "for i in range(3, 6):\n",
    "    base = 'vis_imagenet_6_class_augmentation_2D_CNN_custom_ch_128_DO_075_DO'\n",
    "    model_name = base+'_{}_conv'.format(i)\n",
    "    model = build_2d_cnn_custom_ch_128_DO(conv_num=i)\n",
    "#     model = multi_gpu_model(model, gpus=2)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=1e-4),\n",
    "          metrics=['accuracy'])\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    os.makedirs(model_path, exist_ok=True)\n",
    "    model_filename = model_path+'{epoch:03d}-{val_loss:.4f}.hdf5'\n",
    "    checkpointer = ModelCheckpoint(filepath = model_filename, monitor = \"val_loss\", \n",
    "                                   verbose=1, save_best_only=True)\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=100)\n",
    "    hist = model.fit_generator(\n",
    "            data_generator.flow(x_train, y_train, batch_size=64),\n",
    "            steps_per_epoch=len(x_train)//64,\n",
    "            epochs=10000,\n",
    "            validation_data=data_generator.flow(x_val, y_val, batch_size=64),\n",
    "            validation_steps=len(x_val)//64,\n",
    "            callbacks = [checkpointer, early_stopping],\n",
    "            workers=4, \n",
    "            use_multiprocessing=True\n",
    "    )\n",
    "\n",
    "    print()\n",
    "    print(model_name, 'Model')\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "    ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
    "    ax.plot(hist.history['acc'], 'b', label='train acc')\n",
    "    ax.plot(hist.history['val_acc'], 'g', label='val acc')\n",
    "    ax.set_xlabel('epoch')\n",
    "    ax.set_ylabel('loss')\n",
    "    ax.legend(loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    png_path = 'visualization/learning_curve/'\n",
    "    filename = model_name+'.png'\n",
    "    os.makedirs(png_path, exist_ok=True)\n",
    "    fig.savefig(png_path+filename, transparent=True)\n",
    "\n",
    "    model.save(model_path+'000_last.hdf5')\n",
    "    del(model)\n",
    "\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    model_filename = model_path + sorted(os.listdir(model_path))[-1]\n",
    "    model = load_model(model_filename)\n",
    "    [loss, accuracy] = model.evaluate(x_test, y_test)\n",
    "    print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "    print()\n",
    "\n",
    "    del(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = 'log'\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "base = 'vis_imagenet_6_class_augmentation_2D_CNN_custom_ch_128_DO_075_DO'\n",
    "\n",
    "with open(path.join(log_dir, base), 'w') as log_file:\n",
    "    for i in range(3, 6):\n",
    "        model_name = base+'_{}_conv'.format(i)\n",
    "        print()\n",
    "        print(model_name, 'Model')\n",
    "        model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "        model_filename = model_path + sorted(os.listdir(model_path))[-1]\n",
    "\n",
    "        model = load_model(model_filename)\n",
    "        model.summary()\n",
    "\n",
    "        [loss, accuracy] = model.evaluate(x_test, y_test)\n",
    "        print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "\n",
    "        del(model)\n",
    "\n",
    "        log_file.write('\\t'.join([model_name, str(accuracy), str(loss)])+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3, 6):\n",
    "    model_name = base+'_{}_conv'.format(i)\n",
    "    print()\n",
    "    print(model_name, 'Model')\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    model_filename = model_path + '000_last.hdf5'\n",
    "\n",
    "    model = load_model(model_filename)\n",
    "    model.summary()\n",
    "\n",
    "    [loss, accuracy] = model.evaluate(x_test, y_test)\n",
    "    print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "\n",
    "    del(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

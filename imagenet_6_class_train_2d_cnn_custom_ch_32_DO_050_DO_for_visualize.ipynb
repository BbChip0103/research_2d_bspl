{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import os.path as path\n",
    "import itertools\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.layers import Input,InputLayer, Dense, Activation, BatchNormalization, Flatten, Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D, Dropout\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,LearningRateScheduler, \\\n",
    "                                        EarlyStopping\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.utils import to_categorical, multi_gpu_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.load(path.join(data_dir, 'imagenet_6_class_train_data.npz'))\n",
    "val_data = np.load(path.join(data_dir, 'imagenet_6_class_val_data.npz'))\n",
    "test_data = np.load(path.join(data_dir, 'imagenet_6_class_val_data.npz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4680, 341, 341, 3),\n",
       " (4680,),\n",
       " (1560, 341, 341, 3),\n",
       " (1560,),\n",
       " (1560, 341, 341, 3),\n",
       " (1560,),\n",
       " (6, 2))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = train_data['x_data']\n",
    "y_train = train_data['y_data']\n",
    "x_val = val_data['x_data']\n",
    "y_val = val_data['y_data']\n",
    "x_test = test_data['x_data']\n",
    "y_test = test_data['y_data']\n",
    "y_table_array = test_data['y_table_array']\n",
    "\n",
    "x_train.shape, y_train.shape, x_val.shape, y_val.shape, x_test.shape, y_test.shape, y_table_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4680, 341, 341, 3),\n",
       " (4680, 6),\n",
       " (1560, 341, 341, 3),\n",
       " (1560, 6),\n",
       " (1560, 341, 341, 3),\n",
       " (1560, 6))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = to_categorical(y_train)\n",
    "y_val = to_categorical(y_val)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "x_train.shape, y_train.shape, x_val.shape, y_val.shape, x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bed', 'bird', 'cat', 'dog', 'house', 'tree']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_list = [text for _, text in y_table_array]\n",
    "y_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = x_train[0].shape\n",
    "output_size = len(y_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_2d_cnn_custom_ch_32_DO(conv_num=1):\n",
    "    input_layer = Input(shape=input_shape)\n",
    "    x = input_layer\n",
    "\n",
    "    for i in range(conv_num):\n",
    "        x = Conv2D(kernel_size=5, filters=32*(2**(i//2)), strides=(1,1), padding='same')(x)\n",
    "#         x = BatchNormalization()(x)\n",
    "        x = Activation('relu')(x)\n",
    "        x = MaxPooling2D(pool_size=3, strides=(3,3), padding='same')(x)\n",
    "\n",
    "    x = Flatten()(x)\n",
    "  \n",
    "    x = Dropout(0.5)(x)\n",
    "    output_layer = Dense(output_size, activation='softmax')(x)\n",
    "    \n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 341, 341, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 341, 341, 32)      2432      \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 341, 341, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 114, 114, 32)      0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 415872)            0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 415872)            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 6)                 2495238   \n",
      "=================================================================\n",
      "Total params: 2,497,670\n",
      "Trainable params: 2,497,670\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 341, 341, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 341, 341, 32)      2432      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 341, 341, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 114, 114, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 114, 114, 32)      25632     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 114, 114, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 38, 38, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 46208)             0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 46208)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 6)                 277254    \n",
      "=================================================================\n",
      "Total params: 305,318\n",
      "Trainable params: 305,318\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 341, 341, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 341, 341, 32)      2432      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 341, 341, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 114, 114, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 114, 114, 32)      25632     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 114, 114, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 38, 38, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 38, 38, 64)        51264     \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 38, 38, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 10816)             0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 10816)             0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 6)                 64902     \n",
      "=================================================================\n",
      "Total params: 144,230\n",
      "Trainable params: 144,230\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, 341, 341, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 341, 341, 32)      2432      \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 341, 341, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 114, 114, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 114, 114, 32)      25632     \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 114, 114, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 38, 38, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 38, 38, 64)        51264     \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 38, 38, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 13, 13, 64)        102464    \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 6)                 9606      \n",
      "=================================================================\n",
      "Total params: 191,398\n",
      "Trainable params: 191,398\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         (None, 341, 341, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 341, 341, 32)      2432      \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 341, 341, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 114, 114, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 114, 114, 32)      25632     \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 114, 114, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 38, 38, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 38, 38, 64)        51264     \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 38, 38, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 13, 13, 64)        102464    \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 5, 5, 128)         204928    \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 5, 5, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 2, 2, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 6)                 3078      \n",
      "=================================================================\n",
      "Total params: 389,798\n",
      "Trainable params: 389,798\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 6):\n",
    "    model = build_2d_cnn_custom_ch_32_DO(conv_num=i)\n",
    "    model.summary()\n",
    "    del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4680 samples, validate on 1560 samples\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 1.5220 - acc: 0.3859\n",
      "Epoch 00001: val_loss improved from inf to 1.22440, saving model to model/checkpoint/vis_imagenet_6_class_2D_CNN_custom_ch_32_DO_050_DO_2_conv_checkpoint/001-1.2244.hdf5\n",
      "4680/4680 [==============================] - 17s 4ms/sample - loss: 1.5214 - acc: 0.3863 - val_loss: 1.2244 - val_acc: 0.5250\n",
      "Epoch 2/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 1.1769 - acc: 0.5456\n",
      "Epoch 00002: val_loss improved from 1.22440 to 1.06595, saving model to model/checkpoint/vis_imagenet_6_class_2D_CNN_custom_ch_32_DO_050_DO_2_conv_checkpoint/002-1.0659.hdf5\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 1.1764 - acc: 0.5459 - val_loss: 1.0659 - val_acc: 0.5987\n",
      "Epoch 3/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 1.0279 - acc: 0.6143\n",
      "Epoch 00003: val_loss improved from 1.06595 to 0.98124, saving model to model/checkpoint/vis_imagenet_6_class_2D_CNN_custom_ch_32_DO_050_DO_2_conv_checkpoint/003-0.9812.hdf5\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 1.0273 - acc: 0.6143 - val_loss: 0.9812 - val_acc: 0.6391\n",
      "Epoch 4/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.9562 - acc: 0.6627\n",
      "Epoch 00004: val_loss improved from 0.98124 to 0.96299, saving model to model/checkpoint/vis_imagenet_6_class_2D_CNN_custom_ch_32_DO_050_DO_2_conv_checkpoint/004-0.9630.hdf5\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.9567 - acc: 0.6624 - val_loss: 0.9630 - val_acc: 0.6481\n",
      "Epoch 5/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.8697 - acc: 0.7025\n",
      "Epoch 00005: val_loss improved from 0.96299 to 0.91111, saving model to model/checkpoint/vis_imagenet_6_class_2D_CNN_custom_ch_32_DO_050_DO_2_conv_checkpoint/005-0.9111.hdf5\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.8698 - acc: 0.7021 - val_loss: 0.9111 - val_acc: 0.6673\n",
      "Epoch 6/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.8174 - acc: 0.7217\n",
      "Epoch 00006: val_loss did not improve from 0.91111\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.8173 - acc: 0.7220 - val_loss: 0.9123 - val_acc: 0.6526\n",
      "Epoch 7/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.7870 - acc: 0.7361\n",
      "Epoch 00007: val_loss improved from 0.91111 to 0.89576, saving model to model/checkpoint/vis_imagenet_6_class_2D_CNN_custom_ch_32_DO_050_DO_2_conv_checkpoint/007-0.8958.hdf5\n",
      "4680/4680 [==============================] - 16s 3ms/sample - loss: 0.7866 - acc: 0.7361 - val_loss: 0.8958 - val_acc: 0.6814\n",
      "Epoch 8/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.7418 - acc: 0.7504\n",
      "Epoch 00008: val_loss improved from 0.89576 to 0.88190, saving model to model/checkpoint/vis_imagenet_6_class_2D_CNN_custom_ch_32_DO_050_DO_2_conv_checkpoint/008-0.8819.hdf5\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.7413 - acc: 0.7506 - val_loss: 0.8819 - val_acc: 0.6833\n",
      "Epoch 9/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.7047 - acc: 0.7547\n",
      "Epoch 00009: val_loss improved from 0.88190 to 0.85009, saving model to model/checkpoint/vis_imagenet_6_class_2D_CNN_custom_ch_32_DO_050_DO_2_conv_checkpoint/009-0.8501.hdf5\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.7042 - acc: 0.7551 - val_loss: 0.8501 - val_acc: 0.6853\n",
      "Epoch 10/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.6620 - acc: 0.7798\n",
      "Epoch 00010: val_loss did not improve from 0.85009\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.6629 - acc: 0.7791 - val_loss: 0.8608 - val_acc: 0.6917\n",
      "Epoch 11/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.6470 - acc: 0.7834\n",
      "Epoch 00011: val_loss improved from 0.85009 to 0.83074, saving model to model/checkpoint/vis_imagenet_6_class_2D_CNN_custom_ch_32_DO_050_DO_2_conv_checkpoint/011-0.8307.hdf5\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.6465 - acc: 0.7838 - val_loss: 0.8307 - val_acc: 0.7192\n",
      "Epoch 12/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.5912 - acc: 0.8091\n",
      "Epoch 00012: val_loss did not improve from 0.83074\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.5917 - acc: 0.8090 - val_loss: 0.8447 - val_acc: 0.6936\n",
      "Epoch 13/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.5667 - acc: 0.8157\n",
      "Epoch 00013: val_loss improved from 0.83074 to 0.79783, saving model to model/checkpoint/vis_imagenet_6_class_2D_CNN_custom_ch_32_DO_050_DO_2_conv_checkpoint/013-0.7978.hdf5\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.5660 - acc: 0.8160 - val_loss: 0.7978 - val_acc: 0.7224\n",
      "Epoch 14/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.5466 - acc: 0.8208\n",
      "Epoch 00014: val_loss did not improve from 0.79783\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.5463 - acc: 0.8209 - val_loss: 0.8202 - val_acc: 0.7032\n",
      "Epoch 15/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.5182 - acc: 0.8337\n",
      "Epoch 00015: val_loss improved from 0.79783 to 0.79691, saving model to model/checkpoint/vis_imagenet_6_class_2D_CNN_custom_ch_32_DO_050_DO_2_conv_checkpoint/015-0.7969.hdf5\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.5177 - acc: 0.8340 - val_loss: 0.7969 - val_acc: 0.7224\n",
      "Epoch 16/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.4881 - acc: 0.8435\n",
      "Epoch 00016: val_loss improved from 0.79691 to 0.76473, saving model to model/checkpoint/vis_imagenet_6_class_2D_CNN_custom_ch_32_DO_050_DO_2_conv_checkpoint/016-0.7647.hdf5\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.4881 - acc: 0.8436 - val_loss: 0.7647 - val_acc: 0.7295\n",
      "Epoch 17/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.4615 - acc: 0.8560\n",
      "Epoch 00017: val_loss did not improve from 0.76473\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.4615 - acc: 0.8558 - val_loss: 0.7830 - val_acc: 0.7231\n",
      "Epoch 18/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.4381 - acc: 0.8596\n",
      "Epoch 00018: val_loss did not improve from 0.76473\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.4380 - acc: 0.8596 - val_loss: 0.8152 - val_acc: 0.7064\n",
      "Epoch 19/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.4111 - acc: 0.8731\n",
      "Epoch 00019: val_loss did not improve from 0.76473\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.4108 - acc: 0.8731 - val_loss: 0.7811 - val_acc: 0.7378\n",
      "Epoch 20/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.3859 - acc: 0.8818\n",
      "Epoch 00020: val_loss did not improve from 0.76473\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.3859 - acc: 0.8818 - val_loss: 0.8312 - val_acc: 0.7301\n",
      "Epoch 21/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.3734 - acc: 0.8855\n",
      "Epoch 00021: val_loss did not improve from 0.76473\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.3732 - acc: 0.8857 - val_loss: 0.7836 - val_acc: 0.7385\n",
      "Epoch 22/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.3534 - acc: 0.8936\n",
      "Epoch 00022: val_loss did not improve from 0.76473\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.3530 - acc: 0.8938 - val_loss: 0.7659 - val_acc: 0.7327\n",
      "Epoch 23/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.3396 - acc: 0.8949\n",
      "Epoch 00023: val_loss did not improve from 0.76473\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.3392 - acc: 0.8951 - val_loss: 0.8529 - val_acc: 0.7167\n",
      "Epoch 24/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.3191 - acc: 0.9018\n",
      "Epoch 00024: val_loss did not improve from 0.76473\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.3192 - acc: 0.9019 - val_loss: 0.7939 - val_acc: 0.7327\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.3047 - acc: 0.9114\n",
      "Epoch 00025: val_loss did not improve from 0.76473\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.3042 - acc: 0.9115 - val_loss: 0.8041 - val_acc: 0.7353\n",
      "Epoch 26/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.2884 - acc: 0.9122\n",
      "Epoch 00026: val_loss did not improve from 0.76473\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.2885 - acc: 0.9122 - val_loss: 0.8076 - val_acc: 0.7263\n",
      "Epoch 27/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.2798 - acc: 0.9146\n",
      "Epoch 00027: val_loss did not improve from 0.76473\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.2804 - acc: 0.9143 - val_loss: 0.8294 - val_acc: 0.7218\n",
      "Epoch 28/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.2676 - acc: 0.9157\n",
      "Epoch 00028: val_loss did not improve from 0.76473\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.2677 - acc: 0.9156 - val_loss: 0.7996 - val_acc: 0.7301\n",
      "Epoch 29/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.2457 - acc: 0.9283\n",
      "Epoch 00029: val_loss did not improve from 0.76473\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.2455 - acc: 0.9284 - val_loss: 0.8163 - val_acc: 0.7340\n",
      "Epoch 30/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.2292 - acc: 0.9326\n",
      "Epoch 00030: val_loss did not improve from 0.76473\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.2297 - acc: 0.9323 - val_loss: 0.8589 - val_acc: 0.7263\n",
      "Epoch 31/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.2199 - acc: 0.9317\n",
      "Epoch 00031: val_loss did not improve from 0.76473\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.2197 - acc: 0.9318 - val_loss: 0.8320 - val_acc: 0.7365\n",
      "Epoch 32/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.2036 - acc: 0.9452\n",
      "Epoch 00032: val_loss did not improve from 0.76473\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.2037 - acc: 0.9453 - val_loss: 0.8381 - val_acc: 0.7346\n",
      "Epoch 33/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.2081 - acc: 0.9420\n",
      "Epoch 00033: val_loss did not improve from 0.76473\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.2081 - acc: 0.9419 - val_loss: 0.8690 - val_acc: 0.7333\n",
      "Epoch 34/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.1939 - acc: 0.9478\n",
      "Epoch 00034: val_loss did not improve from 0.76473\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.1940 - acc: 0.9476 - val_loss: 0.8511 - val_acc: 0.7288\n",
      "Epoch 35/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.1806 - acc: 0.9493\n",
      "Epoch 00035: val_loss did not improve from 0.76473\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.1805 - acc: 0.9494 - val_loss: 0.8512 - val_acc: 0.7333\n",
      "Epoch 36/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.1707 - acc: 0.9512\n",
      "Epoch 00036: val_loss did not improve from 0.76473\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.1704 - acc: 0.9513 - val_loss: 0.8696 - val_acc: 0.7327\n",
      "Epoch 37/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.1709 - acc: 0.9525\n",
      "Epoch 00037: val_loss did not improve from 0.76473\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.1707 - acc: 0.9526 - val_loss: 0.9279 - val_acc: 0.7301\n",
      "Epoch 38/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.1598 - acc: 0.9583\n",
      "Epoch 00038: val_loss did not improve from 0.76473\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.1599 - acc: 0.9581 - val_loss: 0.8784 - val_acc: 0.7288\n",
      "Epoch 39/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.1567 - acc: 0.9585\n",
      "Epoch 00039: val_loss did not improve from 0.76473\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.1565 - acc: 0.9585 - val_loss: 0.9303 - val_acc: 0.7308\n",
      "Epoch 40/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.1464 - acc: 0.9615\n",
      "Epoch 00040: val_loss did not improve from 0.76473\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.1463 - acc: 0.9615 - val_loss: 0.9094 - val_acc: 0.7276\n",
      "Epoch 41/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.1308 - acc: 0.9647\n",
      "Epoch 00041: val_loss did not improve from 0.76473\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.1309 - acc: 0.9647 - val_loss: 0.9484 - val_acc: 0.7256\n",
      "Epoch 42/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.1447 - acc: 0.9568\n",
      "Epoch 00042: val_loss did not improve from 0.76473\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.1445 - acc: 0.9568 - val_loss: 0.9515 - val_acc: 0.7276\n",
      "Epoch 43/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.1269 - acc: 0.9679\n",
      "Epoch 00043: val_loss did not improve from 0.76473\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.1269 - acc: 0.9679 - val_loss: 0.9477 - val_acc: 0.7295\n",
      "Epoch 44/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.1233 - acc: 0.9670\n",
      "Epoch 00044: val_loss did not improve from 0.76473\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.1232 - acc: 0.9671 - val_loss: 1.0320 - val_acc: 0.7231\n",
      "Epoch 45/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.1126 - acc: 0.9747\n",
      "Epoch 00045: val_loss did not improve from 0.76473\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.1124 - acc: 0.9748 - val_loss: 0.9919 - val_acc: 0.7288\n",
      "Epoch 46/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.1131 - acc: 0.9705\n",
      "Epoch 00046: val_loss did not improve from 0.76473\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.1131 - acc: 0.9705 - val_loss: 1.0354 - val_acc: 0.7128\n",
      "Epoch 47/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.1108 - acc: 0.9717\n",
      "Epoch 00047: val_loss did not improve from 0.76473\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.1111 - acc: 0.9716 - val_loss: 0.9961 - val_acc: 0.7147\n",
      "Epoch 48/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.0974 - acc: 0.9745\n",
      "Epoch 00048: val_loss did not improve from 0.76473\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.0976 - acc: 0.9744 - val_loss: 1.0404 - val_acc: 0.7276\n",
      "Epoch 49/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.0947 - acc: 0.9760\n",
      "Epoch 00049: val_loss did not improve from 0.76473\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.0947 - acc: 0.9761 - val_loss: 1.0634 - val_acc: 0.7212\n",
      "Epoch 50/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.1001 - acc: 0.9737\n",
      "Epoch 00050: val_loss did not improve from 0.76473\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.1003 - acc: 0.9735 - val_loss: 1.1910 - val_acc: 0.7013\n",
      "Epoch 51/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.1095 - acc: 0.9692\n",
      "Epoch 00051: val_loss did not improve from 0.76473\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.1094 - acc: 0.9692 - val_loss: 1.0288 - val_acc: 0.7199\n",
      "Epoch 52/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.0804 - acc: 0.9833\n",
      "Epoch 00052: val_loss did not improve from 0.76473\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.0806 - acc: 0.9831 - val_loss: 1.0677 - val_acc: 0.7231\n",
      "Epoch 53/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.0806 - acc: 0.9795\n",
      "Epoch 00053: val_loss did not improve from 0.76473\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.0805 - acc: 0.9795 - val_loss: 1.1228 - val_acc: 0.7192\n",
      "Epoch 54/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.0825 - acc: 0.9780\n",
      "Epoch 00054: val_loss did not improve from 0.76473\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.0825 - acc: 0.9780 - val_loss: 1.0813 - val_acc: 0.7231\n",
      "Epoch 55/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.0844 - acc: 0.9775\n",
      "Epoch 00055: val_loss did not improve from 0.76473\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.0843 - acc: 0.9776 - val_loss: 1.1155 - val_acc: 0.7179\n",
      "Epoch 56/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.0741 - acc: 0.9833\n",
      "Epoch 00056: val_loss did not improve from 0.76473\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.0740 - acc: 0.9833 - val_loss: 1.1070 - val_acc: 0.7256\n",
      "Epoch 57/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.0675 - acc: 0.9857\n",
      "Epoch 00057: val_loss did not improve from 0.76473\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.0675 - acc: 0.9857 - val_loss: 1.0880 - val_acc: 0.7263\n",
      "Epoch 58/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.0678 - acc: 0.9842\n",
      "Epoch 00058: val_loss did not improve from 0.76473\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.0677 - acc: 0.9842 - val_loss: 1.1160 - val_acc: 0.7263\n",
      "Epoch 59/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.0658 - acc: 0.9844\n",
      "Epoch 00059: val_loss did not improve from 0.76473\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.0657 - acc: 0.9844 - val_loss: 1.1024 - val_acc: 0.7295\n",
      "Epoch 60/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.0661 - acc: 0.9861\n",
      "Epoch 00060: val_loss did not improve from 0.76473\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.0661 - acc: 0.9861 - val_loss: 1.1672 - val_acc: 0.7269\n",
      "Epoch 61/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.0652 - acc: 0.9846\n",
      "Epoch 00061: val_loss did not improve from 0.76473\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.0651 - acc: 0.9846 - val_loss: 1.1366 - val_acc: 0.7250\n",
      "Epoch 62/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.0612 - acc: 0.9844\n",
      "Epoch 00062: val_loss did not improve from 0.76473\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.0613 - acc: 0.9842 - val_loss: 1.2079 - val_acc: 0.7199\n",
      "Epoch 63/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.0676 - acc: 0.9812\n",
      "Epoch 00063: val_loss did not improve from 0.76473\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.0676 - acc: 0.9812 - val_loss: 1.2679 - val_acc: 0.7167\n",
      "Epoch 64/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.0575 - acc: 0.9865\n",
      "Epoch 00064: val_loss did not improve from 0.76473\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.0575 - acc: 0.9865 - val_loss: 1.1641 - val_acc: 0.7340\n",
      "Epoch 65/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.0615 - acc: 0.9835\n",
      "Epoch 00065: val_loss did not improve from 0.76473\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.0616 - acc: 0.9835 - val_loss: 1.1995 - val_acc: 0.7231\n",
      "Epoch 66/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.0547 - acc: 0.9863\n",
      "Epoch 00066: val_loss did not improve from 0.76473\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.0546 - acc: 0.9863 - val_loss: 1.1575 - val_acc: 0.7218\n",
      "\n",
      "vis_imagenet_6_class_2D_CNN_custom_ch_32_DO_050_DO_2_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1560/1560 [==============================] - 3s 2ms/sample - loss: 0.7697 - acc: 0.7417\n",
      "Loss: 0.7696938050098908 Accuracy: 0.7416667\n",
      "\n",
      "Train on 4680 samples, validate on 1560 samples\n",
      "Epoch 1/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 1.6251 - acc: 0.3166\n",
      "Epoch 00001: val_loss improved from inf to 1.37646, saving model to model/checkpoint/vis_imagenet_6_class_2D_CNN_custom_ch_32_DO_050_DO_3_conv_checkpoint/001-1.3765.hdf5\n",
      "4680/4680 [==============================] - 16s 3ms/sample - loss: 1.6240 - acc: 0.3175 - val_loss: 1.3765 - val_acc: 0.4647\n",
      "Epoch 2/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 1.2810 - acc: 0.4998\n",
      "Epoch 00002: val_loss improved from 1.37646 to 1.22801, saving model to model/checkpoint/vis_imagenet_6_class_2D_CNN_custom_ch_32_DO_050_DO_3_conv_checkpoint/002-1.2280.hdf5\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 1.2806 - acc: 0.5000 - val_loss: 1.2280 - val_acc: 0.5269\n",
      "Epoch 3/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 1.1604 - acc: 0.5514\n",
      "Epoch 00003: val_loss improved from 1.22801 to 1.08150, saving model to model/checkpoint/vis_imagenet_6_class_2D_CNN_custom_ch_32_DO_050_DO_3_conv_checkpoint/003-1.0815.hdf5\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 1.1600 - acc: 0.5517 - val_loss: 1.0815 - val_acc: 0.5878\n",
      "Epoch 4/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 1.0604 - acc: 0.6079\n",
      "Epoch 00004: val_loss improved from 1.08150 to 0.99618, saving model to model/checkpoint/vis_imagenet_6_class_2D_CNN_custom_ch_32_DO_050_DO_3_conv_checkpoint/004-0.9962.hdf5\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 1.0610 - acc: 0.6077 - val_loss: 0.9962 - val_acc: 0.6231\n",
      "Epoch 5/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 1.0122 - acc: 0.6259\n",
      "Epoch 00005: val_loss improved from 0.99618 to 0.93849, saving model to model/checkpoint/vis_imagenet_6_class_2D_CNN_custom_ch_32_DO_050_DO_3_conv_checkpoint/005-0.9385.hdf5\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 1.0119 - acc: 0.6259 - val_loss: 0.9385 - val_acc: 0.6571\n",
      "Epoch 6/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.9588 - acc: 0.6571\n",
      "Epoch 00006: val_loss improved from 0.93849 to 0.90915, saving model to model/checkpoint/vis_imagenet_6_class_2D_CNN_custom_ch_32_DO_050_DO_3_conv_checkpoint/006-0.9091.hdf5\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.9578 - acc: 0.6577 - val_loss: 0.9091 - val_acc: 0.6622\n",
      "Epoch 7/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.9220 - acc: 0.6695\n",
      "Epoch 00007: val_loss improved from 0.90915 to 0.88700, saving model to model/checkpoint/vis_imagenet_6_class_2D_CNN_custom_ch_32_DO_050_DO_3_conv_checkpoint/007-0.8870.hdf5\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.9218 - acc: 0.6697 - val_loss: 0.8870 - val_acc: 0.6692\n",
      "Epoch 8/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.8802 - acc: 0.6886\n",
      "Epoch 00008: val_loss improved from 0.88700 to 0.86473, saving model to model/checkpoint/vis_imagenet_6_class_2D_CNN_custom_ch_32_DO_050_DO_3_conv_checkpoint/008-0.8647.hdf5\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.8796 - acc: 0.6887 - val_loss: 0.8647 - val_acc: 0.6865\n",
      "Epoch 9/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.8597 - acc: 0.6905\n",
      "Epoch 00009: val_loss improved from 0.86473 to 0.86054, saving model to model/checkpoint/vis_imagenet_6_class_2D_CNN_custom_ch_32_DO_050_DO_3_conv_checkpoint/009-0.8605.hdf5\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.8606 - acc: 0.6902 - val_loss: 0.8605 - val_acc: 0.6923\n",
      "Epoch 10/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.8400 - acc: 0.7010\n",
      "Epoch 00010: val_loss improved from 0.86054 to 0.84742, saving model to model/checkpoint/vis_imagenet_6_class_2D_CNN_custom_ch_32_DO_050_DO_3_conv_checkpoint/010-0.8474.hdf5\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.8401 - acc: 0.7009 - val_loss: 0.8474 - val_acc: 0.6936\n",
      "Epoch 11/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.8196 - acc: 0.7130\n",
      "Epoch 00011: val_loss improved from 0.84742 to 0.82264, saving model to model/checkpoint/vis_imagenet_6_class_2D_CNN_custom_ch_32_DO_050_DO_3_conv_checkpoint/011-0.8226.hdf5\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.8198 - acc: 0.7132 - val_loss: 0.8226 - val_acc: 0.7103\n",
      "Epoch 12/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.7888 - acc: 0.7211\n",
      "Epoch 00012: val_loss did not improve from 0.82264\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.7894 - acc: 0.7205 - val_loss: 0.8332 - val_acc: 0.6987\n",
      "Epoch 13/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.7768 - acc: 0.7324\n",
      "Epoch 00013: val_loss improved from 0.82264 to 0.81871, saving model to model/checkpoint/vis_imagenet_6_class_2D_CNN_custom_ch_32_DO_050_DO_3_conv_checkpoint/013-0.8187.hdf5\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.7770 - acc: 0.7323 - val_loss: 0.8187 - val_acc: 0.7160\n",
      "Epoch 14/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.7673 - acc: 0.7273\n",
      "Epoch 00014: val_loss improved from 0.81871 to 0.80724, saving model to model/checkpoint/vis_imagenet_6_class_2D_CNN_custom_ch_32_DO_050_DO_3_conv_checkpoint/014-0.8072.hdf5\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.7679 - acc: 0.7269 - val_loss: 0.8072 - val_acc: 0.7096\n",
      "Epoch 15/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.7314 - acc: 0.7399\n",
      "Epoch 00015: val_loss improved from 0.80724 to 0.79861, saving model to model/checkpoint/vis_imagenet_6_class_2D_CNN_custom_ch_32_DO_050_DO_3_conv_checkpoint/015-0.7986.hdf5\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.7318 - acc: 0.7402 - val_loss: 0.7986 - val_acc: 0.7122\n",
      "Epoch 16/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.7291 - acc: 0.7444\n",
      "Epoch 00016: val_loss improved from 0.79861 to 0.79527, saving model to model/checkpoint/vis_imagenet_6_class_2D_CNN_custom_ch_32_DO_050_DO_3_conv_checkpoint/016-0.7953.hdf5\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.7295 - acc: 0.7440 - val_loss: 0.7953 - val_acc: 0.7308\n",
      "Epoch 17/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.6933 - acc: 0.7581\n",
      "Epoch 00017: val_loss improved from 0.79527 to 0.76433, saving model to model/checkpoint/vis_imagenet_6_class_2D_CNN_custom_ch_32_DO_050_DO_3_conv_checkpoint/017-0.7643.hdf5\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.6939 - acc: 0.7579 - val_loss: 0.7643 - val_acc: 0.7231\n",
      "Epoch 18/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.6963 - acc: 0.7611\n",
      "Epoch 00018: val_loss improved from 0.76433 to 0.74293, saving model to model/checkpoint/vis_imagenet_6_class_2D_CNN_custom_ch_32_DO_050_DO_3_conv_checkpoint/018-0.7429.hdf5\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.6959 - acc: 0.7611 - val_loss: 0.7429 - val_acc: 0.7327\n",
      "Epoch 19/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.6781 - acc: 0.7648\n",
      "Epoch 00019: val_loss did not improve from 0.74293\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.6790 - acc: 0.7645 - val_loss: 0.7552 - val_acc: 0.7288\n",
      "Epoch 20/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.6576 - acc: 0.7727\n",
      "Epoch 00020: val_loss did not improve from 0.74293\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.6578 - acc: 0.7726 - val_loss: 0.7584 - val_acc: 0.7365\n",
      "Epoch 21/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.6475 - acc: 0.7753\n",
      "Epoch 00021: val_loss improved from 0.74293 to 0.72020, saving model to model/checkpoint/vis_imagenet_6_class_2D_CNN_custom_ch_32_DO_050_DO_3_conv_checkpoint/021-0.7202.hdf5\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.6473 - acc: 0.7754 - val_loss: 0.7202 - val_acc: 0.7397\n",
      "Epoch 22/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.6383 - acc: 0.7750\n",
      "Epoch 00022: val_loss did not improve from 0.72020\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.6379 - acc: 0.7754 - val_loss: 0.7403 - val_acc: 0.7417\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.6286 - acc: 0.7817\n",
      "Epoch 00023: val_loss improved from 0.72020 to 0.71773, saving model to model/checkpoint/vis_imagenet_6_class_2D_CNN_custom_ch_32_DO_050_DO_3_conv_checkpoint/023-0.7177.hdf5\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.6289 - acc: 0.7814 - val_loss: 0.7177 - val_acc: 0.7378\n",
      "Epoch 24/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.6076 - acc: 0.7945\n",
      "Epoch 00024: val_loss improved from 0.71773 to 0.70447, saving model to model/checkpoint/vis_imagenet_6_class_2D_CNN_custom_ch_32_DO_050_DO_3_conv_checkpoint/024-0.7045.hdf5\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.6076 - acc: 0.7944 - val_loss: 0.7045 - val_acc: 0.7487\n",
      "Epoch 25/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.5887 - acc: 0.7935\n",
      "Epoch 00025: val_loss did not improve from 0.70447\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.5890 - acc: 0.7934 - val_loss: 0.7056 - val_acc: 0.7558\n",
      "Epoch 26/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.5825 - acc: 0.7935\n",
      "Epoch 00026: val_loss did not improve from 0.70447\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.5830 - acc: 0.7932 - val_loss: 0.7062 - val_acc: 0.7532\n",
      "Epoch 27/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.5600 - acc: 0.8089\n",
      "Epoch 00027: val_loss improved from 0.70447 to 0.69403, saving model to model/checkpoint/vis_imagenet_6_class_2D_CNN_custom_ch_32_DO_050_DO_3_conv_checkpoint/027-0.6940.hdf5\n",
      "4680/4680 [==============================] - 16s 3ms/sample - loss: 0.5601 - acc: 0.8090 - val_loss: 0.6940 - val_acc: 0.7551\n",
      "Epoch 28/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.5470 - acc: 0.8112\n",
      "Epoch 00028: val_loss improved from 0.69403 to 0.67121, saving model to model/checkpoint/vis_imagenet_6_class_2D_CNN_custom_ch_32_DO_050_DO_3_conv_checkpoint/028-0.6712.hdf5\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.5488 - acc: 0.8107 - val_loss: 0.6712 - val_acc: 0.7577\n",
      "Epoch 29/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.5702 - acc: 0.8001\n",
      "Epoch 00029: val_loss did not improve from 0.67121\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.5703 - acc: 0.8002 - val_loss: 0.7035 - val_acc: 0.7487\n",
      "Epoch 30/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.5217 - acc: 0.8204\n",
      "Epoch 00030: val_loss did not improve from 0.67121\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.5222 - acc: 0.8201 - val_loss: 0.6734 - val_acc: 0.7667\n",
      "Epoch 31/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.5238 - acc: 0.8238\n",
      "Epoch 00031: val_loss did not improve from 0.67121\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.5233 - acc: 0.8241 - val_loss: 0.6831 - val_acc: 0.7564\n",
      "Epoch 32/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.5175 - acc: 0.8213\n",
      "Epoch 00032: val_loss improved from 0.67121 to 0.65339, saving model to model/checkpoint/vis_imagenet_6_class_2D_CNN_custom_ch_32_DO_050_DO_3_conv_checkpoint/032-0.6534.hdf5\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.5176 - acc: 0.8212 - val_loss: 0.6534 - val_acc: 0.7731\n",
      "Epoch 33/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.5055 - acc: 0.8262\n",
      "Epoch 00033: val_loss improved from 0.65339 to 0.65087, saving model to model/checkpoint/vis_imagenet_6_class_2D_CNN_custom_ch_32_DO_050_DO_3_conv_checkpoint/033-0.6509.hdf5\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.5065 - acc: 0.8259 - val_loss: 0.6509 - val_acc: 0.7660\n",
      "Epoch 34/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.4854 - acc: 0.8298\n",
      "Epoch 00034: val_loss did not improve from 0.65087\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.4870 - acc: 0.8293 - val_loss: 0.6511 - val_acc: 0.7686\n",
      "Epoch 35/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.4922 - acc: 0.8320\n",
      "Epoch 00035: val_loss did not improve from 0.65087\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.4918 - acc: 0.8321 - val_loss: 0.6755 - val_acc: 0.7590\n",
      "Epoch 36/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.4810 - acc: 0.8363\n",
      "Epoch 00036: val_loss improved from 0.65087 to 0.64281, saving model to model/checkpoint/vis_imagenet_6_class_2D_CNN_custom_ch_32_DO_050_DO_3_conv_checkpoint/036-0.6428.hdf5\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.4809 - acc: 0.8363 - val_loss: 0.6428 - val_acc: 0.7705\n",
      "Epoch 37/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.4502 - acc: 0.8474\n",
      "Epoch 00037: val_loss did not improve from 0.64281\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.4514 - acc: 0.8474 - val_loss: 0.6443 - val_acc: 0.7731\n",
      "Epoch 38/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.4468 - acc: 0.8497\n",
      "Epoch 00038: val_loss did not improve from 0.64281\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.4463 - acc: 0.8500 - val_loss: 0.6567 - val_acc: 0.7724\n",
      "Epoch 39/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.4507 - acc: 0.8472\n",
      "Epoch 00039: val_loss did not improve from 0.64281\n",
      "4680/4680 [==============================] - 16s 3ms/sample - loss: 0.4509 - acc: 0.8470 - val_loss: 0.6508 - val_acc: 0.7737\n",
      "Epoch 40/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.4488 - acc: 0.8461\n",
      "Epoch 00040: val_loss did not improve from 0.64281\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.4488 - acc: 0.8462 - val_loss: 0.6503 - val_acc: 0.7647\n",
      "Epoch 41/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.4197 - acc: 0.8564\n",
      "Epoch 00041: val_loss improved from 0.64281 to 0.63824, saving model to model/checkpoint/vis_imagenet_6_class_2D_CNN_custom_ch_32_DO_050_DO_3_conv_checkpoint/041-0.6382.hdf5\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.4196 - acc: 0.8564 - val_loss: 0.6382 - val_acc: 0.7801\n",
      "Epoch 42/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.4172 - acc: 0.8557\n",
      "Epoch 00042: val_loss improved from 0.63824 to 0.61453, saving model to model/checkpoint/vis_imagenet_6_class_2D_CNN_custom_ch_32_DO_050_DO_3_conv_checkpoint/042-0.6145.hdf5\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.4184 - acc: 0.8553 - val_loss: 0.6145 - val_acc: 0.7897\n",
      "Epoch 43/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.4235 - acc: 0.8583\n",
      "Epoch 00043: val_loss did not improve from 0.61453\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.4232 - acc: 0.8583 - val_loss: 0.6218 - val_acc: 0.7795\n",
      "Epoch 44/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.4016 - acc: 0.8632\n",
      "Epoch 00044: val_loss did not improve from 0.61453\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.4013 - acc: 0.8632 - val_loss: 0.6715 - val_acc: 0.7538\n",
      "Epoch 45/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.3956 - acc: 0.8654\n",
      "Epoch 00045: val_loss did not improve from 0.61453\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.3961 - acc: 0.8654 - val_loss: 0.6240 - val_acc: 0.7846\n",
      "Epoch 46/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.3959 - acc: 0.8660\n",
      "Epoch 00046: val_loss did not improve from 0.61453\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.3954 - acc: 0.8662 - val_loss: 0.6470 - val_acc: 0.7705\n",
      "Epoch 47/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.3742 - acc: 0.8716\n",
      "Epoch 00047: val_loss did not improve from 0.61453\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.3737 - acc: 0.8718 - val_loss: 0.6475 - val_acc: 0.7801\n",
      "Epoch 48/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.3650 - acc: 0.8744\n",
      "Epoch 00048: val_loss did not improve from 0.61453\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.3651 - acc: 0.8744 - val_loss: 0.6188 - val_acc: 0.7846\n",
      "Epoch 49/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.3671 - acc: 0.8765\n",
      "Epoch 00049: val_loss did not improve from 0.61453\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.3674 - acc: 0.8763 - val_loss: 0.6266 - val_acc: 0.7923\n",
      "Epoch 50/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.3582 - acc: 0.8735\n",
      "Epoch 00050: val_loss did not improve from 0.61453\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.3578 - acc: 0.8737 - val_loss: 0.6218 - val_acc: 0.7853\n",
      "Epoch 51/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.3452 - acc: 0.8861\n",
      "Epoch 00051: val_loss did not improve from 0.61453\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.3455 - acc: 0.8861 - val_loss: 0.6350 - val_acc: 0.7891\n",
      "Epoch 52/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.3433 - acc: 0.8868\n",
      "Epoch 00052: val_loss did not improve from 0.61453\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.3433 - acc: 0.8868 - val_loss: 0.6346 - val_acc: 0.7840\n",
      "Epoch 53/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.3248 - acc: 0.8898\n",
      "Epoch 00053: val_loss did not improve from 0.61453\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.3245 - acc: 0.8900 - val_loss: 0.6571 - val_acc: 0.7750\n",
      "Epoch 54/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.3275 - acc: 0.8846\n",
      "Epoch 00054: val_loss did not improve from 0.61453\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.3272 - acc: 0.8848 - val_loss: 0.6721 - val_acc: 0.7590\n",
      "Epoch 55/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.3340 - acc: 0.8853\n",
      "Epoch 00055: val_loss did not improve from 0.61453\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.3345 - acc: 0.8848 - val_loss: 0.6253 - val_acc: 0.7808\n",
      "Epoch 56/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.3214 - acc: 0.8823\n",
      "Epoch 00056: val_loss improved from 0.61453 to 0.60803, saving model to model/checkpoint/vis_imagenet_6_class_2D_CNN_custom_ch_32_DO_050_DO_3_conv_checkpoint/056-0.6080.hdf5\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.3216 - acc: 0.8821 - val_loss: 0.6080 - val_acc: 0.7859\n",
      "Epoch 57/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.3132 - acc: 0.8940\n",
      "Epoch 00057: val_loss did not improve from 0.60803\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.3135 - acc: 0.8940 - val_loss: 0.6150 - val_acc: 0.7936\n",
      "Epoch 58/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.2980 - acc: 0.8998\n",
      "Epoch 00058: val_loss did not improve from 0.60803\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.2981 - acc: 0.8998 - val_loss: 0.6556 - val_acc: 0.7833\n",
      "Epoch 59/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.2948 - acc: 0.8949\n",
      "Epoch 00059: val_loss did not improve from 0.60803\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.2947 - acc: 0.8949 - val_loss: 0.6274 - val_acc: 0.7865\n",
      "Epoch 60/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.2817 - acc: 0.8996\n",
      "Epoch 00060: val_loss improved from 0.60803 to 0.60637, saving model to model/checkpoint/vis_imagenet_6_class_2D_CNN_custom_ch_32_DO_050_DO_3_conv_checkpoint/060-0.6064.hdf5\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.2817 - acc: 0.8996 - val_loss: 0.6064 - val_acc: 0.7942\n",
      "Epoch 61/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.2883 - acc: 0.9020\n",
      "Epoch 00061: val_loss did not improve from 0.60637\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.2885 - acc: 0.9019 - val_loss: 0.6066 - val_acc: 0.7923\n",
      "Epoch 62/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.2822 - acc: 0.9039\n",
      "Epoch 00062: val_loss did not improve from 0.60637\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.2818 - acc: 0.9041 - val_loss: 0.6408 - val_acc: 0.7872\n",
      "Epoch 63/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.2679 - acc: 0.9082\n",
      "Epoch 00063: val_loss did not improve from 0.60637\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.2679 - acc: 0.9081 - val_loss: 0.6242 - val_acc: 0.7962\n",
      "Epoch 64/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.2670 - acc: 0.9067\n",
      "Epoch 00064: val_loss did not improve from 0.60637\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.2667 - acc: 0.9068 - val_loss: 0.6073 - val_acc: 0.8038\n",
      "Epoch 65/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.2642 - acc: 0.9071\n",
      "Epoch 00065: val_loss did not improve from 0.60637\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.2640 - acc: 0.9073 - val_loss: 0.6154 - val_acc: 0.7949\n",
      "Epoch 66/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.2571 - acc: 0.9142\n",
      "Epoch 00066: val_loss did not improve from 0.60637\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.2569 - acc: 0.9143 - val_loss: 0.6650 - val_acc: 0.7891\n",
      "Epoch 67/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.2462 - acc: 0.9148\n",
      "Epoch 00067: val_loss did not improve from 0.60637\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.2461 - acc: 0.9150 - val_loss: 0.6278 - val_acc: 0.7968\n",
      "Epoch 68/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.2362 - acc: 0.9212\n",
      "Epoch 00068: val_loss did not improve from 0.60637\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.2362 - acc: 0.9212 - val_loss: 0.6329 - val_acc: 0.7936\n",
      "Epoch 69/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.2356 - acc: 0.9174\n",
      "Epoch 00069: val_loss did not improve from 0.60637\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.2354 - acc: 0.9175 - val_loss: 0.6397 - val_acc: 0.7942\n",
      "Epoch 70/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.2401 - acc: 0.9195\n",
      "Epoch 00070: val_loss did not improve from 0.60637\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.2401 - acc: 0.9194 - val_loss: 0.6458 - val_acc: 0.8032\n",
      "Epoch 71/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.2317 - acc: 0.9225\n",
      "Epoch 00071: val_loss did not improve from 0.60637\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.2317 - acc: 0.9224 - val_loss: 0.6623 - val_acc: 0.8000\n",
      "Epoch 72/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.2350 - acc: 0.9199\n",
      "Epoch 00072: val_loss did not improve from 0.60637\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.2349 - acc: 0.9201 - val_loss: 0.6347 - val_acc: 0.8019\n",
      "Epoch 73/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.2209 - acc: 0.9227\n",
      "Epoch 00073: val_loss did not improve from 0.60637\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.2208 - acc: 0.9229 - val_loss: 0.6297 - val_acc: 0.7987\n",
      "Epoch 74/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.2106 - acc: 0.9287\n",
      "Epoch 00074: val_loss did not improve from 0.60637\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.2103 - acc: 0.9288 - val_loss: 0.6349 - val_acc: 0.8000\n",
      "Epoch 75/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.2077 - acc: 0.9279\n",
      "Epoch 00075: val_loss did not improve from 0.60637\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.2080 - acc: 0.9278 - val_loss: 0.6595 - val_acc: 0.7955\n",
      "Epoch 76/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.2260 - acc: 0.9214\n",
      "Epoch 00076: val_loss did not improve from 0.60637\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.2265 - acc: 0.9214 - val_loss: 0.6314 - val_acc: 0.8019\n",
      "Epoch 77/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.2088 - acc: 0.9283\n",
      "Epoch 00077: val_loss did not improve from 0.60637\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.2090 - acc: 0.9282 - val_loss: 0.6265 - val_acc: 0.8013\n",
      "Epoch 78/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.2084 - acc: 0.9300\n",
      "Epoch 00078: val_loss did not improve from 0.60637\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.2083 - acc: 0.9301 - val_loss: 0.6959 - val_acc: 0.7840\n",
      "Epoch 79/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.1949 - acc: 0.9336\n",
      "Epoch 00079: val_loss did not improve from 0.60637\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.1953 - acc: 0.9335 - val_loss: 0.6511 - val_acc: 0.8006\n",
      "Epoch 80/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.1963 - acc: 0.9321\n",
      "Epoch 00080: val_loss did not improve from 0.60637\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.1960 - acc: 0.9323 - val_loss: 0.6555 - val_acc: 0.8006\n",
      "Epoch 81/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.1887 - acc: 0.9345\n",
      "Epoch 00081: val_loss did not improve from 0.60637\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.1892 - acc: 0.9342 - val_loss: 0.6596 - val_acc: 0.7981\n",
      "Epoch 82/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.1872 - acc: 0.9332\n",
      "Epoch 00082: val_loss did not improve from 0.60637\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.1872 - acc: 0.9333 - val_loss: 0.6542 - val_acc: 0.8013\n",
      "Epoch 83/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.1780 - acc: 0.9371\n",
      "Epoch 00083: val_loss did not improve from 0.60637\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.1783 - acc: 0.9370 - val_loss: 0.6419 - val_acc: 0.8071\n",
      "Epoch 84/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.1768 - acc: 0.9399\n",
      "Epoch 00084: val_loss did not improve from 0.60637\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.1771 - acc: 0.9397 - val_loss: 0.6911 - val_acc: 0.7981\n",
      "Epoch 85/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.1763 - acc: 0.9371\n",
      "Epoch 00085: val_loss did not improve from 0.60637\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.1762 - acc: 0.9372 - val_loss: 0.6551 - val_acc: 0.8032\n",
      "Epoch 86/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.1696 - acc: 0.9420\n",
      "Epoch 00086: val_loss did not improve from 0.60637\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.1693 - acc: 0.9421 - val_loss: 0.7375 - val_acc: 0.7942\n",
      "Epoch 87/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.1632 - acc: 0.9448\n",
      "Epoch 00087: val_loss did not improve from 0.60637\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.1631 - acc: 0.9449 - val_loss: 0.6787 - val_acc: 0.8051\n",
      "Epoch 88/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.1650 - acc: 0.9418\n",
      "Epoch 00088: val_loss did not improve from 0.60637\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.1650 - acc: 0.9417 - val_loss: 0.6923 - val_acc: 0.8026\n",
      "Epoch 89/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.1780 - acc: 0.9379\n",
      "Epoch 00089: val_loss did not improve from 0.60637\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.1779 - acc: 0.9380 - val_loss: 0.6899 - val_acc: 0.7949\n",
      "Epoch 90/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.1643 - acc: 0.9392\n",
      "Epoch 00090: val_loss did not improve from 0.60637\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.1646 - acc: 0.9391 - val_loss: 0.6665 - val_acc: 0.8083\n",
      "Epoch 91/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.1645 - acc: 0.9429\n",
      "Epoch 00091: val_loss did not improve from 0.60637\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.1644 - acc: 0.9429 - val_loss: 0.6526 - val_acc: 0.8122\n",
      "Epoch 92/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.1420 - acc: 0.9542\n",
      "Epoch 00092: val_loss did not improve from 0.60637\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.1420 - acc: 0.9543 - val_loss: 0.6610 - val_acc: 0.8109\n",
      "Epoch 93/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.1450 - acc: 0.9527\n",
      "Epoch 00093: val_loss did not improve from 0.60637\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.1451 - acc: 0.9526 - val_loss: 0.6895 - val_acc: 0.8103\n",
      "Epoch 94/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.1385 - acc: 0.9488\n",
      "Epoch 00094: val_loss did not improve from 0.60637\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.1384 - acc: 0.9489 - val_loss: 0.6858 - val_acc: 0.8051\n",
      "Epoch 95/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.1362 - acc: 0.9548\n",
      "Epoch 00095: val_loss did not improve from 0.60637\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.1366 - acc: 0.9545 - val_loss: 0.6768 - val_acc: 0.8045\n",
      "Epoch 96/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.1428 - acc: 0.9518\n",
      "Epoch 00096: val_loss did not improve from 0.60637\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.1431 - acc: 0.9517 - val_loss: 0.7038 - val_acc: 0.7981\n",
      "Epoch 97/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.1342 - acc: 0.9529\n",
      "Epoch 00097: val_loss did not improve from 0.60637\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.1344 - acc: 0.9526 - val_loss: 0.7016 - val_acc: 0.8051\n",
      "Epoch 98/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.1364 - acc: 0.9523\n",
      "Epoch 00098: val_loss did not improve from 0.60637\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.1371 - acc: 0.9519 - val_loss: 0.6751 - val_acc: 0.8077\n",
      "Epoch 99/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.1239 - acc: 0.9595\n",
      "Epoch 00099: val_loss did not improve from 0.60637\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.1246 - acc: 0.9594 - val_loss: 0.6753 - val_acc: 0.8096\n",
      "Epoch 100/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.1346 - acc: 0.9529\n",
      "Epoch 00100: val_loss did not improve from 0.60637\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.1354 - acc: 0.9526 - val_loss: 0.6887 - val_acc: 0.8051\n",
      "Epoch 101/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.1537 - acc: 0.9484\n",
      "Epoch 00101: val_loss did not improve from 0.60637\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.1536 - acc: 0.9485 - val_loss: 0.6918 - val_acc: 0.8019\n",
      "Epoch 102/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.1266 - acc: 0.9589\n",
      "Epoch 00102: val_loss did not improve from 0.60637\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.1264 - acc: 0.9590 - val_loss: 0.7337 - val_acc: 0.7981\n",
      "Epoch 103/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.1159 - acc: 0.9604\n",
      "Epoch 00103: val_loss did not improve from 0.60637\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.1157 - acc: 0.9605 - val_loss: 0.7276 - val_acc: 0.8109\n",
      "Epoch 104/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.1269 - acc: 0.9574\n",
      "Epoch 00104: val_loss did not improve from 0.60637\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.1268 - acc: 0.9575 - val_loss: 0.7368 - val_acc: 0.7923\n",
      "Epoch 105/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.1164 - acc: 0.9589\n",
      "Epoch 00105: val_loss did not improve from 0.60637\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.1166 - acc: 0.9588 - val_loss: 0.7154 - val_acc: 0.8064\n",
      "Epoch 106/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.1255 - acc: 0.9551\n",
      "Epoch 00106: val_loss did not improve from 0.60637\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.1254 - acc: 0.9551 - val_loss: 0.7098 - val_acc: 0.8045\n",
      "Epoch 107/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.1050 - acc: 0.9681\n",
      "Epoch 00107: val_loss did not improve from 0.60637\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.1049 - acc: 0.9682 - val_loss: 0.7216 - val_acc: 0.8038\n",
      "Epoch 108/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.1092 - acc: 0.9617\n",
      "Epoch 00108: val_loss did not improve from 0.60637\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.1090 - acc: 0.9618 - val_loss: 0.6952 - val_acc: 0.8077\n",
      "Epoch 109/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.1119 - acc: 0.9613\n",
      "Epoch 00109: val_loss did not improve from 0.60637\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.1117 - acc: 0.9613 - val_loss: 0.7528 - val_acc: 0.7949\n",
      "Epoch 110/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.1166 - acc: 0.9598\n",
      "Epoch 00110: val_loss did not improve from 0.60637\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.1164 - acc: 0.9598 - val_loss: 0.7145 - val_acc: 0.8032\n",
      "\n",
      "vis_imagenet_6_class_2D_CNN_custom_ch_32_DO_050_DO_3_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1560/1560 [==============================] - 3s 2ms/sample - loss: 0.5667 - acc: 0.8077\n",
      "Loss: 0.5667258001290835 Accuracy: 0.8076923\n",
      "\n",
      "Train on 4680 samples, validate on 1560 samples\n",
      "Epoch 1/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 1.7137 - acc: 0.2631\n",
      "Epoch 00001: val_loss improved from inf to 1.49720, saving model to model/checkpoint/vis_imagenet_6_class_2D_CNN_custom_ch_32_DO_050_DO_4_conv_checkpoint/001-1.4972.hdf5\n",
      "4680/4680 [==============================] - 17s 4ms/sample - loss: 1.7135 - acc: 0.2630 - val_loss: 1.4972 - val_acc: 0.4269\n",
      "Epoch 2/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 1.4553 - acc: 0.4028\n",
      "Epoch 00002: val_loss improved from 1.49720 to 1.35111, saving model to model/checkpoint/vis_imagenet_6_class_2D_CNN_custom_ch_32_DO_050_DO_4_conv_checkpoint/002-1.3511.hdf5\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 1.4556 - acc: 0.4028 - val_loss: 1.3511 - val_acc: 0.4840\n",
      "Epoch 3/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 1.3202 - acc: 0.4767\n",
      "Epoch 00003: val_loss improved from 1.35111 to 1.22923, saving model to model/checkpoint/vis_imagenet_6_class_2D_CNN_custom_ch_32_DO_050_DO_4_conv_checkpoint/003-1.2292.hdf5\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 1.3205 - acc: 0.4761 - val_loss: 1.2292 - val_acc: 0.5346\n",
      "Epoch 4/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 1.1971 - acc: 0.5377\n",
      "Epoch 00004: val_loss improved from 1.22923 to 1.09907, saving model to model/checkpoint/vis_imagenet_6_class_2D_CNN_custom_ch_32_DO_050_DO_4_conv_checkpoint/004-1.0991.hdf5\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 1.1978 - acc: 0.5368 - val_loss: 1.0991 - val_acc: 0.6019\n",
      "Epoch 5/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 1.1348 - acc: 0.5672\n",
      "Epoch 00005: val_loss improved from 1.09907 to 1.04431, saving model to model/checkpoint/vis_imagenet_6_class_2D_CNN_custom_ch_32_DO_050_DO_4_conv_checkpoint/005-1.0443.hdf5\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 1.1344 - acc: 0.5671 - val_loss: 1.0443 - val_acc: 0.6000\n",
      "Epoch 6/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 1.0848 - acc: 0.5955\n",
      "Epoch 00006: val_loss improved from 1.04431 to 1.00332, saving model to model/checkpoint/vis_imagenet_6_class_2D_CNN_custom_ch_32_DO_050_DO_4_conv_checkpoint/006-1.0033.hdf5\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 1.0842 - acc: 0.5957 - val_loss: 1.0033 - val_acc: 0.6192\n",
      "Epoch 7/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 1.0451 - acc: 0.6038\n",
      "Epoch 00007: val_loss improved from 1.00332 to 0.94542, saving model to model/checkpoint/vis_imagenet_6_class_2D_CNN_custom_ch_32_DO_050_DO_4_conv_checkpoint/007-0.9454.hdf5\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 1.0453 - acc: 0.6038 - val_loss: 0.9454 - val_acc: 0.6487\n",
      "Epoch 8/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.9952 - acc: 0.6344\n",
      "Epoch 00008: val_loss did not improve from 0.94542\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.9947 - acc: 0.6348 - val_loss: 0.9593 - val_acc: 0.6346\n",
      "Epoch 9/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.9727 - acc: 0.6462\n",
      "Epoch 00009: val_loss improved from 0.94542 to 0.89310, saving model to model/checkpoint/vis_imagenet_6_class_2D_CNN_custom_ch_32_DO_050_DO_4_conv_checkpoint/009-0.8931.hdf5\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.9732 - acc: 0.6455 - val_loss: 0.8931 - val_acc: 0.6667\n",
      "Epoch 10/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.9352 - acc: 0.6586\n",
      "Epoch 00010: val_loss improved from 0.89310 to 0.86362, saving model to model/checkpoint/vis_imagenet_6_class_2D_CNN_custom_ch_32_DO_050_DO_4_conv_checkpoint/010-0.8636.hdf5\n",
      "4680/4680 [==============================] - 16s 3ms/sample - loss: 0.9352 - acc: 0.6585 - val_loss: 0.8636 - val_acc: 0.6808\n",
      "Epoch 11/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.9074 - acc: 0.6691\n",
      "Epoch 00011: val_loss improved from 0.86362 to 0.84780, saving model to model/checkpoint/vis_imagenet_6_class_2D_CNN_custom_ch_32_DO_050_DO_4_conv_checkpoint/011-0.8478.hdf5\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.9076 - acc: 0.6688 - val_loss: 0.8478 - val_acc: 0.6853\n",
      "Epoch 12/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.8791 - acc: 0.6935\n",
      "Epoch 00012: val_loss improved from 0.84780 to 0.82584, saving model to model/checkpoint/vis_imagenet_6_class_2D_CNN_custom_ch_32_DO_050_DO_4_conv_checkpoint/012-0.8258.hdf5\n",
      "4680/4680 [==============================] - 16s 3ms/sample - loss: 0.8787 - acc: 0.6936 - val_loss: 0.8258 - val_acc: 0.6968\n",
      "Epoch 13/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.8559 - acc: 0.6943\n",
      "Epoch 00013: val_loss improved from 0.82584 to 0.81334, saving model to model/checkpoint/vis_imagenet_6_class_2D_CNN_custom_ch_32_DO_050_DO_4_conv_checkpoint/013-0.8133.hdf5\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.8551 - acc: 0.6949 - val_loss: 0.8133 - val_acc: 0.7103\n",
      "Epoch 14/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.8159 - acc: 0.7108\n",
      "Epoch 00014: val_loss improved from 0.81334 to 0.79837, saving model to model/checkpoint/vis_imagenet_6_class_2D_CNN_custom_ch_32_DO_050_DO_4_conv_checkpoint/014-0.7984.hdf5\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.8155 - acc: 0.7111 - val_loss: 0.7984 - val_acc: 0.7109\n",
      "Epoch 15/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.8128 - acc: 0.7183\n",
      "Epoch 00015: val_loss did not improve from 0.79837\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.8126 - acc: 0.7182 - val_loss: 0.8044 - val_acc: 0.7019\n",
      "Epoch 16/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.7704 - acc: 0.7382\n",
      "Epoch 00016: val_loss improved from 0.79837 to 0.78665, saving model to model/checkpoint/vis_imagenet_6_class_2D_CNN_custom_ch_32_DO_050_DO_4_conv_checkpoint/016-0.7866.hdf5\n",
      "4680/4680 [==============================] - 16s 3ms/sample - loss: 0.7721 - acc: 0.7376 - val_loss: 0.7866 - val_acc: 0.7090\n",
      "Epoch 17/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.7963 - acc: 0.7226\n",
      "Epoch 00017: val_loss improved from 0.78665 to 0.78402, saving model to model/checkpoint/vis_imagenet_6_class_2D_CNN_custom_ch_32_DO_050_DO_4_conv_checkpoint/017-0.7840.hdf5\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.7962 - acc: 0.7226 - val_loss: 0.7840 - val_acc: 0.7186\n",
      "Epoch 18/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.7475 - acc: 0.7318\n",
      "Epoch 00018: val_loss improved from 0.78402 to 0.74733, saving model to model/checkpoint/vis_imagenet_6_class_2D_CNN_custom_ch_32_DO_050_DO_4_conv_checkpoint/018-0.7473.hdf5\n",
      "4680/4680 [==============================] - 16s 3ms/sample - loss: 0.7481 - acc: 0.7316 - val_loss: 0.7473 - val_acc: 0.7346\n",
      "Epoch 19/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.7458 - acc: 0.7414\n",
      "Epoch 00019: val_loss did not improve from 0.74733\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.7467 - acc: 0.7410 - val_loss: 0.7924 - val_acc: 0.7103\n",
      "Epoch 20/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.7149 - acc: 0.7451\n",
      "Epoch 00020: val_loss improved from 0.74733 to 0.70938, saving model to model/checkpoint/vis_imagenet_6_class_2D_CNN_custom_ch_32_DO_050_DO_4_conv_checkpoint/020-0.7094.hdf5\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.7151 - acc: 0.7447 - val_loss: 0.7094 - val_acc: 0.7429\n",
      "Epoch 21/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.6900 - acc: 0.7579\n",
      "Epoch 00021: val_loss did not improve from 0.70938\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.6899 - acc: 0.7577 - val_loss: 0.7206 - val_acc: 0.7513\n",
      "Epoch 22/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.6621 - acc: 0.7661\n",
      "Epoch 00022: val_loss improved from 0.70938 to 0.68715, saving model to model/checkpoint/vis_imagenet_6_class_2D_CNN_custom_ch_32_DO_050_DO_4_conv_checkpoint/022-0.6872.hdf5\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.6621 - acc: 0.7658 - val_loss: 0.6872 - val_acc: 0.7468\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.6658 - acc: 0.7637\n",
      "Epoch 00023: val_loss did not improve from 0.68715\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.6656 - acc: 0.7637 - val_loss: 0.7003 - val_acc: 0.7455\n",
      "Epoch 24/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.6339 - acc: 0.7789\n",
      "Epoch 00024: val_loss did not improve from 0.68715\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.6337 - acc: 0.7791 - val_loss: 0.7276 - val_acc: 0.7282\n",
      "Epoch 25/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.6381 - acc: 0.7772\n",
      "Epoch 00025: val_loss improved from 0.68715 to 0.68479, saving model to model/checkpoint/vis_imagenet_6_class_2D_CNN_custom_ch_32_DO_050_DO_4_conv_checkpoint/025-0.6848.hdf5\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.6382 - acc: 0.7771 - val_loss: 0.6848 - val_acc: 0.7571\n",
      "Epoch 26/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.6015 - acc: 0.7881\n",
      "Epoch 00026: val_loss improved from 0.68479 to 0.65432, saving model to model/checkpoint/vis_imagenet_6_class_2D_CNN_custom_ch_32_DO_050_DO_4_conv_checkpoint/026-0.6543.hdf5\n",
      "4680/4680 [==============================] - 16s 3ms/sample - loss: 0.6044 - acc: 0.7872 - val_loss: 0.6543 - val_acc: 0.7596\n",
      "Epoch 27/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.6050 - acc: 0.7838\n",
      "Epoch 00027: val_loss did not improve from 0.65432\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.6043 - acc: 0.7840 - val_loss: 0.6719 - val_acc: 0.7641\n",
      "Epoch 28/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.5860 - acc: 0.7909\n",
      "Epoch 00028: val_loss did not improve from 0.65432\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.5855 - acc: 0.7912 - val_loss: 0.7099 - val_acc: 0.7378\n",
      "Epoch 29/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.5618 - acc: 0.7960\n",
      "Epoch 00029: val_loss did not improve from 0.65432\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.5616 - acc: 0.7959 - val_loss: 0.6720 - val_acc: 0.7391\n",
      "Epoch 30/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.5615 - acc: 0.8046\n",
      "Epoch 00030: val_loss improved from 0.65432 to 0.61742, saving model to model/checkpoint/vis_imagenet_6_class_2D_CNN_custom_ch_32_DO_050_DO_4_conv_checkpoint/030-0.6174.hdf5\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.5617 - acc: 0.8045 - val_loss: 0.6174 - val_acc: 0.7878\n",
      "Epoch 31/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.5314 - acc: 0.8161\n",
      "Epoch 00031: val_loss improved from 0.61742 to 0.60218, saving model to model/checkpoint/vis_imagenet_6_class_2D_CNN_custom_ch_32_DO_050_DO_4_conv_checkpoint/031-0.6022.hdf5\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.5309 - acc: 0.8162 - val_loss: 0.6022 - val_acc: 0.7878\n",
      "Epoch 32/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.5254 - acc: 0.8121\n",
      "Epoch 00032: val_loss improved from 0.60218 to 0.59812, saving model to model/checkpoint/vis_imagenet_6_class_2D_CNN_custom_ch_32_DO_050_DO_4_conv_checkpoint/032-0.5981.hdf5\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.5250 - acc: 0.8122 - val_loss: 0.5981 - val_acc: 0.7885\n",
      "Epoch 33/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.5290 - acc: 0.8106\n",
      "Epoch 00033: val_loss did not improve from 0.59812\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.5283 - acc: 0.8109 - val_loss: 0.6266 - val_acc: 0.7712\n",
      "Epoch 34/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.5083 - acc: 0.8208\n",
      "Epoch 00034: val_loss did not improve from 0.59812\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.5080 - acc: 0.8207 - val_loss: 0.6017 - val_acc: 0.7801\n",
      "Epoch 35/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.4934 - acc: 0.8266\n",
      "Epoch 00035: val_loss did not improve from 0.59812\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.4934 - acc: 0.8267 - val_loss: 0.5989 - val_acc: 0.7885\n",
      "Epoch 36/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.4762 - acc: 0.8307\n",
      "Epoch 00036: val_loss improved from 0.59812 to 0.58358, saving model to model/checkpoint/vis_imagenet_6_class_2D_CNN_custom_ch_32_DO_050_DO_4_conv_checkpoint/036-0.5836.hdf5\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.4768 - acc: 0.8306 - val_loss: 0.5836 - val_acc: 0.7987\n",
      "Epoch 37/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.4685 - acc: 0.8386\n",
      "Epoch 00037: val_loss improved from 0.58358 to 0.57811, saving model to model/checkpoint/vis_imagenet_6_class_2D_CNN_custom_ch_32_DO_050_DO_4_conv_checkpoint/037-0.5781.hdf5\n",
      "4680/4680 [==============================] - 16s 3ms/sample - loss: 0.4688 - acc: 0.8382 - val_loss: 0.5781 - val_acc: 0.7929\n",
      "Epoch 38/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.4595 - acc: 0.8324\n",
      "Epoch 00038: val_loss did not improve from 0.57811\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.4593 - acc: 0.8327 - val_loss: 0.6059 - val_acc: 0.7821\n",
      "Epoch 39/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.4503 - acc: 0.8388\n",
      "Epoch 00039: val_loss did not improve from 0.57811\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.4509 - acc: 0.8385 - val_loss: 0.6436 - val_acc: 0.7609\n",
      "Epoch 40/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.4468 - acc: 0.8401\n",
      "Epoch 00040: val_loss improved from 0.57811 to 0.57698, saving model to model/checkpoint/vis_imagenet_6_class_2D_CNN_custom_ch_32_DO_050_DO_4_conv_checkpoint/040-0.5770.hdf5\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.4471 - acc: 0.8397 - val_loss: 0.5770 - val_acc: 0.7833\n",
      "Epoch 41/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.4622 - acc: 0.8405\n",
      "Epoch 00041: val_loss improved from 0.57698 to 0.57462, saving model to model/checkpoint/vis_imagenet_6_class_2D_CNN_custom_ch_32_DO_050_DO_4_conv_checkpoint/041-0.5746.hdf5\n",
      "4680/4680 [==============================] - 16s 3ms/sample - loss: 0.4620 - acc: 0.8404 - val_loss: 0.5746 - val_acc: 0.7872\n",
      "Epoch 42/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.4404 - acc: 0.8461\n",
      "Epoch 00042: val_loss improved from 0.57462 to 0.55585, saving model to model/checkpoint/vis_imagenet_6_class_2D_CNN_custom_ch_32_DO_050_DO_4_conv_checkpoint/042-0.5559.hdf5\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.4402 - acc: 0.8462 - val_loss: 0.5559 - val_acc: 0.8051\n",
      "Epoch 43/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.4207 - acc: 0.8465\n",
      "Epoch 00043: val_loss did not improve from 0.55585\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.4211 - acc: 0.8466 - val_loss: 0.5746 - val_acc: 0.7872\n",
      "Epoch 44/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.4145 - acc: 0.8551\n",
      "Epoch 00044: val_loss did not improve from 0.55585\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.4146 - acc: 0.8549 - val_loss: 0.5725 - val_acc: 0.7897\n",
      "Epoch 45/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.4158 - acc: 0.8566\n",
      "Epoch 00045: val_loss did not improve from 0.55585\n",
      "4680/4680 [==============================] - 16s 3ms/sample - loss: 0.4160 - acc: 0.8566 - val_loss: 0.5574 - val_acc: 0.8000\n",
      "Epoch 46/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.3974 - acc: 0.8611\n",
      "Epoch 00046: val_loss did not improve from 0.55585\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.3969 - acc: 0.8613 - val_loss: 0.5743 - val_acc: 0.7923\n",
      "Epoch 47/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.4023 - acc: 0.8555\n",
      "Epoch 00047: val_loss improved from 0.55585 to 0.53060, saving model to model/checkpoint/vis_imagenet_6_class_2D_CNN_custom_ch_32_DO_050_DO_4_conv_checkpoint/047-0.5306.hdf5\n",
      "4680/4680 [==============================] - 16s 3ms/sample - loss: 0.4017 - acc: 0.8558 - val_loss: 0.5306 - val_acc: 0.8179\n",
      "Epoch 48/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.3825 - acc: 0.8694\n",
      "Epoch 00048: val_loss did not improve from 0.53060\n",
      "4680/4680 [==============================] - 16s 3ms/sample - loss: 0.3836 - acc: 0.8692 - val_loss: 0.5474 - val_acc: 0.8026\n",
      "Epoch 49/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.3678 - acc: 0.8696\n",
      "Epoch 00049: val_loss did not improve from 0.53060\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.3676 - acc: 0.8697 - val_loss: 0.5510 - val_acc: 0.7994\n",
      "Epoch 50/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.3790 - acc: 0.8643\n",
      "Epoch 00050: val_loss did not improve from 0.53060\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.3785 - acc: 0.8645 - val_loss: 0.5699 - val_acc: 0.7929\n",
      "Epoch 51/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.3550 - acc: 0.8771\n",
      "Epoch 00051: val_loss did not improve from 0.53060\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.3545 - acc: 0.8774 - val_loss: 0.5536 - val_acc: 0.8103\n",
      "Epoch 52/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.3492 - acc: 0.8774\n",
      "Epoch 00052: val_loss did not improve from 0.53060\n",
      "4680/4680 [==============================] - 16s 3ms/sample - loss: 0.3494 - acc: 0.8774 - val_loss: 0.5336 - val_acc: 0.8199\n",
      "Epoch 53/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.3581 - acc: 0.8793\n",
      "Epoch 00053: val_loss did not improve from 0.53060\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.3591 - acc: 0.8791 - val_loss: 0.5736 - val_acc: 0.8032\n",
      "Epoch 54/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.3504 - acc: 0.8765\n",
      "Epoch 00054: val_loss improved from 0.53060 to 0.52487, saving model to model/checkpoint/vis_imagenet_6_class_2D_CNN_custom_ch_32_DO_050_DO_4_conv_checkpoint/054-0.5249.hdf5\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.3502 - acc: 0.8767 - val_loss: 0.5249 - val_acc: 0.8173\n",
      "Epoch 55/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.3288 - acc: 0.8900\n",
      "Epoch 00055: val_loss did not improve from 0.52487\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.3289 - acc: 0.8900 - val_loss: 0.5785 - val_acc: 0.7994\n",
      "Epoch 56/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.3373 - acc: 0.8808\n",
      "Epoch 00056: val_loss improved from 0.52487 to 0.52169, saving model to model/checkpoint/vis_imagenet_6_class_2D_CNN_custom_ch_32_DO_050_DO_4_conv_checkpoint/056-0.5217.hdf5\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.3371 - acc: 0.8810 - val_loss: 0.5217 - val_acc: 0.8186\n",
      "Epoch 57/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.3173 - acc: 0.8930\n",
      "Epoch 00057: val_loss did not improve from 0.52169\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.3172 - acc: 0.8929 - val_loss: 0.5639 - val_acc: 0.8096\n",
      "Epoch 58/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.3208 - acc: 0.8870\n",
      "Epoch 00058: val_loss did not improve from 0.52169\n",
      "4680/4680 [==============================] - 16s 3ms/sample - loss: 0.3208 - acc: 0.8870 - val_loss: 0.5841 - val_acc: 0.8128\n",
      "Epoch 59/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.3213 - acc: 0.8848\n",
      "Epoch 00059: val_loss did not improve from 0.52169\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.3210 - acc: 0.8850 - val_loss: 0.5366 - val_acc: 0.8090\n",
      "Epoch 60/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.3365 - acc: 0.8765\n",
      "Epoch 00060: val_loss improved from 0.52169 to 0.51402, saving model to model/checkpoint/vis_imagenet_6_class_2D_CNN_custom_ch_32_DO_050_DO_4_conv_checkpoint/060-0.5140.hdf5\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.3366 - acc: 0.8765 - val_loss: 0.5140 - val_acc: 0.8218\n",
      "Epoch 61/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.3040 - acc: 0.8962\n",
      "Epoch 00061: val_loss did not improve from 0.51402\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.3046 - acc: 0.8959 - val_loss: 0.5644 - val_acc: 0.7968\n",
      "Epoch 62/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.3058 - acc: 0.8911\n",
      "Epoch 00062: val_loss did not improve from 0.51402\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.3054 - acc: 0.8912 - val_loss: 0.5390 - val_acc: 0.8218\n",
      "Epoch 63/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.3055 - acc: 0.8923\n",
      "Epoch 00063: val_loss did not improve from 0.51402\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.3050 - acc: 0.8925 - val_loss: 0.5253 - val_acc: 0.8276\n",
      "Epoch 64/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.2740 - acc: 0.9003\n",
      "Epoch 00064: val_loss did not improve from 0.51402\n",
      "4680/4680 [==============================] - 16s 3ms/sample - loss: 0.2738 - acc: 0.9004 - val_loss: 0.5595 - val_acc: 0.8026\n",
      "Epoch 65/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.2936 - acc: 0.8949\n",
      "Epoch 00065: val_loss did not improve from 0.51402\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.2935 - acc: 0.8949 - val_loss: 0.5458 - val_acc: 0.8103\n",
      "Epoch 66/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.2957 - acc: 0.8943\n",
      "Epoch 00066: val_loss did not improve from 0.51402\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.2958 - acc: 0.8942 - val_loss: 0.5573 - val_acc: 0.8083\n",
      "Epoch 67/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.2795 - acc: 0.9020\n",
      "Epoch 00067: val_loss did not improve from 0.51402\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.2795 - acc: 0.9017 - val_loss: 0.5230 - val_acc: 0.8192\n",
      "Epoch 68/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.2580 - acc: 0.9116\n",
      "Epoch 00068: val_loss did not improve from 0.51402\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.2578 - acc: 0.9118 - val_loss: 0.5448 - val_acc: 0.8141\n",
      "Epoch 69/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.2612 - acc: 0.9075\n",
      "Epoch 00069: val_loss did not improve from 0.51402\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.2611 - acc: 0.9077 - val_loss: 0.5146 - val_acc: 0.8231\n",
      "Epoch 70/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.2528 - acc: 0.9137\n",
      "Epoch 00070: val_loss did not improve from 0.51402\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.2527 - acc: 0.9139 - val_loss: 0.5281 - val_acc: 0.8224\n",
      "Epoch 71/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.2507 - acc: 0.9082\n",
      "Epoch 00071: val_loss did not improve from 0.51402\n",
      "4680/4680 [==============================] - 16s 3ms/sample - loss: 0.2506 - acc: 0.9083 - val_loss: 0.5548 - val_acc: 0.8212\n",
      "Epoch 72/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.2410 - acc: 0.9157\n",
      "Epoch 00072: val_loss did not improve from 0.51402\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.2411 - acc: 0.9156 - val_loss: 0.5390 - val_acc: 0.8135\n",
      "Epoch 73/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.2584 - acc: 0.9107\n",
      "Epoch 00073: val_loss did not improve from 0.51402\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.2581 - acc: 0.9109 - val_loss: 0.5181 - val_acc: 0.8288\n",
      "Epoch 74/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.2272 - acc: 0.9176\n",
      "Epoch 00074: val_loss did not improve from 0.51402\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.2271 - acc: 0.9175 - val_loss: 0.5170 - val_acc: 0.8333\n",
      "Epoch 75/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.2346 - acc: 0.9161\n",
      "Epoch 00075: val_loss did not improve from 0.51402\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.2343 - acc: 0.9162 - val_loss: 0.5546 - val_acc: 0.8237\n",
      "Epoch 76/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.2394 - acc: 0.9159\n",
      "Epoch 00076: val_loss did not improve from 0.51402\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.2391 - acc: 0.9160 - val_loss: 0.5632 - val_acc: 0.8173\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.2359 - acc: 0.9161\n",
      "Epoch 00077: val_loss did not improve from 0.51402\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.2355 - acc: 0.9162 - val_loss: 0.6077 - val_acc: 0.8090\n",
      "Epoch 78/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.2302 - acc: 0.9165\n",
      "Epoch 00078: val_loss did not improve from 0.51402\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.2300 - acc: 0.9167 - val_loss: 0.5528 - val_acc: 0.8160\n",
      "Epoch 79/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.2236 - acc: 0.9214\n",
      "Epoch 00079: val_loss did not improve from 0.51402\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.2240 - acc: 0.9212 - val_loss: 0.5547 - val_acc: 0.8141\n",
      "Epoch 80/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.2414 - acc: 0.9159\n",
      "Epoch 00080: val_loss did not improve from 0.51402\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.2411 - acc: 0.9160 - val_loss: 0.5595 - val_acc: 0.8077\n",
      "Epoch 81/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.2004 - acc: 0.9272\n",
      "Epoch 00081: val_loss did not improve from 0.51402\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.2009 - acc: 0.9269 - val_loss: 0.5311 - val_acc: 0.8288\n",
      "Epoch 82/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.2088 - acc: 0.9332\n",
      "Epoch 00082: val_loss did not improve from 0.51402\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.2087 - acc: 0.9333 - val_loss: 0.5480 - val_acc: 0.8135\n",
      "Epoch 83/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.2051 - acc: 0.9289\n",
      "Epoch 00083: val_loss did not improve from 0.51402\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.2051 - acc: 0.9288 - val_loss: 0.5709 - val_acc: 0.8288\n",
      "Epoch 84/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.2124 - acc: 0.9270\n",
      "Epoch 00084: val_loss did not improve from 0.51402\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.2121 - acc: 0.9271 - val_loss: 0.5280 - val_acc: 0.8256\n",
      "Epoch 85/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.1946 - acc: 0.9315\n",
      "Epoch 00085: val_loss did not improve from 0.51402\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.1943 - acc: 0.9316 - val_loss: 0.5328 - val_acc: 0.8308\n",
      "Epoch 86/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.1886 - acc: 0.9358\n",
      "Epoch 00086: val_loss did not improve from 0.51402\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.1883 - acc: 0.9359 - val_loss: 0.5462 - val_acc: 0.8256\n",
      "Epoch 87/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.1938 - acc: 0.9300\n",
      "Epoch 00087: val_loss did not improve from 0.51402\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.1938 - acc: 0.9301 - val_loss: 0.5279 - val_acc: 0.8308\n",
      "Epoch 88/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.1805 - acc: 0.9369\n",
      "Epoch 00088: val_loss did not improve from 0.51402\n",
      "4680/4680 [==============================] - 16s 3ms/sample - loss: 0.1802 - acc: 0.9370 - val_loss: 0.5227 - val_acc: 0.8314\n",
      "Epoch 89/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.1840 - acc: 0.9379\n",
      "Epoch 00089: val_loss did not improve from 0.51402\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.1838 - acc: 0.9380 - val_loss: 0.5303 - val_acc: 0.8391\n",
      "Epoch 90/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.1670 - acc: 0.9411\n",
      "Epoch 00090: val_loss did not improve from 0.51402\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.1668 - acc: 0.9412 - val_loss: 0.5955 - val_acc: 0.8237\n",
      "Epoch 91/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.1911 - acc: 0.9330\n",
      "Epoch 00091: val_loss did not improve from 0.51402\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.1911 - acc: 0.9331 - val_loss: 0.5948 - val_acc: 0.8058\n",
      "Epoch 92/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.1674 - acc: 0.9420\n",
      "Epoch 00092: val_loss did not improve from 0.51402\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.1674 - acc: 0.9421 - val_loss: 0.5556 - val_acc: 0.8263\n",
      "Epoch 93/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.1802 - acc: 0.9311\n",
      "Epoch 00093: val_loss did not improve from 0.51402\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.1806 - acc: 0.9306 - val_loss: 0.5814 - val_acc: 0.8160\n",
      "Epoch 94/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.1832 - acc: 0.9341\n",
      "Epoch 00094: val_loss did not improve from 0.51402\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.1829 - acc: 0.9342 - val_loss: 0.5626 - val_acc: 0.8269\n",
      "Epoch 95/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.1596 - acc: 0.9392\n",
      "Epoch 00095: val_loss did not improve from 0.51402\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.1601 - acc: 0.9391 - val_loss: 0.5640 - val_acc: 0.8199\n",
      "Epoch 96/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.1980 - acc: 0.9319\n",
      "Epoch 00096: val_loss did not improve from 0.51402\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.1979 - acc: 0.9321 - val_loss: 0.5316 - val_acc: 0.8385\n",
      "Epoch 97/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.1476 - acc: 0.9510\n",
      "Epoch 00097: val_loss did not improve from 0.51402\n",
      "4680/4680 [==============================] - 16s 3ms/sample - loss: 0.1474 - acc: 0.9511 - val_loss: 0.5471 - val_acc: 0.8295\n",
      "Epoch 98/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.1609 - acc: 0.9435\n",
      "Epoch 00098: val_loss did not improve from 0.51402\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.1607 - acc: 0.9436 - val_loss: 0.5750 - val_acc: 0.8250\n",
      "Epoch 99/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.1460 - acc: 0.9506\n",
      "Epoch 00099: val_loss did not improve from 0.51402\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.1460 - acc: 0.9504 - val_loss: 0.6625 - val_acc: 0.8167\n",
      "Epoch 100/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.1627 - acc: 0.9399\n",
      "Epoch 00100: val_loss did not improve from 0.51402\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.1629 - acc: 0.9397 - val_loss: 0.5797 - val_acc: 0.8109\n",
      "Epoch 101/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.1476 - acc: 0.9495\n",
      "Epoch 00101: val_loss did not improve from 0.51402\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.1480 - acc: 0.9494 - val_loss: 0.5908 - val_acc: 0.8282\n",
      "Epoch 102/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.1582 - acc: 0.9473\n",
      "Epoch 00102: val_loss did not improve from 0.51402\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.1581 - acc: 0.9474 - val_loss: 0.5373 - val_acc: 0.8327\n",
      "Epoch 103/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.1408 - acc: 0.9521\n",
      "Epoch 00103: val_loss did not improve from 0.51402\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.1407 - acc: 0.9521 - val_loss: 0.5542 - val_acc: 0.8391\n",
      "Epoch 104/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.1427 - acc: 0.9536\n",
      "Epoch 00104: val_loss did not improve from 0.51402\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.1426 - acc: 0.9536 - val_loss: 0.5482 - val_acc: 0.8282\n",
      "Epoch 105/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.1484 - acc: 0.9454\n",
      "Epoch 00105: val_loss did not improve from 0.51402\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.1483 - acc: 0.9455 - val_loss: 0.5502 - val_acc: 0.8353\n",
      "Epoch 106/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.1253 - acc: 0.9587\n",
      "Epoch 00106: val_loss did not improve from 0.51402\n",
      "4680/4680 [==============================] - 16s 3ms/sample - loss: 0.1257 - acc: 0.9585 - val_loss: 0.5756 - val_acc: 0.8250\n",
      "Epoch 107/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.1537 - acc: 0.9471\n",
      "Epoch 00107: val_loss did not improve from 0.51402\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.1535 - acc: 0.9472 - val_loss: 0.5680 - val_acc: 0.8256\n",
      "Epoch 108/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.1192 - acc: 0.9606\n",
      "Epoch 00108: val_loss did not improve from 0.51402\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.1191 - acc: 0.9607 - val_loss: 0.5756 - val_acc: 0.8295\n",
      "Epoch 109/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.1278 - acc: 0.9546\n",
      "Epoch 00109: val_loss did not improve from 0.51402\n",
      "4680/4680 [==============================] - 16s 3ms/sample - loss: 0.1276 - acc: 0.9547 - val_loss: 0.5939 - val_acc: 0.8224\n",
      "Epoch 110/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.1317 - acc: 0.9563\n",
      "Epoch 00110: val_loss did not improve from 0.51402\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 0.1323 - acc: 0.9562 - val_loss: 0.6039 - val_acc: 0.8333\n",
      "\n",
      "vis_imagenet_6_class_2D_CNN_custom_ch_32_DO_050_DO_4_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1560/1560 [==============================] - 3s 2ms/sample - loss: 0.5140 - acc: 0.8218\n",
      "Loss: 0.5140190430176563 Accuracy: 0.82179487\n",
      "\n",
      "Train on 4680 samples, validate on 1560 samples\n",
      "Epoch 1/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 1.7005 - acc: 0.2802\n",
      "Epoch 00001: val_loss improved from inf to 1.45787, saving model to model/checkpoint/vis_imagenet_6_class_2D_CNN_custom_ch_32_DO_050_DO_5_conv_checkpoint/001-1.4579.hdf5\n",
      "4680/4680 [==============================] - 17s 4ms/sample - loss: 1.7012 - acc: 0.2799 - val_loss: 1.4579 - val_acc: 0.4468\n",
      "Epoch 2/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 1.3769 - acc: 0.4416\n",
      "Epoch 00002: val_loss improved from 1.45787 to 1.21967, saving model to model/checkpoint/vis_imagenet_6_class_2D_CNN_custom_ch_32_DO_050_DO_5_conv_checkpoint/002-1.2197.hdf5\n",
      "4680/4680 [==============================] - 16s 3ms/sample - loss: 1.3774 - acc: 0.4415 - val_loss: 1.2197 - val_acc: 0.5269\n",
      "Epoch 3/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 1.2440 - acc: 0.5156\n",
      "Epoch 00003: val_loss improved from 1.21967 to 1.17405, saving model to model/checkpoint/vis_imagenet_6_class_2D_CNN_custom_ch_32_DO_050_DO_5_conv_checkpoint/003-1.1740.hdf5\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 1.2435 - acc: 0.5160 - val_loss: 1.1740 - val_acc: 0.5301\n",
      "Epoch 4/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 1.1598 - acc: 0.5484\n",
      "Epoch 00004: val_loss improved from 1.17405 to 1.04237, saving model to model/checkpoint/vis_imagenet_6_class_2D_CNN_custom_ch_32_DO_050_DO_5_conv_checkpoint/004-1.0424.hdf5\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 1.1597 - acc: 0.5487 - val_loss: 1.0424 - val_acc: 0.5955\n",
      "Epoch 5/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 1.0821 - acc: 0.5927\n",
      "Epoch 00005: val_loss improved from 1.04237 to 0.98117, saving model to model/checkpoint/vis_imagenet_6_class_2D_CNN_custom_ch_32_DO_050_DO_5_conv_checkpoint/005-0.9812.hdf5\n",
      "4680/4680 [==============================] - 15s 3ms/sample - loss: 1.0820 - acc: 0.5927 - val_loss: 0.9812 - val_acc: 0.6160\n",
      "Epoch 6/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 1.0233 - acc: 0.6182\n",
      "Epoch 00006: val_loss improved from 0.98117 to 0.96274, saving model to model/checkpoint/vis_imagenet_6_class_2D_CNN_custom_ch_32_DO_050_DO_5_conv_checkpoint/006-0.9627.hdf5\n",
      "4680/4680 [==============================] - 16s 3ms/sample - loss: 1.0220 - acc: 0.6188 - val_loss: 0.9627 - val_acc: 0.6282\n",
      "Epoch 7/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.9698 - acc: 0.6475\n",
      "Epoch 00007: val_loss improved from 0.96274 to 0.88404, saving model to model/checkpoint/vis_imagenet_6_class_2D_CNN_custom_ch_32_DO_050_DO_5_conv_checkpoint/007-0.8840.hdf5\n",
      "4680/4680 [==============================] - 16s 3ms/sample - loss: 0.9693 - acc: 0.6476 - val_loss: 0.8840 - val_acc: 0.6744\n",
      "Epoch 8/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.9039 - acc: 0.6710\n",
      "Epoch 00008: val_loss did not improve from 0.88404\n",
      "4680/4680 [==============================] - 16s 3ms/sample - loss: 0.9035 - acc: 0.6714 - val_loss: 0.8904 - val_acc: 0.6724\n",
      "Epoch 9/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.8821 - acc: 0.6802\n",
      "Epoch 00009: val_loss did not improve from 0.88404\n",
      "4680/4680 [==============================] - 16s 3ms/sample - loss: 0.8821 - acc: 0.6803 - val_loss: 0.8972 - val_acc: 0.6776\n",
      "Epoch 10/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.8559 - acc: 0.6965\n",
      "Epoch 00010: val_loss improved from 0.88404 to 0.84658, saving model to model/checkpoint/vis_imagenet_6_class_2D_CNN_custom_ch_32_DO_050_DO_5_conv_checkpoint/010-0.8466.hdf5\n",
      "4680/4680 [==============================] - 16s 3ms/sample - loss: 0.8563 - acc: 0.6964 - val_loss: 0.8466 - val_acc: 0.6942\n",
      "Epoch 11/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.8304 - acc: 0.7014\n",
      "Epoch 00011: val_loss improved from 0.84658 to 0.79446, saving model to model/checkpoint/vis_imagenet_6_class_2D_CNN_custom_ch_32_DO_050_DO_5_conv_checkpoint/011-0.7945.hdf5\n",
      "4680/4680 [==============================] - 16s 3ms/sample - loss: 0.8304 - acc: 0.7013 - val_loss: 0.7945 - val_acc: 0.7103\n",
      "Epoch 12/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.7978 - acc: 0.7175\n",
      "Epoch 00012: val_loss did not improve from 0.79446\n",
      "4680/4680 [==============================] - 16s 3ms/sample - loss: 0.7976 - acc: 0.7175 - val_loss: 0.8226 - val_acc: 0.6974\n",
      "Epoch 13/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.7774 - acc: 0.7269\n",
      "Epoch 00013: val_loss improved from 0.79446 to 0.76212, saving model to model/checkpoint/vis_imagenet_6_class_2D_CNN_custom_ch_32_DO_050_DO_5_conv_checkpoint/013-0.7621.hdf5\n",
      "4680/4680 [==============================] - 16s 3ms/sample - loss: 0.7775 - acc: 0.7269 - val_loss: 0.7621 - val_acc: 0.7231\n",
      "Epoch 14/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.7461 - acc: 0.7399\n",
      "Epoch 00014: val_loss did not improve from 0.76212\n",
      "4680/4680 [==============================] - 16s 3ms/sample - loss: 0.7460 - acc: 0.7402 - val_loss: 0.7723 - val_acc: 0.7250\n",
      "Epoch 15/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.7046 - acc: 0.7521\n",
      "Epoch 00015: val_loss did not improve from 0.76212\n",
      "4680/4680 [==============================] - 16s 3ms/sample - loss: 0.7041 - acc: 0.7524 - val_loss: 0.8145 - val_acc: 0.6987\n",
      "Epoch 16/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.7085 - acc: 0.7459\n",
      "Epoch 00016: val_loss improved from 0.76212 to 0.73274, saving model to model/checkpoint/vis_imagenet_6_class_2D_CNN_custom_ch_32_DO_050_DO_5_conv_checkpoint/016-0.7327.hdf5\n",
      "4680/4680 [==============================] - 16s 3ms/sample - loss: 0.7088 - acc: 0.7459 - val_loss: 0.7327 - val_acc: 0.7353\n",
      "Epoch 17/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.6682 - acc: 0.7639\n",
      "Epoch 00017: val_loss improved from 0.73274 to 0.71587, saving model to model/checkpoint/vis_imagenet_6_class_2D_CNN_custom_ch_32_DO_050_DO_5_conv_checkpoint/017-0.7159.hdf5\n",
      "4680/4680 [==============================] - 16s 3ms/sample - loss: 0.6689 - acc: 0.7632 - val_loss: 0.7159 - val_acc: 0.7365\n",
      "Epoch 18/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.6453 - acc: 0.7718\n",
      "Epoch 00018: val_loss did not improve from 0.71587\n",
      "4680/4680 [==============================] - 16s 3ms/sample - loss: 0.6457 - acc: 0.7718 - val_loss: 0.7867 - val_acc: 0.7103\n",
      "Epoch 19/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.6406 - acc: 0.7757\n",
      "Epoch 00019: val_loss did not improve from 0.71587\n",
      "4680/4680 [==============================] - 16s 3ms/sample - loss: 0.6398 - acc: 0.7761 - val_loss: 0.8135 - val_acc: 0.7032\n",
      "Epoch 20/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.6258 - acc: 0.7746\n",
      "Epoch 00020: val_loss improved from 0.71587 to 0.66653, saving model to model/checkpoint/vis_imagenet_6_class_2D_CNN_custom_ch_32_DO_050_DO_5_conv_checkpoint/020-0.6665.hdf5\n",
      "4680/4680 [==============================] - 16s 3ms/sample - loss: 0.6252 - acc: 0.7750 - val_loss: 0.6665 - val_acc: 0.7667\n",
      "Epoch 21/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.5930 - acc: 0.7937\n",
      "Epoch 00021: val_loss did not improve from 0.66653\n",
      "4680/4680 [==============================] - 16s 3ms/sample - loss: 0.5925 - acc: 0.7938 - val_loss: 0.7001 - val_acc: 0.7571\n",
      "Epoch 22/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.5860 - acc: 0.7962\n",
      "Epoch 00022: val_loss did not improve from 0.66653\n",
      "4680/4680 [==============================] - 16s 3ms/sample - loss: 0.5857 - acc: 0.7964 - val_loss: 0.6991 - val_acc: 0.7603\n",
      "Epoch 23/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.5788 - acc: 0.8016\n",
      "Epoch 00023: val_loss improved from 0.66653 to 0.66439, saving model to model/checkpoint/vis_imagenet_6_class_2D_CNN_custom_ch_32_DO_050_DO_5_conv_checkpoint/023-0.6644.hdf5\n",
      "4680/4680 [==============================] - 16s 3ms/sample - loss: 0.5782 - acc: 0.8019 - val_loss: 0.6644 - val_acc: 0.7615\n",
      "Epoch 24/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.5365 - acc: 0.8142\n",
      "Epoch 00024: val_loss improved from 0.66439 to 0.64089, saving model to model/checkpoint/vis_imagenet_6_class_2D_CNN_custom_ch_32_DO_050_DO_5_conv_checkpoint/024-0.6409.hdf5\n",
      "4680/4680 [==============================] - 16s 3ms/sample - loss: 0.5368 - acc: 0.8141 - val_loss: 0.6409 - val_acc: 0.7660\n",
      "Epoch 25/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.5247 - acc: 0.8166\n",
      "Epoch 00025: val_loss did not improve from 0.64089\n",
      "4680/4680 [==============================] - 16s 3ms/sample - loss: 0.5243 - acc: 0.8167 - val_loss: 0.6898 - val_acc: 0.7468\n",
      "Epoch 26/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.5075 - acc: 0.8206\n",
      "Epoch 00026: val_loss improved from 0.64089 to 0.61154, saving model to model/checkpoint/vis_imagenet_6_class_2D_CNN_custom_ch_32_DO_050_DO_5_conv_checkpoint/026-0.6115.hdf5\n",
      "4680/4680 [==============================] - 16s 3ms/sample - loss: 0.5068 - acc: 0.8209 - val_loss: 0.6115 - val_acc: 0.7724\n",
      "Epoch 27/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.5063 - acc: 0.8213\n",
      "Epoch 00027: val_loss did not improve from 0.61154\n",
      "4680/4680 [==============================] - 16s 3ms/sample - loss: 0.5064 - acc: 0.8212 - val_loss: 0.6156 - val_acc: 0.7840\n",
      "Epoch 28/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.4857 - acc: 0.8266\n",
      "Epoch 00028: val_loss did not improve from 0.61154\n",
      "4680/4680 [==============================] - 16s 3ms/sample - loss: 0.4861 - acc: 0.8263 - val_loss: 0.6318 - val_acc: 0.7667\n",
      "Epoch 29/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.4680 - acc: 0.8358\n",
      "Epoch 00029: val_loss did not improve from 0.61154\n",
      "4680/4680 [==============================] - 16s 3ms/sample - loss: 0.4682 - acc: 0.8357 - val_loss: 0.6133 - val_acc: 0.7756\n",
      "Epoch 30/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.4620 - acc: 0.8369\n",
      "Epoch 00030: val_loss improved from 0.61154 to 0.59390, saving model to model/checkpoint/vis_imagenet_6_class_2D_CNN_custom_ch_32_DO_050_DO_5_conv_checkpoint/030-0.5939.hdf5\n",
      "4680/4680 [==============================] - 16s 3ms/sample - loss: 0.4618 - acc: 0.8370 - val_loss: 0.5939 - val_acc: 0.7885\n",
      "Epoch 31/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.4242 - acc: 0.8525\n",
      "Epoch 00031: val_loss improved from 0.59390 to 0.59193, saving model to model/checkpoint/vis_imagenet_6_class_2D_CNN_custom_ch_32_DO_050_DO_5_conv_checkpoint/031-0.5919.hdf5\n",
      "4680/4680 [==============================] - 16s 3ms/sample - loss: 0.4254 - acc: 0.8524 - val_loss: 0.5919 - val_acc: 0.7885\n",
      "Epoch 32/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.4257 - acc: 0.8504\n",
      "Epoch 00032: val_loss did not improve from 0.59193\n",
      "4680/4680 [==============================] - 16s 3ms/sample - loss: 0.4254 - acc: 0.8504 - val_loss: 0.5927 - val_acc: 0.7891\n",
      "Epoch 33/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.3993 - acc: 0.8652\n",
      "Epoch 00033: val_loss improved from 0.59193 to 0.57410, saving model to model/checkpoint/vis_imagenet_6_class_2D_CNN_custom_ch_32_DO_050_DO_5_conv_checkpoint/033-0.5741.hdf5\n",
      "4680/4680 [==============================] - 16s 3ms/sample - loss: 0.3992 - acc: 0.8652 - val_loss: 0.5741 - val_acc: 0.7974\n",
      "Epoch 34/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.4071 - acc: 0.8555\n",
      "Epoch 00034: val_loss did not improve from 0.57410\n",
      "4680/4680 [==============================] - 17s 4ms/sample - loss: 0.4081 - acc: 0.8551 - val_loss: 0.6017 - val_acc: 0.7846\n",
      "Epoch 35/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.3863 - acc: 0.8675\n",
      "Epoch 00035: val_loss did not improve from 0.57410\n",
      "4680/4680 [==============================] - 16s 3ms/sample - loss: 0.3860 - acc: 0.8677 - val_loss: 0.5895 - val_acc: 0.7897\n",
      "Epoch 36/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.3766 - acc: 0.8667\n",
      "Epoch 00036: val_loss did not improve from 0.57410\n",
      "4680/4680 [==============================] - 16s 3ms/sample - loss: 0.3762 - acc: 0.8669 - val_loss: 0.5914 - val_acc: 0.7910\n",
      "Epoch 37/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.3404 - acc: 0.8846\n",
      "Epoch 00037: val_loss did not improve from 0.57410\n",
      "4680/4680 [==============================] - 16s 3ms/sample - loss: 0.3410 - acc: 0.8842 - val_loss: 0.6675 - val_acc: 0.7647\n",
      "Epoch 38/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.3560 - acc: 0.8705\n",
      "Epoch 00038: val_loss improved from 0.57410 to 0.56973, saving model to model/checkpoint/vis_imagenet_6_class_2D_CNN_custom_ch_32_DO_050_DO_5_conv_checkpoint/038-0.5697.hdf5\n",
      "4680/4680 [==============================] - 16s 3ms/sample - loss: 0.3554 - acc: 0.8707 - val_loss: 0.5697 - val_acc: 0.8026\n",
      "Epoch 39/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.3312 - acc: 0.8868\n",
      "Epoch 00039: val_loss did not improve from 0.56973\n",
      "4680/4680 [==============================] - 16s 3ms/sample - loss: 0.3312 - acc: 0.8868 - val_loss: 0.6338 - val_acc: 0.7929\n",
      "Epoch 40/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.3252 - acc: 0.8840\n",
      "Epoch 00040: val_loss improved from 0.56973 to 0.56903, saving model to model/checkpoint/vis_imagenet_6_class_2D_CNN_custom_ch_32_DO_050_DO_5_conv_checkpoint/040-0.5690.hdf5\n",
      "4680/4680 [==============================] - 16s 3ms/sample - loss: 0.3249 - acc: 0.8842 - val_loss: 0.5690 - val_acc: 0.8032\n",
      "Epoch 41/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.3242 - acc: 0.8863\n",
      "Epoch 00041: val_loss did not improve from 0.56903\n",
      "4680/4680 [==============================] - 16s 3ms/sample - loss: 0.3240 - acc: 0.8863 - val_loss: 0.6250 - val_acc: 0.7833\n",
      "Epoch 42/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.3428 - acc: 0.8752\n",
      "Epoch 00042: val_loss improved from 0.56903 to 0.55390, saving model to model/checkpoint/vis_imagenet_6_class_2D_CNN_custom_ch_32_DO_050_DO_5_conv_checkpoint/042-0.5539.hdf5\n",
      "4680/4680 [==============================] - 16s 3ms/sample - loss: 0.3425 - acc: 0.8752 - val_loss: 0.5539 - val_acc: 0.8115\n",
      "Epoch 43/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.3034 - acc: 0.8932\n",
      "Epoch 00043: val_loss did not improve from 0.55390\n",
      "4680/4680 [==============================] - 16s 4ms/sample - loss: 0.3034 - acc: 0.8932 - val_loss: 0.5609 - val_acc: 0.8071\n",
      "Epoch 44/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.3074 - acc: 0.8908\n",
      "Epoch 00044: val_loss did not improve from 0.55390\n",
      "4680/4680 [==============================] - 16s 3ms/sample - loss: 0.3070 - acc: 0.8910 - val_loss: 0.6362 - val_acc: 0.7910\n",
      "Epoch 45/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.2591 - acc: 0.9127\n",
      "Epoch 00045: val_loss did not improve from 0.55390\n",
      "4680/4680 [==============================] - 16s 3ms/sample - loss: 0.2588 - acc: 0.9128 - val_loss: 0.5626 - val_acc: 0.8173\n",
      "Epoch 46/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.2591 - acc: 0.9075\n",
      "Epoch 00046: val_loss did not improve from 0.55390\n",
      "4680/4680 [==============================] - 16s 3ms/sample - loss: 0.2589 - acc: 0.9077 - val_loss: 0.6985 - val_acc: 0.7731\n",
      "Epoch 47/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.2568 - acc: 0.9125\n",
      "Epoch 00047: val_loss did not improve from 0.55390\n",
      "4680/4680 [==============================] - 16s 3ms/sample - loss: 0.2567 - acc: 0.9126 - val_loss: 0.6116 - val_acc: 0.8019\n",
      "Epoch 48/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.2556 - acc: 0.9082\n",
      "Epoch 00048: val_loss improved from 0.55390 to 0.54209, saving model to model/checkpoint/vis_imagenet_6_class_2D_CNN_custom_ch_32_DO_050_DO_5_conv_checkpoint/048-0.5421.hdf5\n",
      "4680/4680 [==============================] - 16s 3ms/sample - loss: 0.2554 - acc: 0.9083 - val_loss: 0.5421 - val_acc: 0.8212\n",
      "Epoch 49/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.2480 - acc: 0.9137\n",
      "Epoch 00049: val_loss did not improve from 0.54209\n",
      "4680/4680 [==============================] - 16s 3ms/sample - loss: 0.2478 - acc: 0.9137 - val_loss: 0.5862 - val_acc: 0.8077\n",
      "Epoch 50/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.2309 - acc: 0.9217\n",
      "Epoch 00050: val_loss did not improve from 0.54209\n",
      "4680/4680 [==============================] - 16s 3ms/sample - loss: 0.2316 - acc: 0.9214 - val_loss: 0.6656 - val_acc: 0.7821\n",
      "Epoch 51/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.2454 - acc: 0.9092\n",
      "Epoch 00051: val_loss did not improve from 0.54209\n",
      "4680/4680 [==============================] - 16s 3ms/sample - loss: 0.2474 - acc: 0.9088 - val_loss: 0.6043 - val_acc: 0.8038\n",
      "Epoch 52/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.2638 - acc: 0.9067\n",
      "Epoch 00052: val_loss did not improve from 0.54209\n",
      "4680/4680 [==============================] - 16s 3ms/sample - loss: 0.2634 - acc: 0.9068 - val_loss: 0.5496 - val_acc: 0.8327\n",
      "Epoch 53/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.2015 - acc: 0.9326\n",
      "Epoch 00053: val_loss did not improve from 0.54209\n",
      "4680/4680 [==============================] - 16s 3ms/sample - loss: 0.2016 - acc: 0.9325 - val_loss: 0.5981 - val_acc: 0.8141\n",
      "Epoch 54/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.2038 - acc: 0.9251\n",
      "Epoch 00054: val_loss did not improve from 0.54209\n",
      "4680/4680 [==============================] - 16s 3ms/sample - loss: 0.2040 - acc: 0.9250 - val_loss: 0.5873 - val_acc: 0.8096\n",
      "Epoch 55/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.1932 - acc: 0.9328\n",
      "Epoch 00055: val_loss did not improve from 0.54209\n",
      "4680/4680 [==============================] - 16s 3ms/sample - loss: 0.1934 - acc: 0.9327 - val_loss: 0.6086 - val_acc: 0.8109\n",
      "Epoch 56/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.2011 - acc: 0.9311\n",
      "Epoch 00056: val_loss did not improve from 0.54209\n",
      "4680/4680 [==============================] - 16s 3ms/sample - loss: 0.2008 - acc: 0.9312 - val_loss: 0.5913 - val_acc: 0.8167\n",
      "Epoch 57/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.1757 - acc: 0.9401\n",
      "Epoch 00057: val_loss did not improve from 0.54209\n",
      "4680/4680 [==============================] - 16s 3ms/sample - loss: 0.1760 - acc: 0.9397 - val_loss: 0.6093 - val_acc: 0.8090\n",
      "Epoch 58/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.1852 - acc: 0.9351\n",
      "Epoch 00058: val_loss did not improve from 0.54209\n",
      "4680/4680 [==============================] - 16s 3ms/sample - loss: 0.1852 - acc: 0.9350 - val_loss: 0.6022 - val_acc: 0.8122\n",
      "Epoch 59/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.1725 - acc: 0.9388\n",
      "Epoch 00059: val_loss did not improve from 0.54209\n",
      "4680/4680 [==============================] - 16s 3ms/sample - loss: 0.1724 - acc: 0.9389 - val_loss: 0.5900 - val_acc: 0.8147\n",
      "Epoch 60/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.1616 - acc: 0.9456\n",
      "Epoch 00060: val_loss did not improve from 0.54209\n",
      "4680/4680 [==============================] - 16s 3ms/sample - loss: 0.1614 - acc: 0.9457 - val_loss: 0.5980 - val_acc: 0.8192\n",
      "Epoch 61/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.1469 - acc: 0.9473\n",
      "Epoch 00061: val_loss did not improve from 0.54209\n",
      "4680/4680 [==============================] - 16s 3ms/sample - loss: 0.1470 - acc: 0.9472 - val_loss: 0.6605 - val_acc: 0.8096\n",
      "Epoch 62/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.1819 - acc: 0.9347\n",
      "Epoch 00062: val_loss did not improve from 0.54209\n",
      "4680/4680 [==============================] - 16s 3ms/sample - loss: 0.1816 - acc: 0.9348 - val_loss: 0.6126 - val_acc: 0.8135\n",
      "Epoch 63/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.1362 - acc: 0.9559\n",
      "Epoch 00063: val_loss did not improve from 0.54209\n",
      "4680/4680 [==============================] - 16s 3ms/sample - loss: 0.1360 - acc: 0.9560 - val_loss: 0.6876 - val_acc: 0.8038\n",
      "Epoch 64/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.1299 - acc: 0.9572\n",
      "Epoch 00064: val_loss did not improve from 0.54209\n",
      "4680/4680 [==============================] - 16s 3ms/sample - loss: 0.1302 - acc: 0.9568 - val_loss: 0.6164 - val_acc: 0.8186\n",
      "Epoch 65/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.1624 - acc: 0.9435\n",
      "Epoch 00065: val_loss did not improve from 0.54209\n",
      "4680/4680 [==============================] - 16s 3ms/sample - loss: 0.1621 - acc: 0.9436 - val_loss: 0.6271 - val_acc: 0.8205\n",
      "Epoch 66/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.1326 - acc: 0.9585\n",
      "Epoch 00066: val_loss did not improve from 0.54209\n",
      "4680/4680 [==============================] - 16s 3ms/sample - loss: 0.1324 - acc: 0.9585 - val_loss: 0.6176 - val_acc: 0.8218\n",
      "Epoch 67/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.1117 - acc: 0.9634\n",
      "Epoch 00067: val_loss did not improve from 0.54209\n",
      "4680/4680 [==============================] - 16s 3ms/sample - loss: 0.1118 - acc: 0.9635 - val_loss: 0.6065 - val_acc: 0.8308\n",
      "Epoch 68/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.1255 - acc: 0.9561\n",
      "Epoch 00068: val_loss did not improve from 0.54209\n",
      "4680/4680 [==============================] - 16s 3ms/sample - loss: 0.1257 - acc: 0.9560 - val_loss: 0.6159 - val_acc: 0.8160\n",
      "Epoch 69/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.1224 - acc: 0.9542\n",
      "Epoch 00069: val_loss did not improve from 0.54209\n",
      "4680/4680 [==============================] - 16s 3ms/sample - loss: 0.1226 - acc: 0.9541 - val_loss: 0.6102 - val_acc: 0.8212\n",
      "Epoch 70/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.1054 - acc: 0.9658\n",
      "Epoch 00070: val_loss did not improve from 0.54209\n",
      "4680/4680 [==============================] - 16s 3ms/sample - loss: 0.1055 - acc: 0.9656 - val_loss: 0.6333 - val_acc: 0.8244\n",
      "Epoch 71/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.1109 - acc: 0.9651\n",
      "Epoch 00071: val_loss did not improve from 0.54209\n",
      "4680/4680 [==============================] - 16s 3ms/sample - loss: 0.1109 - acc: 0.9652 - val_loss: 0.6544 - val_acc: 0.8250\n",
      "Epoch 72/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.1044 - acc: 0.9662\n",
      "Epoch 00072: val_loss did not improve from 0.54209\n",
      "4680/4680 [==============================] - 16s 3ms/sample - loss: 0.1044 - acc: 0.9660 - val_loss: 0.6718 - val_acc: 0.8199\n",
      "Epoch 73/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.1085 - acc: 0.9636\n",
      "Epoch 00073: val_loss did not improve from 0.54209\n",
      "4680/4680 [==============================] - 16s 3ms/sample - loss: 0.1088 - acc: 0.9635 - val_loss: 0.6821 - val_acc: 0.7974\n",
      "Epoch 74/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.1177 - acc: 0.9606\n",
      "Epoch 00074: val_loss did not improve from 0.54209\n",
      "4680/4680 [==============================] - 16s 3ms/sample - loss: 0.1182 - acc: 0.9605 - val_loss: 0.6301 - val_acc: 0.8244\n",
      "Epoch 75/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.1326 - acc: 0.9559\n",
      "Epoch 00075: val_loss did not improve from 0.54209\n",
      "4680/4680 [==============================] - 16s 3ms/sample - loss: 0.1325 - acc: 0.9560 - val_loss: 0.6712 - val_acc: 0.8096\n",
      "Epoch 76/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.0881 - acc: 0.9685\n",
      "Epoch 00076: val_loss did not improve from 0.54209\n",
      "4680/4680 [==============================] - 16s 3ms/sample - loss: 0.0880 - acc: 0.9686 - val_loss: 0.6929 - val_acc: 0.8141\n",
      "Epoch 77/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.0833 - acc: 0.9754\n",
      "Epoch 00077: val_loss did not improve from 0.54209\n",
      "4680/4680 [==============================] - 16s 3ms/sample - loss: 0.0832 - acc: 0.9754 - val_loss: 0.6954 - val_acc: 0.8231\n",
      "Epoch 78/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.0784 - acc: 0.9720\n",
      "Epoch 00078: val_loss did not improve from 0.54209\n",
      "4680/4680 [==============================] - 16s 3ms/sample - loss: 0.0784 - acc: 0.9720 - val_loss: 0.6722 - val_acc: 0.8237\n",
      "Epoch 79/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.0906 - acc: 0.9698\n",
      "Epoch 00079: val_loss did not improve from 0.54209\n",
      "4680/4680 [==============================] - 16s 3ms/sample - loss: 0.0904 - acc: 0.9699 - val_loss: 0.7011 - val_acc: 0.8263\n",
      "Epoch 80/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.0689 - acc: 0.9797\n",
      "Epoch 00080: val_loss did not improve from 0.54209\n",
      "4680/4680 [==============================] - 16s 3ms/sample - loss: 0.0689 - acc: 0.9797 - val_loss: 0.6743 - val_acc: 0.8314\n",
      "Epoch 81/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.0706 - acc: 0.9784\n",
      "Epoch 00081: val_loss did not improve from 0.54209\n",
      "4680/4680 [==============================] - 16s 3ms/sample - loss: 0.0705 - acc: 0.9784 - val_loss: 0.6776 - val_acc: 0.8250\n",
      "Epoch 82/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.0649 - acc: 0.9810\n",
      "Epoch 00082: val_loss did not improve from 0.54209\n",
      "4680/4680 [==============================] - 16s 3ms/sample - loss: 0.0649 - acc: 0.9810 - val_loss: 0.6953 - val_acc: 0.8128\n",
      "Epoch 83/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.0832 - acc: 0.9705\n",
      "Epoch 00083: val_loss did not improve from 0.54209\n",
      "4680/4680 [==============================] - 16s 3ms/sample - loss: 0.0831 - acc: 0.9705 - val_loss: 0.7243 - val_acc: 0.8205\n",
      "Epoch 84/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.0765 - acc: 0.9771\n",
      "Epoch 00084: val_loss did not improve from 0.54209\n",
      "4680/4680 [==============================] - 16s 3ms/sample - loss: 0.0764 - acc: 0.9771 - val_loss: 0.7401 - val_acc: 0.8122\n",
      "Epoch 85/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.0657 - acc: 0.9803\n",
      "Epoch 00085: val_loss did not improve from 0.54209\n",
      "4680/4680 [==============================] - 16s 3ms/sample - loss: 0.0656 - acc: 0.9803 - val_loss: 0.7528 - val_acc: 0.8192\n",
      "Epoch 86/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.0585 - acc: 0.9816\n",
      "Epoch 00086: val_loss did not improve from 0.54209\n",
      "4680/4680 [==============================] - 16s 3ms/sample - loss: 0.0585 - acc: 0.9816 - val_loss: 0.7128 - val_acc: 0.8179\n",
      "Epoch 87/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.0673 - acc: 0.9782\n",
      "Epoch 00087: val_loss did not improve from 0.54209\n",
      "4680/4680 [==============================] - 16s 3ms/sample - loss: 0.0673 - acc: 0.9782 - val_loss: 0.7460 - val_acc: 0.8269\n",
      "Epoch 88/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.0675 - acc: 0.9773\n",
      "Epoch 00088: val_loss did not improve from 0.54209\n",
      "4680/4680 [==============================] - 16s 3ms/sample - loss: 0.0674 - acc: 0.9774 - val_loss: 0.7310 - val_acc: 0.8237\n",
      "Epoch 89/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.0719 - acc: 0.9769\n",
      "Epoch 00089: val_loss did not improve from 0.54209\n",
      "4680/4680 [==============================] - 16s 3ms/sample - loss: 0.0718 - acc: 0.9769 - val_loss: 0.7420 - val_acc: 0.8218\n",
      "Epoch 90/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.0463 - acc: 0.9867\n",
      "Epoch 00090: val_loss did not improve from 0.54209\n",
      "4680/4680 [==============================] - 16s 3ms/sample - loss: 0.0464 - acc: 0.9868 - val_loss: 0.7219 - val_acc: 0.8333\n",
      "Epoch 91/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.0528 - acc: 0.9835\n",
      "Epoch 00091: val_loss did not improve from 0.54209\n",
      "4680/4680 [==============================] - 16s 3ms/sample - loss: 0.0528 - acc: 0.9835 - val_loss: 0.8354 - val_acc: 0.8019\n",
      "Epoch 92/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.0470 - acc: 0.9846\n",
      "Epoch 00092: val_loss did not improve from 0.54209\n",
      "4680/4680 [==============================] - 16s 3ms/sample - loss: 0.0470 - acc: 0.9846 - val_loss: 0.7817 - val_acc: 0.8160\n",
      "Epoch 93/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.0519 - acc: 0.9829\n",
      "Epoch 00093: val_loss did not improve from 0.54209\n",
      "4680/4680 [==============================] - 16s 3ms/sample - loss: 0.0519 - acc: 0.9829 - val_loss: 0.7398 - val_acc: 0.8224\n",
      "Epoch 94/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.0688 - acc: 0.9784\n",
      "Epoch 00094: val_loss did not improve from 0.54209\n",
      "4680/4680 [==============================] - 16s 3ms/sample - loss: 0.0687 - acc: 0.9784 - val_loss: 0.7600 - val_acc: 0.8135\n",
      "Epoch 95/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.0515 - acc: 0.9857\n",
      "Epoch 00095: val_loss did not improve from 0.54209\n",
      "4680/4680 [==============================] - 16s 3ms/sample - loss: 0.0514 - acc: 0.9857 - val_loss: 0.7467 - val_acc: 0.8231\n",
      "Epoch 96/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.0497 - acc: 0.9846\n",
      "Epoch 00096: val_loss did not improve from 0.54209\n",
      "4680/4680 [==============================] - 16s 3ms/sample - loss: 0.0509 - acc: 0.9844 - val_loss: 0.8004 - val_acc: 0.8179\n",
      "Epoch 97/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.1379 - acc: 0.9516\n",
      "Epoch 00097: val_loss did not improve from 0.54209\n",
      "4680/4680 [==============================] - 16s 3ms/sample - loss: 0.1377 - acc: 0.9517 - val_loss: 0.6583 - val_acc: 0.8224\n",
      "Epoch 98/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.0490 - acc: 0.9857\n",
      "Epoch 00098: val_loss did not improve from 0.54209\n",
      "4680/4680 [==============================] - 16s 3ms/sample - loss: 0.0493 - acc: 0.9855 - val_loss: 0.7477 - val_acc: 0.8212\n",
      "\n",
      "vis_imagenet_6_class_2D_CNN_custom_ch_32_DO_050_DO_5_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1560/1560 [==============================] - 3s 2ms/sample - loss: 0.5421 - acc: 0.8212\n",
      "Loss: 0.5420906183047173 Accuracy: 0.8211538\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(2, 6):\n",
    "    base = 'vis_imagenet_6_class_2D_CNN_custom_ch_32_DO_050_DO'\n",
    "    model_name = base+'_{}_conv'.format(i)\n",
    "    model = build_2d_cnn_custom_ch_32_DO(conv_num=i)\n",
    "#     model = multi_gpu_model(model, gpus=2)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=1e-4),\n",
    "          metrics=['accuracy'])\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    os.makedirs(model_path, exist_ok=True)\n",
    "    model_filename = model_path+'{epoch:03d}-{val_loss:.4f}.hdf5'\n",
    "    checkpointer = ModelCheckpoint(filepath = model_filename, monitor = \"val_loss\", \n",
    "                                   verbose=1, save_best_only=True)\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=50)\n",
    "    hist = model.fit(x_train, y_train, batch_size=64, epochs=500, \n",
    "                     validation_data=[x_val, y_val], shuffle=True, \n",
    "                     callbacks = [checkpointer, early_stopping])\n",
    "\n",
    "    print()\n",
    "    print(model_name, 'Model')\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "    ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
    "    ax.plot(hist.history['acc'], 'b', label='train acc')\n",
    "    ax.plot(hist.history['val_acc'], 'g', label='val acc')\n",
    "    ax.set_xlabel('epoch')\n",
    "    ax.set_ylabel('loss')\n",
    "    ax.legend(loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    png_path = 'visualization/learning_curve/'\n",
    "    filename = model_name+'.png'\n",
    "    os.makedirs(png_path, exist_ok=True)\n",
    "    fig.savefig(png_path+filename, transparent=True)\n",
    "\n",
    "    model.save(model_path+'000_last.hdf5')\n",
    "    del(model)\n",
    "\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    model_filename = model_path + sorted(os.listdir(model_path))[-1]\n",
    "    model = load_model(model_filename)\n",
    "    [loss, accuracy] = model.evaluate(x_test, y_test)\n",
    "    print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "    print()\n",
    "\n",
    "    del(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "vis_imagenet_6_class_2D_CNN_custom_ch_32_DO_050_DO_2_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         (None, 341, 341, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 341, 341, 32)      2432      \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 341, 341, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling (None, 114, 114, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 114, 114, 32)      25632     \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 114, 114, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling (None, 38, 38, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 46208)             0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 46208)             0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 6)                 277254    \n",
      "=================================================================\n",
      "Total params: 305,318\n",
      "Trainable params: 305,318\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "1560/1560 [==============================] - 3s 2ms/sample - loss: 0.7697 - acc: 0.7417\n",
      "Loss: 0.7696938050098908 Accuracy: 0.7416667\n",
      "\n",
      "vis_imagenet_6_class_2D_CNN_custom_ch_32_DO_050_DO_3_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_7 (InputLayer)         (None, 341, 341, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 341, 341, 32)      2432      \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 341, 341, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_17 (MaxPooling (None, 114, 114, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 114, 114, 32)      25632     \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 114, 114, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_18 (MaxPooling (None, 38, 38, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 38, 38, 64)        51264     \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 38, 38, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_19 (MaxPooling (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 10816)             0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 10816)             0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 6)                 64902     \n",
      "=================================================================\n",
      "Total params: 144,230\n",
      "Trainable params: 144,230\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "1560/1560 [==============================] - 3s 2ms/sample - loss: 0.5667 - acc: 0.8077\n",
      "Loss: 0.5667258001290835 Accuracy: 0.8076923\n",
      "\n",
      "vis_imagenet_6_class_2D_CNN_custom_ch_32_DO_050_DO_4_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_8 (InputLayer)         (None, 341, 341, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 341, 341, 32)      2432      \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 341, 341, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_20 (MaxPooling (None, 114, 114, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 114, 114, 32)      25632     \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 114, 114, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_21 (MaxPooling (None, 38, 38, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_22 (Conv2D)           (None, 38, 38, 64)        51264     \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 38, 38, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_22 (MaxPooling (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 13, 13, 64)        102464    \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_23 (MaxPooling (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 6)                 9606      \n",
      "=================================================================\n",
      "Total params: 191,398\n",
      "Trainable params: 191,398\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "1560/1560 [==============================] - 3s 2ms/sample - loss: 0.5140 - acc: 0.8218\n",
      "Loss: 0.5140190430176563 Accuracy: 0.82179487\n",
      "\n",
      "vis_imagenet_6_class_2D_CNN_custom_ch_32_DO_050_DO_5_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_9 (InputLayer)         (None, 341, 341, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_24 (Conv2D)           (None, 341, 341, 32)      2432      \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 341, 341, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_24 (MaxPooling (None, 114, 114, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_25 (Conv2D)           (None, 114, 114, 32)      25632     \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 114, 114, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_25 (MaxPooling (None, 38, 38, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_26 (Conv2D)           (None, 38, 38, 64)        51264     \n",
      "_________________________________________________________________\n",
      "activation_26 (Activation)   (None, 38, 38, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_26 (MaxPooling (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_27 (Conv2D)           (None, 13, 13, 64)        102464    \n",
      "_________________________________________________________________\n",
      "activation_27 (Activation)   (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_27 (MaxPooling (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_28 (Conv2D)           (None, 5, 5, 128)         204928    \n",
      "_________________________________________________________________\n",
      "activation_28 (Activation)   (None, 5, 5, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_28 (MaxPooling (None, 2, 2, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 6)                 3078      \n",
      "=================================================================\n",
      "Total params: 389,798\n",
      "Trainable params: 389,798\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1560/1560 [==============================] - 3s 2ms/sample - loss: 0.5421 - acc: 0.8212\n",
      "Loss: 0.5420906183047173 Accuracy: 0.8211538\n"
     ]
    }
   ],
   "source": [
    "log_dir = 'log'\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "base = 'vis_imagenet_6_class_2D_CNN_custom_ch_32_DO_050_DO'\n",
    "\n",
    "with open(path.join(log_dir, base), 'w') as log_file:\n",
    "    for i in range(2, 6):\n",
    "        model_name = base+'_{}_conv'.format(i)\n",
    "        print()\n",
    "        print(model_name, 'Model')\n",
    "        model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "        model_filename = model_path + sorted(os.listdir(model_path))[-1]\n",
    "\n",
    "        model = load_model(model_filename)\n",
    "        model.summary()\n",
    "\n",
    "        [loss, accuracy] = model.evaluate(x_test, y_test)\n",
    "        print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "\n",
    "        del(model)\n",
    "\n",
    "        log_file.write('\\t'.join([model_name, str(accuracy), str(loss)])+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "vis_imagenet_6_class_2D_CNN_custom_ch_32_DO_050_DO_2_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         (None, 341, 341, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 341, 341, 32)      2432      \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 341, 341, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling (None, 114, 114, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 114, 114, 32)      25632     \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 114, 114, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling (None, 38, 38, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 46208)             0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 46208)             0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 6)                 277254    \n",
      "=================================================================\n",
      "Total params: 305,318\n",
      "Trainable params: 305,318\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "1560/1560 [==============================] - 3s 2ms/sample - loss: 1.1575 - acc: 0.7218\n",
      "Loss: 1.157523118532621 Accuracy: 0.72179484\n",
      "\n",
      "vis_imagenet_6_class_2D_CNN_custom_ch_32_DO_050_DO_3_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_7 (InputLayer)         (None, 341, 341, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 341, 341, 32)      2432      \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 341, 341, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_17 (MaxPooling (None, 114, 114, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 114, 114, 32)      25632     \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 114, 114, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_18 (MaxPooling (None, 38, 38, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 38, 38, 64)        51264     \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 38, 38, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_19 (MaxPooling (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 10816)             0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 10816)             0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 6)                 64902     \n",
      "=================================================================\n",
      "Total params: 144,230\n",
      "Trainable params: 144,230\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "1560/1560 [==============================] - 3s 2ms/sample - loss: 0.7145 - acc: 0.8032\n",
      "Loss: 0.7144642979670793 Accuracy: 0.80320513\n",
      "\n",
      "vis_imagenet_6_class_2D_CNN_custom_ch_32_DO_050_DO_4_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_8 (InputLayer)         (None, 341, 341, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 341, 341, 32)      2432      \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 341, 341, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_20 (MaxPooling (None, 114, 114, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 114, 114, 32)      25632     \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 114, 114, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_21 (MaxPooling (None, 38, 38, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_22 (Conv2D)           (None, 38, 38, 64)        51264     \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 38, 38, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_22 (MaxPooling (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 13, 13, 64)        102464    \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_23 (MaxPooling (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 6)                 9606      \n",
      "=================================================================\n",
      "Total params: 191,398\n",
      "Trainable params: 191,398\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "1560/1560 [==============================] - 3s 2ms/sample - loss: 0.6039 - acc: 0.8333\n",
      "Loss: 0.6039208872960165 Accuracy: 0.8333333\n",
      "\n",
      "vis_imagenet_6_class_2D_CNN_custom_ch_32_DO_050_DO_5_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_9 (InputLayer)         (None, 341, 341, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_24 (Conv2D)           (None, 341, 341, 32)      2432      \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 341, 341, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_24 (MaxPooling (None, 114, 114, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_25 (Conv2D)           (None, 114, 114, 32)      25632     \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 114, 114, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_25 (MaxPooling (None, 38, 38, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_26 (Conv2D)           (None, 38, 38, 64)        51264     \n",
      "_________________________________________________________________\n",
      "activation_26 (Activation)   (None, 38, 38, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_26 (MaxPooling (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_27 (Conv2D)           (None, 13, 13, 64)        102464    \n",
      "_________________________________________________________________\n",
      "activation_27 (Activation)   (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_27 (MaxPooling (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_28 (Conv2D)           (None, 5, 5, 128)         204928    \n",
      "_________________________________________________________________\n",
      "activation_28 (Activation)   (None, 5, 5, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_28 (MaxPooling (None, 2, 2, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 6)                 3078      \n",
      "=================================================================\n",
      "Total params: 389,798\n",
      "Trainable params: 389,798\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1560/1560 [==============================] - 3s 2ms/sample - loss: 0.7477 - acc: 0.8212\n",
      "Loss: 0.7477427534568004 Accuracy: 0.8211538\n"
     ]
    }
   ],
   "source": [
    "for i in range(2, 6):\n",
    "    model_name = base+'_{}_conv'.format(i)\n",
    "    print()\n",
    "    print(model_name, 'Model')\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    model_filename = model_path + '000_last.hdf5'\n",
    "\n",
    "    model = load_model(model_filename)\n",
    "    model.summary()\n",
    "\n",
    "    [loss, accuracy] = model.evaluate(x_test, y_test)\n",
    "    print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "\n",
    "    del(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

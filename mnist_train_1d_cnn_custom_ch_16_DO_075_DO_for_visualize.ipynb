{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import os.path as path\n",
    "import itertools\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.layers import Input,InputLayer, Dense, Activation, BatchNormalization, Flatten, Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D, Dropout\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,LearningRateScheduler, \\\n",
    "                                        EarlyStopping\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from  tensorflow.keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = mnist.load_data(path='mnist.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = data[0][0][:,:,:,np.newaxis]\n",
    "y_data = data[0][1]\n",
    "x_test = data[1][0][:,:,:,np.newaxis]\n",
    "y_test = data[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((40200, 28, 28, 1),\n",
       " (40200, 10),\n",
       " (19800, 28, 28, 1),\n",
       " (19800, 10),\n",
       " (10000, 28, 28, 1),\n",
       " (10000, 10))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(x_data, y_data, test_size=0.33, random_state=42, stratify=y_data)\n",
    "y_train = to_categorical(y_train)\n",
    "y_val = to_categorical(y_val)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "x_train.shape, y_train.shape, x_val.shape, y_val.shape, x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=uint8)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_list = np.unique(data[1][1])\n",
    "y_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = x_test[0].shape\n",
    "output_size = y_list.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_2d_cnn_custom_ch_16_DO(conv_num=1):\n",
    "    input_layer = Input(shape=input_shape)\n",
    "    x = input_layer\n",
    "\n",
    "    for i in range(conv_num):\n",
    "        x = Conv2D(kernel_size=3, filters=16*(2**(i//2)), strides=(1,1), padding='same')(x)\n",
    "#         x = BatchNormalization()(x)\n",
    "        x = Activation('relu')(x)\n",
    "        x = MaxPooling2D(pool_size=2, strides=(2,2), padding='same')(x)\n",
    "\n",
    "    x = Flatten()(x)\n",
    "  \n",
    "    x = Dropout(0.75)(x)\n",
    "    output_layer = Dense(output_size, activation='softmax')(x)\n",
    "    \n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 28, 28, 16)        160       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 28, 28, 16)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                31370     \n",
      "=================================================================\n",
      "Total params: 31,530\n",
      "Trainable params: 31,530\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 16)        160       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 28, 28, 16)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 14, 14, 16)        2320      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 7, 7, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                7850      \n",
      "=================================================================\n",
      "Total params: 10,330\n",
      "Trainable params: 10,330\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 28, 28, 16)        160       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 28, 28, 16)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 14, 14, 16)        2320      \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 7, 7, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 7, 7, 32)          4640      \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 7, 7, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 4, 4, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 12,250\n",
      "Trainable params: 12,250\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 28, 28, 16)        160       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 28, 28, 16)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 14, 14, 16)        2320      \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 7, 7, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 7, 7, 32)          4640      \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 7, 7, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 4, 4, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 4, 4, 32)          9248      \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 4, 4, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 2, 2, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 17,658\n",
      "Trainable params: 17,658\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 28, 28, 16)        160       \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 28, 28, 16)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 14, 14, 16)        2320      \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 7, 7, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 7, 7, 32)          4640      \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 7, 7, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 4, 4, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 4, 4, 32)          9248      \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 4, 4, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 2, 2, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 2, 2, 64)          18496     \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 2, 2, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 1, 1, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 35,514\n",
      "Trainable params: 35,514\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 6):\n",
    "    model = build_2d_cnn_custom_ch_16_DO(conv_num=i)\n",
    "    model.summary()\n",
    "    del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 40200 samples, validate on 19800 samples\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 10.6849 - acc: 0.3035\n",
      "Epoch 00001: val_loss improved from inf to 4.55475, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_1_conv_checkpoint/001-4.5548.hdf5\n",
      "40200/40200 [==============================] - 6s 145us/sample - loss: 10.6664 - acc: 0.3048 - val_loss: 4.5548 - val_acc: 0.6911\n",
      "Epoch 2/500\n",
      "39552/40200 [============================>.] - ETA: 0s - loss: 6.2695 - acc: 0.5766\n",
      "Epoch 00002: val_loss improved from 4.55475 to 2.46595, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_1_conv_checkpoint/002-2.4659.hdf5\n",
      "40200/40200 [==============================] - 4s 89us/sample - loss: 6.2464 - acc: 0.5780 - val_loss: 2.4659 - val_acc: 0.8185\n",
      "Epoch 3/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 4.3211 - acc: 0.6994\n",
      "Epoch 00003: val_loss improved from 2.46595 to 1.88237, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_1_conv_checkpoint/003-1.8824.hdf5\n",
      "40200/40200 [==============================] - 4s 91us/sample - loss: 4.3173 - acc: 0.6996 - val_loss: 1.8824 - val_acc: 0.8614\n",
      "Epoch 4/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 3.3431 - acc: 0.7610\n",
      "Epoch 00004: val_loss improved from 1.88237 to 1.46319, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_1_conv_checkpoint/004-1.4632.hdf5\n",
      "40200/40200 [==============================] - 4s 98us/sample - loss: 3.3412 - acc: 0.7612 - val_loss: 1.4632 - val_acc: 0.8892\n",
      "Epoch 5/500\n",
      "39680/40200 [============================>.] - ETA: 0s - loss: 2.7854 - acc: 0.7980\n",
      "Epoch 00005: val_loss improved from 1.46319 to 1.27205, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_1_conv_checkpoint/005-1.2720.hdf5\n",
      "40200/40200 [==============================] - 4s 97us/sample - loss: 2.7819 - acc: 0.7983 - val_loss: 1.2720 - val_acc: 0.9020\n",
      "Epoch 6/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 2.3498 - acc: 0.8264\n",
      "Epoch 00006: val_loss improved from 1.27205 to 1.08710, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_1_conv_checkpoint/006-1.0871.hdf5\n",
      "40200/40200 [==============================] - 4s 99us/sample - loss: 2.3462 - acc: 0.8267 - val_loss: 1.0871 - val_acc: 0.9145\n",
      "Epoch 7/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 2.0872 - acc: 0.8433\n",
      "Epoch 00007: val_loss improved from 1.08710 to 0.96615, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_1_conv_checkpoint/007-0.9662.hdf5\n",
      "40200/40200 [==============================] - 4s 102us/sample - loss: 2.0839 - acc: 0.8435 - val_loss: 0.9662 - val_acc: 0.9232\n",
      "Epoch 8/500\n",
      "39744/40200 [============================>.] - ETA: 0s - loss: 1.8712 - acc: 0.8566\n",
      "Epoch 00008: val_loss improved from 0.96615 to 0.84562, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_1_conv_checkpoint/008-0.8456.hdf5\n",
      "40200/40200 [==============================] - 4s 98us/sample - loss: 1.8687 - acc: 0.8567 - val_loss: 0.8456 - val_acc: 0.9321\n",
      "Epoch 9/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 1.6663 - acc: 0.8693\n",
      "Epoch 00009: val_loss improved from 0.84562 to 0.77294, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_1_conv_checkpoint/009-0.7729.hdf5\n",
      "40200/40200 [==============================] - 4s 91us/sample - loss: 1.6635 - acc: 0.8694 - val_loss: 0.7729 - val_acc: 0.9377\n",
      "Epoch 10/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 1.5136 - acc: 0.8788\n",
      "Epoch 00010: val_loss improved from 0.77294 to 0.69238, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_1_conv_checkpoint/010-0.6924.hdf5\n",
      "40200/40200 [==============================] - 4s 109us/sample - loss: 1.5143 - acc: 0.8787 - val_loss: 0.6924 - val_acc: 0.9421\n",
      "Epoch 11/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 1.4066 - acc: 0.8865\n",
      "Epoch 00011: val_loss improved from 0.69238 to 0.63705, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_1_conv_checkpoint/011-0.6371.hdf5\n",
      "40200/40200 [==============================] - 4s 97us/sample - loss: 1.4047 - acc: 0.8865 - val_loss: 0.6371 - val_acc: 0.9454\n",
      "Epoch 12/500\n",
      "39616/40200 [============================>.] - ETA: 0s - loss: 1.3036 - acc: 0.8911\n",
      "Epoch 00012: val_loss improved from 0.63705 to 0.58912, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_1_conv_checkpoint/012-0.5891.hdf5\n",
      "40200/40200 [==============================] - 4s 96us/sample - loss: 1.3014 - acc: 0.8913 - val_loss: 0.5891 - val_acc: 0.9491\n",
      "Epoch 13/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 1.1784 - acc: 0.9004\n",
      "Epoch 00013: val_loss improved from 0.58912 to 0.54358, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_1_conv_checkpoint/013-0.5436.hdf5\n",
      "40200/40200 [==============================] - 4s 95us/sample - loss: 1.1782 - acc: 0.9004 - val_loss: 0.5436 - val_acc: 0.9515\n",
      "Epoch 14/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 1.0852 - acc: 0.9047\n",
      "Epoch 00014: val_loss improved from 0.54358 to 0.48224, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_1_conv_checkpoint/014-0.4822.hdf5\n",
      "40200/40200 [==============================] - 4s 97us/sample - loss: 1.0834 - acc: 0.9049 - val_loss: 0.4822 - val_acc: 0.9551\n",
      "Epoch 15/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.9956 - acc: 0.9094\n",
      "Epoch 00015: val_loss improved from 0.48224 to 0.43859, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_1_conv_checkpoint/015-0.4386.hdf5\n",
      "40200/40200 [==============================] - 4s 94us/sample - loss: 0.9954 - acc: 0.9094 - val_loss: 0.4386 - val_acc: 0.9570\n",
      "Epoch 16/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.9218 - acc: 0.9112\n",
      "Epoch 00016: val_loss improved from 0.43859 to 0.38933, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_1_conv_checkpoint/016-0.3893.hdf5\n",
      "40200/40200 [==============================] - 4s 93us/sample - loss: 0.9230 - acc: 0.9111 - val_loss: 0.3893 - val_acc: 0.9595\n",
      "Epoch 17/500\n",
      "39680/40200 [============================>.] - ETA: 0s - loss: 0.8397 - acc: 0.9157\n",
      "Epoch 00017: val_loss improved from 0.38933 to 0.35463, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_1_conv_checkpoint/017-0.3546.hdf5\n",
      "40200/40200 [==============================] - 3s 85us/sample - loss: 0.8433 - acc: 0.9155 - val_loss: 0.3546 - val_acc: 0.9614\n",
      "Epoch 18/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.7687 - acc: 0.9179\n",
      "Epoch 00018: val_loss improved from 0.35463 to 0.31859, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_1_conv_checkpoint/018-0.3186.hdf5\n",
      "40200/40200 [==============================] - 3s 84us/sample - loss: 0.7687 - acc: 0.9179 - val_loss: 0.3186 - val_acc: 0.9639\n",
      "Epoch 19/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.6834 - acc: 0.9224\n",
      "Epoch 00019: val_loss improved from 0.31859 to 0.27981, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_1_conv_checkpoint/019-0.2798.hdf5\n",
      "40200/40200 [==============================] - 4s 93us/sample - loss: 0.6834 - acc: 0.9225 - val_loss: 0.2798 - val_acc: 0.9653\n",
      "Epoch 20/500\n",
      "39552/40200 [============================>.] - ETA: 0s - loss: 0.6117 - acc: 0.9238\n",
      "Epoch 00020: val_loss improved from 0.27981 to 0.24573, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_1_conv_checkpoint/020-0.2457.hdf5\n",
      "40200/40200 [==============================] - 4s 93us/sample - loss: 0.6101 - acc: 0.9239 - val_loss: 0.2457 - val_acc: 0.9665\n",
      "Epoch 21/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.5487 - acc: 0.9217\n",
      "Epoch 00021: val_loss improved from 0.24573 to 0.20847, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_1_conv_checkpoint/021-0.2085.hdf5\n",
      "40200/40200 [==============================] - 4s 93us/sample - loss: 0.5477 - acc: 0.9216 - val_loss: 0.2085 - val_acc: 0.9681\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.4685 - acc: 0.9230\n",
      "Epoch 00022: val_loss improved from 0.20847 to 0.17064, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_1_conv_checkpoint/022-0.1706.hdf5\n",
      "40200/40200 [==============================] - 4s 93us/sample - loss: 0.4691 - acc: 0.9228 - val_loss: 0.1706 - val_acc: 0.9687\n",
      "Epoch 23/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.4015 - acc: 0.9200\n",
      "Epoch 00023: val_loss improved from 0.17064 to 0.14714, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_1_conv_checkpoint/023-0.1471.hdf5\n",
      "40200/40200 [==============================] - 4s 92us/sample - loss: 0.4014 - acc: 0.9200 - val_loss: 0.1471 - val_acc: 0.9684\n",
      "Epoch 24/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.3394 - acc: 0.9230\n",
      "Epoch 00024: val_loss improved from 0.14714 to 0.13161, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_1_conv_checkpoint/024-0.1316.hdf5\n",
      "40200/40200 [==============================] - 4s 93us/sample - loss: 0.3401 - acc: 0.9228 - val_loss: 0.1316 - val_acc: 0.9687\n",
      "Epoch 25/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.3043 - acc: 0.9237\n",
      "Epoch 00025: val_loss improved from 0.13161 to 0.11894, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_1_conv_checkpoint/025-0.1189.hdf5\n",
      "40200/40200 [==============================] - 4s 92us/sample - loss: 0.3042 - acc: 0.9237 - val_loss: 0.1189 - val_acc: 0.9692\n",
      "Epoch 26/500\n",
      "39680/40200 [============================>.] - ETA: 0s - loss: 0.2759 - acc: 0.9279\n",
      "Epoch 00026: val_loss improved from 0.11894 to 0.11184, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_1_conv_checkpoint/026-0.1118.hdf5\n",
      "40200/40200 [==============================] - 4s 91us/sample - loss: 0.2747 - acc: 0.9283 - val_loss: 0.1118 - val_acc: 0.9697\n",
      "Epoch 27/500\n",
      "39552/40200 [============================>.] - ETA: 0s - loss: 0.2548 - acc: 0.9314\n",
      "Epoch 00027: val_loss improved from 0.11184 to 0.10579, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_1_conv_checkpoint/027-0.1058.hdf5\n",
      "40200/40200 [==============================] - 4s 95us/sample - loss: 0.2545 - acc: 0.9315 - val_loss: 0.1058 - val_acc: 0.9706\n",
      "Epoch 28/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.2400 - acc: 0.9339\n",
      "Epoch 00028: val_loss improved from 0.10579 to 0.10074, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_1_conv_checkpoint/028-0.1007.hdf5\n",
      "40200/40200 [==============================] - 4s 92us/sample - loss: 0.2402 - acc: 0.9338 - val_loss: 0.1007 - val_acc: 0.9719\n",
      "Epoch 29/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.2273 - acc: 0.9363\n",
      "Epoch 00029: val_loss improved from 0.10074 to 0.09694, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_1_conv_checkpoint/029-0.0969.hdf5\n",
      "40200/40200 [==============================] - 4s 92us/sample - loss: 0.2266 - acc: 0.9365 - val_loss: 0.0969 - val_acc: 0.9725\n",
      "Epoch 30/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.2166 - acc: 0.9383\n",
      "Epoch 00030: val_loss improved from 0.09694 to 0.09398, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_1_conv_checkpoint/030-0.0940.hdf5\n",
      "40200/40200 [==============================] - 4s 93us/sample - loss: 0.2166 - acc: 0.9383 - val_loss: 0.0940 - val_acc: 0.9727\n",
      "Epoch 31/500\n",
      "39744/40200 [============================>.] - ETA: 0s - loss: 0.2014 - acc: 0.9425\n",
      "Epoch 00031: val_loss improved from 0.09398 to 0.08997, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_1_conv_checkpoint/031-0.0900.hdf5\n",
      "40200/40200 [==============================] - 4s 93us/sample - loss: 0.2016 - acc: 0.9424 - val_loss: 0.0900 - val_acc: 0.9737\n",
      "Epoch 32/500\n",
      "39552/40200 [============================>.] - ETA: 0s - loss: 0.1961 - acc: 0.9421\n",
      "Epoch 00032: val_loss improved from 0.08997 to 0.08811, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_1_conv_checkpoint/032-0.0881.hdf5\n",
      "40200/40200 [==============================] - 4s 93us/sample - loss: 0.1969 - acc: 0.9420 - val_loss: 0.0881 - val_acc: 0.9744\n",
      "Epoch 33/500\n",
      "39744/40200 [============================>.] - ETA: 0s - loss: 0.1848 - acc: 0.9447\n",
      "Epoch 00033: val_loss improved from 0.08811 to 0.08558, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_1_conv_checkpoint/033-0.0856.hdf5\n",
      "40200/40200 [==============================] - 4s 95us/sample - loss: 0.1845 - acc: 0.9449 - val_loss: 0.0856 - val_acc: 0.9751\n",
      "Epoch 34/500\n",
      "39552/40200 [============================>.] - ETA: 0s - loss: 0.1792 - acc: 0.9463\n",
      "Epoch 00034: val_loss improved from 0.08558 to 0.08423, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_1_conv_checkpoint/034-0.0842.hdf5\n",
      "40200/40200 [==============================] - 3s 84us/sample - loss: 0.1803 - acc: 0.9462 - val_loss: 0.0842 - val_acc: 0.9747\n",
      "Epoch 35/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.1772 - acc: 0.9478\n",
      "Epoch 00035: val_loss improved from 0.08423 to 0.08306, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_1_conv_checkpoint/035-0.0831.hdf5\n",
      "40200/40200 [==============================] - 4s 87us/sample - loss: 0.1774 - acc: 0.9478 - val_loss: 0.0831 - val_acc: 0.9752\n",
      "Epoch 36/500\n",
      "39744/40200 [============================>.] - ETA: 0s - loss: 0.1748 - acc: 0.9469\n",
      "Epoch 00036: val_loss improved from 0.08306 to 0.08174, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_1_conv_checkpoint/036-0.0817.hdf5\n",
      "40200/40200 [==============================] - 4s 92us/sample - loss: 0.1753 - acc: 0.9469 - val_loss: 0.0817 - val_acc: 0.9765\n",
      "Epoch 37/500\n",
      "39744/40200 [============================>.] - ETA: 0s - loss: 0.1729 - acc: 0.9472\n",
      "Epoch 00037: val_loss improved from 0.08174 to 0.08102, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_1_conv_checkpoint/037-0.0810.hdf5\n",
      "40200/40200 [==============================] - 4s 94us/sample - loss: 0.1731 - acc: 0.9471 - val_loss: 0.0810 - val_acc: 0.9763\n",
      "Epoch 38/500\n",
      "39744/40200 [============================>.] - ETA: 0s - loss: 0.1720 - acc: 0.9483\n",
      "Epoch 00038: val_loss improved from 0.08102 to 0.07986, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_1_conv_checkpoint/038-0.0799.hdf5\n",
      "40200/40200 [==============================] - 4s 93us/sample - loss: 0.1719 - acc: 0.9483 - val_loss: 0.0799 - val_acc: 0.9757\n",
      "Epoch 39/500\n",
      "39552/40200 [============================>.] - ETA: 0s - loss: 0.1617 - acc: 0.9520\n",
      "Epoch 00039: val_loss improved from 0.07986 to 0.07787, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_1_conv_checkpoint/039-0.0779.hdf5\n",
      "40200/40200 [==============================] - 4s 93us/sample - loss: 0.1614 - acc: 0.9521 - val_loss: 0.0779 - val_acc: 0.9768\n",
      "Epoch 40/500\n",
      "39552/40200 [============================>.] - ETA: 0s - loss: 0.1599 - acc: 0.9520\n",
      "Epoch 00040: val_loss improved from 0.07787 to 0.07754, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_1_conv_checkpoint/040-0.0775.hdf5\n",
      "40200/40200 [==============================] - 4s 93us/sample - loss: 0.1595 - acc: 0.9521 - val_loss: 0.0775 - val_acc: 0.9770\n",
      "Epoch 41/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.1589 - acc: 0.9521\n",
      "Epoch 00041: val_loss improved from 0.07754 to 0.07677, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_1_conv_checkpoint/041-0.0768.hdf5\n",
      "40200/40200 [==============================] - 4s 93us/sample - loss: 0.1591 - acc: 0.9521 - val_loss: 0.0768 - val_acc: 0.9768\n",
      "Epoch 42/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.1533 - acc: 0.9546\n",
      "Epoch 00042: val_loss did not improve from 0.07677\n",
      "40200/40200 [==============================] - 4s 93us/sample - loss: 0.1534 - acc: 0.9546 - val_loss: 0.0770 - val_acc: 0.9770\n",
      "Epoch 43/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.1479 - acc: 0.9548\n",
      "Epoch 00043: val_loss improved from 0.07677 to 0.07448, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_1_conv_checkpoint/043-0.0745.hdf5\n",
      "40200/40200 [==============================] - 4s 92us/sample - loss: 0.1479 - acc: 0.9548 - val_loss: 0.0745 - val_acc: 0.9777\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.1510 - acc: 0.9525\n",
      "Epoch 00044: val_loss improved from 0.07448 to 0.07344, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_1_conv_checkpoint/044-0.0734.hdf5\n",
      "40200/40200 [==============================] - 4s 92us/sample - loss: 0.1515 - acc: 0.9525 - val_loss: 0.0734 - val_acc: 0.9779\n",
      "Epoch 45/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.1433 - acc: 0.9559\n",
      "Epoch 00045: val_loss improved from 0.07344 to 0.07312, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_1_conv_checkpoint/045-0.0731.hdf5\n",
      "40200/40200 [==============================] - 4s 93us/sample - loss: 0.1432 - acc: 0.9559 - val_loss: 0.0731 - val_acc: 0.9786\n",
      "Epoch 46/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.1467 - acc: 0.9558\n",
      "Epoch 00046: val_loss did not improve from 0.07312\n",
      "40200/40200 [==============================] - 4s 93us/sample - loss: 0.1466 - acc: 0.9558 - val_loss: 0.0735 - val_acc: 0.9783\n",
      "Epoch 47/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.1475 - acc: 0.9554\n",
      "Epoch 00047: val_loss improved from 0.07312 to 0.07273, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_1_conv_checkpoint/047-0.0727.hdf5\n",
      "40200/40200 [==============================] - 4s 93us/sample - loss: 0.1475 - acc: 0.9553 - val_loss: 0.0727 - val_acc: 0.9780\n",
      "Epoch 48/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.1487 - acc: 0.9542\n",
      "Epoch 00048: val_loss improved from 0.07273 to 0.07256, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_1_conv_checkpoint/048-0.0726.hdf5\n",
      "40200/40200 [==============================] - 4s 93us/sample - loss: 0.1487 - acc: 0.9543 - val_loss: 0.0726 - val_acc: 0.9786\n",
      "Epoch 49/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.1425 - acc: 0.9566\n",
      "Epoch 00049: val_loss improved from 0.07256 to 0.07228, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_1_conv_checkpoint/049-0.0723.hdf5\n",
      "40200/40200 [==============================] - 4s 94us/sample - loss: 0.1424 - acc: 0.9564 - val_loss: 0.0723 - val_acc: 0.9781\n",
      "Epoch 50/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.1424 - acc: 0.9567\n",
      "Epoch 00050: val_loss improved from 0.07228 to 0.07147, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_1_conv_checkpoint/050-0.0715.hdf5\n",
      "40200/40200 [==============================] - 3s 85us/sample - loss: 0.1427 - acc: 0.9567 - val_loss: 0.0715 - val_acc: 0.9781\n",
      "Epoch 51/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.1425 - acc: 0.9556\n",
      "Epoch 00051: val_loss improved from 0.07147 to 0.07136, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_1_conv_checkpoint/051-0.0714.hdf5\n",
      "40200/40200 [==============================] - 3s 85us/sample - loss: 0.1427 - acc: 0.9555 - val_loss: 0.0714 - val_acc: 0.9791\n",
      "Epoch 52/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.1438 - acc: 0.9561\n",
      "Epoch 00052: val_loss improved from 0.07136 to 0.07022, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_1_conv_checkpoint/052-0.0702.hdf5\n",
      "40200/40200 [==============================] - 4s 92us/sample - loss: 0.1432 - acc: 0.9562 - val_loss: 0.0702 - val_acc: 0.9798\n",
      "Epoch 53/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.1378 - acc: 0.9568\n",
      "Epoch 00053: val_loss did not improve from 0.07022\n",
      "40200/40200 [==============================] - 4s 93us/sample - loss: 0.1380 - acc: 0.9569 - val_loss: 0.0703 - val_acc: 0.9789\n",
      "Epoch 54/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.1368 - acc: 0.9570\n",
      "Epoch 00054: val_loss improved from 0.07022 to 0.06969, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_1_conv_checkpoint/054-0.0697.hdf5\n",
      "40200/40200 [==============================] - 4s 93us/sample - loss: 0.1368 - acc: 0.9570 - val_loss: 0.0697 - val_acc: 0.9792\n",
      "Epoch 55/500\n",
      "39744/40200 [============================>.] - ETA: 0s - loss: 0.1386 - acc: 0.9571\n",
      "Epoch 00055: val_loss did not improve from 0.06969\n",
      "40200/40200 [==============================] - 4s 92us/sample - loss: 0.1387 - acc: 0.9571 - val_loss: 0.0701 - val_acc: 0.9792\n",
      "Epoch 56/500\n",
      "39616/40200 [============================>.] - ETA: 0s - loss: 0.1332 - acc: 0.9585\n",
      "Epoch 00056: val_loss improved from 0.06969 to 0.06882, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_1_conv_checkpoint/056-0.0688.hdf5\n",
      "40200/40200 [==============================] - 4s 93us/sample - loss: 0.1339 - acc: 0.9583 - val_loss: 0.0688 - val_acc: 0.9801\n",
      "Epoch 57/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.1314 - acc: 0.9596\n",
      "Epoch 00057: val_loss did not improve from 0.06882\n",
      "40200/40200 [==============================] - 4s 92us/sample - loss: 0.1311 - acc: 0.9596 - val_loss: 0.0694 - val_acc: 0.9799\n",
      "Epoch 58/500\n",
      "39616/40200 [============================>.] - ETA: 0s - loss: 0.1293 - acc: 0.9597\n",
      "Epoch 00058: val_loss did not improve from 0.06882\n",
      "40200/40200 [==============================] - 4s 93us/sample - loss: 0.1296 - acc: 0.9596 - val_loss: 0.0693 - val_acc: 0.9798\n",
      "Epoch 59/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.1344 - acc: 0.9582\n",
      "Epoch 00059: val_loss improved from 0.06882 to 0.06833, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_1_conv_checkpoint/059-0.0683.hdf5\n",
      "40200/40200 [==============================] - 4s 93us/sample - loss: 0.1341 - acc: 0.9583 - val_loss: 0.0683 - val_acc: 0.9805\n",
      "Epoch 60/500\n",
      "39616/40200 [============================>.] - ETA: 0s - loss: 0.1340 - acc: 0.9582\n",
      "Epoch 00060: val_loss did not improve from 0.06833\n",
      "40200/40200 [==============================] - 4s 92us/sample - loss: 0.1340 - acc: 0.9581 - val_loss: 0.0692 - val_acc: 0.9795\n",
      "Epoch 61/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.1342 - acc: 0.9581\n",
      "Epoch 00061: val_loss improved from 0.06833 to 0.06827, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_1_conv_checkpoint/061-0.0683.hdf5\n",
      "40200/40200 [==============================] - 4s 92us/sample - loss: 0.1341 - acc: 0.9581 - val_loss: 0.0683 - val_acc: 0.9807\n",
      "Epoch 62/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.1352 - acc: 0.9577\n",
      "Epoch 00062: val_loss improved from 0.06827 to 0.06773, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_1_conv_checkpoint/062-0.0677.hdf5\n",
      "40200/40200 [==============================] - 4s 93us/sample - loss: 0.1352 - acc: 0.9577 - val_loss: 0.0677 - val_acc: 0.9808\n",
      "Epoch 63/500\n",
      "39552/40200 [============================>.] - ETA: 0s - loss: 0.1307 - acc: 0.9593\n",
      "Epoch 00063: val_loss improved from 0.06773 to 0.06656, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_1_conv_checkpoint/063-0.0666.hdf5\n",
      "40200/40200 [==============================] - 4s 93us/sample - loss: 0.1312 - acc: 0.9594 - val_loss: 0.0666 - val_acc: 0.9813\n",
      "Epoch 64/500\n",
      "39552/40200 [============================>.] - ETA: 0s - loss: 0.1322 - acc: 0.9587\n",
      "Epoch 00064: val_loss did not improve from 0.06656\n",
      "40200/40200 [==============================] - 4s 93us/sample - loss: 0.1322 - acc: 0.9587 - val_loss: 0.0673 - val_acc: 0.9803\n",
      "Epoch 65/500\n",
      "39744/40200 [============================>.] - ETA: 0s - loss: 0.1318 - acc: 0.9579\n",
      "Epoch 00065: val_loss did not improve from 0.06656\n",
      "40200/40200 [==============================] - 4s 92us/sample - loss: 0.1321 - acc: 0.9579 - val_loss: 0.0672 - val_acc: 0.9809\n",
      "Epoch 66/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.1278 - acc: 0.9601\n",
      "Epoch 00066: val_loss did not improve from 0.06656\n",
      "40200/40200 [==============================] - 4s 88us/sample - loss: 0.1277 - acc: 0.9601 - val_loss: 0.0668 - val_acc: 0.9805\n",
      "Epoch 67/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.1296 - acc: 0.9598\n",
      "Epoch 00067: val_loss did not improve from 0.06656\n",
      "40200/40200 [==============================] - 3s 83us/sample - loss: 0.1295 - acc: 0.9598 - val_loss: 0.0678 - val_acc: 0.9802\n",
      "Epoch 68/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.1277 - acc: 0.9588\n",
      "Epoch 00068: val_loss did not improve from 0.06656\n",
      "40200/40200 [==============================] - 4s 89us/sample - loss: 0.1277 - acc: 0.9588 - val_loss: 0.0669 - val_acc: 0.9808\n",
      "Epoch 69/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.1288 - acc: 0.9587\n",
      "Epoch 00069: val_loss improved from 0.06656 to 0.06598, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_1_conv_checkpoint/069-0.0660.hdf5\n",
      "40200/40200 [==============================] - 4s 91us/sample - loss: 0.1285 - acc: 0.9588 - val_loss: 0.0660 - val_acc: 0.9811\n",
      "Epoch 70/500\n",
      "39552/40200 [============================>.] - ETA: 0s - loss: 0.1294 - acc: 0.9590\n",
      "Epoch 00070: val_loss did not improve from 0.06598\n",
      "40200/40200 [==============================] - 4s 92us/sample - loss: 0.1294 - acc: 0.9591 - val_loss: 0.0688 - val_acc: 0.9797\n",
      "Epoch 71/500\n",
      "39616/40200 [============================>.] - ETA: 0s - loss: 0.1306 - acc: 0.9590\n",
      "Epoch 00071: val_loss did not improve from 0.06598\n",
      "40200/40200 [==============================] - 4s 93us/sample - loss: 0.1311 - acc: 0.9590 - val_loss: 0.0661 - val_acc: 0.9814\n",
      "Epoch 72/500\n",
      "39552/40200 [============================>.] - ETA: 0s - loss: 0.1262 - acc: 0.9593\n",
      "Epoch 00072: val_loss improved from 0.06598 to 0.06597, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_1_conv_checkpoint/072-0.0660.hdf5\n",
      "40200/40200 [==============================] - 4s 94us/sample - loss: 0.1268 - acc: 0.9592 - val_loss: 0.0660 - val_acc: 0.9800\n",
      "Epoch 73/500\n",
      "39552/40200 [============================>.] - ETA: 0s - loss: 0.1274 - acc: 0.9608\n",
      "Epoch 00073: val_loss did not improve from 0.06597\n",
      "40200/40200 [==============================] - 4s 92us/sample - loss: 0.1274 - acc: 0.9608 - val_loss: 0.0663 - val_acc: 0.9802\n",
      "Epoch 74/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.1274 - acc: 0.9601\n",
      "Epoch 00074: val_loss did not improve from 0.06597\n",
      "40200/40200 [==============================] - 4s 92us/sample - loss: 0.1271 - acc: 0.9602 - val_loss: 0.0662 - val_acc: 0.9805\n",
      "Epoch 75/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.1233 - acc: 0.9611\n",
      "Epoch 00075: val_loss did not improve from 0.06597\n",
      "40200/40200 [==============================] - 4s 92us/sample - loss: 0.1229 - acc: 0.9612 - val_loss: 0.0661 - val_acc: 0.9811\n",
      "Epoch 76/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.1280 - acc: 0.9602\n",
      "Epoch 00076: val_loss improved from 0.06597 to 0.06543, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_1_conv_checkpoint/076-0.0654.hdf5\n",
      "40200/40200 [==============================] - 4s 92us/sample - loss: 0.1284 - acc: 0.9600 - val_loss: 0.0654 - val_acc: 0.9806\n",
      "Epoch 77/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.1243 - acc: 0.9601\n",
      "Epoch 00077: val_loss improved from 0.06543 to 0.06513, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_1_conv_checkpoint/077-0.0651.hdf5\n",
      "40200/40200 [==============================] - 4s 92us/sample - loss: 0.1243 - acc: 0.9601 - val_loss: 0.0651 - val_acc: 0.9807\n",
      "Epoch 78/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.1237 - acc: 0.9612\n",
      "Epoch 00078: val_loss did not improve from 0.06513\n",
      "40200/40200 [==============================] - 4s 92us/sample - loss: 0.1241 - acc: 0.9610 - val_loss: 0.0656 - val_acc: 0.9804\n",
      "Epoch 79/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.1304 - acc: 0.9594\n",
      "Epoch 00079: val_loss did not improve from 0.06513\n",
      "40200/40200 [==============================] - 4s 92us/sample - loss: 0.1305 - acc: 0.9594 - val_loss: 0.0658 - val_acc: 0.9805\n",
      "Epoch 80/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.1235 - acc: 0.9618\n",
      "Epoch 00080: val_loss improved from 0.06513 to 0.06492, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_1_conv_checkpoint/080-0.0649.hdf5\n",
      "40200/40200 [==============================] - 4s 93us/sample - loss: 0.1237 - acc: 0.9619 - val_loss: 0.0649 - val_acc: 0.9807\n",
      "Epoch 81/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.1231 - acc: 0.9611\n",
      "Epoch 00081: val_loss did not improve from 0.06492\n",
      "40200/40200 [==============================] - 4s 93us/sample - loss: 0.1234 - acc: 0.9610 - val_loss: 0.0656 - val_acc: 0.9808\n",
      "Epoch 82/500\n",
      "39744/40200 [============================>.] - ETA: 0s - loss: 0.1252 - acc: 0.9601\n",
      "Epoch 00082: val_loss improved from 0.06492 to 0.06489, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_1_conv_checkpoint/082-0.0649.hdf5\n",
      "40200/40200 [==============================] - 4s 93us/sample - loss: 0.1251 - acc: 0.9601 - val_loss: 0.0649 - val_acc: 0.9813\n",
      "Epoch 83/500\n",
      "39616/40200 [============================>.] - ETA: 0s - loss: 0.1264 - acc: 0.9617\n",
      "Epoch 00083: val_loss did not improve from 0.06489\n",
      "40200/40200 [==============================] - 4s 93us/sample - loss: 0.1260 - acc: 0.9617 - val_loss: 0.0666 - val_acc: 0.9801\n",
      "Epoch 84/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.1243 - acc: 0.9612\n",
      "Epoch 00084: val_loss did not improve from 0.06489\n",
      "40200/40200 [==============================] - 4s 92us/sample - loss: 0.1244 - acc: 0.9612 - val_loss: 0.0651 - val_acc: 0.9811\n",
      "Epoch 85/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.1233 - acc: 0.9604\n",
      "Epoch 00085: val_loss improved from 0.06489 to 0.06487, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_1_conv_checkpoint/085-0.0649.hdf5\n",
      "40200/40200 [==============================] - 4s 93us/sample - loss: 0.1234 - acc: 0.9603 - val_loss: 0.0649 - val_acc: 0.9817\n",
      "Epoch 86/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.1260 - acc: 0.9600\n",
      "Epoch 00086: val_loss improved from 0.06487 to 0.06471, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_1_conv_checkpoint/086-0.0647.hdf5\n",
      "40200/40200 [==============================] - 4s 92us/sample - loss: 0.1260 - acc: 0.9600 - val_loss: 0.0647 - val_acc: 0.9807\n",
      "Epoch 87/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.1228 - acc: 0.9605\n",
      "Epoch 00087: val_loss did not improve from 0.06471\n",
      "40200/40200 [==============================] - 4s 93us/sample - loss: 0.1228 - acc: 0.9605 - val_loss: 0.0655 - val_acc: 0.9809\n",
      "Epoch 88/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.1226 - acc: 0.9609\n",
      "Epoch 00088: val_loss did not improve from 0.06471\n",
      "40200/40200 [==============================] - 4s 92us/sample - loss: 0.1227 - acc: 0.9609 - val_loss: 0.0667 - val_acc: 0.9799\n",
      "Epoch 89/500\n",
      "39744/40200 [============================>.] - ETA: 0s - loss: 0.1208 - acc: 0.9629\n",
      "Epoch 00089: val_loss did not improve from 0.06471\n",
      "40200/40200 [==============================] - 3s 85us/sample - loss: 0.1203 - acc: 0.9630 - val_loss: 0.0650 - val_acc: 0.9799\n",
      "Epoch 90/500\n",
      "39680/40200 [============================>.] - ETA: 0s - loss: 0.1223 - acc: 0.9613\n",
      "Epoch 00090: val_loss improved from 0.06471 to 0.06459, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_1_conv_checkpoint/090-0.0646.hdf5\n",
      "40200/40200 [==============================] - 3s 83us/sample - loss: 0.1228 - acc: 0.9611 - val_loss: 0.0646 - val_acc: 0.9806\n",
      "Epoch 91/500\n",
      "39616/40200 [============================>.] - ETA: 0s - loss: 0.1239 - acc: 0.9617\n",
      "Epoch 00091: val_loss did not improve from 0.06459\n",
      "40200/40200 [==============================] - 4s 91us/sample - loss: 0.1243 - acc: 0.9618 - val_loss: 0.0657 - val_acc: 0.9805\n",
      "Epoch 92/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.1235 - acc: 0.9614\n",
      "Epoch 00092: val_loss did not improve from 0.06459\n",
      "40200/40200 [==============================] - 4s 92us/sample - loss: 0.1235 - acc: 0.9614 - val_loss: 0.0657 - val_acc: 0.9803\n",
      "Epoch 93/500\n",
      "39744/40200 [============================>.] - ETA: 0s - loss: 0.1230 - acc: 0.9608\n",
      "Epoch 00093: val_loss did not improve from 0.06459\n",
      "40200/40200 [==============================] - 4s 92us/sample - loss: 0.1230 - acc: 0.9608 - val_loss: 0.0658 - val_acc: 0.9804\n",
      "Epoch 94/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.1190 - acc: 0.9631\n",
      "Epoch 00094: val_loss improved from 0.06459 to 0.06456, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_1_conv_checkpoint/094-0.0646.hdf5\n",
      "40200/40200 [==============================] - 4s 93us/sample - loss: 0.1193 - acc: 0.9629 - val_loss: 0.0646 - val_acc: 0.9812\n",
      "Epoch 95/500\n",
      "39680/40200 [============================>.] - ETA: 0s - loss: 0.1236 - acc: 0.9607\n",
      "Epoch 00095: val_loss improved from 0.06456 to 0.06385, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_1_conv_checkpoint/095-0.0638.hdf5\n",
      "40200/40200 [==============================] - 4s 93us/sample - loss: 0.1242 - acc: 0.9606 - val_loss: 0.0638 - val_acc: 0.9815\n",
      "Epoch 96/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.1190 - acc: 0.9625\n",
      "Epoch 00096: val_loss did not improve from 0.06385\n",
      "40200/40200 [==============================] - 4s 92us/sample - loss: 0.1191 - acc: 0.9625 - val_loss: 0.0659 - val_acc: 0.9808\n",
      "Epoch 97/500\n",
      "39616/40200 [============================>.] - ETA: 0s - loss: 0.1205 - acc: 0.9617\n",
      "Epoch 00097: val_loss did not improve from 0.06385\n",
      "40200/40200 [==============================] - 4s 92us/sample - loss: 0.1208 - acc: 0.9615 - val_loss: 0.0645 - val_acc: 0.9813\n",
      "Epoch 98/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.1207 - acc: 0.9614\n",
      "Epoch 00098: val_loss did not improve from 0.06385\n",
      "40200/40200 [==============================] - 4s 93us/sample - loss: 0.1209 - acc: 0.9613 - val_loss: 0.0648 - val_acc: 0.9807\n",
      "Epoch 99/500\n",
      "39680/40200 [============================>.] - ETA: 0s - loss: 0.1219 - acc: 0.9622\n",
      "Epoch 00099: val_loss did not improve from 0.06385\n",
      "40200/40200 [==============================] - 4s 93us/sample - loss: 0.1219 - acc: 0.9621 - val_loss: 0.0644 - val_acc: 0.9809\n",
      "Epoch 100/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.1167 - acc: 0.9632\n",
      "Epoch 00100: val_loss did not improve from 0.06385\n",
      "40200/40200 [==============================] - 4s 92us/sample - loss: 0.1166 - acc: 0.9632 - val_loss: 0.0651 - val_acc: 0.9808\n",
      "Epoch 101/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.1197 - acc: 0.9626\n",
      "Epoch 00101: val_loss did not improve from 0.06385\n",
      "40200/40200 [==============================] - 4s 93us/sample - loss: 0.1196 - acc: 0.9626 - val_loss: 0.0646 - val_acc: 0.9809\n",
      "Epoch 102/500\n",
      "39680/40200 [============================>.] - ETA: 0s - loss: 0.1191 - acc: 0.9626\n",
      "Epoch 00102: val_loss did not improve from 0.06385\n",
      "40200/40200 [==============================] - 4s 93us/sample - loss: 0.1192 - acc: 0.9626 - val_loss: 0.0644 - val_acc: 0.9811\n",
      "Epoch 103/500\n",
      "39744/40200 [============================>.] - ETA: 0s - loss: 0.1204 - acc: 0.9626\n",
      "Epoch 00103: val_loss did not improve from 0.06385\n",
      "40200/40200 [==============================] - 4s 93us/sample - loss: 0.1205 - acc: 0.9626 - val_loss: 0.0663 - val_acc: 0.9801\n",
      "Epoch 104/500\n",
      "39616/40200 [============================>.] - ETA: 0s - loss: 0.1181 - acc: 0.9628\n",
      "Epoch 00104: val_loss did not improve from 0.06385\n",
      "40200/40200 [==============================] - 4s 92us/sample - loss: 0.1183 - acc: 0.9629 - val_loss: 0.0643 - val_acc: 0.9813\n",
      "Epoch 105/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.1187 - acc: 0.9624\n",
      "Epoch 00105: val_loss did not improve from 0.06385\n",
      "40200/40200 [==============================] - 4s 92us/sample - loss: 0.1187 - acc: 0.9624 - val_loss: 0.0645 - val_acc: 0.9809\n",
      "Epoch 106/500\n",
      "39552/40200 [============================>.] - ETA: 0s - loss: 0.1171 - acc: 0.9627\n",
      "Epoch 00106: val_loss improved from 0.06385 to 0.06374, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_1_conv_checkpoint/106-0.0637.hdf5\n",
      "40200/40200 [==============================] - 3s 83us/sample - loss: 0.1179 - acc: 0.9625 - val_loss: 0.0637 - val_acc: 0.9816\n",
      "Epoch 107/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.1161 - acc: 0.9635\n",
      "Epoch 00107: val_loss did not improve from 0.06374\n",
      "40200/40200 [==============================] - 3s 86us/sample - loss: 0.1162 - acc: 0.9635 - val_loss: 0.0638 - val_acc: 0.9813\n",
      "Epoch 108/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.1225 - acc: 0.9611\n",
      "Epoch 00108: val_loss did not improve from 0.06374\n",
      "40200/40200 [==============================] - 4s 92us/sample - loss: 0.1225 - acc: 0.9612 - val_loss: 0.0649 - val_acc: 0.9813\n",
      "Epoch 109/500\n",
      "39616/40200 [============================>.] - ETA: 0s - loss: 0.1199 - acc: 0.9620\n",
      "Epoch 00109: val_loss did not improve from 0.06374\n",
      "40200/40200 [==============================] - 4s 93us/sample - loss: 0.1198 - acc: 0.9621 - val_loss: 0.0639 - val_acc: 0.9814\n",
      "Epoch 110/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.1226 - acc: 0.9610\n",
      "Epoch 00110: val_loss did not improve from 0.06374\n",
      "40200/40200 [==============================] - 4s 93us/sample - loss: 0.1225 - acc: 0.9611 - val_loss: 0.0638 - val_acc: 0.9810\n",
      "Epoch 111/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.1183 - acc: 0.9631\n",
      "Epoch 00111: val_loss did not improve from 0.06374\n",
      "40200/40200 [==============================] - 4s 92us/sample - loss: 0.1183 - acc: 0.9631 - val_loss: 0.0641 - val_acc: 0.9811\n",
      "Epoch 112/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.1179 - acc: 0.9622\n",
      "Epoch 00112: val_loss did not improve from 0.06374\n",
      "40200/40200 [==============================] - 4s 92us/sample - loss: 0.1178 - acc: 0.9622 - val_loss: 0.0642 - val_acc: 0.9808\n",
      "Epoch 113/500\n",
      "39616/40200 [============================>.] - ETA: 0s - loss: 0.1204 - acc: 0.9611\n",
      "Epoch 00113: val_loss did not improve from 0.06374\n",
      "40200/40200 [==============================] - 4s 92us/sample - loss: 0.1204 - acc: 0.9611 - val_loss: 0.0643 - val_acc: 0.9806\n",
      "Epoch 114/500\n",
      "39744/40200 [============================>.] - ETA: 0s - loss: 0.1167 - acc: 0.9618\n",
      "Epoch 00114: val_loss did not improve from 0.06374\n",
      "40200/40200 [==============================] - 4s 92us/sample - loss: 0.1164 - acc: 0.9618 - val_loss: 0.0641 - val_acc: 0.9813\n",
      "Epoch 115/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.1173 - acc: 0.9618\n",
      "Epoch 00115: val_loss did not improve from 0.06374\n",
      "40200/40200 [==============================] - 4s 92us/sample - loss: 0.1173 - acc: 0.9619 - val_loss: 0.0642 - val_acc: 0.9810\n",
      "Epoch 116/500\n",
      "39616/40200 [============================>.] - ETA: 0s - loss: 0.1192 - acc: 0.9625\n",
      "Epoch 00116: val_loss did not improve from 0.06374\n",
      "40200/40200 [==============================] - 4s 91us/sample - loss: 0.1190 - acc: 0.9626 - val_loss: 0.0638 - val_acc: 0.9805\n",
      "Epoch 117/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.1158 - acc: 0.9634\n",
      "Epoch 00117: val_loss did not improve from 0.06374\n",
      "40200/40200 [==============================] - 4s 92us/sample - loss: 0.1157 - acc: 0.9635 - val_loss: 0.0642 - val_acc: 0.9807\n",
      "Epoch 118/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.1191 - acc: 0.9621\n",
      "Epoch 00118: val_loss did not improve from 0.06374\n",
      "40200/40200 [==============================] - 4s 93us/sample - loss: 0.1191 - acc: 0.9621 - val_loss: 0.0639 - val_acc: 0.9814\n",
      "Epoch 119/500\n",
      "39744/40200 [============================>.] - ETA: 0s - loss: 0.1194 - acc: 0.9609\n",
      "Epoch 00119: val_loss did not improve from 0.06374\n",
      "40200/40200 [==============================] - 4s 93us/sample - loss: 0.1194 - acc: 0.9608 - val_loss: 0.0641 - val_acc: 0.9810\n",
      "Epoch 120/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.1198 - acc: 0.9616\n",
      "Epoch 00120: val_loss did not improve from 0.06374\n",
      "40200/40200 [==============================] - 4s 92us/sample - loss: 0.1197 - acc: 0.9616 - val_loss: 0.0642 - val_acc: 0.9805\n",
      "Epoch 121/500\n",
      "39680/40200 [============================>.] - ETA: 0s - loss: 0.1136 - acc: 0.9635\n",
      "Epoch 00121: val_loss improved from 0.06374 to 0.06338, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_1_conv_checkpoint/121-0.0634.hdf5\n",
      "40200/40200 [==============================] - 4s 93us/sample - loss: 0.1134 - acc: 0.9637 - val_loss: 0.0634 - val_acc: 0.9810\n",
      "Epoch 122/500\n",
      "39680/40200 [============================>.] - ETA: 0s - loss: 0.1160 - acc: 0.9634\n",
      "Epoch 00122: val_loss did not improve from 0.06338\n",
      "40200/40200 [==============================] - 3s 85us/sample - loss: 0.1157 - acc: 0.9635 - val_loss: 0.0649 - val_acc: 0.9811\n",
      "Epoch 123/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.1192 - acc: 0.9622\n",
      "Epoch 00123: val_loss did not improve from 0.06338\n",
      "40200/40200 [==============================] - 3s 84us/sample - loss: 0.1192 - acc: 0.9622 - val_loss: 0.0639 - val_acc: 0.9811\n",
      "Epoch 124/500\n",
      "39744/40200 [============================>.] - ETA: 0s - loss: 0.1212 - acc: 0.9607\n",
      "Epoch 00124: val_loss did not improve from 0.06338\n",
      "40200/40200 [==============================] - 4s 90us/sample - loss: 0.1210 - acc: 0.9608 - val_loss: 0.0647 - val_acc: 0.9804\n",
      "Epoch 125/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.1186 - acc: 0.9625\n",
      "Epoch 00125: val_loss did not improve from 0.06338\n",
      "40200/40200 [==============================] - 4s 93us/sample - loss: 0.1185 - acc: 0.9625 - val_loss: 0.0638 - val_acc: 0.9814\n",
      "Epoch 126/500\n",
      "39744/40200 [============================>.] - ETA: 0s - loss: 0.1156 - acc: 0.9629\n",
      "Epoch 00126: val_loss improved from 0.06338 to 0.06336, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_1_conv_checkpoint/126-0.0634.hdf5\n",
      "40200/40200 [==============================] - 4s 93us/sample - loss: 0.1156 - acc: 0.9630 - val_loss: 0.0634 - val_acc: 0.9812\n",
      "Epoch 127/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.1179 - acc: 0.9618\n",
      "Epoch 00127: val_loss did not improve from 0.06336\n",
      "40200/40200 [==============================] - 4s 92us/sample - loss: 0.1180 - acc: 0.9618 - val_loss: 0.0649 - val_acc: 0.9802\n",
      "Epoch 128/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.1203 - acc: 0.9613\n",
      "Epoch 00128: val_loss did not improve from 0.06336\n",
      "40200/40200 [==============================] - 4s 93us/sample - loss: 0.1202 - acc: 0.9614 - val_loss: 0.0636 - val_acc: 0.9807\n",
      "Epoch 129/500\n",
      "39680/40200 [============================>.] - ETA: 0s - loss: 0.1206 - acc: 0.9618\n",
      "Epoch 00129: val_loss did not improve from 0.06336\n",
      "40200/40200 [==============================] - 4s 92us/sample - loss: 0.1210 - acc: 0.9619 - val_loss: 0.0639 - val_acc: 0.9805\n",
      "Epoch 130/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.1193 - acc: 0.9626\n",
      "Epoch 00130: val_loss did not improve from 0.06336\n",
      "40200/40200 [==============================] - 4s 91us/sample - loss: 0.1193 - acc: 0.9626 - val_loss: 0.0643 - val_acc: 0.9801\n",
      "Epoch 131/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.1162 - acc: 0.9620\n",
      "Epoch 00131: val_loss did not improve from 0.06336\n",
      "40200/40200 [==============================] - 4s 92us/sample - loss: 0.1164 - acc: 0.9620 - val_loss: 0.0638 - val_acc: 0.9811\n",
      "Epoch 132/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.1157 - acc: 0.9632\n",
      "Epoch 00132: val_loss did not improve from 0.06336\n",
      "40200/40200 [==============================] - 4s 93us/sample - loss: 0.1156 - acc: 0.9632 - val_loss: 0.0638 - val_acc: 0.9804\n",
      "Epoch 133/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.1182 - acc: 0.9625\n",
      "Epoch 00133: val_loss did not improve from 0.06336\n",
      "40200/40200 [==============================] - 4s 92us/sample - loss: 0.1181 - acc: 0.9625 - val_loss: 0.0637 - val_acc: 0.9810\n",
      "Epoch 134/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.1170 - acc: 0.9618\n",
      "Epoch 00134: val_loss did not improve from 0.06336\n",
      "40200/40200 [==============================] - 4s 92us/sample - loss: 0.1167 - acc: 0.9619 - val_loss: 0.0634 - val_acc: 0.9812\n",
      "Epoch 135/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.1181 - acc: 0.9624\n",
      "Epoch 00135: val_loss improved from 0.06336 to 0.06331, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_1_conv_checkpoint/135-0.0633.hdf5\n",
      "40200/40200 [==============================] - 4s 92us/sample - loss: 0.1181 - acc: 0.9623 - val_loss: 0.0633 - val_acc: 0.9813\n",
      "Epoch 136/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.1184 - acc: 0.9631\n",
      "Epoch 00136: val_loss improved from 0.06331 to 0.06310, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_1_conv_checkpoint/136-0.0631.hdf5\n",
      "40200/40200 [==============================] - 4s 93us/sample - loss: 0.1181 - acc: 0.9633 - val_loss: 0.0631 - val_acc: 0.9805\n",
      "Epoch 137/500\n",
      "39680/40200 [============================>.] - ETA: 0s - loss: 0.1156 - acc: 0.9623\n",
      "Epoch 00137: val_loss did not improve from 0.06310\n",
      "40200/40200 [==============================] - 4s 92us/sample - loss: 0.1159 - acc: 0.9623 - val_loss: 0.0635 - val_acc: 0.9809\n",
      "Epoch 138/500\n",
      "39616/40200 [============================>.] - ETA: 0s - loss: 0.1218 - acc: 0.9621\n",
      "Epoch 00138: val_loss did not improve from 0.06310\n",
      "40200/40200 [==============================] - 4s 93us/sample - loss: 0.1219 - acc: 0.9622 - val_loss: 0.0634 - val_acc: 0.9815\n",
      "Epoch 139/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.1163 - acc: 0.9632\n",
      "Epoch 00139: val_loss improved from 0.06310 to 0.06301, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_1_conv_checkpoint/139-0.0630.hdf5\n",
      "40200/40200 [==============================] - 3s 85us/sample - loss: 0.1163 - acc: 0.9632 - val_loss: 0.0630 - val_acc: 0.9817\n",
      "Epoch 140/500\n",
      "39488/40200 [============================>.] - ETA: 0s - loss: 0.1188 - acc: 0.9625\n",
      "Epoch 00140: val_loss did not improve from 0.06301\n",
      "40200/40200 [==============================] - 3s 83us/sample - loss: 0.1192 - acc: 0.9623 - val_loss: 0.0635 - val_acc: 0.9815\n",
      "Epoch 141/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.1173 - acc: 0.9622\n",
      "Epoch 00141: val_loss did not improve from 0.06301\n",
      "40200/40200 [==============================] - 4s 92us/sample - loss: 0.1170 - acc: 0.9623 - val_loss: 0.0633 - val_acc: 0.9814\n",
      "Epoch 142/500\n",
      "39616/40200 [============================>.] - ETA: 0s - loss: 0.1142 - acc: 0.9634\n",
      "Epoch 00142: val_loss did not improve from 0.06301\n",
      "40200/40200 [==============================] - 4s 92us/sample - loss: 0.1143 - acc: 0.9634 - val_loss: 0.0643 - val_acc: 0.9819\n",
      "Epoch 143/500\n",
      "39616/40200 [============================>.] - ETA: 0s - loss: 0.1159 - acc: 0.9636\n",
      "Epoch 00143: val_loss did not improve from 0.06301\n",
      "40200/40200 [==============================] - 4s 92us/sample - loss: 0.1155 - acc: 0.9636 - val_loss: 0.0634 - val_acc: 0.9812\n",
      "Epoch 144/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.1170 - acc: 0.9628\n",
      "Epoch 00144: val_loss did not improve from 0.06301\n",
      "40200/40200 [==============================] - 4s 91us/sample - loss: 0.1169 - acc: 0.9628 - val_loss: 0.0634 - val_acc: 0.9809\n",
      "Epoch 145/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.1164 - acc: 0.9633\n",
      "Epoch 00145: val_loss did not improve from 0.06301\n",
      "40200/40200 [==============================] - 4s 93us/sample - loss: 0.1164 - acc: 0.9633 - val_loss: 0.0639 - val_acc: 0.9812\n",
      "Epoch 146/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.1163 - acc: 0.9629\n",
      "Epoch 00146: val_loss did not improve from 0.06301\n",
      "40200/40200 [==============================] - 4s 92us/sample - loss: 0.1171 - acc: 0.9628 - val_loss: 0.0633 - val_acc: 0.9812\n",
      "Epoch 147/500\n",
      "39616/40200 [============================>.] - ETA: 0s - loss: 0.1158 - acc: 0.9623\n",
      "Epoch 00147: val_loss did not improve from 0.06301\n",
      "40200/40200 [==============================] - 4s 91us/sample - loss: 0.1161 - acc: 0.9622 - val_loss: 0.0642 - val_acc: 0.9812\n",
      "Epoch 148/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.1165 - acc: 0.9629\n",
      "Epoch 00148: val_loss did not improve from 0.06301\n",
      "40200/40200 [==============================] - 4s 93us/sample - loss: 0.1166 - acc: 0.9629 - val_loss: 0.0631 - val_acc: 0.9810\n",
      "Epoch 149/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.1173 - acc: 0.9630\n",
      "Epoch 00149: val_loss improved from 0.06301 to 0.06269, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_1_conv_checkpoint/149-0.0627.hdf5\n",
      "40200/40200 [==============================] - 4s 93us/sample - loss: 0.1173 - acc: 0.9629 - val_loss: 0.0627 - val_acc: 0.9813\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 150/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.1153 - acc: 0.9638\n",
      "Epoch 00150: val_loss did not improve from 0.06269\n",
      "40200/40200 [==============================] - 4s 91us/sample - loss: 0.1152 - acc: 0.9637 - val_loss: 0.0630 - val_acc: 0.9814\n",
      "Epoch 151/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.1154 - acc: 0.9631\n",
      "Epoch 00151: val_loss did not improve from 0.06269\n",
      "40200/40200 [==============================] - 4s 92us/sample - loss: 0.1152 - acc: 0.9632 - val_loss: 0.0643 - val_acc: 0.9809\n",
      "Epoch 152/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.1189 - acc: 0.9622\n",
      "Epoch 00152: val_loss did not improve from 0.06269\n",
      "40200/40200 [==============================] - 4s 92us/sample - loss: 0.1189 - acc: 0.9622 - val_loss: 0.0627 - val_acc: 0.9814\n",
      "Epoch 153/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.1162 - acc: 0.9640\n",
      "Epoch 00153: val_loss did not improve from 0.06269\n",
      "40200/40200 [==============================] - 4s 92us/sample - loss: 0.1163 - acc: 0.9641 - val_loss: 0.0647 - val_acc: 0.9810\n",
      "Epoch 154/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.1156 - acc: 0.9630\n",
      "Epoch 00154: val_loss did not improve from 0.06269\n",
      "40200/40200 [==============================] - 4s 91us/sample - loss: 0.1153 - acc: 0.9631 - val_loss: 0.0634 - val_acc: 0.9813\n",
      "Epoch 155/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.1159 - acc: 0.9632\n",
      "Epoch 00155: val_loss did not improve from 0.06269\n",
      "40200/40200 [==============================] - 3s 86us/sample - loss: 0.1158 - acc: 0.9631 - val_loss: 0.0629 - val_acc: 0.9815\n",
      "Epoch 156/500\n",
      "39680/40200 [============================>.] - ETA: 0s - loss: 0.1130 - acc: 0.9633\n",
      "Epoch 00156: val_loss did not improve from 0.06269\n",
      "40200/40200 [==============================] - 3s 81us/sample - loss: 0.1123 - acc: 0.9634 - val_loss: 0.0641 - val_acc: 0.9813\n",
      "Epoch 157/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.1176 - acc: 0.9635\n",
      "Epoch 00157: val_loss did not improve from 0.06269\n",
      "40200/40200 [==============================] - 3s 87us/sample - loss: 0.1175 - acc: 0.9636 - val_loss: 0.0644 - val_acc: 0.9813\n",
      "Epoch 158/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.1134 - acc: 0.9632\n",
      "Epoch 00158: val_loss did not improve from 0.06269\n",
      "40200/40200 [==============================] - 4s 93us/sample - loss: 0.1135 - acc: 0.9632 - val_loss: 0.0637 - val_acc: 0.9814\n",
      "Epoch 159/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.1161 - acc: 0.9633\n",
      "Epoch 00159: val_loss improved from 0.06269 to 0.06251, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_1_conv_checkpoint/159-0.0625.hdf5\n",
      "40200/40200 [==============================] - 4s 90us/sample - loss: 0.1163 - acc: 0.9633 - val_loss: 0.0625 - val_acc: 0.9817\n",
      "Epoch 160/500\n",
      "39744/40200 [============================>.] - ETA: 0s - loss: 0.1155 - acc: 0.9628\n",
      "Epoch 00160: val_loss did not improve from 0.06251\n",
      "40200/40200 [==============================] - 4s 93us/sample - loss: 0.1154 - acc: 0.9628 - val_loss: 0.0634 - val_acc: 0.9815\n",
      "Epoch 161/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.1130 - acc: 0.9636\n",
      "Epoch 00161: val_loss did not improve from 0.06251\n",
      "40200/40200 [==============================] - 4s 92us/sample - loss: 0.1132 - acc: 0.9637 - val_loss: 0.0630 - val_acc: 0.9812\n",
      "Epoch 162/500\n",
      "39616/40200 [============================>.] - ETA: 0s - loss: 0.1140 - acc: 0.9643\n",
      "Epoch 00162: val_loss did not improve from 0.06251\n",
      "40200/40200 [==============================] - 4s 92us/sample - loss: 0.1141 - acc: 0.9643 - val_loss: 0.0633 - val_acc: 0.9812\n",
      "Epoch 163/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.1131 - acc: 0.9642\n",
      "Epoch 00163: val_loss did not improve from 0.06251\n",
      "40200/40200 [==============================] - 4s 91us/sample - loss: 0.1131 - acc: 0.9642 - val_loss: 0.0630 - val_acc: 0.9817\n",
      "Epoch 164/500\n",
      "39744/40200 [============================>.] - ETA: 0s - loss: 0.1173 - acc: 0.9625\n",
      "Epoch 00164: val_loss did not improve from 0.06251\n",
      "40200/40200 [==============================] - 4s 92us/sample - loss: 0.1176 - acc: 0.9625 - val_loss: 0.0638 - val_acc: 0.9810\n",
      "Epoch 165/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.1113 - acc: 0.9640\n",
      "Epoch 00165: val_loss did not improve from 0.06251\n",
      "40200/40200 [==============================] - 4s 92us/sample - loss: 0.1116 - acc: 0.9640 - val_loss: 0.0625 - val_acc: 0.9815\n",
      "Epoch 166/500\n",
      "39616/40200 [============================>.] - ETA: 0s - loss: 0.1131 - acc: 0.9650\n",
      "Epoch 00166: val_loss did not improve from 0.06251\n",
      "40200/40200 [==============================] - 4s 92us/sample - loss: 0.1141 - acc: 0.9649 - val_loss: 0.0627 - val_acc: 0.9818\n",
      "Epoch 167/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.1171 - acc: 0.9616\n",
      "Epoch 00167: val_loss did not improve from 0.06251\n",
      "40200/40200 [==============================] - 4s 91us/sample - loss: 0.1171 - acc: 0.9616 - val_loss: 0.0629 - val_acc: 0.9819\n",
      "Epoch 168/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.1133 - acc: 0.9646\n",
      "Epoch 00168: val_loss did not improve from 0.06251\n",
      "40200/40200 [==============================] - 4s 91us/sample - loss: 0.1133 - acc: 0.9646 - val_loss: 0.0626 - val_acc: 0.9814\n",
      "Epoch 169/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.1172 - acc: 0.9622\n",
      "Epoch 00169: val_loss did not improve from 0.06251\n",
      "40200/40200 [==============================] - 4s 91us/sample - loss: 0.1172 - acc: 0.9622 - val_loss: 0.0626 - val_acc: 0.9817\n",
      "Epoch 170/500\n",
      "39680/40200 [============================>.] - ETA: 0s - loss: 0.1149 - acc: 0.9630\n",
      "Epoch 00170: val_loss did not improve from 0.06251\n",
      "40200/40200 [==============================] - 4s 92us/sample - loss: 0.1147 - acc: 0.9631 - val_loss: 0.0632 - val_acc: 0.9813\n",
      "Epoch 171/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.1135 - acc: 0.9644\n",
      "Epoch 00171: val_loss did not improve from 0.06251\n",
      "40200/40200 [==============================] - 4s 92us/sample - loss: 0.1134 - acc: 0.9645 - val_loss: 0.0641 - val_acc: 0.9811\n",
      "Epoch 172/500\n",
      "39744/40200 [============================>.] - ETA: 0s - loss: 0.1124 - acc: 0.9648\n",
      "Epoch 00172: val_loss improved from 0.06251 to 0.06230, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_1_conv_checkpoint/172-0.0623.hdf5\n",
      "40200/40200 [==============================] - 3s 86us/sample - loss: 0.1130 - acc: 0.9646 - val_loss: 0.0623 - val_acc: 0.9815\n",
      "Epoch 173/500\n",
      "39488/40200 [============================>.] - ETA: 0s - loss: 0.1134 - acc: 0.9647\n",
      "Epoch 00173: val_loss did not improve from 0.06230\n",
      "40200/40200 [==============================] - 3s 83us/sample - loss: 0.1132 - acc: 0.9648 - val_loss: 0.0629 - val_acc: 0.9814\n",
      "Epoch 174/500\n",
      "39552/40200 [============================>.] - ETA: 0s - loss: 0.1169 - acc: 0.9634\n",
      "Epoch 00174: val_loss did not improve from 0.06230\n",
      "40200/40200 [==============================] - 4s 89us/sample - loss: 0.1167 - acc: 0.9633 - val_loss: 0.0627 - val_acc: 0.9815\n",
      "Epoch 175/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.1176 - acc: 0.9636\n",
      "Epoch 00175: val_loss did not improve from 0.06230\n",
      "40200/40200 [==============================] - 4s 92us/sample - loss: 0.1174 - acc: 0.9636 - val_loss: 0.0629 - val_acc: 0.9811\n",
      "Epoch 176/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.1144 - acc: 0.9637\n",
      "Epoch 00176: val_loss did not improve from 0.06230\n",
      "40200/40200 [==============================] - 4s 91us/sample - loss: 0.1142 - acc: 0.9638 - val_loss: 0.0627 - val_acc: 0.9819\n",
      "Epoch 177/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.1150 - acc: 0.9645\n",
      "Epoch 00177: val_loss did not improve from 0.06230\n",
      "40200/40200 [==============================] - 4s 91us/sample - loss: 0.1149 - acc: 0.9645 - val_loss: 0.0636 - val_acc: 0.9816\n",
      "Epoch 178/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.1140 - acc: 0.9638\n",
      "Epoch 00178: val_loss did not improve from 0.06230\n",
      "40200/40200 [==============================] - 4s 92us/sample - loss: 0.1137 - acc: 0.9638 - val_loss: 0.0628 - val_acc: 0.9818\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 179/500\n",
      "39552/40200 [============================>.] - ETA: 0s - loss: 0.1123 - acc: 0.9640\n",
      "Epoch 00179: val_loss improved from 0.06230 to 0.06222, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_1_conv_checkpoint/179-0.0622.hdf5\n",
      "40200/40200 [==============================] - 4s 93us/sample - loss: 0.1125 - acc: 0.9640 - val_loss: 0.0622 - val_acc: 0.9816\n",
      "Epoch 180/500\n",
      "39680/40200 [============================>.] - ETA: 0s - loss: 0.1175 - acc: 0.9641\n",
      "Epoch 00180: val_loss did not improve from 0.06222\n",
      "40200/40200 [==============================] - 4s 92us/sample - loss: 0.1174 - acc: 0.9640 - val_loss: 0.0626 - val_acc: 0.9815\n",
      "Epoch 181/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.1164 - acc: 0.9630\n",
      "Epoch 00181: val_loss did not improve from 0.06222\n",
      "40200/40200 [==============================] - 4s 93us/sample - loss: 0.1162 - acc: 0.9631 - val_loss: 0.0623 - val_acc: 0.9821\n",
      "Epoch 182/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.1170 - acc: 0.9629\n",
      "Epoch 00182: val_loss improved from 0.06222 to 0.06189, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_1_conv_checkpoint/182-0.0619.hdf5\n",
      "40200/40200 [==============================] - 4s 93us/sample - loss: 0.1170 - acc: 0.9629 - val_loss: 0.0619 - val_acc: 0.9820\n",
      "Epoch 183/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.1141 - acc: 0.9641\n",
      "Epoch 00183: val_loss did not improve from 0.06189\n",
      "40200/40200 [==============================] - 4s 92us/sample - loss: 0.1140 - acc: 0.9642 - val_loss: 0.0628 - val_acc: 0.9811\n",
      "Epoch 184/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.1105 - acc: 0.9642\n",
      "Epoch 00184: val_loss did not improve from 0.06189\n",
      "40200/40200 [==============================] - 4s 92us/sample - loss: 0.1106 - acc: 0.9641 - val_loss: 0.0626 - val_acc: 0.9811\n",
      "Epoch 185/500\n",
      "39552/40200 [============================>.] - ETA: 0s - loss: 0.1151 - acc: 0.9631\n",
      "Epoch 00185: val_loss did not improve from 0.06189\n",
      "40200/40200 [==============================] - 4s 91us/sample - loss: 0.1160 - acc: 0.9627 - val_loss: 0.0627 - val_acc: 0.9814\n",
      "Epoch 186/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.1170 - acc: 0.9633\n",
      "Epoch 00186: val_loss improved from 0.06189 to 0.06151, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_1_conv_checkpoint/186-0.0615.hdf5\n",
      "40200/40200 [==============================] - 4s 92us/sample - loss: 0.1170 - acc: 0.9633 - val_loss: 0.0615 - val_acc: 0.9816\n",
      "Epoch 187/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.1148 - acc: 0.9648\n",
      "Epoch 00187: val_loss did not improve from 0.06151\n",
      "40200/40200 [==============================] - 4s 92us/sample - loss: 0.1147 - acc: 0.9648 - val_loss: 0.0620 - val_acc: 0.9818\n",
      "Epoch 188/500\n",
      "39744/40200 [============================>.] - ETA: 0s - loss: 0.1114 - acc: 0.9647\n",
      "Epoch 00188: val_loss did not improve from 0.06151\n",
      "40200/40200 [==============================] - 4s 92us/sample - loss: 0.1113 - acc: 0.9647 - val_loss: 0.0637 - val_acc: 0.9812\n",
      "Epoch 189/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.1123 - acc: 0.9647\n",
      "Epoch 00189: val_loss did not improve from 0.06151\n",
      "40200/40200 [==============================] - 3s 84us/sample - loss: 0.1121 - acc: 0.9649 - val_loss: 0.0635 - val_acc: 0.9818\n",
      "Epoch 190/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.1132 - acc: 0.9642\n",
      "Epoch 00190: val_loss did not improve from 0.06151\n",
      "40200/40200 [==============================] - 3s 85us/sample - loss: 0.1129 - acc: 0.9644 - val_loss: 0.0628 - val_acc: 0.9819\n",
      "Epoch 191/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.1115 - acc: 0.9641\n",
      "Epoch 00191: val_loss did not improve from 0.06151\n",
      "40200/40200 [==============================] - 4s 93us/sample - loss: 0.1115 - acc: 0.9641 - val_loss: 0.0636 - val_acc: 0.9814\n",
      "Epoch 192/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.1140 - acc: 0.9646\n",
      "Epoch 00192: val_loss did not improve from 0.06151\n",
      "40200/40200 [==============================] - 4s 92us/sample - loss: 0.1137 - acc: 0.9648 - val_loss: 0.0620 - val_acc: 0.9819\n",
      "Epoch 193/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.1125 - acc: 0.9645\n",
      "Epoch 00193: val_loss did not improve from 0.06151\n",
      "40200/40200 [==============================] - 4s 91us/sample - loss: 0.1127 - acc: 0.9645 - val_loss: 0.0621 - val_acc: 0.9826\n",
      "Epoch 194/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.1135 - acc: 0.9646\n",
      "Epoch 00194: val_loss did not improve from 0.06151\n",
      "40200/40200 [==============================] - 4s 91us/sample - loss: 0.1135 - acc: 0.9646 - val_loss: 0.0640 - val_acc: 0.9814\n",
      "Epoch 195/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.1116 - acc: 0.9653\n",
      "Epoch 00195: val_loss did not improve from 0.06151\n",
      "40200/40200 [==============================] - 4s 91us/sample - loss: 0.1117 - acc: 0.9652 - val_loss: 0.0619 - val_acc: 0.9823\n",
      "Epoch 196/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.1105 - acc: 0.9657\n",
      "Epoch 00196: val_loss did not improve from 0.06151\n",
      "40200/40200 [==============================] - 4s 92us/sample - loss: 0.1108 - acc: 0.9656 - val_loss: 0.0653 - val_acc: 0.9804\n",
      "Epoch 197/500\n",
      "39616/40200 [============================>.] - ETA: 0s - loss: 0.1107 - acc: 0.9644\n",
      "Epoch 00197: val_loss did not improve from 0.06151\n",
      "40200/40200 [==============================] - 4s 93us/sample - loss: 0.1107 - acc: 0.9643 - val_loss: 0.0632 - val_acc: 0.9811\n",
      "Epoch 198/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.1159 - acc: 0.9638\n",
      "Epoch 00198: val_loss did not improve from 0.06151\n",
      "40200/40200 [==============================] - 4s 91us/sample - loss: 0.1157 - acc: 0.9639 - val_loss: 0.0632 - val_acc: 0.9814\n",
      "Epoch 199/500\n",
      "39680/40200 [============================>.] - ETA: 0s - loss: 0.1112 - acc: 0.9639\n",
      "Epoch 00199: val_loss did not improve from 0.06151\n",
      "40200/40200 [==============================] - 4s 93us/sample - loss: 0.1113 - acc: 0.9638 - val_loss: 0.0625 - val_acc: 0.9816\n",
      "Epoch 200/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.1147 - acc: 0.9635\n",
      "Epoch 00200: val_loss did not improve from 0.06151\n",
      "40200/40200 [==============================] - 4s 92us/sample - loss: 0.1147 - acc: 0.9634 - val_loss: 0.0618 - val_acc: 0.9817\n",
      "Epoch 201/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.1142 - acc: 0.9640\n",
      "Epoch 00201: val_loss did not improve from 0.06151\n",
      "40200/40200 [==============================] - 4s 92us/sample - loss: 0.1144 - acc: 0.9640 - val_loss: 0.0637 - val_acc: 0.9808\n",
      "Epoch 202/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.1154 - acc: 0.9635\n",
      "Epoch 00202: val_loss did not improve from 0.06151\n",
      "40200/40200 [==============================] - 4s 92us/sample - loss: 0.1154 - acc: 0.9635 - val_loss: 0.0625 - val_acc: 0.9815\n",
      "Epoch 203/500\n",
      "39552/40200 [============================>.] - ETA: 0s - loss: 0.1152 - acc: 0.9635\n",
      "Epoch 00203: val_loss did not improve from 0.06151\n",
      "40200/40200 [==============================] - 4s 92us/sample - loss: 0.1148 - acc: 0.9637 - val_loss: 0.0626 - val_acc: 0.9819\n",
      "Epoch 204/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.1134 - acc: 0.9645\n",
      "Epoch 00204: val_loss did not improve from 0.06151\n",
      "40200/40200 [==============================] - 4s 91us/sample - loss: 0.1132 - acc: 0.9646 - val_loss: 0.0634 - val_acc: 0.9810\n",
      "Epoch 205/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.1143 - acc: 0.9631\n",
      "Epoch 00205: val_loss did not improve from 0.06151\n",
      "40200/40200 [==============================] - 3s 86us/sample - loss: 0.1146 - acc: 0.9630 - val_loss: 0.0624 - val_acc: 0.9814\n",
      "Epoch 206/500\n",
      "39680/40200 [============================>.] - ETA: 0s - loss: 0.1137 - acc: 0.9649\n",
      "Epoch 00206: val_loss did not improve from 0.06151\n",
      "40200/40200 [==============================] - 3s 84us/sample - loss: 0.1139 - acc: 0.9647 - val_loss: 0.0620 - val_acc: 0.9815\n",
      "Epoch 207/500\n",
      "39680/40200 [============================>.] - ETA: 0s - loss: 0.1123 - acc: 0.9637\n",
      "Epoch 00207: val_loss did not improve from 0.06151\n",
      "40200/40200 [==============================] - 4s 91us/sample - loss: 0.1122 - acc: 0.9638 - val_loss: 0.0641 - val_acc: 0.9810\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 208/500\n",
      "39616/40200 [============================>.] - ETA: 0s - loss: 0.1106 - acc: 0.9649\n",
      "Epoch 00208: val_loss did not improve from 0.06151\n",
      "40200/40200 [==============================] - 4s 92us/sample - loss: 0.1110 - acc: 0.9649 - val_loss: 0.0637 - val_acc: 0.9808\n",
      "Epoch 209/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.1134 - acc: 0.9632\n",
      "Epoch 00209: val_loss did not improve from 0.06151\n",
      "40200/40200 [==============================] - 4s 92us/sample - loss: 0.1132 - acc: 0.9632 - val_loss: 0.0624 - val_acc: 0.9815\n",
      "Epoch 210/500\n",
      "39616/40200 [============================>.] - ETA: 0s - loss: 0.1109 - acc: 0.9646\n",
      "Epoch 00210: val_loss did not improve from 0.06151\n",
      "40200/40200 [==============================] - 4s 92us/sample - loss: 0.1112 - acc: 0.9645 - val_loss: 0.0622 - val_acc: 0.9815\n",
      "Epoch 211/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.1159 - acc: 0.9635\n",
      "Epoch 00211: val_loss did not improve from 0.06151\n",
      "40200/40200 [==============================] - 4s 93us/sample - loss: 0.1158 - acc: 0.9635 - val_loss: 0.0624 - val_acc: 0.9817\n",
      "Epoch 212/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.1127 - acc: 0.9643\n",
      "Epoch 00212: val_loss did not improve from 0.06151\n",
      "40200/40200 [==============================] - 4s 92us/sample - loss: 0.1126 - acc: 0.9644 - val_loss: 0.0629 - val_acc: 0.9812\n",
      "Epoch 213/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.1098 - acc: 0.9651\n",
      "Epoch 00213: val_loss did not improve from 0.06151\n",
      "40200/40200 [==============================] - 4s 92us/sample - loss: 0.1099 - acc: 0.9650 - val_loss: 0.0620 - val_acc: 0.9818\n",
      "Epoch 214/500\n",
      "39744/40200 [============================>.] - ETA: 0s - loss: 0.1131 - acc: 0.9640\n",
      "Epoch 00214: val_loss did not improve from 0.06151\n",
      "40200/40200 [==============================] - 4s 92us/sample - loss: 0.1132 - acc: 0.9640 - val_loss: 0.0619 - val_acc: 0.9819\n",
      "Epoch 215/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.1102 - acc: 0.9643\n",
      "Epoch 00215: val_loss did not improve from 0.06151\n",
      "40200/40200 [==============================] - 4s 92us/sample - loss: 0.1102 - acc: 0.9643 - val_loss: 0.0622 - val_acc: 0.9818\n",
      "Epoch 216/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.1108 - acc: 0.9644\n",
      "Epoch 00216: val_loss did not improve from 0.06151\n",
      "40200/40200 [==============================] - 4s 92us/sample - loss: 0.1104 - acc: 0.9645 - val_loss: 0.0624 - val_acc: 0.9819\n",
      "Epoch 217/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.1127 - acc: 0.9649\n",
      "Epoch 00217: val_loss did not improve from 0.06151\n",
      "40200/40200 [==============================] - 4s 93us/sample - loss: 0.1126 - acc: 0.9649 - val_loss: 0.0636 - val_acc: 0.9811\n",
      "Epoch 218/500\n",
      "39616/40200 [============================>.] - ETA: 0s - loss: 0.1121 - acc: 0.9641\n",
      "Epoch 00218: val_loss did not improve from 0.06151\n",
      "40200/40200 [==============================] - 4s 92us/sample - loss: 0.1120 - acc: 0.9641 - val_loss: 0.0635 - val_acc: 0.9818\n",
      "Epoch 219/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.1146 - acc: 0.9631\n",
      "Epoch 00219: val_loss did not improve from 0.06151\n",
      "40200/40200 [==============================] - 4s 92us/sample - loss: 0.1144 - acc: 0.9631 - val_loss: 0.0628 - val_acc: 0.9817\n",
      "Epoch 220/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.1118 - acc: 0.9632\n",
      "Epoch 00220: val_loss did not improve from 0.06151\n",
      "40200/40200 [==============================] - 4s 93us/sample - loss: 0.1119 - acc: 0.9632 - val_loss: 0.0630 - val_acc: 0.9812\n",
      "Epoch 221/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.1121 - acc: 0.9642\n",
      "Epoch 00221: val_loss did not improve from 0.06151\n",
      "40200/40200 [==============================] - 4s 91us/sample - loss: 0.1120 - acc: 0.9642 - val_loss: 0.0633 - val_acc: 0.9814\n",
      "Epoch 222/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.1152 - acc: 0.9635\n",
      "Epoch 00222: val_loss did not improve from 0.06151\n",
      "40200/40200 [==============================] - 3s 83us/sample - loss: 0.1154 - acc: 0.9635 - val_loss: 0.0640 - val_acc: 0.9806\n",
      "Epoch 223/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.1103 - acc: 0.9643\n",
      "Epoch 00223: val_loss did not improve from 0.06151\n",
      "40200/40200 [==============================] - 3s 84us/sample - loss: 0.1103 - acc: 0.9644 - val_loss: 0.0638 - val_acc: 0.9807\n",
      "Epoch 224/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.1120 - acc: 0.9655\n",
      "Epoch 00224: val_loss did not improve from 0.06151\n",
      "40200/40200 [==============================] - 4s 92us/sample - loss: 0.1122 - acc: 0.9654 - val_loss: 0.0624 - val_acc: 0.9815\n",
      "Epoch 225/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.1130 - acc: 0.9635\n",
      "Epoch 00225: val_loss did not improve from 0.06151\n",
      "40200/40200 [==============================] - 4s 93us/sample - loss: 0.1134 - acc: 0.9635 - val_loss: 0.0624 - val_acc: 0.9813\n",
      "Epoch 226/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.1103 - acc: 0.9656\n",
      "Epoch 00226: val_loss did not improve from 0.06151\n",
      "40200/40200 [==============================] - 4s 92us/sample - loss: 0.1103 - acc: 0.9656 - val_loss: 0.0621 - val_acc: 0.9816\n",
      "Epoch 227/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.1141 - acc: 0.9639\n",
      "Epoch 00227: val_loss did not improve from 0.06151\n",
      "40200/40200 [==============================] - 4s 93us/sample - loss: 0.1139 - acc: 0.9640 - val_loss: 0.0621 - val_acc: 0.9817\n",
      "Epoch 228/500\n",
      "39616/40200 [============================>.] - ETA: 0s - loss: 0.1109 - acc: 0.9645\n",
      "Epoch 00228: val_loss did not improve from 0.06151\n",
      "40200/40200 [==============================] - 4s 92us/sample - loss: 0.1105 - acc: 0.9647 - val_loss: 0.0628 - val_acc: 0.9817\n",
      "Epoch 229/500\n",
      "39744/40200 [============================>.] - ETA: 0s - loss: 0.1118 - acc: 0.9654\n",
      "Epoch 00229: val_loss improved from 0.06151 to 0.06132, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_1_conv_checkpoint/229-0.0613.hdf5\n",
      "40200/40200 [==============================] - 4s 93us/sample - loss: 0.1116 - acc: 0.9655 - val_loss: 0.0613 - val_acc: 0.9815\n",
      "Epoch 230/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.1142 - acc: 0.9657\n",
      "Epoch 00230: val_loss did not improve from 0.06132\n",
      "40200/40200 [==============================] - 4s 92us/sample - loss: 0.1146 - acc: 0.9655 - val_loss: 0.0615 - val_acc: 0.9817\n",
      "Epoch 231/500\n",
      "39552/40200 [============================>.] - ETA: 0s - loss: 0.1152 - acc: 0.9641\n",
      "Epoch 00231: val_loss did not improve from 0.06132\n",
      "40200/40200 [==============================] - 4s 93us/sample - loss: 0.1148 - acc: 0.9643 - val_loss: 0.0627 - val_acc: 0.9809\n",
      "Epoch 232/500\n",
      "39616/40200 [============================>.] - ETA: 0s - loss: 0.1133 - acc: 0.9639\n",
      "Epoch 00232: val_loss did not improve from 0.06132\n",
      "40200/40200 [==============================] - 4s 93us/sample - loss: 0.1138 - acc: 0.9638 - val_loss: 0.0620 - val_acc: 0.9812\n",
      "Epoch 233/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.1147 - acc: 0.9629\n",
      "Epoch 00233: val_loss did not improve from 0.06132\n",
      "40200/40200 [==============================] - 4s 93us/sample - loss: 0.1147 - acc: 0.9629 - val_loss: 0.0618 - val_acc: 0.9814\n",
      "Epoch 234/500\n",
      "39744/40200 [============================>.] - ETA: 0s - loss: 0.1138 - acc: 0.9636\n",
      "Epoch 00234: val_loss did not improve from 0.06132\n",
      "40200/40200 [==============================] - 4s 90us/sample - loss: 0.1134 - acc: 0.9637 - val_loss: 0.0634 - val_acc: 0.9808\n",
      "Epoch 235/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.1119 - acc: 0.9637\n",
      "Epoch 00235: val_loss did not improve from 0.06132\n",
      "40200/40200 [==============================] - 4s 89us/sample - loss: 0.1122 - acc: 0.9637 - val_loss: 0.0614 - val_acc: 0.9814\n",
      "Epoch 236/500\n",
      "39680/40200 [============================>.] - ETA: 0s - loss: 0.1150 - acc: 0.9636\n",
      "Epoch 00236: val_loss did not improve from 0.06132\n",
      "40200/40200 [==============================] - 4s 92us/sample - loss: 0.1152 - acc: 0.9636 - val_loss: 0.0632 - val_acc: 0.9812\n",
      "Epoch 237/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.1097 - acc: 0.9644\n",
      "Epoch 00237: val_loss did not improve from 0.06132\n",
      "40200/40200 [==============================] - 4s 92us/sample - loss: 0.1097 - acc: 0.9644 - val_loss: 0.0632 - val_acc: 0.9813\n",
      "Epoch 238/500\n",
      "39680/40200 [============================>.] - ETA: 0s - loss: 0.1162 - acc: 0.9635\n",
      "Epoch 00238: val_loss did not improve from 0.06132\n",
      "40200/40200 [==============================] - 4s 89us/sample - loss: 0.1160 - acc: 0.9636 - val_loss: 0.0627 - val_acc: 0.9818\n",
      "Epoch 239/500\n",
      "39552/40200 [============================>.] - ETA: 0s - loss: 0.1145 - acc: 0.9639\n",
      "Epoch 00239: val_loss did not improve from 0.06132\n",
      "40200/40200 [==============================] - 3s 84us/sample - loss: 0.1143 - acc: 0.9640 - val_loss: 0.0628 - val_acc: 0.9815\n",
      "Epoch 240/500\n",
      "39680/40200 [============================>.] - ETA: 0s - loss: 0.1115 - acc: 0.9647\n",
      "Epoch 00240: val_loss did not improve from 0.06132\n",
      "40200/40200 [==============================] - 4s 88us/sample - loss: 0.1119 - acc: 0.9648 - val_loss: 0.0623 - val_acc: 0.9820\n",
      "Epoch 241/500\n",
      "39616/40200 [============================>.] - ETA: 0s - loss: 0.1081 - acc: 0.9655\n",
      "Epoch 00241: val_loss did not improve from 0.06132\n",
      "40200/40200 [==============================] - 4s 92us/sample - loss: 0.1077 - acc: 0.9657 - val_loss: 0.0632 - val_acc: 0.9817\n",
      "Epoch 242/500\n",
      "39616/40200 [============================>.] - ETA: 0s - loss: 0.1133 - acc: 0.9651\n",
      "Epoch 00242: val_loss did not improve from 0.06132\n",
      "40200/40200 [==============================] - 4s 93us/sample - loss: 0.1130 - acc: 0.9652 - val_loss: 0.0624 - val_acc: 0.9815\n",
      "Epoch 243/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.1114 - acc: 0.9642\n",
      "Epoch 00243: val_loss did not improve from 0.06132\n",
      "40200/40200 [==============================] - 4s 93us/sample - loss: 0.1113 - acc: 0.9642 - val_loss: 0.0615 - val_acc: 0.9822\n",
      "Epoch 244/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.1136 - acc: 0.9635\n",
      "Epoch 00244: val_loss did not improve from 0.06132\n",
      "40200/40200 [==============================] - 4s 93us/sample - loss: 0.1135 - acc: 0.9633 - val_loss: 0.0617 - val_acc: 0.9814\n",
      "Epoch 245/500\n",
      "39616/40200 [============================>.] - ETA: 0s - loss: 0.1109 - acc: 0.9648\n",
      "Epoch 00245: val_loss did not improve from 0.06132\n",
      "40200/40200 [==============================] - 4s 92us/sample - loss: 0.1110 - acc: 0.9647 - val_loss: 0.0617 - val_acc: 0.9823\n",
      "Epoch 246/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.1083 - acc: 0.9656\n",
      "Epoch 00246: val_loss did not improve from 0.06132\n",
      "40200/40200 [==============================] - 4s 92us/sample - loss: 0.1083 - acc: 0.9656 - val_loss: 0.0619 - val_acc: 0.9820\n",
      "Epoch 247/500\n",
      "39680/40200 [============================>.] - ETA: 0s - loss: 0.1131 - acc: 0.9650\n",
      "Epoch 00247: val_loss did not improve from 0.06132\n",
      "40200/40200 [==============================] - 4s 92us/sample - loss: 0.1128 - acc: 0.9650 - val_loss: 0.0613 - val_acc: 0.9820\n",
      "Epoch 248/500\n",
      "39680/40200 [============================>.] - ETA: 0s - loss: 0.1130 - acc: 0.9646\n",
      "Epoch 00248: val_loss did not improve from 0.06132\n",
      "40200/40200 [==============================] - 4s 93us/sample - loss: 0.1135 - acc: 0.9645 - val_loss: 0.0632 - val_acc: 0.9810\n",
      "Epoch 249/500\n",
      "39744/40200 [============================>.] - ETA: 0s - loss: 0.1126 - acc: 0.9645\n",
      "Epoch 00249: val_loss did not improve from 0.06132\n",
      "40200/40200 [==============================] - 4s 92us/sample - loss: 0.1126 - acc: 0.9645 - val_loss: 0.0626 - val_acc: 0.9815\n",
      "Epoch 250/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.1078 - acc: 0.9652\n",
      "Epoch 00250: val_loss did not improve from 0.06132\n",
      "40200/40200 [==============================] - 4s 92us/sample - loss: 0.1082 - acc: 0.9651 - val_loss: 0.0620 - val_acc: 0.9816\n",
      "Epoch 251/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.1132 - acc: 0.9646\n",
      "Epoch 00251: val_loss did not improve from 0.06132\n",
      "40200/40200 [==============================] - 4s 92us/sample - loss: 0.1131 - acc: 0.9646 - val_loss: 0.0637 - val_acc: 0.9819\n",
      "Epoch 252/500\n",
      "39744/40200 [============================>.] - ETA: 0s - loss: 0.1128 - acc: 0.9636\n",
      "Epoch 00252: val_loss did not improve from 0.06132\n",
      "40200/40200 [==============================] - 4s 93us/sample - loss: 0.1130 - acc: 0.9636 - val_loss: 0.0624 - val_acc: 0.9816\n",
      "Epoch 253/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.1097 - acc: 0.9648\n",
      "Epoch 00253: val_loss did not improve from 0.06132\n",
      "40200/40200 [==============================] - 4s 92us/sample - loss: 0.1096 - acc: 0.9648 - val_loss: 0.0622 - val_acc: 0.9815\n",
      "Epoch 254/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.1120 - acc: 0.9641\n",
      "Epoch 00254: val_loss did not improve from 0.06132\n",
      "40200/40200 [==============================] - 4s 92us/sample - loss: 0.1119 - acc: 0.9642 - val_loss: 0.0616 - val_acc: 0.9817\n",
      "Epoch 255/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.1087 - acc: 0.9655\n",
      "Epoch 00255: val_loss did not improve from 0.06132\n",
      "40200/40200 [==============================] - 3s 83us/sample - loss: 0.1089 - acc: 0.9654 - val_loss: 0.0633 - val_acc: 0.9815\n",
      "Epoch 256/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.1098 - acc: 0.9655\n",
      "Epoch 00256: val_loss did not improve from 0.06132\n",
      "40200/40200 [==============================] - 3s 84us/sample - loss: 0.1097 - acc: 0.9654 - val_loss: 0.0627 - val_acc: 0.9818\n",
      "Epoch 257/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.1113 - acc: 0.9642\n",
      "Epoch 00257: val_loss did not improve from 0.06132\n",
      "40200/40200 [==============================] - 4s 92us/sample - loss: 0.1112 - acc: 0.9643 - val_loss: 0.0619 - val_acc: 0.9816\n",
      "Epoch 258/500\n",
      "39552/40200 [============================>.] - ETA: 0s - loss: 0.1103 - acc: 0.9652\n",
      "Epoch 00258: val_loss did not improve from 0.06132\n",
      "40200/40200 [==============================] - 4s 92us/sample - loss: 0.1105 - acc: 0.9650 - val_loss: 0.0639 - val_acc: 0.9811\n",
      "Epoch 259/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.1151 - acc: 0.9636\n",
      "Epoch 00259: val_loss did not improve from 0.06132\n",
      "40200/40200 [==============================] - 4s 93us/sample - loss: 0.1150 - acc: 0.9636 - val_loss: 0.0621 - val_acc: 0.9815\n",
      "Epoch 260/500\n",
      "39744/40200 [============================>.] - ETA: 0s - loss: 0.1127 - acc: 0.9633\n",
      "Epoch 00260: val_loss did not improve from 0.06132\n",
      "40200/40200 [==============================] - 4s 92us/sample - loss: 0.1130 - acc: 0.9632 - val_loss: 0.0620 - val_acc: 0.9816\n",
      "Epoch 261/500\n",
      "39552/40200 [============================>.] - ETA: 0s - loss: 0.1112 - acc: 0.9640\n",
      "Epoch 00261: val_loss did not improve from 0.06132\n",
      "40200/40200 [==============================] - 4s 92us/sample - loss: 0.1112 - acc: 0.9641 - val_loss: 0.0620 - val_acc: 0.9817\n",
      "Epoch 262/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.1120 - acc: 0.9637\n",
      "Epoch 00262: val_loss did not improve from 0.06132\n",
      "40200/40200 [==============================] - 4s 92us/sample - loss: 0.1115 - acc: 0.9639 - val_loss: 0.0633 - val_acc: 0.9816\n",
      "Epoch 263/500\n",
      "39616/40200 [============================>.] - ETA: 0s - loss: 0.1124 - acc: 0.9644\n",
      "Epoch 00263: val_loss did not improve from 0.06132\n",
      "40200/40200 [==============================] - 4s 92us/sample - loss: 0.1124 - acc: 0.9644 - val_loss: 0.0628 - val_acc: 0.9815\n",
      "Epoch 264/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.1114 - acc: 0.9638\n",
      "Epoch 00264: val_loss did not improve from 0.06132\n",
      "40200/40200 [==============================] - 4s 92us/sample - loss: 0.1114 - acc: 0.9637 - val_loss: 0.0627 - val_acc: 0.9811\n",
      "Epoch 265/500\n",
      "39744/40200 [============================>.] - ETA: 0s - loss: 0.1144 - acc: 0.9637\n",
      "Epoch 00265: val_loss did not improve from 0.06132\n",
      "40200/40200 [==============================] - 4s 92us/sample - loss: 0.1144 - acc: 0.9637 - val_loss: 0.0624 - val_acc: 0.9814\n",
      "Epoch 266/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.1134 - acc: 0.9634\n",
      "Epoch 00266: val_loss did not improve from 0.06132\n",
      "40200/40200 [==============================] - 4s 92us/sample - loss: 0.1135 - acc: 0.9634 - val_loss: 0.0623 - val_acc: 0.9812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 267/500\n",
      "39680/40200 [============================>.] - ETA: 0s - loss: 0.1126 - acc: 0.9647\n",
      "Epoch 00267: val_loss did not improve from 0.06132\n",
      "40200/40200 [==============================] - 4s 93us/sample - loss: 0.1120 - acc: 0.9648 - val_loss: 0.0621 - val_acc: 0.9814\n",
      "Epoch 268/500\n",
      "39552/40200 [============================>.] - ETA: 0s - loss: 0.1106 - acc: 0.9648\n",
      "Epoch 00268: val_loss did not improve from 0.06132\n",
      "40200/40200 [==============================] - 4s 92us/sample - loss: 0.1100 - acc: 0.9650 - val_loss: 0.0620 - val_acc: 0.9818\n",
      "Epoch 269/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.1115 - acc: 0.9651\n",
      "Epoch 00269: val_loss improved from 0.06132 to 0.06112, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_1_conv_checkpoint/269-0.0611.hdf5\n",
      "40200/40200 [==============================] - 4s 93us/sample - loss: 0.1115 - acc: 0.9651 - val_loss: 0.0611 - val_acc: 0.9820\n",
      "Epoch 270/500\n",
      "39616/40200 [============================>.] - ETA: 0s - loss: 0.1139 - acc: 0.9629\n",
      "Epoch 00270: val_loss did not improve from 0.06112\n",
      "40200/40200 [==============================] - 4s 92us/sample - loss: 0.1134 - acc: 0.9631 - val_loss: 0.0620 - val_acc: 0.9823\n",
      "Epoch 271/500\n",
      "39552/40200 [============================>.] - ETA: 0s - loss: 0.1109 - acc: 0.9643\n",
      "Epoch 00271: val_loss did not improve from 0.06112\n",
      "40200/40200 [==============================] - 4s 88us/sample - loss: 0.1108 - acc: 0.9644 - val_loss: 0.0632 - val_acc: 0.9816\n",
      "Epoch 272/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.1139 - acc: 0.9642\n",
      "Epoch 00272: val_loss did not improve from 0.06112\n",
      "40200/40200 [==============================] - 3s 83us/sample - loss: 0.1148 - acc: 0.9640 - val_loss: 0.0623 - val_acc: 0.9815\n",
      "Epoch 273/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.1095 - acc: 0.9651\n",
      "Epoch 00273: val_loss did not improve from 0.06112\n",
      "40200/40200 [==============================] - 4s 89us/sample - loss: 0.1095 - acc: 0.9651 - val_loss: 0.0623 - val_acc: 0.9819\n",
      "Epoch 274/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.1103 - acc: 0.9657\n",
      "Epoch 00274: val_loss did not improve from 0.06112\n",
      "40200/40200 [==============================] - 4s 92us/sample - loss: 0.1103 - acc: 0.9657 - val_loss: 0.0626 - val_acc: 0.9816\n",
      "Epoch 275/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.1105 - acc: 0.9648\n",
      "Epoch 00275: val_loss did not improve from 0.06112\n",
      "40200/40200 [==============================] - 4s 92us/sample - loss: 0.1105 - acc: 0.9649 - val_loss: 0.0628 - val_acc: 0.9817\n",
      "Epoch 276/500\n",
      "39680/40200 [============================>.] - ETA: 0s - loss: 0.1126 - acc: 0.9642\n",
      "Epoch 00276: val_loss did not improve from 0.06112\n",
      "40200/40200 [==============================] - 4s 91us/sample - loss: 0.1127 - acc: 0.9641 - val_loss: 0.0628 - val_acc: 0.9813\n",
      "Epoch 277/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.1107 - acc: 0.9647\n",
      "Epoch 00277: val_loss did not improve from 0.06112\n",
      "40200/40200 [==============================] - 4s 91us/sample - loss: 0.1107 - acc: 0.9647 - val_loss: 0.0624 - val_acc: 0.9816\n",
      "Epoch 278/500\n",
      "39744/40200 [============================>.] - ETA: 0s - loss: 0.1106 - acc: 0.9643\n",
      "Epoch 00278: val_loss did not improve from 0.06112\n",
      "40200/40200 [==============================] - 4s 92us/sample - loss: 0.1102 - acc: 0.9645 - val_loss: 0.0626 - val_acc: 0.9818\n",
      "Epoch 279/500\n",
      "39744/40200 [============================>.] - ETA: 0s - loss: 0.1123 - acc: 0.9646\n",
      "Epoch 00279: val_loss did not improve from 0.06112\n",
      "40200/40200 [==============================] - 4s 93us/sample - loss: 0.1125 - acc: 0.9645 - val_loss: 0.0631 - val_acc: 0.9813\n",
      "Epoch 280/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.1118 - acc: 0.9649\n",
      "Epoch 00280: val_loss did not improve from 0.06112\n",
      "40200/40200 [==============================] - 4s 93us/sample - loss: 0.1116 - acc: 0.9649 - val_loss: 0.0625 - val_acc: 0.9816\n",
      "Epoch 281/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.1103 - acc: 0.9653\n",
      "Epoch 00281: val_loss did not improve from 0.06112\n",
      "40200/40200 [==============================] - 4s 93us/sample - loss: 0.1098 - acc: 0.9654 - val_loss: 0.0621 - val_acc: 0.9823\n",
      "Epoch 282/500\n",
      "39680/40200 [============================>.] - ETA: 0s - loss: 0.1097 - acc: 0.9663\n",
      "Epoch 00282: val_loss did not improve from 0.06112\n",
      "40200/40200 [==============================] - 4s 92us/sample - loss: 0.1093 - acc: 0.9663 - val_loss: 0.0616 - val_acc: 0.9820\n",
      "Epoch 283/500\n",
      "39680/40200 [============================>.] - ETA: 0s - loss: 0.1111 - acc: 0.9661\n",
      "Epoch 00283: val_loss did not improve from 0.06112\n",
      "40200/40200 [==============================] - 4s 92us/sample - loss: 0.1113 - acc: 0.9660 - val_loss: 0.0631 - val_acc: 0.9813\n",
      "Epoch 284/500\n",
      "39744/40200 [============================>.] - ETA: 0s - loss: 0.1127 - acc: 0.9634\n",
      "Epoch 00284: val_loss improved from 0.06112 to 0.06065, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_1_conv_checkpoint/284-0.0606.hdf5\n",
      "40200/40200 [==============================] - 4s 93us/sample - loss: 0.1126 - acc: 0.9634 - val_loss: 0.0606 - val_acc: 0.9820\n",
      "Epoch 285/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.1135 - acc: 0.9643\n",
      "Epoch 00285: val_loss did not improve from 0.06065\n",
      "40200/40200 [==============================] - 4s 93us/sample - loss: 0.1136 - acc: 0.9642 - val_loss: 0.0632 - val_acc: 0.9815\n",
      "Epoch 286/500\n",
      "39744/40200 [============================>.] - ETA: 0s - loss: 0.1072 - acc: 0.9652\n",
      "Epoch 00286: val_loss did not improve from 0.06065\n",
      "40200/40200 [==============================] - 4s 92us/sample - loss: 0.1072 - acc: 0.9652 - val_loss: 0.0643 - val_acc: 0.9820\n",
      "Epoch 287/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.1075 - acc: 0.9656\n",
      "Epoch 00287: val_loss did not improve from 0.06065\n",
      "40200/40200 [==============================] - 4s 92us/sample - loss: 0.1078 - acc: 0.9656 - val_loss: 0.0627 - val_acc: 0.9819\n",
      "Epoch 288/500\n",
      "39552/40200 [============================>.] - ETA: 0s - loss: 0.1087 - acc: 0.9646\n",
      "Epoch 00288: val_loss did not improve from 0.06065\n",
      "40200/40200 [==============================] - 3s 86us/sample - loss: 0.1085 - acc: 0.9647 - val_loss: 0.0640 - val_acc: 0.9806\n",
      "Epoch 289/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.1143 - acc: 0.9640\n",
      "Epoch 00289: val_loss did not improve from 0.06065\n",
      "40200/40200 [==============================] - 3s 83us/sample - loss: 0.1141 - acc: 0.9641 - val_loss: 0.0614 - val_acc: 0.9821\n",
      "Epoch 290/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.1113 - acc: 0.9647\n",
      "Epoch 00290: val_loss did not improve from 0.06065\n",
      "40200/40200 [==============================] - 4s 91us/sample - loss: 0.1117 - acc: 0.9645 - val_loss: 0.0622 - val_acc: 0.9822\n",
      "Epoch 291/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.1116 - acc: 0.9646\n",
      "Epoch 00291: val_loss did not improve from 0.06065\n",
      "40200/40200 [==============================] - 4s 92us/sample - loss: 0.1116 - acc: 0.9646 - val_loss: 0.0621 - val_acc: 0.9811\n",
      "Epoch 292/500\n",
      "39552/40200 [============================>.] - ETA: 0s - loss: 0.1130 - acc: 0.9635\n",
      "Epoch 00292: val_loss did not improve from 0.06065\n",
      "40200/40200 [==============================] - 4s 92us/sample - loss: 0.1131 - acc: 0.9637 - val_loss: 0.0619 - val_acc: 0.9816\n",
      "Epoch 293/500\n",
      "39552/40200 [============================>.] - ETA: 0s - loss: 0.1095 - acc: 0.9654\n",
      "Epoch 00293: val_loss did not improve from 0.06065\n",
      "40200/40200 [==============================] - 4s 92us/sample - loss: 0.1102 - acc: 0.9650 - val_loss: 0.0614 - val_acc: 0.9814\n",
      "Epoch 294/500\n",
      "39616/40200 [============================>.] - ETA: 0s - loss: 0.1091 - acc: 0.9648\n",
      "Epoch 00294: val_loss did not improve from 0.06065\n",
      "40200/40200 [==============================] - 4s 93us/sample - loss: 0.1089 - acc: 0.9649 - val_loss: 0.0631 - val_acc: 0.9810\n",
      "Epoch 295/500\n",
      "39616/40200 [============================>.] - ETA: 0s - loss: 0.1114 - acc: 0.9650\n",
      "Epoch 00295: val_loss did not improve from 0.06065\n",
      "40200/40200 [==============================] - 4s 92us/sample - loss: 0.1117 - acc: 0.9649 - val_loss: 0.0625 - val_acc: 0.9812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 296/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.1116 - acc: 0.9647\n",
      "Epoch 00296: val_loss did not improve from 0.06065\n",
      "40200/40200 [==============================] - 4s 92us/sample - loss: 0.1116 - acc: 0.9647 - val_loss: 0.0628 - val_acc: 0.9821\n",
      "Epoch 297/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.1108 - acc: 0.9643\n",
      "Epoch 00297: val_loss did not improve from 0.06065\n",
      "40200/40200 [==============================] - 4s 93us/sample - loss: 0.1105 - acc: 0.9644 - val_loss: 0.0626 - val_acc: 0.9814\n",
      "Epoch 298/500\n",
      "39552/40200 [============================>.] - ETA: 0s - loss: 0.1094 - acc: 0.9651\n",
      "Epoch 00298: val_loss did not improve from 0.06065\n",
      "40200/40200 [==============================] - 4s 92us/sample - loss: 0.1091 - acc: 0.9653 - val_loss: 0.0625 - val_acc: 0.9816\n",
      "Epoch 299/500\n",
      "39680/40200 [============================>.] - ETA: 0s - loss: 0.1099 - acc: 0.9647\n",
      "Epoch 00299: val_loss did not improve from 0.06065\n",
      "40200/40200 [==============================] - 4s 92us/sample - loss: 0.1102 - acc: 0.9647 - val_loss: 0.0620 - val_acc: 0.9819\n",
      "Epoch 300/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.1092 - acc: 0.9649\n",
      "Epoch 00300: val_loss did not improve from 0.06065\n",
      "40200/40200 [==============================] - 4s 91us/sample - loss: 0.1096 - acc: 0.9648 - val_loss: 0.0621 - val_acc: 0.9817\n",
      "Epoch 301/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.1075 - acc: 0.9654\n",
      "Epoch 00301: val_loss did not improve from 0.06065\n",
      "40200/40200 [==============================] - 4s 92us/sample - loss: 0.1072 - acc: 0.9655 - val_loss: 0.0625 - val_acc: 0.9818\n",
      "Epoch 302/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.1078 - acc: 0.9663\n",
      "Epoch 00302: val_loss did not improve from 0.06065\n",
      "40200/40200 [==============================] - 4s 92us/sample - loss: 0.1076 - acc: 0.9663 - val_loss: 0.0614 - val_acc: 0.9817\n",
      "Epoch 303/500\n",
      "39744/40200 [============================>.] - ETA: 0s - loss: 0.1102 - acc: 0.9647\n",
      "Epoch 00303: val_loss did not improve from 0.06065\n",
      "40200/40200 [==============================] - 4s 93us/sample - loss: 0.1097 - acc: 0.9649 - val_loss: 0.0612 - val_acc: 0.9819\n",
      "Epoch 304/500\n",
      "39680/40200 [============================>.] - ETA: 0s - loss: 0.1107 - acc: 0.9647\n",
      "Epoch 00304: val_loss did not improve from 0.06065\n",
      "40200/40200 [==============================] - 4s 91us/sample - loss: 0.1106 - acc: 0.9647 - val_loss: 0.0620 - val_acc: 0.9815\n",
      "Epoch 305/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.1099 - acc: 0.9647\n",
      "Epoch 00305: val_loss did not improve from 0.06065\n",
      "40200/40200 [==============================] - 3s 83us/sample - loss: 0.1097 - acc: 0.9648 - val_loss: 0.0623 - val_acc: 0.9814\n",
      "Epoch 306/500\n",
      "39680/40200 [============================>.] - ETA: 0s - loss: 0.1126 - acc: 0.9647\n",
      "Epoch 00306: val_loss did not improve from 0.06065\n",
      "40200/40200 [==============================] - 3s 85us/sample - loss: 0.1129 - acc: 0.9646 - val_loss: 0.0627 - val_acc: 0.9817\n",
      "Epoch 307/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.1092 - acc: 0.9644\n",
      "Epoch 00307: val_loss did not improve from 0.06065\n",
      "40200/40200 [==============================] - 4s 92us/sample - loss: 0.1093 - acc: 0.9643 - val_loss: 0.0609 - val_acc: 0.9820\n",
      "Epoch 308/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.1121 - acc: 0.9644\n",
      "Epoch 00308: val_loss did not improve from 0.06065\n",
      "40200/40200 [==============================] - 4s 93us/sample - loss: 0.1120 - acc: 0.9644 - val_loss: 0.0617 - val_acc: 0.9816\n",
      "Epoch 309/500\n",
      "39552/40200 [============================>.] - ETA: 0s - loss: 0.1077 - acc: 0.9659\n",
      "Epoch 00309: val_loss did not improve from 0.06065\n",
      "40200/40200 [==============================] - 4s 93us/sample - loss: 0.1075 - acc: 0.9660 - val_loss: 0.0623 - val_acc: 0.9815\n",
      "Epoch 310/500\n",
      "39680/40200 [============================>.] - ETA: 0s - loss: 0.1138 - acc: 0.9641\n",
      "Epoch 00310: val_loss did not improve from 0.06065\n",
      "40200/40200 [==============================] - 4s 92us/sample - loss: 0.1138 - acc: 0.9642 - val_loss: 0.0615 - val_acc: 0.9819\n",
      "Epoch 311/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.1102 - acc: 0.9648\n",
      "Epoch 00311: val_loss did not improve from 0.06065\n",
      "40200/40200 [==============================] - 4s 93us/sample - loss: 0.1103 - acc: 0.9648 - val_loss: 0.0627 - val_acc: 0.9816\n",
      "Epoch 312/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.1106 - acc: 0.9651\n",
      "Epoch 00312: val_loss did not improve from 0.06065\n",
      "40200/40200 [==============================] - 4s 92us/sample - loss: 0.1106 - acc: 0.9651 - val_loss: 0.0624 - val_acc: 0.9816\n",
      "Epoch 313/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.1102 - acc: 0.9644\n",
      "Epoch 00313: val_loss did not improve from 0.06065\n",
      "40200/40200 [==============================] - 4s 92us/sample - loss: 0.1100 - acc: 0.9645 - val_loss: 0.0621 - val_acc: 0.9820\n",
      "Epoch 314/500\n",
      "39552/40200 [============================>.] - ETA: 0s - loss: 0.1069 - acc: 0.9654\n",
      "Epoch 00314: val_loss did not improve from 0.06065\n",
      "40200/40200 [==============================] - 4s 92us/sample - loss: 0.1070 - acc: 0.9654 - val_loss: 0.0609 - val_acc: 0.9822\n",
      "Epoch 315/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.1104 - acc: 0.9650\n",
      "Epoch 00315: val_loss did not improve from 0.06065\n",
      "40200/40200 [==============================] - 4s 92us/sample - loss: 0.1103 - acc: 0.9650 - val_loss: 0.0618 - val_acc: 0.9820\n",
      "Epoch 316/500\n",
      "39616/40200 [============================>.] - ETA: 0s - loss: 0.1111 - acc: 0.9658\n",
      "Epoch 00316: val_loss did not improve from 0.06065\n",
      "40200/40200 [==============================] - 4s 91us/sample - loss: 0.1107 - acc: 0.9659 - val_loss: 0.0616 - val_acc: 0.9818\n",
      "Epoch 317/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.1107 - acc: 0.9651\n",
      "Epoch 00317: val_loss did not improve from 0.06065\n",
      "40200/40200 [==============================] - 4s 92us/sample - loss: 0.1106 - acc: 0.9652 - val_loss: 0.0648 - val_acc: 0.9812\n",
      "Epoch 318/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.1134 - acc: 0.9652\n",
      "Epoch 00318: val_loss did not improve from 0.06065\n",
      "40200/40200 [==============================] - 4s 92us/sample - loss: 0.1130 - acc: 0.9653 - val_loss: 0.0616 - val_acc: 0.9818\n",
      "Epoch 319/500\n",
      "39552/40200 [============================>.] - ETA: 0s - loss: 0.1099 - acc: 0.9646\n",
      "Epoch 00319: val_loss did not improve from 0.06065\n",
      "40200/40200 [==============================] - 4s 92us/sample - loss: 0.1097 - acc: 0.9648 - val_loss: 0.0626 - val_acc: 0.9818\n",
      "Epoch 320/500\n",
      "39616/40200 [============================>.] - ETA: 0s - loss: 0.1115 - acc: 0.9648\n",
      "Epoch 00320: val_loss did not improve from 0.06065\n",
      "40200/40200 [==============================] - 4s 93us/sample - loss: 0.1119 - acc: 0.9647 - val_loss: 0.0619 - val_acc: 0.9817\n",
      "Epoch 321/500\n",
      "39744/40200 [============================>.] - ETA: 0s - loss: 0.1128 - acc: 0.9645\n",
      "Epoch 00321: val_loss did not improve from 0.06065\n",
      "40200/40200 [==============================] - 3s 85us/sample - loss: 0.1125 - acc: 0.9646 - val_loss: 0.0609 - val_acc: 0.9816\n",
      "Epoch 322/500\n",
      "39680/40200 [============================>.] - ETA: 0s - loss: 0.1108 - acc: 0.9652\n",
      "Epoch 00322: val_loss did not improve from 0.06065\n",
      "40200/40200 [==============================] - 3s 84us/sample - loss: 0.1108 - acc: 0.9651 - val_loss: 0.0622 - val_acc: 0.9815\n",
      "Epoch 323/500\n",
      "39744/40200 [============================>.] - ETA: 0s - loss: 0.1085 - acc: 0.9663\n",
      "Epoch 00323: val_loss did not improve from 0.06065\n",
      "40200/40200 [==============================] - 4s 91us/sample - loss: 0.1088 - acc: 0.9661 - val_loss: 0.0625 - val_acc: 0.9814\n",
      "Epoch 324/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.1078 - acc: 0.9659\n",
      "Epoch 00324: val_loss did not improve from 0.06065\n",
      "40200/40200 [==============================] - 4s 93us/sample - loss: 0.1081 - acc: 0.9657 - val_loss: 0.0614 - val_acc: 0.9818\n",
      "Epoch 325/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.1092 - acc: 0.9649\n",
      "Epoch 00325: val_loss did not improve from 0.06065\n",
      "40200/40200 [==============================] - 4s 91us/sample - loss: 0.1096 - acc: 0.9648 - val_loss: 0.0622 - val_acc: 0.9815\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 326/500\n",
      "39744/40200 [============================>.] - ETA: 0s - loss: 0.1093 - acc: 0.9653\n",
      "Epoch 00326: val_loss did not improve from 0.06065\n",
      "40200/40200 [==============================] - 4s 92us/sample - loss: 0.1089 - acc: 0.9654 - val_loss: 0.0612 - val_acc: 0.9816\n",
      "Epoch 327/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.1110 - acc: 0.9641\n",
      "Epoch 00327: val_loss did not improve from 0.06065\n",
      "40200/40200 [==============================] - 4s 92us/sample - loss: 0.1109 - acc: 0.9641 - val_loss: 0.0622 - val_acc: 0.9816\n",
      "Epoch 328/500\n",
      "39680/40200 [============================>.] - ETA: 0s - loss: 0.1124 - acc: 0.9646\n",
      "Epoch 00328: val_loss did not improve from 0.06065\n",
      "40200/40200 [==============================] - 4s 92us/sample - loss: 0.1123 - acc: 0.9646 - val_loss: 0.0618 - val_acc: 0.9820\n",
      "Epoch 329/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.1064 - acc: 0.9656\n",
      "Epoch 00329: val_loss did not improve from 0.06065\n",
      "40200/40200 [==============================] - 4s 91us/sample - loss: 0.1064 - acc: 0.9656 - val_loss: 0.0614 - val_acc: 0.9818\n",
      "Epoch 330/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.1104 - acc: 0.9639\n",
      "Epoch 00330: val_loss did not improve from 0.06065\n",
      "40200/40200 [==============================] - 4s 93us/sample - loss: 0.1103 - acc: 0.9640 - val_loss: 0.0617 - val_acc: 0.9818\n",
      "Epoch 331/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.1077 - acc: 0.9657\n",
      "Epoch 00331: val_loss did not improve from 0.06065\n",
      "40200/40200 [==============================] - 4s 91us/sample - loss: 0.1077 - acc: 0.9656 - val_loss: 0.0626 - val_acc: 0.9820\n",
      "Epoch 332/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.1119 - acc: 0.9642\n",
      "Epoch 00332: val_loss did not improve from 0.06065\n",
      "40200/40200 [==============================] - 4s 93us/sample - loss: 0.1120 - acc: 0.9641 - val_loss: 0.0624 - val_acc: 0.9819\n",
      "Epoch 333/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.1104 - acc: 0.9646\n",
      "Epoch 00333: val_loss did not improve from 0.06065\n",
      "40200/40200 [==============================] - 4s 92us/sample - loss: 0.1103 - acc: 0.9646 - val_loss: 0.0615 - val_acc: 0.9819\n",
      "Epoch 334/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.1074 - acc: 0.9659\n",
      "Epoch 00334: val_loss did not improve from 0.06065\n",
      "40200/40200 [==============================] - 4s 92us/sample - loss: 0.1077 - acc: 0.9658 - val_loss: 0.0625 - val_acc: 0.9812\n",
      "\n",
      "vis_2D_CNN_custom_ch_16_DO_075_DO_1_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 75us/sample - loss: 0.0625 - acc: 0.9828\n",
      "Loss: 0.0625295720718801 Accuracy: 0.9828\n",
      "\n",
      "Train on 40200 samples, validate on 19800 samples\n",
      "Epoch 1/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 12.9679 - acc: 0.1675\n",
      "Epoch 00001: val_loss improved from inf to 7.71543, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_2_conv_checkpoint/001-7.7154.hdf5\n",
      "40200/40200 [==============================] - 5s 129us/sample - loss: 12.9584 - acc: 0.1680 - val_loss: 7.7154 - val_acc: 0.4546\n",
      "Epoch 2/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 9.4805 - acc: 0.3552\n",
      "Epoch 00002: val_loss improved from 7.71543 to 3.82106, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_2_conv_checkpoint/002-3.8211.hdf5\n",
      "40200/40200 [==============================] - 4s 102us/sample - loss: 9.4770 - acc: 0.3554 - val_loss: 3.8211 - val_acc: 0.6832\n",
      "Epoch 3/500\n",
      "39744/40200 [============================>.] - ETA: 0s - loss: 6.3092 - acc: 0.4986\n",
      "Epoch 00003: val_loss improved from 3.82106 to 1.45889, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_2_conv_checkpoint/003-1.4589.hdf5\n",
      "40200/40200 [==============================] - 4s 101us/sample - loss: 6.2889 - acc: 0.4994 - val_loss: 1.4589 - val_acc: 0.7930\n",
      "Epoch 4/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 3.1506 - acc: 0.5191\n",
      "Epoch 00004: val_loss improved from 1.45889 to 0.85897, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_2_conv_checkpoint/004-0.8590.hdf5\n",
      "40200/40200 [==============================] - 4s 108us/sample - loss: 3.1416 - acc: 0.5188 - val_loss: 0.8590 - val_acc: 0.7358\n",
      "Epoch 5/500\n",
      "39680/40200 [============================>.] - ETA: 0s - loss: 1.6665 - acc: 0.4813\n",
      "Epoch 00005: val_loss improved from 0.85897 to 0.78343, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_2_conv_checkpoint/005-0.7834.hdf5\n",
      "40200/40200 [==============================] - 4s 108us/sample - loss: 1.6652 - acc: 0.4815 - val_loss: 0.7834 - val_acc: 0.7770\n",
      "Epoch 6/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 1.4419 - acc: 0.5416\n",
      "Epoch 00006: val_loss improved from 0.78343 to 0.64049, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_2_conv_checkpoint/006-0.6405.hdf5\n",
      "40200/40200 [==============================] - 4s 108us/sample - loss: 1.4421 - acc: 0.5416 - val_loss: 0.6405 - val_acc: 0.8214\n",
      "Epoch 7/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 1.2302 - acc: 0.6055\n",
      "Epoch 00007: val_loss improved from 0.64049 to 0.50628, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_2_conv_checkpoint/007-0.5063.hdf5\n",
      "40200/40200 [==============================] - 4s 109us/sample - loss: 1.2304 - acc: 0.6052 - val_loss: 0.5063 - val_acc: 0.8493\n",
      "Epoch 8/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 1.0582 - acc: 0.6634\n",
      "Epoch 00008: val_loss improved from 0.50628 to 0.41724, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_2_conv_checkpoint/008-0.4172.hdf5\n",
      "40200/40200 [==============================] - 4s 110us/sample - loss: 1.0579 - acc: 0.6635 - val_loss: 0.4172 - val_acc: 0.8773\n",
      "Epoch 9/500\n",
      "39680/40200 [============================>.] - ETA: 0s - loss: 0.9238 - acc: 0.7067\n",
      "Epoch 00009: val_loss improved from 0.41724 to 0.34626, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_2_conv_checkpoint/009-0.3463.hdf5\n",
      "40200/40200 [==============================] - 4s 109us/sample - loss: 0.9223 - acc: 0.7069 - val_loss: 0.3463 - val_acc: 0.8967\n",
      "Epoch 10/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.8084 - acc: 0.7426\n",
      "Epoch 00010: val_loss improved from 0.34626 to 0.29995, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_2_conv_checkpoint/010-0.3000.hdf5\n",
      "40200/40200 [==============================] - 4s 109us/sample - loss: 0.8074 - acc: 0.7430 - val_loss: 0.3000 - val_acc: 0.9102\n",
      "Epoch 11/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.7088 - acc: 0.7766\n",
      "Epoch 00011: val_loss improved from 0.29995 to 0.25581, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_2_conv_checkpoint/011-0.2558.hdf5\n",
      "40200/40200 [==============================] - 4s 109us/sample - loss: 0.7088 - acc: 0.7766 - val_loss: 0.2558 - val_acc: 0.9229\n",
      "Epoch 12/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.6290 - acc: 0.8017\n",
      "Epoch 00012: val_loss improved from 0.25581 to 0.23310, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_2_conv_checkpoint/012-0.2331.hdf5\n",
      "40200/40200 [==============================] - 4s 110us/sample - loss: 0.6294 - acc: 0.8016 - val_loss: 0.2331 - val_acc: 0.9298\n",
      "Epoch 13/500\n",
      "39680/40200 [============================>.] - ETA: 0s - loss: 0.5683 - acc: 0.8204\n",
      "Epoch 00013: val_loss improved from 0.23310 to 0.20342, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_2_conv_checkpoint/013-0.2034.hdf5\n",
      "40200/40200 [==============================] - 4s 109us/sample - loss: 0.5684 - acc: 0.8205 - val_loss: 0.2034 - val_acc: 0.9390\n",
      "Epoch 14/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.5275 - acc: 0.8348\n",
      "Epoch 00014: val_loss improved from 0.20342 to 0.19012, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_2_conv_checkpoint/014-0.1901.hdf5\n",
      "40200/40200 [==============================] - 4s 108us/sample - loss: 0.5276 - acc: 0.8348 - val_loss: 0.1901 - val_acc: 0.9417\n",
      "Epoch 15/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.4817 - acc: 0.8508\n",
      "Epoch 00015: val_loss improved from 0.19012 to 0.17378, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_2_conv_checkpoint/015-0.1738.hdf5\n",
      "40200/40200 [==============================] - 4s 110us/sample - loss: 0.4815 - acc: 0.8509 - val_loss: 0.1738 - val_acc: 0.9468\n",
      "Epoch 16/500\n",
      "39616/40200 [============================>.] - ETA: 0s - loss: 0.4545 - acc: 0.8570\n",
      "Epoch 00016: val_loss improved from 0.17378 to 0.16166, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_2_conv_checkpoint/016-0.1617.hdf5\n",
      "40200/40200 [==============================] - 4s 102us/sample - loss: 0.4535 - acc: 0.8572 - val_loss: 0.1617 - val_acc: 0.9492\n",
      "Epoch 17/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.4190 - acc: 0.8704\n",
      "Epoch 00017: val_loss improved from 0.16166 to 0.15241, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_2_conv_checkpoint/017-0.1524.hdf5\n",
      "40200/40200 [==============================] - 4s 99us/sample - loss: 0.4191 - acc: 0.8706 - val_loss: 0.1524 - val_acc: 0.9515\n",
      "Epoch 18/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.3951 - acc: 0.8786\n",
      "Epoch 00018: val_loss improved from 0.15241 to 0.14444, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_2_conv_checkpoint/018-0.1444.hdf5\n",
      "40200/40200 [==============================] - 4s 109us/sample - loss: 0.3947 - acc: 0.8787 - val_loss: 0.1444 - val_acc: 0.9549\n",
      "Epoch 19/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.3808 - acc: 0.8832\n",
      "Epoch 00019: val_loss improved from 0.14444 to 0.13608, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_2_conv_checkpoint/019-0.1361.hdf5\n",
      "40200/40200 [==============================] - 4s 109us/sample - loss: 0.3808 - acc: 0.8831 - val_loss: 0.1361 - val_acc: 0.9569\n",
      "Epoch 20/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.3614 - acc: 0.8874\n",
      "Epoch 00020: val_loss improved from 0.13608 to 0.12895, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_2_conv_checkpoint/020-0.1289.hdf5\n",
      "40200/40200 [==============================] - 4s 109us/sample - loss: 0.3616 - acc: 0.8874 - val_loss: 0.1289 - val_acc: 0.9592\n",
      "Epoch 21/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.3477 - acc: 0.8929\n",
      "Epoch 00021: val_loss improved from 0.12895 to 0.12512, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_2_conv_checkpoint/021-0.1251.hdf5\n",
      "40200/40200 [==============================] - 4s 108us/sample - loss: 0.3476 - acc: 0.8929 - val_loss: 0.1251 - val_acc: 0.9595\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.3362 - acc: 0.8967\n",
      "Epoch 00022: val_loss improved from 0.12512 to 0.11822, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_2_conv_checkpoint/022-0.1182.hdf5\n",
      "40200/40200 [==============================] - 4s 109us/sample - loss: 0.3358 - acc: 0.8968 - val_loss: 0.1182 - val_acc: 0.9619\n",
      "Epoch 23/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.3198 - acc: 0.9017\n",
      "Epoch 00023: val_loss improved from 0.11822 to 0.11084, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_2_conv_checkpoint/023-0.1108.hdf5\n",
      "40200/40200 [==============================] - 4s 109us/sample - loss: 0.3198 - acc: 0.9017 - val_loss: 0.1108 - val_acc: 0.9653\n",
      "Epoch 24/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.3109 - acc: 0.9054\n",
      "Epoch 00024: val_loss improved from 0.11084 to 0.10929, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_2_conv_checkpoint/024-0.1093.hdf5\n",
      "40200/40200 [==============================] - 4s 109us/sample - loss: 0.3111 - acc: 0.9051 - val_loss: 0.1093 - val_acc: 0.9655\n",
      "Epoch 25/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.3061 - acc: 0.9066\n",
      "Epoch 00025: val_loss improved from 0.10929 to 0.10822, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_2_conv_checkpoint/025-0.1082.hdf5\n",
      "40200/40200 [==============================] - 4s 109us/sample - loss: 0.3061 - acc: 0.9067 - val_loss: 0.1082 - val_acc: 0.9660\n",
      "Epoch 26/500\n",
      "39744/40200 [============================>.] - ETA: 0s - loss: 0.2951 - acc: 0.9089\n",
      "Epoch 00026: val_loss improved from 0.10822 to 0.10371, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_2_conv_checkpoint/026-0.1037.hdf5\n",
      "40200/40200 [==============================] - 4s 110us/sample - loss: 0.2958 - acc: 0.9087 - val_loss: 0.1037 - val_acc: 0.9672\n",
      "Epoch 27/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.2899 - acc: 0.9096\n",
      "Epoch 00027: val_loss improved from 0.10371 to 0.09952, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_2_conv_checkpoint/027-0.0995.hdf5\n",
      "40200/40200 [==============================] - 4s 110us/sample - loss: 0.2898 - acc: 0.9096 - val_loss: 0.0995 - val_acc: 0.9688\n",
      "Epoch 28/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.2757 - acc: 0.9144\n",
      "Epoch 00028: val_loss improved from 0.09952 to 0.09719, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_2_conv_checkpoint/028-0.0972.hdf5\n",
      "40200/40200 [==============================] - 4s 109us/sample - loss: 0.2758 - acc: 0.9143 - val_loss: 0.0972 - val_acc: 0.9696\n",
      "Epoch 29/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.2748 - acc: 0.9145\n",
      "Epoch 00029: val_loss improved from 0.09719 to 0.09420, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_2_conv_checkpoint/029-0.0942.hdf5\n",
      "40200/40200 [==============================] - 4s 109us/sample - loss: 0.2748 - acc: 0.9145 - val_loss: 0.0942 - val_acc: 0.9711\n",
      "Epoch 30/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.2662 - acc: 0.9161\n",
      "Epoch 00030: val_loss improved from 0.09420 to 0.09082, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_2_conv_checkpoint/030-0.0908.hdf5\n",
      "40200/40200 [==============================] - 4s 103us/sample - loss: 0.2662 - acc: 0.9161 - val_loss: 0.0908 - val_acc: 0.9719\n",
      "Epoch 31/500\n",
      "39744/40200 [============================>.] - ETA: 0s - loss: 0.2603 - acc: 0.9202\n",
      "Epoch 00031: val_loss improved from 0.09082 to 0.08817, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_2_conv_checkpoint/031-0.0882.hdf5\n",
      "40200/40200 [==============================] - 4s 99us/sample - loss: 0.2600 - acc: 0.9201 - val_loss: 0.0882 - val_acc: 0.9729\n",
      "Epoch 32/500\n",
      "39744/40200 [============================>.] - ETA: 0s - loss: 0.2605 - acc: 0.9196\n",
      "Epoch 00032: val_loss improved from 0.08817 to 0.08656, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_2_conv_checkpoint/032-0.0866.hdf5\n",
      "40200/40200 [==============================] - 4s 108us/sample - loss: 0.2609 - acc: 0.9196 - val_loss: 0.0866 - val_acc: 0.9735\n",
      "Epoch 33/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.2518 - acc: 0.9214\n",
      "Epoch 00033: val_loss improved from 0.08656 to 0.08461, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_2_conv_checkpoint/033-0.0846.hdf5\n",
      "40200/40200 [==============================] - 4s 109us/sample - loss: 0.2517 - acc: 0.9214 - val_loss: 0.0846 - val_acc: 0.9739\n",
      "Epoch 34/500\n",
      "39552/40200 [============================>.] - ETA: 0s - loss: 0.2464 - acc: 0.9234\n",
      "Epoch 00034: val_loss improved from 0.08461 to 0.08363, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_2_conv_checkpoint/034-0.0836.hdf5\n",
      "40200/40200 [==============================] - 4s 106us/sample - loss: 0.2459 - acc: 0.9235 - val_loss: 0.0836 - val_acc: 0.9738\n",
      "Epoch 35/500\n",
      "39744/40200 [============================>.] - ETA: 0s - loss: 0.2461 - acc: 0.9238\n",
      "Epoch 00035: val_loss improved from 0.08363 to 0.08264, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_2_conv_checkpoint/035-0.0826.hdf5\n",
      "40200/40200 [==============================] - 4s 105us/sample - loss: 0.2459 - acc: 0.9239 - val_loss: 0.0826 - val_acc: 0.9750\n",
      "Epoch 36/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.2399 - acc: 0.9240\n",
      "Epoch 00036: val_loss improved from 0.08264 to 0.08162, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_2_conv_checkpoint/036-0.0816.hdf5\n",
      "40200/40200 [==============================] - 4s 109us/sample - loss: 0.2394 - acc: 0.9240 - val_loss: 0.0816 - val_acc: 0.9746\n",
      "Epoch 37/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.2298 - acc: 0.9281\n",
      "Epoch 00037: val_loss improved from 0.08162 to 0.08014, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_2_conv_checkpoint/037-0.0801.hdf5\n",
      "40200/40200 [==============================] - 4s 109us/sample - loss: 0.2298 - acc: 0.9282 - val_loss: 0.0801 - val_acc: 0.9758\n",
      "Epoch 38/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.2321 - acc: 0.9291\n",
      "Epoch 00038: val_loss improved from 0.08014 to 0.07742, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_2_conv_checkpoint/038-0.0774.hdf5\n",
      "40200/40200 [==============================] - 4s 109us/sample - loss: 0.2323 - acc: 0.9291 - val_loss: 0.0774 - val_acc: 0.9765\n",
      "Epoch 39/500\n",
      "39744/40200 [============================>.] - ETA: 0s - loss: 0.2306 - acc: 0.9299\n",
      "Epoch 00039: val_loss improved from 0.07742 to 0.07709, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_2_conv_checkpoint/039-0.0771.hdf5\n",
      "40200/40200 [==============================] - 4s 109us/sample - loss: 0.2302 - acc: 0.9299 - val_loss: 0.0771 - val_acc: 0.9768\n",
      "Epoch 40/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.2306 - acc: 0.9300\n",
      "Epoch 00040: val_loss improved from 0.07709 to 0.07708, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_2_conv_checkpoint/040-0.0771.hdf5\n",
      "40200/40200 [==============================] - 4s 109us/sample - loss: 0.2306 - acc: 0.9300 - val_loss: 0.0771 - val_acc: 0.9757\n",
      "Epoch 41/500\n",
      "39680/40200 [============================>.] - ETA: 0s - loss: 0.2223 - acc: 0.9308\n",
      "Epoch 00041: val_loss improved from 0.07708 to 0.07497, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_2_conv_checkpoint/041-0.0750.hdf5\n",
      "40200/40200 [==============================] - 4s 110us/sample - loss: 0.2227 - acc: 0.9306 - val_loss: 0.0750 - val_acc: 0.9768\n",
      "Epoch 42/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.2177 - acc: 0.9319\n",
      "Epoch 00042: val_loss improved from 0.07497 to 0.07426, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_2_conv_checkpoint/042-0.0743.hdf5\n",
      "40200/40200 [==============================] - 4s 109us/sample - loss: 0.2180 - acc: 0.9318 - val_loss: 0.0743 - val_acc: 0.9776\n",
      "Epoch 43/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.2192 - acc: 0.9319\n",
      "Epoch 00043: val_loss improved from 0.07426 to 0.07288, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_2_conv_checkpoint/043-0.0729.hdf5\n",
      "40200/40200 [==============================] - 4s 109us/sample - loss: 0.2185 - acc: 0.9321 - val_loss: 0.0729 - val_acc: 0.9783\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.2108 - acc: 0.9338\n",
      "Epoch 00044: val_loss improved from 0.07288 to 0.06999, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_2_conv_checkpoint/044-0.0700.hdf5\n",
      "40200/40200 [==============================] - 4s 104us/sample - loss: 0.2103 - acc: 0.9339 - val_loss: 0.0700 - val_acc: 0.9787\n",
      "Epoch 45/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.2119 - acc: 0.9352\n",
      "Epoch 00045: val_loss did not improve from 0.06999\n",
      "40200/40200 [==============================] - 4s 98us/sample - loss: 0.2119 - acc: 0.9352 - val_loss: 0.0730 - val_acc: 0.9773\n",
      "Epoch 46/500\n",
      "39616/40200 [============================>.] - ETA: 0s - loss: 0.2099 - acc: 0.9346\n",
      "Epoch 00046: val_loss improved from 0.06999 to 0.06970, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_2_conv_checkpoint/046-0.0697.hdf5\n",
      "40200/40200 [==============================] - 4s 108us/sample - loss: 0.2102 - acc: 0.9346 - val_loss: 0.0697 - val_acc: 0.9788\n",
      "Epoch 47/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.2091 - acc: 0.9331\n",
      "Epoch 00047: val_loss did not improve from 0.06970\n",
      "40200/40200 [==============================] - 4s 109us/sample - loss: 0.2092 - acc: 0.9331 - val_loss: 0.0715 - val_acc: 0.9782\n",
      "Epoch 48/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.2009 - acc: 0.9376\n",
      "Epoch 00048: val_loss improved from 0.06970 to 0.06895, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_2_conv_checkpoint/048-0.0689.hdf5\n",
      "40200/40200 [==============================] - 4s 109us/sample - loss: 0.2006 - acc: 0.9377 - val_loss: 0.0689 - val_acc: 0.9795\n",
      "Epoch 49/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.2052 - acc: 0.9356\n",
      "Epoch 00049: val_loss improved from 0.06895 to 0.06871, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_2_conv_checkpoint/049-0.0687.hdf5\n",
      "40200/40200 [==============================] - 4s 108us/sample - loss: 0.2052 - acc: 0.9356 - val_loss: 0.0687 - val_acc: 0.9797\n",
      "Epoch 50/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.2109 - acc: 0.9352\n",
      "Epoch 00050: val_loss did not improve from 0.06871\n",
      "40200/40200 [==============================] - 4s 108us/sample - loss: 0.2112 - acc: 0.9351 - val_loss: 0.0698 - val_acc: 0.9794\n",
      "Epoch 51/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.2019 - acc: 0.9366\n",
      "Epoch 00051: val_loss improved from 0.06871 to 0.06766, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_2_conv_checkpoint/051-0.0677.hdf5\n",
      "40200/40200 [==============================] - 4s 109us/sample - loss: 0.2019 - acc: 0.9366 - val_loss: 0.0677 - val_acc: 0.9796\n",
      "Epoch 52/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.1975 - acc: 0.9396\n",
      "Epoch 00052: val_loss improved from 0.06766 to 0.06643, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_2_conv_checkpoint/052-0.0664.hdf5\n",
      "40200/40200 [==============================] - 4s 109us/sample - loss: 0.1975 - acc: 0.9396 - val_loss: 0.0664 - val_acc: 0.9799\n",
      "Epoch 53/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.1986 - acc: 0.9384\n",
      "Epoch 00053: val_loss improved from 0.06643 to 0.06584, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_2_conv_checkpoint/053-0.0658.hdf5\n",
      "40200/40200 [==============================] - 4s 109us/sample - loss: 0.1986 - acc: 0.9383 - val_loss: 0.0658 - val_acc: 0.9802\n",
      "Epoch 54/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.1950 - acc: 0.9377\n",
      "Epoch 00054: val_loss did not improve from 0.06584\n",
      "40200/40200 [==============================] - 4s 108us/sample - loss: 0.1949 - acc: 0.9377 - val_loss: 0.0667 - val_acc: 0.9798\n",
      "Epoch 55/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.1956 - acc: 0.9390\n",
      "Epoch 00055: val_loss did not improve from 0.06584\n",
      "40200/40200 [==============================] - 4s 108us/sample - loss: 0.1955 - acc: 0.9390 - val_loss: 0.0662 - val_acc: 0.9792\n",
      "Epoch 56/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.1877 - acc: 0.9425\n",
      "Epoch 00056: val_loss did not improve from 0.06584\n",
      "40200/40200 [==============================] - 4s 108us/sample - loss: 0.1886 - acc: 0.9424 - val_loss: 0.0662 - val_acc: 0.9791\n",
      "Epoch 57/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.1951 - acc: 0.9388\n",
      "Epoch 00057: val_loss did not improve from 0.06584\n",
      "40200/40200 [==============================] - 4s 109us/sample - loss: 0.1951 - acc: 0.9388 - val_loss: 0.0679 - val_acc: 0.9792\n",
      "Epoch 58/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.1882 - acc: 0.9410\n",
      "Epoch 00058: val_loss improved from 0.06584 to 0.06467, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_2_conv_checkpoint/058-0.0647.hdf5\n",
      "40200/40200 [==============================] - 4s 107us/sample - loss: 0.1878 - acc: 0.9411 - val_loss: 0.0647 - val_acc: 0.9805\n",
      "Epoch 59/500\n",
      "39616/40200 [============================>.] - ETA: 0s - loss: 0.1937 - acc: 0.9403\n",
      "Epoch 00059: val_loss improved from 0.06467 to 0.06440, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_2_conv_checkpoint/059-0.0644.hdf5\n",
      "40200/40200 [==============================] - 4s 100us/sample - loss: 0.1938 - acc: 0.9403 - val_loss: 0.0644 - val_acc: 0.9799\n",
      "Epoch 60/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.1832 - acc: 0.9432\n",
      "Epoch 00060: val_loss improved from 0.06440 to 0.06375, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_2_conv_checkpoint/060-0.0637.hdf5\n",
      "40200/40200 [==============================] - 4s 106us/sample - loss: 0.1832 - acc: 0.9432 - val_loss: 0.0637 - val_acc: 0.9802\n",
      "Epoch 61/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.1833 - acc: 0.9429\n",
      "Epoch 00061: val_loss did not improve from 0.06375\n",
      "40200/40200 [==============================] - 4s 108us/sample - loss: 0.1839 - acc: 0.9429 - val_loss: 0.0639 - val_acc: 0.9803\n",
      "Epoch 62/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.1867 - acc: 0.9423\n",
      "Epoch 00062: val_loss improved from 0.06375 to 0.06153, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_2_conv_checkpoint/062-0.0615.hdf5\n",
      "40200/40200 [==============================] - 5s 113us/sample - loss: 0.1866 - acc: 0.9423 - val_loss: 0.0615 - val_acc: 0.9812\n",
      "Epoch 63/500\n",
      "39680/40200 [============================>.] - ETA: 0s - loss: 0.1896 - acc: 0.9419\n",
      "Epoch 00063: val_loss did not improve from 0.06153\n",
      "40200/40200 [==============================] - 4s 108us/sample - loss: 0.1899 - acc: 0.9419 - val_loss: 0.0636 - val_acc: 0.9805\n",
      "Epoch 64/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.1804 - acc: 0.9438\n",
      "Epoch 00064: val_loss did not improve from 0.06153\n",
      "40200/40200 [==============================] - 4s 108us/sample - loss: 0.1806 - acc: 0.9438 - val_loss: 0.0626 - val_acc: 0.9810\n",
      "Epoch 65/500\n",
      "39680/40200 [============================>.] - ETA: 0s - loss: 0.1844 - acc: 0.9423\n",
      "Epoch 00065: val_loss did not improve from 0.06153\n",
      "40200/40200 [==============================] - 4s 108us/sample - loss: 0.1840 - acc: 0.9425 - val_loss: 0.0626 - val_acc: 0.9806\n",
      "Epoch 66/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.1750 - acc: 0.9445\n",
      "Epoch 00066: val_loss did not improve from 0.06153\n",
      "40200/40200 [==============================] - 4s 109us/sample - loss: 0.1757 - acc: 0.9443 - val_loss: 0.0622 - val_acc: 0.9810\n",
      "Epoch 67/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.1787 - acc: 0.9447\n",
      "Epoch 00067: val_loss improved from 0.06153 to 0.06064, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_2_conv_checkpoint/067-0.0606.hdf5\n",
      "40200/40200 [==============================] - 4s 110us/sample - loss: 0.1782 - acc: 0.9448 - val_loss: 0.0606 - val_acc: 0.9815\n",
      "Epoch 68/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.1754 - acc: 0.9447\n",
      "Epoch 00068: val_loss improved from 0.06064 to 0.05904, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_2_conv_checkpoint/068-0.0590.hdf5\n",
      "40200/40200 [==============================] - 4s 110us/sample - loss: 0.1751 - acc: 0.9448 - val_loss: 0.0590 - val_acc: 0.9815\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.1751 - acc: 0.9457\n",
      "Epoch 00069: val_loss did not improve from 0.05904\n",
      "40200/40200 [==============================] - 4s 109us/sample - loss: 0.1750 - acc: 0.9457 - val_loss: 0.0605 - val_acc: 0.9810\n",
      "Epoch 70/500\n",
      "39744/40200 [============================>.] - ETA: 0s - loss: 0.1772 - acc: 0.9446\n",
      "Epoch 00070: val_loss did not improve from 0.05904\n",
      "40200/40200 [==============================] - 4s 108us/sample - loss: 0.1767 - acc: 0.9447 - val_loss: 0.0605 - val_acc: 0.9812\n",
      "Epoch 71/500\n",
      "39744/40200 [============================>.] - ETA: 0s - loss: 0.1727 - acc: 0.9459\n",
      "Epoch 00071: val_loss did not improve from 0.05904\n",
      "40200/40200 [==============================] - 4s 109us/sample - loss: 0.1725 - acc: 0.9460 - val_loss: 0.0606 - val_acc: 0.9807\n",
      "Epoch 72/500\n",
      "39680/40200 [============================>.] - ETA: 0s - loss: 0.1752 - acc: 0.9442\n",
      "Epoch 00072: val_loss did not improve from 0.05904\n",
      "40200/40200 [==============================] - 4s 106us/sample - loss: 0.1747 - acc: 0.9444 - val_loss: 0.0592 - val_acc: 0.9810\n",
      "Epoch 73/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.1721 - acc: 0.9473\n",
      "Epoch 00073: val_loss did not improve from 0.05904\n",
      "40200/40200 [==============================] - 4s 98us/sample - loss: 0.1722 - acc: 0.9473 - val_loss: 0.0604 - val_acc: 0.9809\n",
      "Epoch 74/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.1720 - acc: 0.9451\n",
      "Epoch 00074: val_loss did not improve from 0.05904\n",
      "40200/40200 [==============================] - 4s 105us/sample - loss: 0.1720 - acc: 0.9452 - val_loss: 0.0594 - val_acc: 0.9815\n",
      "Epoch 75/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.1684 - acc: 0.9463\n",
      "Epoch 00075: val_loss did not improve from 0.05904\n",
      "40200/40200 [==============================] - 4s 108us/sample - loss: 0.1689 - acc: 0.9462 - val_loss: 0.0594 - val_acc: 0.9811\n",
      "Epoch 76/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.1729 - acc: 0.9465\n",
      "Epoch 00076: val_loss did not improve from 0.05904\n",
      "40200/40200 [==============================] - 4s 109us/sample - loss: 0.1728 - acc: 0.9465 - val_loss: 0.0592 - val_acc: 0.9814\n",
      "Epoch 77/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.1644 - acc: 0.9477\n",
      "Epoch 00077: val_loss improved from 0.05904 to 0.05870, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_2_conv_checkpoint/077-0.0587.hdf5\n",
      "40200/40200 [==============================] - 4s 109us/sample - loss: 0.1641 - acc: 0.9478 - val_loss: 0.0587 - val_acc: 0.9813\n",
      "Epoch 78/500\n",
      "39744/40200 [============================>.] - ETA: 0s - loss: 0.1646 - acc: 0.9485\n",
      "Epoch 00078: val_loss improved from 0.05870 to 0.05833, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_2_conv_checkpoint/078-0.0583.hdf5\n",
      "40200/40200 [==============================] - 4s 109us/sample - loss: 0.1650 - acc: 0.9484 - val_loss: 0.0583 - val_acc: 0.9820\n",
      "Epoch 79/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.1720 - acc: 0.9471\n",
      "Epoch 00079: val_loss improved from 0.05833 to 0.05796, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_2_conv_checkpoint/079-0.0580.hdf5\n",
      "40200/40200 [==============================] - 4s 108us/sample - loss: 0.1719 - acc: 0.9471 - val_loss: 0.0580 - val_acc: 0.9817\n",
      "Epoch 80/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.1681 - acc: 0.9473\n",
      "Epoch 00080: val_loss improved from 0.05796 to 0.05697, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_2_conv_checkpoint/080-0.0570.hdf5\n",
      "40200/40200 [==============================] - 4s 108us/sample - loss: 0.1680 - acc: 0.9473 - val_loss: 0.0570 - val_acc: 0.9817\n",
      "Epoch 81/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.1694 - acc: 0.9477\n",
      "Epoch 00081: val_loss did not improve from 0.05697\n",
      "40200/40200 [==============================] - 4s 107us/sample - loss: 0.1704 - acc: 0.9475 - val_loss: 0.0597 - val_acc: 0.9814\n",
      "Epoch 82/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.1650 - acc: 0.9481\n",
      "Epoch 00082: val_loss improved from 0.05697 to 0.05686, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_2_conv_checkpoint/082-0.0569.hdf5\n",
      "40200/40200 [==============================] - 4s 109us/sample - loss: 0.1649 - acc: 0.9481 - val_loss: 0.0569 - val_acc: 0.9824\n",
      "Epoch 83/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.1691 - acc: 0.9484\n",
      "Epoch 00083: val_loss did not improve from 0.05686\n",
      "40200/40200 [==============================] - 4s 109us/sample - loss: 0.1691 - acc: 0.9484 - val_loss: 0.0576 - val_acc: 0.9822\n",
      "Epoch 84/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.1645 - acc: 0.9498\n",
      "Epoch 00084: val_loss did not improve from 0.05686\n",
      "40200/40200 [==============================] - 4s 109us/sample - loss: 0.1644 - acc: 0.9499 - val_loss: 0.0573 - val_acc: 0.9825\n",
      "Epoch 85/500\n",
      "39744/40200 [============================>.] - ETA: 0s - loss: 0.1642 - acc: 0.9486\n",
      "Epoch 00085: val_loss did not improve from 0.05686\n",
      "40200/40200 [==============================] - 4s 108us/sample - loss: 0.1640 - acc: 0.9486 - val_loss: 0.0579 - val_acc: 0.9821\n",
      "Epoch 86/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.1603 - acc: 0.9498\n",
      "Epoch 00086: val_loss did not improve from 0.05686\n",
      "40200/40200 [==============================] - 4s 105us/sample - loss: 0.1601 - acc: 0.9498 - val_loss: 0.0571 - val_acc: 0.9823\n",
      "Epoch 87/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.1587 - acc: 0.9507\n",
      "Epoch 00087: val_loss did not improve from 0.05686\n",
      "40200/40200 [==============================] - 4s 99us/sample - loss: 0.1589 - acc: 0.9507 - val_loss: 0.0580 - val_acc: 0.9818\n",
      "Epoch 88/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.1634 - acc: 0.9489\n",
      "Epoch 00088: val_loss did not improve from 0.05686\n",
      "40200/40200 [==============================] - 4s 105us/sample - loss: 0.1635 - acc: 0.9489 - val_loss: 0.0584 - val_acc: 0.9817\n",
      "Epoch 89/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.1597 - acc: 0.9495\n",
      "Epoch 00089: val_loss improved from 0.05686 to 0.05557, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_2_conv_checkpoint/089-0.0556.hdf5\n",
      "40200/40200 [==============================] - 4s 109us/sample - loss: 0.1597 - acc: 0.9495 - val_loss: 0.0556 - val_acc: 0.9828\n",
      "Epoch 90/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.1634 - acc: 0.9475\n",
      "Epoch 00090: val_loss improved from 0.05557 to 0.05539, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_2_conv_checkpoint/090-0.0554.hdf5\n",
      "40200/40200 [==============================] - 4s 109us/sample - loss: 0.1631 - acc: 0.9475 - val_loss: 0.0554 - val_acc: 0.9829\n",
      "Epoch 91/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.1577 - acc: 0.9505\n",
      "Epoch 00091: val_loss did not improve from 0.05539\n",
      "40200/40200 [==============================] - 4s 108us/sample - loss: 0.1579 - acc: 0.9505 - val_loss: 0.0562 - val_acc: 0.9824\n",
      "Epoch 92/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.1600 - acc: 0.9512\n",
      "Epoch 00092: val_loss did not improve from 0.05539\n",
      "40200/40200 [==============================] - 4s 109us/sample - loss: 0.1601 - acc: 0.9512 - val_loss: 0.0560 - val_acc: 0.9828\n",
      "Epoch 93/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.1589 - acc: 0.9499\n",
      "Epoch 00093: val_loss did not improve from 0.05539\n",
      "40200/40200 [==============================] - 4s 108us/sample - loss: 0.1588 - acc: 0.9498 - val_loss: 0.0558 - val_acc: 0.9831\n",
      "Epoch 94/500\n",
      "39680/40200 [============================>.] - ETA: 0s - loss: 0.1614 - acc: 0.9498\n",
      "Epoch 00094: val_loss improved from 0.05539 to 0.05523, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_2_conv_checkpoint/094-0.0552.hdf5\n",
      "40200/40200 [==============================] - 4s 110us/sample - loss: 0.1616 - acc: 0.9498 - val_loss: 0.0552 - val_acc: 0.9825\n",
      "Epoch 95/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.1574 - acc: 0.9513\n",
      "Epoch 00095: val_loss improved from 0.05523 to 0.05406, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_2_conv_checkpoint/095-0.0541.hdf5\n",
      "40200/40200 [==============================] - 4s 110us/sample - loss: 0.1573 - acc: 0.9513 - val_loss: 0.0541 - val_acc: 0.9837\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.1541 - acc: 0.9531\n",
      "Epoch 00096: val_loss improved from 0.05406 to 0.05375, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_2_conv_checkpoint/096-0.0537.hdf5\n",
      "40200/40200 [==============================] - 4s 109us/sample - loss: 0.1538 - acc: 0.9531 - val_loss: 0.0537 - val_acc: 0.9838\n",
      "Epoch 97/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.1528 - acc: 0.9530\n",
      "Epoch 00097: val_loss did not improve from 0.05375\n",
      "40200/40200 [==============================] - 4s 108us/sample - loss: 0.1533 - acc: 0.9529 - val_loss: 0.0547 - val_acc: 0.9833\n",
      "Epoch 98/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.1544 - acc: 0.9509\n",
      "Epoch 00098: val_loss did not improve from 0.05375\n",
      "40200/40200 [==============================] - 4s 108us/sample - loss: 0.1544 - acc: 0.9508 - val_loss: 0.0546 - val_acc: 0.9839\n",
      "Epoch 99/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.1484 - acc: 0.9529\n",
      "Epoch 00099: val_loss did not improve from 0.05375\n",
      "40200/40200 [==============================] - 4s 107us/sample - loss: 0.1486 - acc: 0.9529 - val_loss: 0.0545 - val_acc: 0.9830\n",
      "Epoch 100/500\n",
      "39680/40200 [============================>.] - ETA: 0s - loss: 0.1542 - acc: 0.9520\n",
      "Epoch 00100: val_loss improved from 0.05375 to 0.05280, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_2_conv_checkpoint/100-0.0528.hdf5\n",
      "40200/40200 [==============================] - 4s 109us/sample - loss: 0.1538 - acc: 0.9520 - val_loss: 0.0528 - val_acc: 0.9838\n",
      "Epoch 101/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.1538 - acc: 0.9524\n",
      "Epoch 00101: val_loss did not improve from 0.05280\n",
      "40200/40200 [==============================] - 4s 99us/sample - loss: 0.1538 - acc: 0.9524 - val_loss: 0.0533 - val_acc: 0.9833\n",
      "Epoch 102/500\n",
      "39680/40200 [============================>.] - ETA: 0s - loss: 0.1516 - acc: 0.9523\n",
      "Epoch 00102: val_loss did not improve from 0.05280\n",
      "40200/40200 [==============================] - 4s 102us/sample - loss: 0.1516 - acc: 0.9523 - val_loss: 0.0535 - val_acc: 0.9838\n",
      "Epoch 103/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.1551 - acc: 0.9509\n",
      "Epoch 00103: val_loss did not improve from 0.05280\n",
      "40200/40200 [==============================] - 4s 109us/sample - loss: 0.1550 - acc: 0.9509 - val_loss: 0.0533 - val_acc: 0.9838\n",
      "Epoch 104/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.1516 - acc: 0.9524\n",
      "Epoch 00104: val_loss did not improve from 0.05280\n",
      "40200/40200 [==============================] - 4s 108us/sample - loss: 0.1517 - acc: 0.9524 - val_loss: 0.0531 - val_acc: 0.9840\n",
      "Epoch 105/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.1520 - acc: 0.9516\n",
      "Epoch 00105: val_loss did not improve from 0.05280\n",
      "40200/40200 [==============================] - 4s 109us/sample - loss: 0.1519 - acc: 0.9516 - val_loss: 0.0534 - val_acc: 0.9835\n",
      "Epoch 106/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.1500 - acc: 0.9530\n",
      "Epoch 00106: val_loss did not improve from 0.05280\n",
      "40200/40200 [==============================] - 4s 108us/sample - loss: 0.1501 - acc: 0.9531 - val_loss: 0.0529 - val_acc: 0.9840\n",
      "Epoch 107/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.1478 - acc: 0.9526\n",
      "Epoch 00107: val_loss did not improve from 0.05280\n",
      "40200/40200 [==============================] - 4s 109us/sample - loss: 0.1477 - acc: 0.9526 - val_loss: 0.0528 - val_acc: 0.9838\n",
      "Epoch 108/500\n",
      "39680/40200 [============================>.] - ETA: 0s - loss: 0.1507 - acc: 0.9526\n",
      "Epoch 00108: val_loss did not improve from 0.05280\n",
      "40200/40200 [==============================] - 4s 108us/sample - loss: 0.1511 - acc: 0.9525 - val_loss: 0.0528 - val_acc: 0.9838\n",
      "Epoch 109/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.1504 - acc: 0.9519\n",
      "Epoch 00109: val_loss improved from 0.05280 to 0.05206, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_2_conv_checkpoint/109-0.0521.hdf5\n",
      "40200/40200 [==============================] - 4s 109us/sample - loss: 0.1499 - acc: 0.9520 - val_loss: 0.0521 - val_acc: 0.9842\n",
      "Epoch 110/500\n",
      "39744/40200 [============================>.] - ETA: 0s - loss: 0.1528 - acc: 0.9522\n",
      "Epoch 00110: val_loss did not improve from 0.05206\n",
      "40200/40200 [==============================] - 4s 107us/sample - loss: 0.1527 - acc: 0.9522 - val_loss: 0.0531 - val_acc: 0.9846\n",
      "Epoch 111/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.1449 - acc: 0.9548\n",
      "Epoch 00111: val_loss did not improve from 0.05206\n",
      "40200/40200 [==============================] - 4s 108us/sample - loss: 0.1448 - acc: 0.9548 - val_loss: 0.0525 - val_acc: 0.9839\n",
      "Epoch 112/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.1475 - acc: 0.9540\n",
      "Epoch 00112: val_loss improved from 0.05206 to 0.05124, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_2_conv_checkpoint/112-0.0512.hdf5\n",
      "40200/40200 [==============================] - 4s 109us/sample - loss: 0.1481 - acc: 0.9540 - val_loss: 0.0512 - val_acc: 0.9843\n",
      "Epoch 113/500\n",
      "39680/40200 [============================>.] - ETA: 0s - loss: 0.1502 - acc: 0.9530\n",
      "Epoch 00113: val_loss did not improve from 0.05124\n",
      "40200/40200 [==============================] - 4s 109us/sample - loss: 0.1496 - acc: 0.9532 - val_loss: 0.0515 - val_acc: 0.9845\n",
      "Epoch 114/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.1456 - acc: 0.9552\n",
      "Epoch 00114: val_loss did not improve from 0.05124\n",
      "40200/40200 [==============================] - 5s 118us/sample - loss: 0.1453 - acc: 0.9553 - val_loss: 0.0523 - val_acc: 0.9836\n",
      "Epoch 115/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.1430 - acc: 0.9543\n",
      "Epoch 00115: val_loss improved from 0.05124 to 0.05030, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_2_conv_checkpoint/115-0.0503.hdf5\n",
      "40200/40200 [==============================] - 4s 104us/sample - loss: 0.1429 - acc: 0.9544 - val_loss: 0.0503 - val_acc: 0.9840\n",
      "Epoch 116/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.1504 - acc: 0.9527\n",
      "Epoch 00116: val_loss did not improve from 0.05030\n",
      "40200/40200 [==============================] - 4s 106us/sample - loss: 0.1511 - acc: 0.9525 - val_loss: 0.0529 - val_acc: 0.9840\n",
      "Epoch 117/500\n",
      "39744/40200 [============================>.] - ETA: 0s - loss: 0.1410 - acc: 0.9555\n",
      "Epoch 00117: val_loss did not improve from 0.05030\n",
      "40200/40200 [==============================] - 4s 108us/sample - loss: 0.1411 - acc: 0.9555 - val_loss: 0.0509 - val_acc: 0.9845\n",
      "Epoch 118/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.1425 - acc: 0.9545\n",
      "Epoch 00118: val_loss did not improve from 0.05030\n",
      "40200/40200 [==============================] - 4s 108us/sample - loss: 0.1425 - acc: 0.9544 - val_loss: 0.0511 - val_acc: 0.9845\n",
      "Epoch 119/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.1438 - acc: 0.9544\n",
      "Epoch 00119: val_loss did not improve from 0.05030\n",
      "40200/40200 [==============================] - 4s 108us/sample - loss: 0.1442 - acc: 0.9541 - val_loss: 0.0505 - val_acc: 0.9842\n",
      "Epoch 120/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.1421 - acc: 0.9549\n",
      "Epoch 00120: val_loss did not improve from 0.05030\n",
      "40200/40200 [==============================] - 4s 109us/sample - loss: 0.1426 - acc: 0.9549 - val_loss: 0.0510 - val_acc: 0.9842\n",
      "Epoch 121/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.1483 - acc: 0.9537\n",
      "Epoch 00121: val_loss improved from 0.05030 to 0.04977, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_2_conv_checkpoint/121-0.0498.hdf5\n",
      "40200/40200 [==============================] - 5s 118us/sample - loss: 0.1482 - acc: 0.9538 - val_loss: 0.0498 - val_acc: 0.9851\n",
      "Epoch 122/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.1401 - acc: 0.9557\n",
      "Epoch 00122: val_loss did not improve from 0.04977\n",
      "40200/40200 [==============================] - 4s 108us/sample - loss: 0.1405 - acc: 0.9555 - val_loss: 0.0512 - val_acc: 0.9842\n",
      "Epoch 123/500\n",
      "39744/40200 [============================>.] - ETA: 0s - loss: 0.1422 - acc: 0.9546\n",
      "Epoch 00123: val_loss improved from 0.04977 to 0.04919, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_2_conv_checkpoint/123-0.0492.hdf5\n",
      "40200/40200 [==============================] - 4s 110us/sample - loss: 0.1421 - acc: 0.9548 - val_loss: 0.0492 - val_acc: 0.9853\n",
      "Epoch 124/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.1392 - acc: 0.9559\n",
      "Epoch 00124: val_loss did not improve from 0.04919\n",
      "40200/40200 [==============================] - 4s 109us/sample - loss: 0.1394 - acc: 0.9558 - val_loss: 0.0503 - val_acc: 0.9845\n",
      "Epoch 125/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.1435 - acc: 0.9554\n",
      "Epoch 00125: val_loss did not improve from 0.04919\n",
      "40200/40200 [==============================] - 4s 108us/sample - loss: 0.1439 - acc: 0.9553 - val_loss: 0.0515 - val_acc: 0.9842\n",
      "Epoch 126/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.1434 - acc: 0.9548\n",
      "Epoch 00126: val_loss did not improve from 0.04919\n",
      "40200/40200 [==============================] - 4s 108us/sample - loss: 0.1433 - acc: 0.9548 - val_loss: 0.0506 - val_acc: 0.9846\n",
      "Epoch 127/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.1427 - acc: 0.9555\n",
      "Epoch 00127: val_loss did not improve from 0.04919\n",
      "40200/40200 [==============================] - 4s 108us/sample - loss: 0.1428 - acc: 0.9555 - val_loss: 0.0502 - val_acc: 0.9848\n",
      "Epoch 128/500\n",
      "39744/40200 [============================>.] - ETA: 0s - loss: 0.1406 - acc: 0.9549\n",
      "Epoch 00128: val_loss did not improve from 0.04919\n",
      "40200/40200 [==============================] - 4s 105us/sample - loss: 0.1403 - acc: 0.9549 - val_loss: 0.0503 - val_acc: 0.9851\n",
      "Epoch 129/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.1422 - acc: 0.9544\n",
      "Epoch 00129: val_loss did not improve from 0.04919\n",
      "40200/40200 [==============================] - 4s 98us/sample - loss: 0.1422 - acc: 0.9543 - val_loss: 0.0503 - val_acc: 0.9843\n",
      "Epoch 130/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.1403 - acc: 0.9567\n",
      "Epoch 00130: val_loss improved from 0.04919 to 0.04883, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_2_conv_checkpoint/130-0.0488.hdf5\n",
      "40200/40200 [==============================] - 4s 105us/sample - loss: 0.1405 - acc: 0.9566 - val_loss: 0.0488 - val_acc: 0.9857\n",
      "Epoch 131/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.1390 - acc: 0.9562\n",
      "Epoch 00131: val_loss did not improve from 0.04883\n",
      "40200/40200 [==============================] - 4s 108us/sample - loss: 0.1390 - acc: 0.9561 - val_loss: 0.0507 - val_acc: 0.9844\n",
      "Epoch 132/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.1394 - acc: 0.9560\n",
      "Epoch 00132: val_loss did not improve from 0.04883\n",
      "40200/40200 [==============================] - 4s 108us/sample - loss: 0.1397 - acc: 0.9559 - val_loss: 0.0509 - val_acc: 0.9840\n",
      "Epoch 133/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.1398 - acc: 0.9565\n",
      "Epoch 00133: val_loss did not improve from 0.04883\n",
      "40200/40200 [==============================] - 4s 109us/sample - loss: 0.1400 - acc: 0.9564 - val_loss: 0.0505 - val_acc: 0.9846\n",
      "Epoch 134/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.1392 - acc: 0.9566\n",
      "Epoch 00134: val_loss did not improve from 0.04883\n",
      "40200/40200 [==============================] - 4s 108us/sample - loss: 0.1394 - acc: 0.9567 - val_loss: 0.0499 - val_acc: 0.9848\n",
      "Epoch 135/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.1335 - acc: 0.9576\n",
      "Epoch 00135: val_loss did not improve from 0.04883\n",
      "40200/40200 [==============================] - 4s 108us/sample - loss: 0.1340 - acc: 0.9576 - val_loss: 0.0515 - val_acc: 0.9843\n",
      "Epoch 136/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.1399 - acc: 0.9559\n",
      "Epoch 00136: val_loss did not improve from 0.04883\n",
      "40200/40200 [==============================] - 4s 108us/sample - loss: 0.1400 - acc: 0.9559 - val_loss: 0.0491 - val_acc: 0.9849\n",
      "Epoch 137/500\n",
      "39680/40200 [============================>.] - ETA: 0s - loss: 0.1346 - acc: 0.9578\n",
      "Epoch 00137: val_loss improved from 0.04883 to 0.04856, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_2_conv_checkpoint/137-0.0486.hdf5\n",
      "40200/40200 [==============================] - 4s 108us/sample - loss: 0.1345 - acc: 0.9580 - val_loss: 0.0486 - val_acc: 0.9852\n",
      "Epoch 138/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.1364 - acc: 0.9567\n",
      "Epoch 00138: val_loss did not improve from 0.04856\n",
      "40200/40200 [==============================] - 4s 108us/sample - loss: 0.1360 - acc: 0.9569 - val_loss: 0.0493 - val_acc: 0.9848\n",
      "Epoch 139/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.1368 - acc: 0.9572\n",
      "Epoch 00139: val_loss improved from 0.04856 to 0.04849, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_2_conv_checkpoint/139-0.0485.hdf5\n",
      "40200/40200 [==============================] - 4s 108us/sample - loss: 0.1371 - acc: 0.9571 - val_loss: 0.0485 - val_acc: 0.9848\n",
      "Epoch 140/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.1370 - acc: 0.9564\n",
      "Epoch 00140: val_loss improved from 0.04849 to 0.04784, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_2_conv_checkpoint/140-0.0478.hdf5\n",
      "40200/40200 [==============================] - 4s 109us/sample - loss: 0.1367 - acc: 0.9565 - val_loss: 0.0478 - val_acc: 0.9855\n",
      "Epoch 141/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.1342 - acc: 0.9580\n",
      "Epoch 00141: val_loss improved from 0.04784 to 0.04757, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_2_conv_checkpoint/141-0.0476.hdf5\n",
      "40200/40200 [==============================] - 4s 109us/sample - loss: 0.1342 - acc: 0.9580 - val_loss: 0.0476 - val_acc: 0.9856\n",
      "Epoch 142/500\n",
      "39744/40200 [============================>.] - ETA: 0s - loss: 0.1348 - acc: 0.9576\n",
      "Epoch 00142: val_loss did not improve from 0.04757\n",
      "40200/40200 [==============================] - 4s 105us/sample - loss: 0.1354 - acc: 0.9575 - val_loss: 0.0486 - val_acc: 0.9851\n",
      "Epoch 143/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.1353 - acc: 0.9578\n",
      "Epoch 00143: val_loss did not improve from 0.04757\n",
      "40200/40200 [==============================] - 4s 98us/sample - loss: 0.1358 - acc: 0.9578 - val_loss: 0.0481 - val_acc: 0.9849\n",
      "Epoch 144/500\n",
      "39680/40200 [============================>.] - ETA: 0s - loss: 0.1360 - acc: 0.9575\n",
      "Epoch 00144: val_loss did not improve from 0.04757\n",
      "40200/40200 [==============================] - 4s 100us/sample - loss: 0.1364 - acc: 0.9575 - val_loss: 0.0484 - val_acc: 0.9853\n",
      "Epoch 145/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.1344 - acc: 0.9587\n",
      "Epoch 00145: val_loss did not improve from 0.04757\n",
      "40200/40200 [==============================] - 4s 107us/sample - loss: 0.1340 - acc: 0.9588 - val_loss: 0.0487 - val_acc: 0.9847\n",
      "Epoch 146/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.1357 - acc: 0.9566\n",
      "Epoch 00146: val_loss did not improve from 0.04757\n",
      "40200/40200 [==============================] - 4s 108us/sample - loss: 0.1354 - acc: 0.9567 - val_loss: 0.0484 - val_acc: 0.9851\n",
      "Epoch 147/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.1362 - acc: 0.9561\n",
      "Epoch 00147: val_loss improved from 0.04757 to 0.04751, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_2_conv_checkpoint/147-0.0475.hdf5\n",
      "40200/40200 [==============================] - 4s 109us/sample - loss: 0.1362 - acc: 0.9561 - val_loss: 0.0475 - val_acc: 0.9855\n",
      "Epoch 148/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.1351 - acc: 0.9578\n",
      "Epoch 00148: val_loss improved from 0.04751 to 0.04717, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_2_conv_checkpoint/148-0.0472.hdf5\n",
      "40200/40200 [==============================] - 4s 109us/sample - loss: 0.1347 - acc: 0.9579 - val_loss: 0.0472 - val_acc: 0.9858\n",
      "Epoch 149/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.1389 - acc: 0.9569\n",
      "Epoch 00149: val_loss did not improve from 0.04717\n",
      "40200/40200 [==============================] - 4s 108us/sample - loss: 0.1385 - acc: 0.9570 - val_loss: 0.0483 - val_acc: 0.9848\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 150/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.1366 - acc: 0.9566\n",
      "Epoch 00150: val_loss did not improve from 0.04717\n",
      "40200/40200 [==============================] - 4s 108us/sample - loss: 0.1366 - acc: 0.9566 - val_loss: 0.0475 - val_acc: 0.9859\n",
      "Epoch 151/500\n",
      "39744/40200 [============================>.] - ETA: 0s - loss: 0.1324 - acc: 0.9581\n",
      "Epoch 00151: val_loss did not improve from 0.04717\n",
      "40200/40200 [==============================] - 4s 108us/sample - loss: 0.1331 - acc: 0.9579 - val_loss: 0.0479 - val_acc: 0.9852\n",
      "Epoch 152/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.1357 - acc: 0.9580\n",
      "Epoch 00152: val_loss did not improve from 0.04717\n",
      "40200/40200 [==============================] - 4s 107us/sample - loss: 0.1358 - acc: 0.9580 - val_loss: 0.0484 - val_acc: 0.9851\n",
      "Epoch 153/500\n",
      "39680/40200 [============================>.] - ETA: 0s - loss: 0.1315 - acc: 0.9588\n",
      "Epoch 00153: val_loss did not improve from 0.04717\n",
      "40200/40200 [==============================] - 4s 108us/sample - loss: 0.1317 - acc: 0.9587 - val_loss: 0.0483 - val_acc: 0.9847\n",
      "Epoch 154/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.1359 - acc: 0.9578\n",
      "Epoch 00154: val_loss did not improve from 0.04717\n",
      "40200/40200 [==============================] - 4s 109us/sample - loss: 0.1359 - acc: 0.9578 - val_loss: 0.0479 - val_acc: 0.9856\n",
      "Epoch 155/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.1384 - acc: 0.9569\n",
      "Epoch 00155: val_loss did not improve from 0.04717\n",
      "40200/40200 [==============================] - 4s 108us/sample - loss: 0.1382 - acc: 0.9569 - val_loss: 0.0475 - val_acc: 0.9856\n",
      "Epoch 156/500\n",
      "39616/40200 [============================>.] - ETA: 0s - loss: 0.1335 - acc: 0.9583\n",
      "Epoch 00156: val_loss did not improve from 0.04717\n",
      "40200/40200 [==============================] - 4s 107us/sample - loss: 0.1337 - acc: 0.9582 - val_loss: 0.0478 - val_acc: 0.9858\n",
      "Epoch 157/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.1294 - acc: 0.9593\n",
      "Epoch 00157: val_loss did not improve from 0.04717\n",
      "40200/40200 [==============================] - 4s 99us/sample - loss: 0.1295 - acc: 0.9594 - val_loss: 0.0487 - val_acc: 0.9843\n",
      "Epoch 158/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.1305 - acc: 0.9595\n",
      "Epoch 00158: val_loss did not improve from 0.04717\n",
      "40200/40200 [==============================] - 4s 102us/sample - loss: 0.1306 - acc: 0.9595 - val_loss: 0.0482 - val_acc: 0.9852\n",
      "Epoch 159/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.1360 - acc: 0.9559\n",
      "Epoch 00159: val_loss did not improve from 0.04717\n",
      "40200/40200 [==============================] - 4s 111us/sample - loss: 0.1360 - acc: 0.9560 - val_loss: 0.0473 - val_acc: 0.9859\n",
      "Epoch 160/500\n",
      "39744/40200 [============================>.] - ETA: 0s - loss: 0.1354 - acc: 0.9562\n",
      "Epoch 00160: val_loss did not improve from 0.04717\n",
      "40200/40200 [==============================] - 5s 118us/sample - loss: 0.1358 - acc: 0.9562 - val_loss: 0.0482 - val_acc: 0.9853\n",
      "Epoch 161/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.1294 - acc: 0.9594\n",
      "Epoch 00161: val_loss did not improve from 0.04717\n",
      "40200/40200 [==============================] - 5s 117us/sample - loss: 0.1293 - acc: 0.9594 - val_loss: 0.0480 - val_acc: 0.9856\n",
      "Epoch 162/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.1305 - acc: 0.9592\n",
      "Epoch 00162: val_loss did not improve from 0.04717\n",
      "40200/40200 [==============================] - 5s 118us/sample - loss: 0.1305 - acc: 0.9592 - val_loss: 0.0473 - val_acc: 0.9857\n",
      "Epoch 163/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.1328 - acc: 0.9583\n",
      "Epoch 00163: val_loss did not improve from 0.04717\n",
      "40200/40200 [==============================] - 5s 113us/sample - loss: 0.1323 - acc: 0.9585 - val_loss: 0.0477 - val_acc: 0.9857\n",
      "Epoch 164/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.1312 - acc: 0.9589\n",
      "Epoch 00164: val_loss did not improve from 0.04717\n",
      "40200/40200 [==============================] - 4s 108us/sample - loss: 0.1311 - acc: 0.9589 - val_loss: 0.0476 - val_acc: 0.9852\n",
      "Epoch 165/500\n",
      "39744/40200 [============================>.] - ETA: 0s - loss: 0.1275 - acc: 0.9594\n",
      "Epoch 00165: val_loss did not improve from 0.04717\n",
      "40200/40200 [==============================] - 4s 108us/sample - loss: 0.1270 - acc: 0.9596 - val_loss: 0.0472 - val_acc: 0.9851\n",
      "Epoch 166/500\n",
      "39680/40200 [============================>.] - ETA: 0s - loss: 0.1286 - acc: 0.9584\n",
      "Epoch 00166: val_loss improved from 0.04717 to 0.04648, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_2_conv_checkpoint/166-0.0465.hdf5\n",
      "40200/40200 [==============================] - 4s 109us/sample - loss: 0.1279 - acc: 0.9585 - val_loss: 0.0465 - val_acc: 0.9860\n",
      "Epoch 167/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.1288 - acc: 0.9601\n",
      "Epoch 00167: val_loss did not improve from 0.04648\n",
      "40200/40200 [==============================] - 4s 107us/sample - loss: 0.1288 - acc: 0.9600 - val_loss: 0.0477 - val_acc: 0.9855\n",
      "Epoch 168/500\n",
      "39744/40200 [============================>.] - ETA: 0s - loss: 0.1283 - acc: 0.9595\n",
      "Epoch 00168: val_loss did not improve from 0.04648\n",
      "40200/40200 [==============================] - 4s 108us/sample - loss: 0.1282 - acc: 0.9596 - val_loss: 0.0484 - val_acc: 0.9849\n",
      "Epoch 169/500\n",
      "39744/40200 [============================>.] - ETA: 0s - loss: 0.1306 - acc: 0.9575\n",
      "Epoch 00169: val_loss did not improve from 0.04648\n",
      "40200/40200 [==============================] - 4s 109us/sample - loss: 0.1310 - acc: 0.9573 - val_loss: 0.0482 - val_acc: 0.9852\n",
      "Epoch 170/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.1275 - acc: 0.9593\n",
      "Epoch 00170: val_loss did not improve from 0.04648\n",
      "40200/40200 [==============================] - 4s 106us/sample - loss: 0.1276 - acc: 0.9592 - val_loss: 0.0465 - val_acc: 0.9859\n",
      "Epoch 171/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.1331 - acc: 0.9585\n",
      "Epoch 00171: val_loss improved from 0.04648 to 0.04639, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_2_conv_checkpoint/171-0.0464.hdf5\n",
      "40200/40200 [==============================] - 4s 99us/sample - loss: 0.1330 - acc: 0.9586 - val_loss: 0.0464 - val_acc: 0.9856\n",
      "Epoch 172/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.1265 - acc: 0.9595\n",
      "Epoch 00172: val_loss did not improve from 0.04639\n",
      "40200/40200 [==============================] - 4s 104us/sample - loss: 0.1267 - acc: 0.9595 - val_loss: 0.0464 - val_acc: 0.9859\n",
      "Epoch 173/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.1266 - acc: 0.9603\n",
      "Epoch 00173: val_loss did not improve from 0.04639\n",
      "40200/40200 [==============================] - 4s 107us/sample - loss: 0.1266 - acc: 0.9602 - val_loss: 0.0468 - val_acc: 0.9852\n",
      "Epoch 174/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.1268 - acc: 0.9600\n",
      "Epoch 00174: val_loss did not improve from 0.04639\n",
      "40200/40200 [==============================] - 4s 108us/sample - loss: 0.1271 - acc: 0.9599 - val_loss: 0.0470 - val_acc: 0.9856\n",
      "Epoch 175/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.1270 - acc: 0.9598\n",
      "Epoch 00175: val_loss did not improve from 0.04639\n",
      "40200/40200 [==============================] - 4s 108us/sample - loss: 0.1281 - acc: 0.9596 - val_loss: 0.0470 - val_acc: 0.9857\n",
      "Epoch 176/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.1302 - acc: 0.9598\n",
      "Epoch 00176: val_loss did not improve from 0.04639\n",
      "40200/40200 [==============================] - 4s 108us/sample - loss: 0.1301 - acc: 0.9598 - val_loss: 0.0466 - val_acc: 0.9852\n",
      "Epoch 177/500\n",
      "39744/40200 [============================>.] - ETA: 0s - loss: 0.1298 - acc: 0.9599\n",
      "Epoch 00177: val_loss improved from 0.04639 to 0.04628, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_2_conv_checkpoint/177-0.0463.hdf5\n",
      "40200/40200 [==============================] - 4s 109us/sample - loss: 0.1298 - acc: 0.9600 - val_loss: 0.0463 - val_acc: 0.9856\n",
      "Epoch 178/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.1268 - acc: 0.9606\n",
      "Epoch 00178: val_loss improved from 0.04628 to 0.04590, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_2_conv_checkpoint/178-0.0459.hdf5\n",
      "40200/40200 [==============================] - 4s 110us/sample - loss: 0.1268 - acc: 0.9606 - val_loss: 0.0459 - val_acc: 0.9856\n",
      "Epoch 179/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.1237 - acc: 0.9611\n",
      "Epoch 00179: val_loss did not improve from 0.04590\n",
      "40200/40200 [==============================] - 4s 108us/sample - loss: 0.1238 - acc: 0.9611 - val_loss: 0.0474 - val_acc: 0.9850\n",
      "Epoch 180/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.1253 - acc: 0.9602\n",
      "Epoch 00180: val_loss did not improve from 0.04590\n",
      "40200/40200 [==============================] - 4s 106us/sample - loss: 0.1255 - acc: 0.9602 - val_loss: 0.0466 - val_acc: 0.9854\n",
      "Epoch 181/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.1245 - acc: 0.9605\n",
      "Epoch 00181: val_loss did not improve from 0.04590\n",
      "40200/40200 [==============================] - 4s 101us/sample - loss: 0.1245 - acc: 0.9606 - val_loss: 0.0466 - val_acc: 0.9856\n",
      "Epoch 182/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.1258 - acc: 0.9609\n",
      "Epoch 00182: val_loss did not improve from 0.04590\n",
      "40200/40200 [==============================] - 4s 105us/sample - loss: 0.1258 - acc: 0.9609 - val_loss: 0.0474 - val_acc: 0.9857\n",
      "Epoch 183/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.1280 - acc: 0.9590\n",
      "Epoch 00183: val_loss did not improve from 0.04590\n",
      "40200/40200 [==============================] - 4s 108us/sample - loss: 0.1278 - acc: 0.9591 - val_loss: 0.0478 - val_acc: 0.9855\n",
      "Epoch 184/500\n",
      "39680/40200 [============================>.] - ETA: 0s - loss: 0.1295 - acc: 0.9593\n",
      "Epoch 00184: val_loss did not improve from 0.04590\n",
      "40200/40200 [==============================] - 4s 106us/sample - loss: 0.1295 - acc: 0.9592 - val_loss: 0.0473 - val_acc: 0.9853\n",
      "Epoch 185/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.1255 - acc: 0.9605\n",
      "Epoch 00185: val_loss improved from 0.04590 to 0.04582, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_2_conv_checkpoint/185-0.0458.hdf5\n",
      "40200/40200 [==============================] - 4s 99us/sample - loss: 0.1255 - acc: 0.9604 - val_loss: 0.0458 - val_acc: 0.9860\n",
      "Epoch 186/500\n",
      "39744/40200 [============================>.] - ETA: 0s - loss: 0.1282 - acc: 0.9601\n",
      "Epoch 00186: val_loss did not improve from 0.04582\n",
      "40200/40200 [==============================] - 4s 102us/sample - loss: 0.1279 - acc: 0.9601 - val_loss: 0.0483 - val_acc: 0.9851\n",
      "Epoch 187/500\n",
      "39680/40200 [============================>.] - ETA: 0s - loss: 0.1271 - acc: 0.9594\n",
      "Epoch 00187: val_loss improved from 0.04582 to 0.04581, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_2_conv_checkpoint/187-0.0458.hdf5\n",
      "40200/40200 [==============================] - 4s 109us/sample - loss: 0.1269 - acc: 0.9596 - val_loss: 0.0458 - val_acc: 0.9860\n",
      "Epoch 188/500\n",
      "39744/40200 [============================>.] - ETA: 0s - loss: 0.1269 - acc: 0.9598\n",
      "Epoch 00188: val_loss did not improve from 0.04581\n",
      "40200/40200 [==============================] - 4s 109us/sample - loss: 0.1264 - acc: 0.9600 - val_loss: 0.0479 - val_acc: 0.9846\n",
      "Epoch 189/500\n",
      "39744/40200 [============================>.] - ETA: 0s - loss: 0.1223 - acc: 0.9614\n",
      "Epoch 00189: val_loss improved from 0.04581 to 0.04577, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_2_conv_checkpoint/189-0.0458.hdf5\n",
      "40200/40200 [==============================] - 4s 109us/sample - loss: 0.1225 - acc: 0.9614 - val_loss: 0.0458 - val_acc: 0.9861\n",
      "Epoch 190/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.1245 - acc: 0.9607\n",
      "Epoch 00190: val_loss improved from 0.04577 to 0.04575, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_2_conv_checkpoint/190-0.0458.hdf5\n",
      "40200/40200 [==============================] - 5s 117us/sample - loss: 0.1245 - acc: 0.9607 - val_loss: 0.0458 - val_acc: 0.9859\n",
      "Epoch 191/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.1228 - acc: 0.9614\n",
      "Epoch 00191: val_loss did not improve from 0.04575\n",
      "40200/40200 [==============================] - 5s 117us/sample - loss: 0.1225 - acc: 0.9615 - val_loss: 0.0460 - val_acc: 0.9858\n",
      "Epoch 192/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.1240 - acc: 0.9604\n",
      "Epoch 00192: val_loss did not improve from 0.04575\n",
      "40200/40200 [==============================] - 5s 116us/sample - loss: 0.1239 - acc: 0.9604 - val_loss: 0.0466 - val_acc: 0.9856\n",
      "Epoch 193/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.1238 - acc: 0.9602\n",
      "Epoch 00193: val_loss did not improve from 0.04575\n",
      "40200/40200 [==============================] - 4s 110us/sample - loss: 0.1238 - acc: 0.9603 - val_loss: 0.0461 - val_acc: 0.9858\n",
      "Epoch 194/500\n",
      "39744/40200 [============================>.] - ETA: 0s - loss: 0.1221 - acc: 0.9614\n",
      "Epoch 00194: val_loss improved from 0.04575 to 0.04527, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_2_conv_checkpoint/194-0.0453.hdf5\n",
      "40200/40200 [==============================] - 4s 110us/sample - loss: 0.1225 - acc: 0.9613 - val_loss: 0.0453 - val_acc: 0.9863\n",
      "Epoch 195/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.1282 - acc: 0.9592\n",
      "Epoch 00195: val_loss did not improve from 0.04527\n",
      "40200/40200 [==============================] - 4s 109us/sample - loss: 0.1281 - acc: 0.9592 - val_loss: 0.0460 - val_acc: 0.9858\n",
      "Epoch 196/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.1274 - acc: 0.9604\n",
      "Epoch 00196: val_loss did not improve from 0.04527\n",
      "40200/40200 [==============================] - 4s 109us/sample - loss: 0.1273 - acc: 0.9603 - val_loss: 0.0464 - val_acc: 0.9861\n",
      "Epoch 197/500\n",
      "39680/40200 [============================>.] - ETA: 0s - loss: 0.1213 - acc: 0.9614\n",
      "Epoch 00197: val_loss did not improve from 0.04527\n",
      "40200/40200 [==============================] - 4s 109us/sample - loss: 0.1216 - acc: 0.9614 - val_loss: 0.0465 - val_acc: 0.9854\n",
      "Epoch 198/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.1211 - acc: 0.9622\n",
      "Epoch 00198: val_loss did not improve from 0.04527\n",
      "40200/40200 [==============================] - 4s 104us/sample - loss: 0.1212 - acc: 0.9622 - val_loss: 0.0469 - val_acc: 0.9852\n",
      "Epoch 199/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.1237 - acc: 0.9614\n",
      "Epoch 00199: val_loss did not improve from 0.04527\n",
      "40200/40200 [==============================] - 4s 98us/sample - loss: 0.1238 - acc: 0.9614 - val_loss: 0.0458 - val_acc: 0.9859\n",
      "Epoch 200/500\n",
      "39744/40200 [============================>.] - ETA: 0s - loss: 0.1233 - acc: 0.9602\n",
      "Epoch 00200: val_loss did not improve from 0.04527\n",
      "40200/40200 [==============================] - 4s 105us/sample - loss: 0.1233 - acc: 0.9602 - val_loss: 0.0462 - val_acc: 0.9856\n",
      "Epoch 201/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.1215 - acc: 0.9615\n",
      "Epoch 00201: val_loss did not improve from 0.04527\n",
      "40200/40200 [==============================] - 4s 109us/sample - loss: 0.1215 - acc: 0.9615 - val_loss: 0.0465 - val_acc: 0.9855\n",
      "Epoch 202/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.1204 - acc: 0.9623\n",
      "Epoch 00202: val_loss did not improve from 0.04527\n",
      "40200/40200 [==============================] - 4s 107us/sample - loss: 0.1205 - acc: 0.9623 - val_loss: 0.0459 - val_acc: 0.9860\n",
      "Epoch 203/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.1211 - acc: 0.9613\n",
      "Epoch 00203: val_loss improved from 0.04527 to 0.04507, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_2_conv_checkpoint/203-0.0451.hdf5\n",
      "40200/40200 [==============================] - 4s 108us/sample - loss: 0.1215 - acc: 0.9612 - val_loss: 0.0451 - val_acc: 0.9859\n",
      "Epoch 204/500\n",
      "39744/40200 [============================>.] - ETA: 0s - loss: 0.1239 - acc: 0.9601\n",
      "Epoch 00204: val_loss did not improve from 0.04507\n",
      "40200/40200 [==============================] - 4s 107us/sample - loss: 0.1245 - acc: 0.9600 - val_loss: 0.0460 - val_acc: 0.9856\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 205/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.1209 - acc: 0.9615\n",
      "Epoch 00205: val_loss did not improve from 0.04507\n",
      "40200/40200 [==============================] - 4s 109us/sample - loss: 0.1206 - acc: 0.9616 - val_loss: 0.0471 - val_acc: 0.9854\n",
      "Epoch 206/500\n",
      "39744/40200 [============================>.] - ETA: 0s - loss: 0.1226 - acc: 0.9609\n",
      "Epoch 00206: val_loss did not improve from 0.04507\n",
      "40200/40200 [==============================] - 4s 107us/sample - loss: 0.1231 - acc: 0.9609 - val_loss: 0.0458 - val_acc: 0.9858\n",
      "Epoch 207/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.1193 - acc: 0.9608\n",
      "Epoch 00207: val_loss did not improve from 0.04507\n",
      "40200/40200 [==============================] - 4s 109us/sample - loss: 0.1188 - acc: 0.9610 - val_loss: 0.0458 - val_acc: 0.9860\n",
      "Epoch 208/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.1211 - acc: 0.9616\n",
      "Epoch 00208: val_loss did not improve from 0.04507\n",
      "40200/40200 [==============================] - 4s 107us/sample - loss: 0.1208 - acc: 0.9616 - val_loss: 0.0451 - val_acc: 0.9858\n",
      "Epoch 209/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.1222 - acc: 0.9612\n",
      "Epoch 00209: val_loss did not improve from 0.04507\n",
      "40200/40200 [==============================] - 4s 108us/sample - loss: 0.1219 - acc: 0.9613 - val_loss: 0.0456 - val_acc: 0.9862\n",
      "Epoch 210/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.1163 - acc: 0.9627\n",
      "Epoch 00210: val_loss did not improve from 0.04507\n",
      "40200/40200 [==============================] - 4s 107us/sample - loss: 0.1165 - acc: 0.9626 - val_loss: 0.0466 - val_acc: 0.9860\n",
      "Epoch 211/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.1210 - acc: 0.9619\n",
      "Epoch 00211: val_loss did not improve from 0.04507\n",
      "40200/40200 [==============================] - 4s 109us/sample - loss: 0.1210 - acc: 0.9619 - val_loss: 0.0464 - val_acc: 0.9859\n",
      "Epoch 212/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.1203 - acc: 0.9622\n",
      "Epoch 00212: val_loss improved from 0.04507 to 0.04466, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_2_conv_checkpoint/212-0.0447.hdf5\n",
      "40200/40200 [==============================] - 4s 103us/sample - loss: 0.1203 - acc: 0.9622 - val_loss: 0.0447 - val_acc: 0.9863\n",
      "Epoch 213/500\n",
      "39680/40200 [============================>.] - ETA: 0s - loss: 0.1225 - acc: 0.9613\n",
      "Epoch 00213: val_loss did not improve from 0.04466\n",
      "40200/40200 [==============================] - 4s 99us/sample - loss: 0.1227 - acc: 0.9613 - val_loss: 0.0459 - val_acc: 0.9856\n",
      "Epoch 214/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.1205 - acc: 0.9621\n",
      "Epoch 00214: val_loss did not improve from 0.04466\n",
      "40200/40200 [==============================] - 4s 109us/sample - loss: 0.1211 - acc: 0.9619 - val_loss: 0.0464 - val_acc: 0.9857\n",
      "Epoch 215/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.1174 - acc: 0.9617\n",
      "Epoch 00215: val_loss did not improve from 0.04466\n",
      "40200/40200 [==============================] - 4s 109us/sample - loss: 0.1173 - acc: 0.9618 - val_loss: 0.0454 - val_acc: 0.9860\n",
      "Epoch 216/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.1212 - acc: 0.9613\n",
      "Epoch 00216: val_loss did not improve from 0.04466\n",
      "40200/40200 [==============================] - 4s 108us/sample - loss: 0.1212 - acc: 0.9613 - val_loss: 0.0453 - val_acc: 0.9859\n",
      "Epoch 217/500\n",
      "39744/40200 [============================>.] - ETA: 0s - loss: 0.1207 - acc: 0.9617\n",
      "Epoch 00217: val_loss did not improve from 0.04466\n",
      "40200/40200 [==============================] - 4s 107us/sample - loss: 0.1210 - acc: 0.9616 - val_loss: 0.0450 - val_acc: 0.9858\n",
      "Epoch 218/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.1192 - acc: 0.9629\n",
      "Epoch 00218: val_loss did not improve from 0.04466\n",
      "40200/40200 [==============================] - 4s 107us/sample - loss: 0.1191 - acc: 0.9628 - val_loss: 0.0451 - val_acc: 0.9859\n",
      "Epoch 219/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.1206 - acc: 0.9618\n",
      "Epoch 00219: val_loss did not improve from 0.04466\n",
      "40200/40200 [==============================] - 5s 117us/sample - loss: 0.1201 - acc: 0.9620 - val_loss: 0.0454 - val_acc: 0.9857\n",
      "Epoch 220/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.1215 - acc: 0.9625\n",
      "Epoch 00220: val_loss did not improve from 0.04466\n",
      "40200/40200 [==============================] - 5s 116us/sample - loss: 0.1213 - acc: 0.9626 - val_loss: 0.0455 - val_acc: 0.9857\n",
      "Epoch 221/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.1155 - acc: 0.9620\n",
      "Epoch 00221: val_loss improved from 0.04466 to 0.04428, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_2_conv_checkpoint/221-0.0443.hdf5\n",
      "40200/40200 [==============================] - 4s 110us/sample - loss: 0.1155 - acc: 0.9620 - val_loss: 0.0443 - val_acc: 0.9865\n",
      "Epoch 222/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.1160 - acc: 0.9630\n",
      "Epoch 00222: val_loss did not improve from 0.04428\n",
      "40200/40200 [==============================] - 4s 109us/sample - loss: 0.1162 - acc: 0.9630 - val_loss: 0.0444 - val_acc: 0.9864\n",
      "Epoch 223/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.1198 - acc: 0.9616\n",
      "Epoch 00223: val_loss improved from 0.04428 to 0.04396, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_2_conv_checkpoint/223-0.0440.hdf5\n",
      "40200/40200 [==============================] - 4s 109us/sample - loss: 0.1197 - acc: 0.9616 - val_loss: 0.0440 - val_acc: 0.9868\n",
      "Epoch 224/500\n",
      "39680/40200 [============================>.] - ETA: 0s - loss: 0.1180 - acc: 0.9627\n",
      "Epoch 00224: val_loss did not improve from 0.04396\n",
      "40200/40200 [==============================] - 4s 108us/sample - loss: 0.1181 - acc: 0.9627 - val_loss: 0.0456 - val_acc: 0.9859\n",
      "Epoch 225/500\n",
      "39616/40200 [============================>.] - ETA: 0s - loss: 0.1243 - acc: 0.9610\n",
      "Epoch 00225: val_loss did not improve from 0.04396\n",
      "40200/40200 [==============================] - 4s 108us/sample - loss: 0.1243 - acc: 0.9609 - val_loss: 0.0462 - val_acc: 0.9860\n",
      "Epoch 226/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.1173 - acc: 0.9626\n",
      "Epoch 00226: val_loss did not improve from 0.04396\n",
      "40200/40200 [==============================] - 4s 103us/sample - loss: 0.1171 - acc: 0.9627 - val_loss: 0.0451 - val_acc: 0.9858\n",
      "Epoch 227/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.1178 - acc: 0.9632\n",
      "Epoch 00227: val_loss did not improve from 0.04396\n",
      "40200/40200 [==============================] - 4s 98us/sample - loss: 0.1177 - acc: 0.9632 - val_loss: 0.0452 - val_acc: 0.9858\n",
      "Epoch 228/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.1169 - acc: 0.9627\n",
      "Epoch 00228: val_loss did not improve from 0.04396\n",
      "40200/40200 [==============================] - 4s 108us/sample - loss: 0.1167 - acc: 0.9628 - val_loss: 0.0467 - val_acc: 0.9858\n",
      "Epoch 229/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.1193 - acc: 0.9623\n",
      "Epoch 00229: val_loss did not improve from 0.04396\n",
      "40200/40200 [==============================] - 4s 108us/sample - loss: 0.1193 - acc: 0.9623 - val_loss: 0.0451 - val_acc: 0.9863\n",
      "Epoch 230/500\n",
      "39744/40200 [============================>.] - ETA: 0s - loss: 0.1222 - acc: 0.9608\n",
      "Epoch 00230: val_loss did not improve from 0.04396\n",
      "40200/40200 [==============================] - 4s 109us/sample - loss: 0.1222 - acc: 0.9608 - val_loss: 0.0463 - val_acc: 0.9857\n",
      "Epoch 231/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.1198 - acc: 0.9627\n",
      "Epoch 00231: val_loss did not improve from 0.04396\n",
      "40200/40200 [==============================] - 4s 108us/sample - loss: 0.1195 - acc: 0.9628 - val_loss: 0.0454 - val_acc: 0.9862\n",
      "Epoch 232/500\n",
      "39744/40200 [============================>.] - ETA: 0s - loss: 0.1175 - acc: 0.9627\n",
      "Epoch 00232: val_loss did not improve from 0.04396\n",
      "40200/40200 [==============================] - 4s 108us/sample - loss: 0.1175 - acc: 0.9627 - val_loss: 0.0446 - val_acc: 0.9865\n",
      "Epoch 233/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.1178 - acc: 0.9617\n",
      "Epoch 00233: val_loss did not improve from 0.04396\n",
      "40200/40200 [==============================] - 4s 109us/sample - loss: 0.1177 - acc: 0.9617 - val_loss: 0.0449 - val_acc: 0.9860\n",
      "Epoch 234/500\n",
      "39744/40200 [============================>.] - ETA: 0s - loss: 0.1200 - acc: 0.9618\n",
      "Epoch 00234: val_loss did not improve from 0.04396\n",
      "40200/40200 [==============================] - 4s 108us/sample - loss: 0.1204 - acc: 0.9618 - val_loss: 0.0469 - val_acc: 0.9853\n",
      "Epoch 235/500\n",
      "39680/40200 [============================>.] - ETA: 0s - loss: 0.1194 - acc: 0.9626\n",
      "Epoch 00235: val_loss did not improve from 0.04396\n",
      "40200/40200 [==============================] - 4s 108us/sample - loss: 0.1195 - acc: 0.9626 - val_loss: 0.0446 - val_acc: 0.9865\n",
      "Epoch 236/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.1203 - acc: 0.9633\n",
      "Epoch 00236: val_loss did not improve from 0.04396\n",
      "40200/40200 [==============================] - 4s 108us/sample - loss: 0.1203 - acc: 0.9632 - val_loss: 0.0462 - val_acc: 0.9861\n",
      "Epoch 237/500\n",
      "39744/40200 [============================>.] - ETA: 0s - loss: 0.1187 - acc: 0.9624\n",
      "Epoch 00237: val_loss did not improve from 0.04396\n",
      "40200/40200 [==============================] - 4s 109us/sample - loss: 0.1184 - acc: 0.9625 - val_loss: 0.0453 - val_acc: 0.9857\n",
      "Epoch 238/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.1156 - acc: 0.9630\n",
      "Epoch 00238: val_loss did not improve from 0.04396\n",
      "40200/40200 [==============================] - 4s 109us/sample - loss: 0.1156 - acc: 0.9630 - val_loss: 0.0453 - val_acc: 0.9859\n",
      "Epoch 239/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.1187 - acc: 0.9626\n",
      "Epoch 00239: val_loss did not improve from 0.04396\n",
      "40200/40200 [==============================] - 4s 108us/sample - loss: 0.1184 - acc: 0.9627 - val_loss: 0.0451 - val_acc: 0.9863\n",
      "Epoch 240/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.1173 - acc: 0.9635\n",
      "Epoch 00240: val_loss did not improve from 0.04396\n",
      "40200/40200 [==============================] - 4s 101us/sample - loss: 0.1178 - acc: 0.9633 - val_loss: 0.0448 - val_acc: 0.9860\n",
      "Epoch 241/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.1154 - acc: 0.9638\n",
      "Epoch 00241: val_loss did not improve from 0.04396\n",
      "40200/40200 [==============================] - 4s 97us/sample - loss: 0.1153 - acc: 0.9639 - val_loss: 0.0462 - val_acc: 0.9857\n",
      "Epoch 242/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.1167 - acc: 0.9632\n",
      "Epoch 00242: val_loss did not improve from 0.04396\n",
      "40200/40200 [==============================] - 4s 108us/sample - loss: 0.1168 - acc: 0.9632 - val_loss: 0.0450 - val_acc: 0.9861\n",
      "Epoch 243/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.1169 - acc: 0.9621\n",
      "Epoch 00243: val_loss did not improve from 0.04396\n",
      "40200/40200 [==============================] - 4s 108us/sample - loss: 0.1168 - acc: 0.9620 - val_loss: 0.0446 - val_acc: 0.9864\n",
      "Epoch 244/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.1191 - acc: 0.9624\n",
      "Epoch 00244: val_loss did not improve from 0.04396\n",
      "40200/40200 [==============================] - 4s 103us/sample - loss: 0.1191 - acc: 0.9623 - val_loss: 0.0458 - val_acc: 0.9856\n",
      "Epoch 245/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.1148 - acc: 0.9630\n",
      "Epoch 00245: val_loss improved from 0.04396 to 0.04354, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_2_conv_checkpoint/245-0.0435.hdf5\n",
      "40200/40200 [==============================] - 4s 103us/sample - loss: 0.1148 - acc: 0.9630 - val_loss: 0.0435 - val_acc: 0.9871\n",
      "Epoch 246/500\n",
      "39744/40200 [============================>.] - ETA: 0s - loss: 0.1160 - acc: 0.9631\n",
      "Epoch 00246: val_loss did not improve from 0.04354\n",
      "40200/40200 [==============================] - 4s 110us/sample - loss: 0.1156 - acc: 0.9632 - val_loss: 0.0443 - val_acc: 0.9862\n",
      "Epoch 247/500\n",
      "39680/40200 [============================>.] - ETA: 0s - loss: 0.1138 - acc: 0.9641\n",
      "Epoch 00247: val_loss did not improve from 0.04354\n",
      "40200/40200 [==============================] - 4s 108us/sample - loss: 0.1138 - acc: 0.9640 - val_loss: 0.0445 - val_acc: 0.9864\n",
      "Epoch 248/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.1173 - acc: 0.9625\n",
      "Epoch 00248: val_loss did not improve from 0.04354\n",
      "40200/40200 [==============================] - 4s 108us/sample - loss: 0.1174 - acc: 0.9623 - val_loss: 0.0452 - val_acc: 0.9858\n",
      "Epoch 249/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.1151 - acc: 0.9632\n",
      "Epoch 00249: val_loss did not improve from 0.04354\n",
      "40200/40200 [==============================] - 4s 108us/sample - loss: 0.1152 - acc: 0.9632 - val_loss: 0.0437 - val_acc: 0.9868\n",
      "Epoch 250/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.1149 - acc: 0.9633\n",
      "Epoch 00250: val_loss did not improve from 0.04354\n",
      "40200/40200 [==============================] - 5s 112us/sample - loss: 0.1149 - acc: 0.9633 - val_loss: 0.0443 - val_acc: 0.9866\n",
      "Epoch 251/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.1158 - acc: 0.9630\n",
      "Epoch 00251: val_loss did not improve from 0.04354\n",
      "40200/40200 [==============================] - 5s 117us/sample - loss: 0.1162 - acc: 0.9629 - val_loss: 0.0448 - val_acc: 0.9863\n",
      "Epoch 252/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.1169 - acc: 0.9626\n",
      "Epoch 00252: val_loss did not improve from 0.04354\n",
      "40200/40200 [==============================] - 5s 119us/sample - loss: 0.1164 - acc: 0.9627 - val_loss: 0.0452 - val_acc: 0.9864\n",
      "Epoch 253/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.1142 - acc: 0.9642\n",
      "Epoch 00253: val_loss did not improve from 0.04354\n",
      "40200/40200 [==============================] - 5s 118us/sample - loss: 0.1146 - acc: 0.9641 - val_loss: 0.0440 - val_acc: 0.9866\n",
      "Epoch 254/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.1152 - acc: 0.9636\n",
      "Epoch 00254: val_loss did not improve from 0.04354\n",
      "40200/40200 [==============================] - 4s 104us/sample - loss: 0.1152 - acc: 0.9636 - val_loss: 0.0446 - val_acc: 0.9861\n",
      "Epoch 255/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.1194 - acc: 0.9622\n",
      "Epoch 00255: val_loss did not improve from 0.04354\n",
      "40200/40200 [==============================] - 4s 101us/sample - loss: 0.1192 - acc: 0.9623 - val_loss: 0.0472 - val_acc: 0.9858\n",
      "Epoch 256/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.1171 - acc: 0.9626\n",
      "Epoch 00256: val_loss did not improve from 0.04354\n",
      "40200/40200 [==============================] - 5s 115us/sample - loss: 0.1174 - acc: 0.9625 - val_loss: 0.0439 - val_acc: 0.9870\n",
      "Epoch 257/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.1136 - acc: 0.9644\n",
      "Epoch 00257: val_loss did not improve from 0.04354\n",
      "40200/40200 [==============================] - 5s 113us/sample - loss: 0.1136 - acc: 0.9644 - val_loss: 0.0439 - val_acc: 0.9865\n",
      "Epoch 258/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.1160 - acc: 0.9638\n",
      "Epoch 00258: val_loss did not improve from 0.04354\n",
      "40200/40200 [==============================] - 5s 120us/sample - loss: 0.1163 - acc: 0.9637 - val_loss: 0.0437 - val_acc: 0.9870\n",
      "Epoch 259/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.1139 - acc: 0.9644\n",
      "Epoch 00259: val_loss did not improve from 0.04354\n",
      "40200/40200 [==============================] - 4s 108us/sample - loss: 0.1137 - acc: 0.9645 - val_loss: 0.0448 - val_acc: 0.9858\n",
      "Epoch 260/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.1141 - acc: 0.9639\n",
      "Epoch 00260: val_loss improved from 0.04354 to 0.04319, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_2_conv_checkpoint/260-0.0432.hdf5\n",
      "40200/40200 [==============================] - 4s 109us/sample - loss: 0.1141 - acc: 0.9639 - val_loss: 0.0432 - val_acc: 0.9870\n",
      "Epoch 261/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.1106 - acc: 0.9645\n",
      "Epoch 00261: val_loss did not improve from 0.04319\n",
      "40200/40200 [==============================] - 4s 108us/sample - loss: 0.1105 - acc: 0.9645 - val_loss: 0.0437 - val_acc: 0.9871\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 262/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.1118 - acc: 0.9653\n",
      "Epoch 00262: val_loss did not improve from 0.04319\n",
      "40200/40200 [==============================] - 4s 109us/sample - loss: 0.1118 - acc: 0.9653 - val_loss: 0.0443 - val_acc: 0.9864\n",
      "Epoch 263/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.1141 - acc: 0.9648\n",
      "Epoch 00263: val_loss did not improve from 0.04319\n",
      "40200/40200 [==============================] - 4s 108us/sample - loss: 0.1140 - acc: 0.9647 - val_loss: 0.0443 - val_acc: 0.9863\n",
      "Epoch 264/500\n",
      "39680/40200 [============================>.] - ETA: 0s - loss: 0.1144 - acc: 0.9637\n",
      "Epoch 00264: val_loss did not improve from 0.04319\n",
      "40200/40200 [==============================] - 4s 108us/sample - loss: 0.1143 - acc: 0.9636 - val_loss: 0.0435 - val_acc: 0.9870\n",
      "Epoch 265/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.1137 - acc: 0.9640\n",
      "Epoch 00265: val_loss did not improve from 0.04319\n",
      "40200/40200 [==============================] - 4s 108us/sample - loss: 0.1140 - acc: 0.9639 - val_loss: 0.0434 - val_acc: 0.9866\n",
      "Epoch 266/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.1154 - acc: 0.9637\n",
      "Epoch 00266: val_loss did not improve from 0.04319\n",
      "40200/40200 [==============================] - 4s 107us/sample - loss: 0.1154 - acc: 0.9638 - val_loss: 0.0444 - val_acc: 0.9863\n",
      "Epoch 267/500\n",
      "39744/40200 [============================>.] - ETA: 0s - loss: 0.1133 - acc: 0.9643\n",
      "Epoch 00267: val_loss did not improve from 0.04319\n",
      "40200/40200 [==============================] - 4s 107us/sample - loss: 0.1132 - acc: 0.9643 - val_loss: 0.0456 - val_acc: 0.9865\n",
      "Epoch 268/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.1140 - acc: 0.9638\n",
      "Epoch 00268: val_loss did not improve from 0.04319\n",
      "40200/40200 [==============================] - 4s 98us/sample - loss: 0.1138 - acc: 0.9639 - val_loss: 0.0439 - val_acc: 0.9863\n",
      "Epoch 269/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.1138 - acc: 0.9641\n",
      "Epoch 00269: val_loss did not improve from 0.04319\n",
      "40200/40200 [==============================] - 4s 103us/sample - loss: 0.1138 - acc: 0.9641 - val_loss: 0.0437 - val_acc: 0.9871\n",
      "Epoch 270/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.1142 - acc: 0.9635\n",
      "Epoch 00270: val_loss did not improve from 0.04319\n",
      "40200/40200 [==============================] - 4s 109us/sample - loss: 0.1142 - acc: 0.9636 - val_loss: 0.0452 - val_acc: 0.9861\n",
      "Epoch 271/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.1115 - acc: 0.9654\n",
      "Epoch 00271: val_loss did not improve from 0.04319\n",
      "40200/40200 [==============================] - 4s 107us/sample - loss: 0.1114 - acc: 0.9653 - val_loss: 0.0463 - val_acc: 0.9852\n",
      "Epoch 272/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.1113 - acc: 0.9647\n",
      "Epoch 00272: val_loss did not improve from 0.04319\n",
      "40200/40200 [==============================] - 4s 108us/sample - loss: 0.1116 - acc: 0.9646 - val_loss: 0.0452 - val_acc: 0.9862\n",
      "Epoch 273/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.1132 - acc: 0.9640\n",
      "Epoch 00273: val_loss did not improve from 0.04319\n",
      "40200/40200 [==============================] - 4s 108us/sample - loss: 0.1136 - acc: 0.9639 - val_loss: 0.0456 - val_acc: 0.9868\n",
      "Epoch 274/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.1142 - acc: 0.9647\n",
      "Epoch 00274: val_loss did not improve from 0.04319\n",
      "40200/40200 [==============================] - 4s 108us/sample - loss: 0.1139 - acc: 0.9648 - val_loss: 0.0444 - val_acc: 0.9864\n",
      "Epoch 275/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.1152 - acc: 0.9627\n",
      "Epoch 00275: val_loss improved from 0.04319 to 0.04318, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_2_conv_checkpoint/275-0.0432.hdf5\n",
      "40200/40200 [==============================] - 4s 108us/sample - loss: 0.1150 - acc: 0.9628 - val_loss: 0.0432 - val_acc: 0.9871\n",
      "Epoch 276/500\n",
      "39744/40200 [============================>.] - ETA: 0s - loss: 0.1129 - acc: 0.9641\n",
      "Epoch 00276: val_loss did not improve from 0.04318\n",
      "40200/40200 [==============================] - 4s 109us/sample - loss: 0.1126 - acc: 0.9642 - val_loss: 0.0437 - val_acc: 0.9865\n",
      "Epoch 277/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.1135 - acc: 0.9635\n",
      "Epoch 00277: val_loss did not improve from 0.04318\n",
      "40200/40200 [==============================] - 4s 107us/sample - loss: 0.1138 - acc: 0.9634 - val_loss: 0.0445 - val_acc: 0.9863\n",
      "Epoch 278/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.1126 - acc: 0.9637\n",
      "Epoch 00278: val_loss did not improve from 0.04318\n",
      "40200/40200 [==============================] - 4s 109us/sample - loss: 0.1126 - acc: 0.9638 - val_loss: 0.0438 - val_acc: 0.9866\n",
      "Epoch 279/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.1146 - acc: 0.9648\n",
      "Epoch 00279: val_loss did not improve from 0.04318\n",
      "40200/40200 [==============================] - 4s 109us/sample - loss: 0.1146 - acc: 0.9648 - val_loss: 0.0442 - val_acc: 0.9865\n",
      "Epoch 280/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.1113 - acc: 0.9649\n",
      "Epoch 00280: val_loss improved from 0.04318 to 0.04317, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_2_conv_checkpoint/280-0.0432.hdf5\n",
      "40200/40200 [==============================] - 4s 112us/sample - loss: 0.1111 - acc: 0.9650 - val_loss: 0.0432 - val_acc: 0.9870\n",
      "Epoch 281/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.1157 - acc: 0.9631\n",
      "Epoch 00281: val_loss did not improve from 0.04317\n",
      "40200/40200 [==============================] - 4s 112us/sample - loss: 0.1157 - acc: 0.9631 - val_loss: 0.0452 - val_acc: 0.9860\n",
      "Epoch 282/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.1126 - acc: 0.9651\n",
      "Epoch 00282: val_loss did not improve from 0.04317\n",
      "40200/40200 [==============================] - 4s 96us/sample - loss: 0.1128 - acc: 0.9651 - val_loss: 0.0465 - val_acc: 0.9853\n",
      "Epoch 283/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.1158 - acc: 0.9628\n",
      "Epoch 00283: val_loss did not improve from 0.04317\n",
      "40200/40200 [==============================] - 4s 104us/sample - loss: 0.1160 - acc: 0.9628 - val_loss: 0.0445 - val_acc: 0.9867\n",
      "Epoch 284/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.1070 - acc: 0.9652\n",
      "Epoch 00284: val_loss did not improve from 0.04317\n",
      "40200/40200 [==============================] - 5s 120us/sample - loss: 0.1068 - acc: 0.9652 - val_loss: 0.0447 - val_acc: 0.9862\n",
      "Epoch 285/500\n",
      "39744/40200 [============================>.] - ETA: 0s - loss: 0.1125 - acc: 0.9647\n",
      "Epoch 00285: val_loss did not improve from 0.04317\n",
      "40200/40200 [==============================] - 4s 111us/sample - loss: 0.1123 - acc: 0.9648 - val_loss: 0.0437 - val_acc: 0.9866\n",
      "Epoch 286/500\n",
      "39680/40200 [============================>.] - ETA: 0s - loss: 0.1145 - acc: 0.9632\n",
      "Epoch 00286: val_loss improved from 0.04317 to 0.04311, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_2_conv_checkpoint/286-0.0431.hdf5\n",
      "40200/40200 [==============================] - 4s 109us/sample - loss: 0.1145 - acc: 0.9632 - val_loss: 0.0431 - val_acc: 0.9866\n",
      "Epoch 287/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.1119 - acc: 0.9648\n",
      "Epoch 00287: val_loss improved from 0.04311 to 0.04203, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_2_conv_checkpoint/287-0.0420.hdf5\n",
      "40200/40200 [==============================] - 4s 109us/sample - loss: 0.1118 - acc: 0.9648 - val_loss: 0.0420 - val_acc: 0.9872\n",
      "Epoch 288/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.1161 - acc: 0.9640\n",
      "Epoch 00288: val_loss did not improve from 0.04203\n",
      "40200/40200 [==============================] - 4s 108us/sample - loss: 0.1157 - acc: 0.9641 - val_loss: 0.0436 - val_acc: 0.9863\n",
      "Epoch 289/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.1111 - acc: 0.9644\n",
      "Epoch 00289: val_loss did not improve from 0.04203\n",
      "40200/40200 [==============================] - 4s 107us/sample - loss: 0.1109 - acc: 0.9644 - val_loss: 0.0430 - val_acc: 0.9868\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 290/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.1126 - acc: 0.9629\n",
      "Epoch 00290: val_loss did not improve from 0.04203\n",
      "40200/40200 [==============================] - 4s 108us/sample - loss: 0.1124 - acc: 0.9630 - val_loss: 0.0442 - val_acc: 0.9867\n",
      "Epoch 291/500\n",
      "39744/40200 [============================>.] - ETA: 0s - loss: 0.1136 - acc: 0.9639\n",
      "Epoch 00291: val_loss did not improve from 0.04203\n",
      "40200/40200 [==============================] - 4s 107us/sample - loss: 0.1136 - acc: 0.9639 - val_loss: 0.0434 - val_acc: 0.9866\n",
      "Epoch 292/500\n",
      "39744/40200 [============================>.] - ETA: 0s - loss: 0.1145 - acc: 0.9630\n",
      "Epoch 00292: val_loss did not improve from 0.04203\n",
      "40200/40200 [==============================] - 4s 108us/sample - loss: 0.1147 - acc: 0.9629 - val_loss: 0.0436 - val_acc: 0.9869\n",
      "Epoch 293/500\n",
      "39744/40200 [============================>.] - ETA: 0s - loss: 0.1097 - acc: 0.9654\n",
      "Epoch 00293: val_loss did not improve from 0.04203\n",
      "40200/40200 [==============================] - 4s 108us/sample - loss: 0.1101 - acc: 0.9654 - val_loss: 0.0426 - val_acc: 0.9871\n",
      "Epoch 294/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.1117 - acc: 0.9650\n",
      "Epoch 00294: val_loss did not improve from 0.04203\n",
      "40200/40200 [==============================] - 4s 108us/sample - loss: 0.1117 - acc: 0.9650 - val_loss: 0.0428 - val_acc: 0.9871\n",
      "Epoch 295/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.1145 - acc: 0.9645\n",
      "Epoch 00295: val_loss did not improve from 0.04203\n",
      "40200/40200 [==============================] - 4s 103us/sample - loss: 0.1146 - acc: 0.9645 - val_loss: 0.0431 - val_acc: 0.9868\n",
      "Epoch 296/500\n",
      "39616/40200 [============================>.] - ETA: 0s - loss: 0.1105 - acc: 0.9653\n",
      "Epoch 00296: val_loss did not improve from 0.04203\n",
      "40200/40200 [==============================] - 4s 99us/sample - loss: 0.1106 - acc: 0.9652 - val_loss: 0.0430 - val_acc: 0.9865\n",
      "Epoch 297/500\n",
      "39680/40200 [============================>.] - ETA: 0s - loss: 0.1102 - acc: 0.9653\n",
      "Epoch 00297: val_loss did not improve from 0.04203\n",
      "40200/40200 [==============================] - 4s 105us/sample - loss: 0.1103 - acc: 0.9651 - val_loss: 0.0449 - val_acc: 0.9862\n",
      "Epoch 298/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.1134 - acc: 0.9643\n",
      "Epoch 00298: val_loss did not improve from 0.04203\n",
      "40200/40200 [==============================] - 4s 107us/sample - loss: 0.1135 - acc: 0.9642 - val_loss: 0.0431 - val_acc: 0.9868\n",
      "Epoch 299/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.1126 - acc: 0.9643\n",
      "Epoch 00299: val_loss did not improve from 0.04203\n",
      "40200/40200 [==============================] - 4s 101us/sample - loss: 0.1126 - acc: 0.9643 - val_loss: 0.0426 - val_acc: 0.9870\n",
      "Epoch 300/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.1069 - acc: 0.9657\n",
      "Epoch 00300: val_loss did not improve from 0.04203\n",
      "40200/40200 [==============================] - 4s 106us/sample - loss: 0.1069 - acc: 0.9657 - val_loss: 0.0422 - val_acc: 0.9872\n",
      "Epoch 301/500\n",
      "39744/40200 [============================>.] - ETA: 0s - loss: 0.1111 - acc: 0.9651\n",
      "Epoch 00301: val_loss did not improve from 0.04203\n",
      "40200/40200 [==============================] - 4s 108us/sample - loss: 0.1114 - acc: 0.9650 - val_loss: 0.0422 - val_acc: 0.9873\n",
      "Epoch 302/500\n",
      "39744/40200 [============================>.] - ETA: 0s - loss: 0.1096 - acc: 0.9653\n",
      "Epoch 00302: val_loss did not improve from 0.04203\n",
      "40200/40200 [==============================] - 4s 104us/sample - loss: 0.1099 - acc: 0.9651 - val_loss: 0.0429 - val_acc: 0.9870\n",
      "Epoch 303/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.1124 - acc: 0.9648\n",
      "Epoch 00303: val_loss did not improve from 0.04203\n",
      "40200/40200 [==============================] - 4s 105us/sample - loss: 0.1122 - acc: 0.9648 - val_loss: 0.0445 - val_acc: 0.9864\n",
      "Epoch 304/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.1095 - acc: 0.9648\n",
      "Epoch 00304: val_loss did not improve from 0.04203\n",
      "40200/40200 [==============================] - 4s 108us/sample - loss: 0.1092 - acc: 0.9649 - val_loss: 0.0441 - val_acc: 0.9866\n",
      "Epoch 305/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.1081 - acc: 0.9658\n",
      "Epoch 00305: val_loss did not improve from 0.04203\n",
      "40200/40200 [==============================] - 4s 108us/sample - loss: 0.1083 - acc: 0.9658 - val_loss: 0.0439 - val_acc: 0.9868\n",
      "Epoch 306/500\n",
      "39744/40200 [============================>.] - ETA: 0s - loss: 0.1071 - acc: 0.9661\n",
      "Epoch 00306: val_loss did not improve from 0.04203\n",
      "40200/40200 [==============================] - 4s 108us/sample - loss: 0.1072 - acc: 0.9660 - val_loss: 0.0432 - val_acc: 0.9861\n",
      "Epoch 307/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.1107 - acc: 0.9660\n",
      "Epoch 00307: val_loss did not improve from 0.04203\n",
      "40200/40200 [==============================] - 4s 107us/sample - loss: 0.1107 - acc: 0.9660 - val_loss: 0.0434 - val_acc: 0.9870\n",
      "Epoch 308/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.1141 - acc: 0.9642\n",
      "Epoch 00308: val_loss did not improve from 0.04203\n",
      "40200/40200 [==============================] - 4s 108us/sample - loss: 0.1144 - acc: 0.9641 - val_loss: 0.0438 - val_acc: 0.9866\n",
      "Epoch 309/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.1115 - acc: 0.9651\n",
      "Epoch 00309: val_loss did not improve from 0.04203\n",
      "40200/40200 [==============================] - 4s 106us/sample - loss: 0.1116 - acc: 0.9650 - val_loss: 0.0428 - val_acc: 0.9868\n",
      "Epoch 310/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.1091 - acc: 0.9647\n",
      "Epoch 00310: val_loss did not improve from 0.04203\n",
      "40200/40200 [==============================] - 4s 98us/sample - loss: 0.1089 - acc: 0.9648 - val_loss: 0.0428 - val_acc: 0.9871\n",
      "Epoch 311/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.1132 - acc: 0.9636\n",
      "Epoch 00311: val_loss did not improve from 0.04203\n",
      "40200/40200 [==============================] - 4s 104us/sample - loss: 0.1135 - acc: 0.9636 - val_loss: 0.0430 - val_acc: 0.9871\n",
      "Epoch 312/500\n",
      "39680/40200 [============================>.] - ETA: 0s - loss: 0.1084 - acc: 0.9652\n",
      "Epoch 00312: val_loss did not improve from 0.04203\n",
      "40200/40200 [==============================] - 4s 109us/sample - loss: 0.1080 - acc: 0.9654 - val_loss: 0.0426 - val_acc: 0.9872\n",
      "Epoch 313/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.1081 - acc: 0.9650\n",
      "Epoch 00313: val_loss did not improve from 0.04203\n",
      "40200/40200 [==============================] - 4s 107us/sample - loss: 0.1081 - acc: 0.9650 - val_loss: 0.0440 - val_acc: 0.9868\n",
      "Epoch 314/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.1101 - acc: 0.9647\n",
      "Epoch 00314: val_loss did not improve from 0.04203\n",
      "40200/40200 [==============================] - 4s 107us/sample - loss: 0.1099 - acc: 0.9647 - val_loss: 0.0440 - val_acc: 0.9868\n",
      "Epoch 315/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.1115 - acc: 0.9650\n",
      "Epoch 00315: val_loss did not improve from 0.04203\n",
      "40200/40200 [==============================] - 4s 107us/sample - loss: 0.1114 - acc: 0.9650 - val_loss: 0.0454 - val_acc: 0.9862\n",
      "Epoch 316/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.1076 - acc: 0.9671\n",
      "Epoch 00316: val_loss did not improve from 0.04203\n",
      "40200/40200 [==============================] - 4s 108us/sample - loss: 0.1079 - acc: 0.9671 - val_loss: 0.0449 - val_acc: 0.9867\n",
      "Epoch 317/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.1098 - acc: 0.9656\n",
      "Epoch 00317: val_loss did not improve from 0.04203\n",
      "40200/40200 [==============================] - 4s 108us/sample - loss: 0.1098 - acc: 0.9655 - val_loss: 0.0437 - val_acc: 0.9866\n",
      "Epoch 318/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.1138 - acc: 0.9640\n",
      "Epoch 00318: val_loss did not improve from 0.04203\n",
      "40200/40200 [==============================] - 4s 108us/sample - loss: 0.1136 - acc: 0.9641 - val_loss: 0.0430 - val_acc: 0.9868\n",
      "Epoch 319/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.1053 - acc: 0.9658\n",
      "Epoch 00319: val_loss did not improve from 0.04203\n",
      "40200/40200 [==============================] - 4s 108us/sample - loss: 0.1053 - acc: 0.9658 - val_loss: 0.0441 - val_acc: 0.9871\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 320/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.1069 - acc: 0.9661\n",
      "Epoch 00320: val_loss did not improve from 0.04203\n",
      "40200/40200 [==============================] - 4s 108us/sample - loss: 0.1069 - acc: 0.9661 - val_loss: 0.0441 - val_acc: 0.9869\n",
      "Epoch 321/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.1075 - acc: 0.9658\n",
      "Epoch 00321: val_loss did not improve from 0.04203\n",
      "40200/40200 [==============================] - 4s 108us/sample - loss: 0.1076 - acc: 0.9657 - val_loss: 0.0438 - val_acc: 0.9864\n",
      "Epoch 322/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.1084 - acc: 0.9657\n",
      "Epoch 00322: val_loss did not improve from 0.04203\n",
      "40200/40200 [==============================] - 4s 109us/sample - loss: 0.1082 - acc: 0.9657 - val_loss: 0.0430 - val_acc: 0.9869\n",
      "Epoch 323/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.1111 - acc: 0.9648\n",
      "Epoch 00323: val_loss did not improve from 0.04203\n",
      "40200/40200 [==============================] - 4s 105us/sample - loss: 0.1109 - acc: 0.9648 - val_loss: 0.0435 - val_acc: 0.9871\n",
      "Epoch 324/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.1099 - acc: 0.9643\n",
      "Epoch 00324: val_loss did not improve from 0.04203\n",
      "40200/40200 [==============================] - 4s 99us/sample - loss: 0.1100 - acc: 0.9642 - val_loss: 0.0432 - val_acc: 0.9871\n",
      "Epoch 325/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.1051 - acc: 0.9668\n",
      "Epoch 00325: val_loss did not improve from 0.04203\n",
      "40200/40200 [==============================] - 4s 104us/sample - loss: 0.1053 - acc: 0.9667 - val_loss: 0.0431 - val_acc: 0.9872\n",
      "Epoch 326/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.1110 - acc: 0.9643\n",
      "Epoch 00326: val_loss did not improve from 0.04203\n",
      "40200/40200 [==============================] - 4s 108us/sample - loss: 0.1109 - acc: 0.9642 - val_loss: 0.0425 - val_acc: 0.9871\n",
      "Epoch 327/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.1080 - acc: 0.9654\n",
      "Epoch 00327: val_loss did not improve from 0.04203\n",
      "40200/40200 [==============================] - 4s 108us/sample - loss: 0.1080 - acc: 0.9654 - val_loss: 0.0425 - val_acc: 0.9874\n",
      "Epoch 328/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.1115 - acc: 0.9649\n",
      "Epoch 00328: val_loss did not improve from 0.04203\n",
      "40200/40200 [==============================] - 4s 107us/sample - loss: 0.1115 - acc: 0.9649 - val_loss: 0.0432 - val_acc: 0.9865\n",
      "Epoch 329/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.1131 - acc: 0.9638\n",
      "Epoch 00329: val_loss did not improve from 0.04203\n",
      "40200/40200 [==============================] - 4s 108us/sample - loss: 0.1132 - acc: 0.9638 - val_loss: 0.0430 - val_acc: 0.9870\n",
      "Epoch 330/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.1061 - acc: 0.9667\n",
      "Epoch 00330: val_loss did not improve from 0.04203\n",
      "40200/40200 [==============================] - 4s 109us/sample - loss: 0.1061 - acc: 0.9667 - val_loss: 0.0438 - val_acc: 0.9867\n",
      "Epoch 331/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.1111 - acc: 0.9660\n",
      "Epoch 00331: val_loss did not improve from 0.04203\n",
      "40200/40200 [==============================] - 4s 109us/sample - loss: 0.1113 - acc: 0.9660 - val_loss: 0.0435 - val_acc: 0.9866\n",
      "Epoch 332/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.1085 - acc: 0.9665\n",
      "Epoch 00332: val_loss did not improve from 0.04203\n",
      "40200/40200 [==============================] - 4s 108us/sample - loss: 0.1083 - acc: 0.9667 - val_loss: 0.0433 - val_acc: 0.9873\n",
      "Epoch 333/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.1112 - acc: 0.9640\n",
      "Epoch 00333: val_loss did not improve from 0.04203\n",
      "40200/40200 [==============================] - 4s 108us/sample - loss: 0.1111 - acc: 0.9639 - val_loss: 0.0430 - val_acc: 0.9874\n",
      "Epoch 334/500\n",
      "39616/40200 [============================>.] - ETA: 0s - loss: 0.1080 - acc: 0.9665\n",
      "Epoch 00334: val_loss did not improve from 0.04203\n",
      "40200/40200 [==============================] - 4s 107us/sample - loss: 0.1078 - acc: 0.9665 - val_loss: 0.0425 - val_acc: 0.9871\n",
      "Epoch 335/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.1101 - acc: 0.9660\n",
      "Epoch 00335: val_loss did not improve from 0.04203\n",
      "40200/40200 [==============================] - 4s 108us/sample - loss: 0.1098 - acc: 0.9660 - val_loss: 0.0439 - val_acc: 0.9866\n",
      "Epoch 336/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.1060 - acc: 0.9668\n",
      "Epoch 00336: val_loss did not improve from 0.04203\n",
      "40200/40200 [==============================] - 4s 108us/sample - loss: 0.1057 - acc: 0.9669 - val_loss: 0.0430 - val_acc: 0.9871\n",
      "Epoch 337/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.1008 - acc: 0.9677\n",
      "Epoch 00337: val_loss did not improve from 0.04203\n",
      "40200/40200 [==============================] - 4s 108us/sample - loss: 0.1009 - acc: 0.9676 - val_loss: 0.0436 - val_acc: 0.9867\n",
      "\n",
      "vis_2D_CNN_custom_ch_16_DO_075_DO_2_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 75us/sample - loss: 0.0361 - acc: 0.9875\n",
      "Loss: 0.0361479557828512 Accuracy: 0.9875\n",
      "\n",
      "Train on 40200 samples, validate on 19800 samples\n",
      "Epoch 1/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 12.3148 - acc: 0.1750\n",
      "Epoch 00001: val_loss improved from inf to 5.49217, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_3_conv_checkpoint/001-5.4922.hdf5\n",
      "40200/40200 [==============================] - 7s 165us/sample - loss: 12.2934 - acc: 0.1756 - val_loss: 5.4922 - val_acc: 0.4748\n",
      "Epoch 2/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 3.3479 - acc: 0.3037\n",
      "Epoch 00002: val_loss improved from 5.49217 to 1.38038, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_3_conv_checkpoint/002-1.3804.hdf5\n",
      "40200/40200 [==============================] - 5s 129us/sample - loss: 3.3451 - acc: 0.3039 - val_loss: 1.3804 - val_acc: 0.6180\n",
      "Epoch 3/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 1.7320 - acc: 0.4122\n",
      "Epoch 00003: val_loss improved from 1.38038 to 0.94823, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_3_conv_checkpoint/003-0.9482.hdf5\n",
      "40200/40200 [==============================] - 5s 124us/sample - loss: 1.7313 - acc: 0.4126 - val_loss: 0.9482 - val_acc: 0.7562\n",
      "Epoch 4/500\n",
      "39744/40200 [============================>.] - ETA: 0s - loss: 1.4139 - acc: 0.5248\n",
      "Epoch 00004: val_loss improved from 0.94823 to 0.65424, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_3_conv_checkpoint/004-0.6542.hdf5\n",
      "40200/40200 [==============================] - 5s 125us/sample - loss: 1.4128 - acc: 0.5252 - val_loss: 0.6542 - val_acc: 0.8325\n",
      "Epoch 5/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 1.1322 - acc: 0.6247\n",
      "Epoch 00005: val_loss improved from 0.65424 to 0.46162, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_3_conv_checkpoint/005-0.4616.hdf5\n",
      "40200/40200 [==============================] - 5s 126us/sample - loss: 1.1306 - acc: 0.6251 - val_loss: 0.4616 - val_acc: 0.8813\n",
      "Epoch 6/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.9238 - acc: 0.6934\n",
      "Epoch 00006: val_loss improved from 0.46162 to 0.34325, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_3_conv_checkpoint/006-0.3433.hdf5\n",
      "40200/40200 [==============================] - 5s 125us/sample - loss: 0.9238 - acc: 0.6934 - val_loss: 0.3433 - val_acc: 0.9063\n",
      "Epoch 7/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.7879 - acc: 0.7403\n",
      "Epoch 00007: val_loss improved from 0.34325 to 0.28031, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_3_conv_checkpoint/007-0.2803.hdf5\n",
      "40200/40200 [==============================] - 5s 125us/sample - loss: 0.7878 - acc: 0.7402 - val_loss: 0.2803 - val_acc: 0.9222\n",
      "Epoch 8/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.6797 - acc: 0.7797\n",
      "Epoch 00008: val_loss improved from 0.28031 to 0.24522, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_3_conv_checkpoint/008-0.2452.hdf5\n",
      "40200/40200 [==============================] - 5s 126us/sample - loss: 0.6800 - acc: 0.7798 - val_loss: 0.2452 - val_acc: 0.9310\n",
      "Epoch 9/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.6099 - acc: 0.8047\n",
      "Epoch 00009: val_loss improved from 0.24522 to 0.21972, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_3_conv_checkpoint/009-0.2197.hdf5\n",
      "40200/40200 [==============================] - 5s 125us/sample - loss: 0.6096 - acc: 0.8047 - val_loss: 0.2197 - val_acc: 0.9399\n",
      "Epoch 10/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.5399 - acc: 0.8284\n",
      "Epoch 00010: val_loss improved from 0.21972 to 0.19370, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_3_conv_checkpoint/010-0.1937.hdf5\n",
      "40200/40200 [==============================] - 5s 125us/sample - loss: 0.5399 - acc: 0.8284 - val_loss: 0.1937 - val_acc: 0.9460\n",
      "Epoch 11/500\n",
      "39680/40200 [============================>.] - ETA: 0s - loss: 0.4864 - acc: 0.8451\n",
      "Epoch 00011: val_loss improved from 0.19370 to 0.17431, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_3_conv_checkpoint/011-0.1743.hdf5\n",
      "40200/40200 [==============================] - 5s 121us/sample - loss: 0.4859 - acc: 0.8452 - val_loss: 0.1743 - val_acc: 0.9510\n",
      "Epoch 12/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.4514 - acc: 0.8570\n",
      "Epoch 00012: val_loss improved from 0.17431 to 0.16374, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_3_conv_checkpoint/012-0.1637.hdf5\n",
      "40200/40200 [==============================] - 5s 113us/sample - loss: 0.4513 - acc: 0.8571 - val_loss: 0.1637 - val_acc: 0.9544\n",
      "Epoch 13/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.4215 - acc: 0.8684\n",
      "Epoch 00013: val_loss improved from 0.16374 to 0.15071, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_3_conv_checkpoint/013-0.1507.hdf5\n",
      "40200/40200 [==============================] - 5s 122us/sample - loss: 0.4211 - acc: 0.8685 - val_loss: 0.1507 - val_acc: 0.9569\n",
      "Epoch 14/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.3853 - acc: 0.8800\n",
      "Epoch 00014: val_loss improved from 0.15071 to 0.14119, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_3_conv_checkpoint/014-0.1412.hdf5\n",
      "40200/40200 [==============================] - 5s 125us/sample - loss: 0.3854 - acc: 0.8800 - val_loss: 0.1412 - val_acc: 0.9596\n",
      "Epoch 15/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.3608 - acc: 0.8872\n",
      "Epoch 00015: val_loss improved from 0.14119 to 0.13313, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_3_conv_checkpoint/015-0.1331.hdf5\n",
      "40200/40200 [==============================] - 5s 125us/sample - loss: 0.3608 - acc: 0.8871 - val_loss: 0.1331 - val_acc: 0.9621\n",
      "Epoch 16/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.3348 - acc: 0.8949\n",
      "Epoch 00016: val_loss improved from 0.13313 to 0.12915, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_3_conv_checkpoint/016-0.1292.hdf5\n",
      "40200/40200 [==============================] - 5s 126us/sample - loss: 0.3346 - acc: 0.8949 - val_loss: 0.1292 - val_acc: 0.9620\n",
      "Epoch 17/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.3145 - acc: 0.9035\n",
      "Epoch 00017: val_loss improved from 0.12915 to 0.11679, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_3_conv_checkpoint/017-0.1168.hdf5\n",
      "40200/40200 [==============================] - 5s 124us/sample - loss: 0.3145 - acc: 0.9035 - val_loss: 0.1168 - val_acc: 0.9665\n",
      "Epoch 18/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.3079 - acc: 0.9054\n",
      "Epoch 00018: val_loss improved from 0.11679 to 0.11158, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_3_conv_checkpoint/018-0.1116.hdf5\n",
      "40200/40200 [==============================] - 5s 124us/sample - loss: 0.3080 - acc: 0.9053 - val_loss: 0.1116 - val_acc: 0.9677\n",
      "Epoch 19/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.2932 - acc: 0.9110\n",
      "Epoch 00019: val_loss improved from 0.11158 to 0.10912, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_3_conv_checkpoint/019-0.1091.hdf5\n",
      "40200/40200 [==============================] - 5s 125us/sample - loss: 0.2932 - acc: 0.9110 - val_loss: 0.1091 - val_acc: 0.9684\n",
      "Epoch 20/500\n",
      "39680/40200 [============================>.] - ETA: 0s - loss: 0.2813 - acc: 0.9137\n",
      "Epoch 00020: val_loss improved from 0.10912 to 0.10500, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_3_conv_checkpoint/020-0.1050.hdf5\n",
      "40200/40200 [==============================] - 5s 125us/sample - loss: 0.2814 - acc: 0.9137 - val_loss: 0.1050 - val_acc: 0.9688\n",
      "Epoch 21/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.2677 - acc: 0.9162\n",
      "Epoch 00021: val_loss improved from 0.10500 to 0.10201, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_3_conv_checkpoint/021-0.1020.hdf5\n",
      "40200/40200 [==============================] - 5s 121us/sample - loss: 0.2678 - acc: 0.9161 - val_loss: 0.1020 - val_acc: 0.9699\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.2567 - acc: 0.9219\n",
      "Epoch 00022: val_loss improved from 0.10201 to 0.09584, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_3_conv_checkpoint/022-0.0958.hdf5\n",
      "40200/40200 [==============================] - 5s 121us/sample - loss: 0.2570 - acc: 0.9219 - val_loss: 0.0958 - val_acc: 0.9709\n",
      "Epoch 23/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.2469 - acc: 0.9234\n",
      "Epoch 00023: val_loss did not improve from 0.09584\n",
      "40200/40200 [==============================] - 5s 119us/sample - loss: 0.2471 - acc: 0.9234 - val_loss: 0.0969 - val_acc: 0.9711\n",
      "Epoch 24/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.2364 - acc: 0.9268\n",
      "Epoch 00024: val_loss improved from 0.09584 to 0.09079, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_3_conv_checkpoint/024-0.0908.hdf5\n",
      "40200/40200 [==============================] - 5s 114us/sample - loss: 0.2361 - acc: 0.9268 - val_loss: 0.0908 - val_acc: 0.9735\n",
      "Epoch 25/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.2266 - acc: 0.9289\n",
      "Epoch 00025: val_loss improved from 0.09079 to 0.08815, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_3_conv_checkpoint/025-0.0882.hdf5\n",
      "40200/40200 [==============================] - 5s 122us/sample - loss: 0.2271 - acc: 0.9289 - val_loss: 0.0882 - val_acc: 0.9739\n",
      "Epoch 26/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.2220 - acc: 0.9328\n",
      "Epoch 00026: val_loss improved from 0.08815 to 0.08739, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_3_conv_checkpoint/026-0.0874.hdf5\n",
      "40200/40200 [==============================] - 5s 124us/sample - loss: 0.2218 - acc: 0.9328 - val_loss: 0.0874 - val_acc: 0.9727\n",
      "Epoch 27/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.2169 - acc: 0.9322\n",
      "Epoch 00027: val_loss improved from 0.08739 to 0.08292, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_3_conv_checkpoint/027-0.0829.hdf5\n",
      "40200/40200 [==============================] - 5s 123us/sample - loss: 0.2166 - acc: 0.9324 - val_loss: 0.0829 - val_acc: 0.9749\n",
      "Epoch 28/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.2110 - acc: 0.9346\n",
      "Epoch 00028: val_loss improved from 0.08292 to 0.08169, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_3_conv_checkpoint/028-0.0817.hdf5\n",
      "40200/40200 [==============================] - 5s 123us/sample - loss: 0.2114 - acc: 0.9345 - val_loss: 0.0817 - val_acc: 0.9756\n",
      "Epoch 29/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.2062 - acc: 0.9355\n",
      "Epoch 00029: val_loss improved from 0.08169 to 0.07956, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_3_conv_checkpoint/029-0.0796.hdf5\n",
      "40200/40200 [==============================] - 5s 124us/sample - loss: 0.2062 - acc: 0.9356 - val_loss: 0.0796 - val_acc: 0.9761\n",
      "Epoch 30/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.1978 - acc: 0.9386\n",
      "Epoch 00030: val_loss improved from 0.07956 to 0.07904, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_3_conv_checkpoint/030-0.0790.hdf5\n",
      "40200/40200 [==============================] - 5s 125us/sample - loss: 0.1976 - acc: 0.9387 - val_loss: 0.0790 - val_acc: 0.9759\n",
      "Epoch 31/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.1902 - acc: 0.9408\n",
      "Epoch 00031: val_loss improved from 0.07904 to 0.07580, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_3_conv_checkpoint/031-0.0758.hdf5\n",
      "40200/40200 [==============================] - 5s 125us/sample - loss: 0.1903 - acc: 0.9408 - val_loss: 0.0758 - val_acc: 0.9768\n",
      "Epoch 32/500\n",
      "39744/40200 [============================>.] - ETA: 0s - loss: 0.1827 - acc: 0.9448\n",
      "Epoch 00032: val_loss improved from 0.07580 to 0.07313, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_3_conv_checkpoint/032-0.0731.hdf5\n",
      "40200/40200 [==============================] - 5s 124us/sample - loss: 0.1830 - acc: 0.9447 - val_loss: 0.0731 - val_acc: 0.9775\n",
      "Epoch 33/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.1799 - acc: 0.9436\n",
      "Epoch 00033: val_loss improved from 0.07313 to 0.07207, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_3_conv_checkpoint/033-0.0721.hdf5\n",
      "40200/40200 [==============================] - 5s 125us/sample - loss: 0.1803 - acc: 0.9436 - val_loss: 0.0721 - val_acc: 0.9778\n",
      "Epoch 34/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.1792 - acc: 0.9446\n",
      "Epoch 00034: val_loss improved from 0.07207 to 0.07036, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_3_conv_checkpoint/034-0.0704.hdf5\n",
      "40200/40200 [==============================] - 5s 125us/sample - loss: 0.1792 - acc: 0.9446 - val_loss: 0.0704 - val_acc: 0.9786\n",
      "Epoch 35/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.1804 - acc: 0.9431\n",
      "Epoch 00035: val_loss did not improve from 0.07036\n",
      "40200/40200 [==============================] - 5s 122us/sample - loss: 0.1808 - acc: 0.9429 - val_loss: 0.0705 - val_acc: 0.9782\n",
      "Epoch 36/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.1705 - acc: 0.9471\n",
      "Epoch 00036: val_loss improved from 0.07036 to 0.06821, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_3_conv_checkpoint/036-0.0682.hdf5\n",
      "40200/40200 [==============================] - 5s 112us/sample - loss: 0.1702 - acc: 0.9472 - val_loss: 0.0682 - val_acc: 0.9789\n",
      "Epoch 37/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.1663 - acc: 0.9491\n",
      "Epoch 00037: val_loss did not improve from 0.06821\n",
      "40200/40200 [==============================] - 5s 121us/sample - loss: 0.1662 - acc: 0.9490 - val_loss: 0.0698 - val_acc: 0.9787\n",
      "Epoch 38/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.1597 - acc: 0.9502\n",
      "Epoch 00038: val_loss improved from 0.06821 to 0.06651, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_3_conv_checkpoint/038-0.0665.hdf5\n",
      "40200/40200 [==============================] - 5s 124us/sample - loss: 0.1600 - acc: 0.9501 - val_loss: 0.0665 - val_acc: 0.9798\n",
      "Epoch 39/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.1623 - acc: 0.9501\n",
      "Epoch 00039: val_loss did not improve from 0.06651\n",
      "40200/40200 [==============================] - 5s 123us/sample - loss: 0.1630 - acc: 0.9500 - val_loss: 0.0676 - val_acc: 0.9790\n",
      "Epoch 40/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.1573 - acc: 0.9525\n",
      "Epoch 00040: val_loss improved from 0.06651 to 0.06431, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_3_conv_checkpoint/040-0.0643.hdf5\n",
      "40200/40200 [==============================] - 5s 124us/sample - loss: 0.1572 - acc: 0.9525 - val_loss: 0.0643 - val_acc: 0.9803\n",
      "Epoch 41/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.1550 - acc: 0.9516\n",
      "Epoch 00041: val_loss improved from 0.06431 to 0.06314, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_3_conv_checkpoint/041-0.0631.hdf5\n",
      "40200/40200 [==============================] - 5s 125us/sample - loss: 0.1549 - acc: 0.9516 - val_loss: 0.0631 - val_acc: 0.9805\n",
      "Epoch 42/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.1492 - acc: 0.9542\n",
      "Epoch 00042: val_loss did not improve from 0.06314\n",
      "40200/40200 [==============================] - 5s 124us/sample - loss: 0.1492 - acc: 0.9542 - val_loss: 0.0639 - val_acc: 0.9803\n",
      "Epoch 43/500\n",
      "39744/40200 [============================>.] - ETA: 0s - loss: 0.1496 - acc: 0.9538\n",
      "Epoch 00043: val_loss improved from 0.06314 to 0.06148, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_3_conv_checkpoint/043-0.0615.hdf5\n",
      "40200/40200 [==============================] - 5s 124us/sample - loss: 0.1498 - acc: 0.9537 - val_loss: 0.0615 - val_acc: 0.9822\n",
      "Epoch 44/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.1466 - acc: 0.9560\n",
      "Epoch 00044: val_loss did not improve from 0.06148\n",
      "40200/40200 [==============================] - 5s 123us/sample - loss: 0.1464 - acc: 0.9560 - val_loss: 0.0625 - val_acc: 0.9806\n",
      "Epoch 45/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.1401 - acc: 0.9568\n",
      "Epoch 00045: val_loss did not improve from 0.06148\n",
      "40200/40200 [==============================] - 5s 122us/sample - loss: 0.1400 - acc: 0.9568 - val_loss: 0.0635 - val_acc: 0.9812\n",
      "Epoch 46/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.1382 - acc: 0.9568\n",
      "Epoch 00046: val_loss improved from 0.06148 to 0.05872, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_3_conv_checkpoint/046-0.0587.hdf5\n",
      "40200/40200 [==============================] - 5s 124us/sample - loss: 0.1384 - acc: 0.9568 - val_loss: 0.0587 - val_acc: 0.9822\n",
      "Epoch 47/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.1344 - acc: 0.9587\n",
      "Epoch 00047: val_loss did not improve from 0.05872\n",
      "40200/40200 [==============================] - 5s 124us/sample - loss: 0.1341 - acc: 0.9588 - val_loss: 0.0600 - val_acc: 0.9814\n",
      "Epoch 48/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.1372 - acc: 0.9572\n",
      "Epoch 00048: val_loss improved from 0.05872 to 0.05809, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_3_conv_checkpoint/048-0.0581.hdf5\n",
      "40200/40200 [==============================] - 5s 114us/sample - loss: 0.1370 - acc: 0.9573 - val_loss: 0.0581 - val_acc: 0.9822\n",
      "Epoch 49/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.1359 - acc: 0.9571\n",
      "Epoch 00049: val_loss did not improve from 0.05809\n",
      "40200/40200 [==============================] - 5s 120us/sample - loss: 0.1355 - acc: 0.9572 - val_loss: 0.0583 - val_acc: 0.9822\n",
      "Epoch 50/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.1312 - acc: 0.9591\n",
      "Epoch 00050: val_loss did not improve from 0.05809\n",
      "40200/40200 [==============================] - 5s 124us/sample - loss: 0.1313 - acc: 0.9590 - val_loss: 0.0586 - val_acc: 0.9816\n",
      "Epoch 51/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.1322 - acc: 0.9589\n",
      "Epoch 00051: val_loss improved from 0.05809 to 0.05706, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_3_conv_checkpoint/051-0.0571.hdf5\n",
      "40200/40200 [==============================] - 5s 124us/sample - loss: 0.1323 - acc: 0.9589 - val_loss: 0.0571 - val_acc: 0.9822\n",
      "Epoch 52/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.1282 - acc: 0.9611\n",
      "Epoch 00052: val_loss improved from 0.05706 to 0.05581, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_3_conv_checkpoint/052-0.0558.hdf5\n",
      "40200/40200 [==============================] - 5s 125us/sample - loss: 0.1282 - acc: 0.9612 - val_loss: 0.0558 - val_acc: 0.9821\n",
      "Epoch 53/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.1254 - acc: 0.9611\n",
      "Epoch 00053: val_loss did not improve from 0.05581\n",
      "40200/40200 [==============================] - 5s 124us/sample - loss: 0.1259 - acc: 0.9609 - val_loss: 0.0560 - val_acc: 0.9826\n",
      "Epoch 54/500\n",
      "39744/40200 [============================>.] - ETA: 0s - loss: 0.1269 - acc: 0.9596\n",
      "Epoch 00054: val_loss did not improve from 0.05581\n",
      "40200/40200 [==============================] - 5s 123us/sample - loss: 0.1268 - acc: 0.9596 - val_loss: 0.0564 - val_acc: 0.9823\n",
      "Epoch 55/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.1252 - acc: 0.9606\n",
      "Epoch 00055: val_loss improved from 0.05581 to 0.05484, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_3_conv_checkpoint/055-0.0548.hdf5\n",
      "40200/40200 [==============================] - 5s 124us/sample - loss: 0.1249 - acc: 0.9607 - val_loss: 0.0548 - val_acc: 0.9825\n",
      "Epoch 56/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.1216 - acc: 0.9624\n",
      "Epoch 00056: val_loss improved from 0.05484 to 0.05472, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_3_conv_checkpoint/056-0.0547.hdf5\n",
      "40200/40200 [==============================] - 5s 125us/sample - loss: 0.1215 - acc: 0.9624 - val_loss: 0.0547 - val_acc: 0.9825\n",
      "Epoch 57/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.1200 - acc: 0.9630\n",
      "Epoch 00057: val_loss did not improve from 0.05472\n",
      "40200/40200 [==============================] - 5s 123us/sample - loss: 0.1197 - acc: 0.9631 - val_loss: 0.0547 - val_acc: 0.9830\n",
      "Epoch 58/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.1184 - acc: 0.9620\n",
      "Epoch 00058: val_loss improved from 0.05472 to 0.05419, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_3_conv_checkpoint/058-0.0542.hdf5\n",
      "40200/40200 [==============================] - 5s 125us/sample - loss: 0.1184 - acc: 0.9620 - val_loss: 0.0542 - val_acc: 0.9835\n",
      "Epoch 59/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.1179 - acc: 0.9633\n",
      "Epoch 00059: val_loss improved from 0.05419 to 0.05287, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_3_conv_checkpoint/059-0.0529.hdf5\n",
      "40200/40200 [==============================] - 5s 125us/sample - loss: 0.1180 - acc: 0.9632 - val_loss: 0.0529 - val_acc: 0.9838\n",
      "Epoch 60/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.1142 - acc: 0.9644\n",
      "Epoch 00060: val_loss did not improve from 0.05287\n",
      "40200/40200 [==============================] - 5s 113us/sample - loss: 0.1140 - acc: 0.9645 - val_loss: 0.0546 - val_acc: 0.9829\n",
      "Epoch 61/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.1196 - acc: 0.9626\n",
      "Epoch 00061: val_loss improved from 0.05287 to 0.05265, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_3_conv_checkpoint/061-0.0526.hdf5\n",
      "40200/40200 [==============================] - 5s 120us/sample - loss: 0.1197 - acc: 0.9626 - val_loss: 0.0526 - val_acc: 0.9835\n",
      "Epoch 62/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.1149 - acc: 0.9640\n",
      "Epoch 00062: val_loss improved from 0.05265 to 0.05201, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_3_conv_checkpoint/062-0.0520.hdf5\n",
      "40200/40200 [==============================] - 5s 124us/sample - loss: 0.1149 - acc: 0.9640 - val_loss: 0.0520 - val_acc: 0.9843\n",
      "Epoch 63/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.1086 - acc: 0.9656\n",
      "Epoch 00063: val_loss did not improve from 0.05201\n",
      "40200/40200 [==============================] - 5s 123us/sample - loss: 0.1087 - acc: 0.9656 - val_loss: 0.0537 - val_acc: 0.9842\n",
      "Epoch 64/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.1083 - acc: 0.9663\n",
      "Epoch 00064: val_loss improved from 0.05201 to 0.05070, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_3_conv_checkpoint/064-0.0507.hdf5\n",
      "40200/40200 [==============================] - 5s 123us/sample - loss: 0.1084 - acc: 0.9662 - val_loss: 0.0507 - val_acc: 0.9844\n",
      "Epoch 65/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.1095 - acc: 0.9669\n",
      "Epoch 00065: val_loss did not improve from 0.05070\n",
      "40200/40200 [==============================] - 5s 124us/sample - loss: 0.1095 - acc: 0.9669 - val_loss: 0.0517 - val_acc: 0.9836\n",
      "Epoch 66/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.1089 - acc: 0.9668\n",
      "Epoch 00066: val_loss improved from 0.05070 to 0.05011, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_3_conv_checkpoint/066-0.0501.hdf5\n",
      "40200/40200 [==============================] - 5s 124us/sample - loss: 0.1088 - acc: 0.9668 - val_loss: 0.0501 - val_acc: 0.9844\n",
      "Epoch 67/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.1116 - acc: 0.9655\n",
      "Epoch 00067: val_loss did not improve from 0.05011\n",
      "40200/40200 [==============================] - 5s 124us/sample - loss: 0.1114 - acc: 0.9655 - val_loss: 0.0508 - val_acc: 0.9838\n",
      "Epoch 68/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.1050 - acc: 0.9665\n",
      "Epoch 00068: val_loss did not improve from 0.05011\n",
      "40200/40200 [==============================] - 5s 123us/sample - loss: 0.1054 - acc: 0.9665 - val_loss: 0.0502 - val_acc: 0.9842\n",
      "Epoch 69/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.1034 - acc: 0.9672\n",
      "Epoch 00069: val_loss improved from 0.05011 to 0.04967, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_3_conv_checkpoint/069-0.0497.hdf5\n",
      "40200/40200 [==============================] - 5s 125us/sample - loss: 0.1034 - acc: 0.9671 - val_loss: 0.0497 - val_acc: 0.9843\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.1043 - acc: 0.9670\n",
      "Epoch 00070: val_loss did not improve from 0.04967\n",
      "40200/40200 [==============================] - 5s 119us/sample - loss: 0.1042 - acc: 0.9670 - val_loss: 0.0512 - val_acc: 0.9845\n",
      "Epoch 71/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.1034 - acc: 0.9675\n",
      "Epoch 00071: val_loss did not improve from 0.04967\n",
      "40200/40200 [==============================] - 5s 116us/sample - loss: 0.1035 - acc: 0.9675 - val_loss: 0.0509 - val_acc: 0.9843\n",
      "Epoch 72/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.1020 - acc: 0.9676\n",
      "Epoch 00072: val_loss improved from 0.04967 to 0.04806, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_3_conv_checkpoint/072-0.0481.hdf5\n",
      "40200/40200 [==============================] - 5s 117us/sample - loss: 0.1019 - acc: 0.9676 - val_loss: 0.0481 - val_acc: 0.9851\n",
      "Epoch 73/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.1027 - acc: 0.9674\n",
      "Epoch 00073: val_loss did not improve from 0.04806\n",
      "40200/40200 [==============================] - 5s 115us/sample - loss: 0.1027 - acc: 0.9674 - val_loss: 0.0496 - val_acc: 0.9847\n",
      "Epoch 74/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.1010 - acc: 0.9689\n",
      "Epoch 00074: val_loss did not improve from 0.04806\n",
      "40200/40200 [==============================] - 5s 116us/sample - loss: 0.1009 - acc: 0.9689 - val_loss: 0.0493 - val_acc: 0.9847\n",
      "Epoch 75/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.0972 - acc: 0.9695\n",
      "Epoch 00075: val_loss improved from 0.04806 to 0.04725, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_3_conv_checkpoint/075-0.0473.hdf5\n",
      "40200/40200 [==============================] - 5s 120us/sample - loss: 0.0972 - acc: 0.9695 - val_loss: 0.0473 - val_acc: 0.9852\n",
      "Epoch 76/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.0993 - acc: 0.9683\n",
      "Epoch 00076: val_loss did not improve from 0.04725\n",
      "40200/40200 [==============================] - 5s 119us/sample - loss: 0.0992 - acc: 0.9683 - val_loss: 0.0490 - val_acc: 0.9848\n",
      "Epoch 77/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.0993 - acc: 0.9692\n",
      "Epoch 00077: val_loss did not improve from 0.04725\n",
      "40200/40200 [==============================] - 5s 118us/sample - loss: 0.0994 - acc: 0.9692 - val_loss: 0.0486 - val_acc: 0.9851\n",
      "Epoch 78/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.1007 - acc: 0.9689\n",
      "Epoch 00078: val_loss did not improve from 0.04725\n",
      "40200/40200 [==============================] - 5s 120us/sample - loss: 0.1009 - acc: 0.9689 - val_loss: 0.0480 - val_acc: 0.9853\n",
      "Epoch 79/500\n",
      "39744/40200 [============================>.] - ETA: 0s - loss: 0.0975 - acc: 0.9691\n",
      "Epoch 00079: val_loss did not improve from 0.04725\n",
      "40200/40200 [==============================] - 5s 114us/sample - loss: 0.0975 - acc: 0.9690 - val_loss: 0.0478 - val_acc: 0.9851\n",
      "Epoch 80/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.0946 - acc: 0.9699\n",
      "Epoch 00080: val_loss did not improve from 0.04725\n",
      "40200/40200 [==============================] - 5s 113us/sample - loss: 0.0946 - acc: 0.9700 - val_loss: 0.0484 - val_acc: 0.9852\n",
      "Epoch 81/500\n",
      "39744/40200 [============================>.] - ETA: 0s - loss: 0.0971 - acc: 0.9699\n",
      "Epoch 00081: val_loss improved from 0.04725 to 0.04711, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_3_conv_checkpoint/081-0.0471.hdf5\n",
      "40200/40200 [==============================] - 5s 120us/sample - loss: 0.0968 - acc: 0.9700 - val_loss: 0.0471 - val_acc: 0.9859\n",
      "Epoch 82/500\n",
      "39744/40200 [============================>.] - ETA: 0s - loss: 0.0913 - acc: 0.9714\n",
      "Epoch 00082: val_loss improved from 0.04711 to 0.04682, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_3_conv_checkpoint/082-0.0468.hdf5\n",
      "40200/40200 [==============================] - 5s 117us/sample - loss: 0.0912 - acc: 0.9714 - val_loss: 0.0468 - val_acc: 0.9856\n",
      "Epoch 83/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.0960 - acc: 0.9699\n",
      "Epoch 00083: val_loss improved from 0.04682 to 0.04616, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_3_conv_checkpoint/083-0.0462.hdf5\n",
      "40200/40200 [==============================] - 5s 116us/sample - loss: 0.0958 - acc: 0.9699 - val_loss: 0.0462 - val_acc: 0.9861\n",
      "Epoch 84/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.0930 - acc: 0.9708\n",
      "Epoch 00084: val_loss did not improve from 0.04616\n",
      "40200/40200 [==============================] - 5s 113us/sample - loss: 0.0929 - acc: 0.9707 - val_loss: 0.0465 - val_acc: 0.9857\n",
      "Epoch 85/500\n",
      "39744/40200 [============================>.] - ETA: 0s - loss: 0.0931 - acc: 0.9715\n",
      "Epoch 00085: val_loss did not improve from 0.04616\n",
      "40200/40200 [==============================] - 4s 111us/sample - loss: 0.0932 - acc: 0.9714 - val_loss: 0.0473 - val_acc: 0.9862\n",
      "Epoch 86/500\n",
      "39680/40200 [============================>.] - ETA: 0s - loss: 0.0901 - acc: 0.9716\n",
      "Epoch 00086: val_loss improved from 0.04616 to 0.04552, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_3_conv_checkpoint/086-0.0455.hdf5\n",
      "40200/40200 [==============================] - 5s 113us/sample - loss: 0.0903 - acc: 0.9716 - val_loss: 0.0455 - val_acc: 0.9864\n",
      "Epoch 87/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.0901 - acc: 0.9715\n",
      "Epoch 00087: val_loss did not improve from 0.04552\n",
      "40200/40200 [==============================] - 5s 114us/sample - loss: 0.0904 - acc: 0.9715 - val_loss: 0.0474 - val_acc: 0.9861\n",
      "Epoch 88/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.0878 - acc: 0.9718\n",
      "Epoch 00088: val_loss improved from 0.04552 to 0.04482, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_3_conv_checkpoint/088-0.0448.hdf5\n",
      "40200/40200 [==============================] - 5s 118us/sample - loss: 0.0875 - acc: 0.9719 - val_loss: 0.0448 - val_acc: 0.9866\n",
      "Epoch 89/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.0900 - acc: 0.9718\n",
      "Epoch 00089: val_loss improved from 0.04482 to 0.04427, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_3_conv_checkpoint/089-0.0443.hdf5\n",
      "40200/40200 [==============================] - 5s 116us/sample - loss: 0.0899 - acc: 0.9718 - val_loss: 0.0443 - val_acc: 0.9865\n",
      "Epoch 90/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.0892 - acc: 0.9712\n",
      "Epoch 00090: val_loss did not improve from 0.04427\n",
      "40200/40200 [==============================] - 5s 118us/sample - loss: 0.0895 - acc: 0.9711 - val_loss: 0.0451 - val_acc: 0.9861\n",
      "Epoch 91/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.0889 - acc: 0.9718\n",
      "Epoch 00091: val_loss did not improve from 0.04427\n",
      "40200/40200 [==============================] - 5s 113us/sample - loss: 0.0888 - acc: 0.9718 - val_loss: 0.0455 - val_acc: 0.9863\n",
      "Epoch 92/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.0890 - acc: 0.9718\n",
      "Epoch 00092: val_loss did not improve from 0.04427\n",
      "40200/40200 [==============================] - 5s 117us/sample - loss: 0.0890 - acc: 0.9718 - val_loss: 0.0461 - val_acc: 0.9857\n",
      "Epoch 93/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.0838 - acc: 0.9732\n",
      "Epoch 00093: val_loss did not improve from 0.04427\n",
      "40200/40200 [==============================] - 5s 118us/sample - loss: 0.0839 - acc: 0.9731 - val_loss: 0.0447 - val_acc: 0.9865\n",
      "Epoch 94/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.0848 - acc: 0.9726\n",
      "Epoch 00094: val_loss improved from 0.04427 to 0.04391, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_3_conv_checkpoint/094-0.0439.hdf5\n",
      "40200/40200 [==============================] - 5s 124us/sample - loss: 0.0849 - acc: 0.9724 - val_loss: 0.0439 - val_acc: 0.9867\n",
      "Epoch 95/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.0858 - acc: 0.9736\n",
      "Epoch 00095: val_loss did not improve from 0.04391\n",
      "40200/40200 [==============================] - 5s 123us/sample - loss: 0.0859 - acc: 0.9735 - val_loss: 0.0445 - val_acc: 0.9868\n",
      "Epoch 96/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.0894 - acc: 0.9721\n",
      "Epoch 00096: val_loss did not improve from 0.04391\n",
      "40200/40200 [==============================] - 5s 124us/sample - loss: 0.0893 - acc: 0.9721 - val_loss: 0.0448 - val_acc: 0.9865\n",
      "Epoch 97/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.0839 - acc: 0.9732\n",
      "Epoch 00097: val_loss did not improve from 0.04391\n",
      "40200/40200 [==============================] - 5s 116us/sample - loss: 0.0841 - acc: 0.9732 - val_loss: 0.0444 - val_acc: 0.9867\n",
      "Epoch 98/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.0849 - acc: 0.9728\n",
      "Epoch 00098: val_loss improved from 0.04391 to 0.04331, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_3_conv_checkpoint/098-0.0433.hdf5\n",
      "40200/40200 [==============================] - 5s 117us/sample - loss: 0.0854 - acc: 0.9727 - val_loss: 0.0433 - val_acc: 0.9862\n",
      "Epoch 99/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.0858 - acc: 0.9729\n",
      "Epoch 00099: val_loss did not improve from 0.04331\n",
      "40200/40200 [==============================] - 5s 123us/sample - loss: 0.0862 - acc: 0.9728 - val_loss: 0.0438 - val_acc: 0.9865\n",
      "Epoch 100/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.0837 - acc: 0.9732\n",
      "Epoch 00100: val_loss did not improve from 0.04331\n",
      "40200/40200 [==============================] - 5s 123us/sample - loss: 0.0834 - acc: 0.9732 - val_loss: 0.0444 - val_acc: 0.9867\n",
      "Epoch 101/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.0821 - acc: 0.9736\n",
      "Epoch 00101: val_loss did not improve from 0.04331\n",
      "40200/40200 [==============================] - 5s 124us/sample - loss: 0.0822 - acc: 0.9737 - val_loss: 0.0450 - val_acc: 0.9865\n",
      "Epoch 102/500\n",
      "39744/40200 [============================>.] - ETA: 0s - loss: 0.0827 - acc: 0.9733\n",
      "Epoch 00102: val_loss did not improve from 0.04331\n",
      "40200/40200 [==============================] - 5s 124us/sample - loss: 0.0826 - acc: 0.9732 - val_loss: 0.0444 - val_acc: 0.9870\n",
      "Epoch 103/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.0793 - acc: 0.9745\n",
      "Epoch 00103: val_loss did not improve from 0.04331\n",
      "40200/40200 [==============================] - 5s 123us/sample - loss: 0.0793 - acc: 0.9745 - val_loss: 0.0446 - val_acc: 0.9868\n",
      "Epoch 104/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.0806 - acc: 0.9735\n",
      "Epoch 00104: val_loss did not improve from 0.04331\n",
      "40200/40200 [==============================] - 5s 124us/sample - loss: 0.0805 - acc: 0.9735 - val_loss: 0.0441 - val_acc: 0.9868\n",
      "Epoch 105/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.0838 - acc: 0.9742\n",
      "Epoch 00105: val_loss did not improve from 0.04331\n",
      "40200/40200 [==============================] - 5s 122us/sample - loss: 0.0835 - acc: 0.9743 - val_loss: 0.0448 - val_acc: 0.9866\n",
      "Epoch 106/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.0744 - acc: 0.9757\n",
      "Epoch 00106: val_loss did not improve from 0.04331\n",
      "40200/40200 [==============================] - 5s 124us/sample - loss: 0.0744 - acc: 0.9756 - val_loss: 0.0435 - val_acc: 0.9874\n",
      "Epoch 107/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.0771 - acc: 0.9747\n",
      "Epoch 00107: val_loss did not improve from 0.04331\n",
      "40200/40200 [==============================] - 5s 123us/sample - loss: 0.0769 - acc: 0.9748 - val_loss: 0.0441 - val_acc: 0.9868\n",
      "Epoch 108/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.0809 - acc: 0.9740\n",
      "Epoch 00108: val_loss did not improve from 0.04331\n",
      "40200/40200 [==============================] - 5s 123us/sample - loss: 0.0809 - acc: 0.9740 - val_loss: 0.0445 - val_acc: 0.9874\n",
      "Epoch 109/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.0778 - acc: 0.9754\n",
      "Epoch 00109: val_loss improved from 0.04331 to 0.04230, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_3_conv_checkpoint/109-0.0423.hdf5\n",
      "40200/40200 [==============================] - 5s 117us/sample - loss: 0.0777 - acc: 0.9754 - val_loss: 0.0423 - val_acc: 0.9870\n",
      "Epoch 110/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.0778 - acc: 0.9749\n",
      "Epoch 00110: val_loss did not improve from 0.04230\n",
      "40200/40200 [==============================] - 5s 115us/sample - loss: 0.0777 - acc: 0.9749 - val_loss: 0.0440 - val_acc: 0.9864\n",
      "Epoch 111/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.0791 - acc: 0.9749\n",
      "Epoch 00111: val_loss improved from 0.04230 to 0.04196, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_3_conv_checkpoint/111-0.0420.hdf5\n",
      "40200/40200 [==============================] - 5s 123us/sample - loss: 0.0792 - acc: 0.9749 - val_loss: 0.0420 - val_acc: 0.9877\n",
      "Epoch 112/500\n",
      "39744/40200 [============================>.] - ETA: 0s - loss: 0.0757 - acc: 0.9759\n",
      "Epoch 00112: val_loss did not improve from 0.04196\n",
      "40200/40200 [==============================] - 5s 117us/sample - loss: 0.0758 - acc: 0.9760 - val_loss: 0.0430 - val_acc: 0.9866\n",
      "Epoch 113/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.0772 - acc: 0.9750\n",
      "Epoch 00113: val_loss did not improve from 0.04196\n",
      "40200/40200 [==============================] - 5s 116us/sample - loss: 0.0773 - acc: 0.9750 - val_loss: 0.0421 - val_acc: 0.9874\n",
      "Epoch 114/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.0798 - acc: 0.9743\n",
      "Epoch 00114: val_loss improved from 0.04196 to 0.04195, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_3_conv_checkpoint/114-0.0419.hdf5\n",
      "40200/40200 [==============================] - 5s 119us/sample - loss: 0.0796 - acc: 0.9744 - val_loss: 0.0419 - val_acc: 0.9877\n",
      "Epoch 115/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.0760 - acc: 0.9753\n",
      "Epoch 00115: val_loss improved from 0.04195 to 0.04126, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_3_conv_checkpoint/115-0.0413.hdf5\n",
      "40200/40200 [==============================] - 5s 120us/sample - loss: 0.0758 - acc: 0.9753 - val_loss: 0.0413 - val_acc: 0.9873\n",
      "Epoch 116/500\n",
      "39744/40200 [============================>.] - ETA: 0s - loss: 0.0740 - acc: 0.9763\n",
      "Epoch 00116: val_loss did not improve from 0.04126\n",
      "40200/40200 [==============================] - 5s 118us/sample - loss: 0.0740 - acc: 0.9763 - val_loss: 0.0427 - val_acc: 0.9880\n",
      "Epoch 117/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.0731 - acc: 0.9764\n",
      "Epoch 00117: val_loss did not improve from 0.04126\n",
      "40200/40200 [==============================] - 5s 119us/sample - loss: 0.0730 - acc: 0.9764 - val_loss: 0.0424 - val_acc: 0.9875\n",
      "Epoch 118/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.0747 - acc: 0.9760\n",
      "Epoch 00118: val_loss did not improve from 0.04126\n",
      "40200/40200 [==============================] - 5s 120us/sample - loss: 0.0750 - acc: 0.9759 - val_loss: 0.0431 - val_acc: 0.9875\n",
      "Epoch 119/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.0748 - acc: 0.9765\n",
      "Epoch 00119: val_loss did not improve from 0.04126\n",
      "40200/40200 [==============================] - 5s 115us/sample - loss: 0.0747 - acc: 0.9765 - val_loss: 0.0428 - val_acc: 0.9874\n",
      "Epoch 120/500\n",
      "39680/40200 [============================>.] - ETA: 0s - loss: 0.0741 - acc: 0.9761\n",
      "Epoch 00120: val_loss did not improve from 0.04126\n",
      "40200/40200 [==============================] - 5s 121us/sample - loss: 0.0740 - acc: 0.9760 - val_loss: 0.0420 - val_acc: 0.9875\n",
      "Epoch 121/500\n",
      "39744/40200 [============================>.] - ETA: 0s - loss: 0.0747 - acc: 0.9756\n",
      "Epoch 00121: val_loss did not improve from 0.04126\n",
      "40200/40200 [==============================] - 5s 115us/sample - loss: 0.0747 - acc: 0.9756 - val_loss: 0.0422 - val_acc: 0.9872\n",
      "Epoch 122/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.0764 - acc: 0.9760\n",
      "Epoch 00122: val_loss did not improve from 0.04126\n",
      "40200/40200 [==============================] - 5s 114us/sample - loss: 0.0763 - acc: 0.9760 - val_loss: 0.0421 - val_acc: 0.9869\n",
      "Epoch 123/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.0744 - acc: 0.9766\n",
      "Epoch 00123: val_loss improved from 0.04126 to 0.04119, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_3_conv_checkpoint/123-0.0412.hdf5\n",
      "40200/40200 [==============================] - 5s 118us/sample - loss: 0.0745 - acc: 0.9766 - val_loss: 0.0412 - val_acc: 0.9875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 124/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.0751 - acc: 0.9756\n",
      "Epoch 00124: val_loss did not improve from 0.04119\n",
      "40200/40200 [==============================] - 5s 116us/sample - loss: 0.0750 - acc: 0.9756 - val_loss: 0.0446 - val_acc: 0.9873\n",
      "Epoch 125/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.0711 - acc: 0.9771\n",
      "Epoch 00125: val_loss improved from 0.04119 to 0.04098, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_3_conv_checkpoint/125-0.0410.hdf5\n",
      "40200/40200 [==============================] - 5s 117us/sample - loss: 0.0709 - acc: 0.9771 - val_loss: 0.0410 - val_acc: 0.9871\n",
      "Epoch 126/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.0717 - acc: 0.9771\n",
      "Epoch 00126: val_loss did not improve from 0.04098\n",
      "40200/40200 [==============================] - 5s 114us/sample - loss: 0.0723 - acc: 0.9770 - val_loss: 0.0418 - val_acc: 0.9877\n",
      "Epoch 127/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.0693 - acc: 0.9778\n",
      "Epoch 00127: val_loss did not improve from 0.04098\n",
      "40200/40200 [==============================] - 5s 115us/sample - loss: 0.0693 - acc: 0.9778 - val_loss: 0.0429 - val_acc: 0.9873\n",
      "Epoch 128/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.0700 - acc: 0.9778\n",
      "Epoch 00128: val_loss improved from 0.04098 to 0.04077, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_3_conv_checkpoint/128-0.0408.hdf5\n",
      "40200/40200 [==============================] - 5s 117us/sample - loss: 0.0700 - acc: 0.9778 - val_loss: 0.0408 - val_acc: 0.9882\n",
      "Epoch 129/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.0706 - acc: 0.9780\n",
      "Epoch 00129: val_loss did not improve from 0.04077\n",
      "40200/40200 [==============================] - 5s 116us/sample - loss: 0.0708 - acc: 0.9779 - val_loss: 0.0430 - val_acc: 0.9876\n",
      "Epoch 130/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.0707 - acc: 0.9766\n",
      "Epoch 00130: val_loss did not improve from 0.04077\n",
      "40200/40200 [==============================] - 5s 118us/sample - loss: 0.0705 - acc: 0.9767 - val_loss: 0.0423 - val_acc: 0.9875\n",
      "Epoch 131/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.0729 - acc: 0.9766\n",
      "Epoch 00131: val_loss did not improve from 0.04077\n",
      "40200/40200 [==============================] - 5s 114us/sample - loss: 0.0729 - acc: 0.9766 - val_loss: 0.0409 - val_acc: 0.9878\n",
      "Epoch 132/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.0676 - acc: 0.9780\n",
      "Epoch 00132: val_loss did not improve from 0.04077\n",
      "40200/40200 [==============================] - 5s 116us/sample - loss: 0.0673 - acc: 0.9781 - val_loss: 0.0413 - val_acc: 0.9872\n",
      "Epoch 133/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.0683 - acc: 0.9778\n",
      "Epoch 00133: val_loss did not improve from 0.04077\n",
      "40200/40200 [==============================] - 5s 121us/sample - loss: 0.0684 - acc: 0.9778 - val_loss: 0.0414 - val_acc: 0.9876\n",
      "Epoch 134/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.0663 - acc: 0.9785\n",
      "Epoch 00134: val_loss did not improve from 0.04077\n",
      "40200/40200 [==============================] - 5s 116us/sample - loss: 0.0662 - acc: 0.9785 - val_loss: 0.0422 - val_acc: 0.9873\n",
      "Epoch 135/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.0682 - acc: 0.9782\n",
      "Epoch 00135: val_loss did not improve from 0.04077\n",
      "40200/40200 [==============================] - 5s 118us/sample - loss: 0.0682 - acc: 0.9782 - val_loss: 0.0414 - val_acc: 0.9873\n",
      "Epoch 136/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.0675 - acc: 0.9779\n",
      "Epoch 00136: val_loss did not improve from 0.04077\n",
      "40200/40200 [==============================] - 5s 124us/sample - loss: 0.0674 - acc: 0.9779 - val_loss: 0.0421 - val_acc: 0.9877\n",
      "Epoch 137/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.0719 - acc: 0.9771\n",
      "Epoch 00137: val_loss did not improve from 0.04077\n",
      "40200/40200 [==============================] - 5s 125us/sample - loss: 0.0721 - acc: 0.9770 - val_loss: 0.0416 - val_acc: 0.9877\n",
      "Epoch 138/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.0677 - acc: 0.9780\n",
      "Epoch 00138: val_loss did not improve from 0.04077\n",
      "40200/40200 [==============================] - 5s 125us/sample - loss: 0.0677 - acc: 0.9780 - val_loss: 0.0413 - val_acc: 0.9874\n",
      "Epoch 139/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.0713 - acc: 0.9769\n",
      "Epoch 00139: val_loss improved from 0.04077 to 0.04052, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_3_conv_checkpoint/139-0.0405.hdf5\n",
      "40200/40200 [==============================] - 5s 125us/sample - loss: 0.0712 - acc: 0.9769 - val_loss: 0.0405 - val_acc: 0.9874\n",
      "Epoch 140/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.0679 - acc: 0.9779\n",
      "Epoch 00140: val_loss did not improve from 0.04052\n",
      "40200/40200 [==============================] - 5s 125us/sample - loss: 0.0679 - acc: 0.9779 - val_loss: 0.0420 - val_acc: 0.9872\n",
      "Epoch 141/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.0676 - acc: 0.9778\n",
      "Epoch 00141: val_loss improved from 0.04052 to 0.03988, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_3_conv_checkpoint/141-0.0399.hdf5\n",
      "40200/40200 [==============================] - 5s 127us/sample - loss: 0.0675 - acc: 0.9779 - val_loss: 0.0399 - val_acc: 0.9884\n",
      "Epoch 142/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.0687 - acc: 0.9783\n",
      "Epoch 00142: val_loss did not improve from 0.03988\n",
      "40200/40200 [==============================] - 5s 124us/sample - loss: 0.0686 - acc: 0.9784 - val_loss: 0.0407 - val_acc: 0.9881\n",
      "Epoch 143/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.0665 - acc: 0.9793\n",
      "Epoch 00143: val_loss did not improve from 0.03988\n",
      "40200/40200 [==============================] - 5s 125us/sample - loss: 0.0665 - acc: 0.9793 - val_loss: 0.0405 - val_acc: 0.9881\n",
      "Epoch 144/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.0675 - acc: 0.9785\n",
      "Epoch 00144: val_loss did not improve from 0.03988\n",
      "40200/40200 [==============================] - 5s 124us/sample - loss: 0.0674 - acc: 0.9785 - val_loss: 0.0405 - val_acc: 0.9878\n",
      "Epoch 145/500\n",
      "39744/40200 [============================>.] - ETA: 0s - loss: 0.0625 - acc: 0.9795\n",
      "Epoch 00145: val_loss did not improve from 0.03988\n",
      "40200/40200 [==============================] - 5s 126us/sample - loss: 0.0624 - acc: 0.9796 - val_loss: 0.0404 - val_acc: 0.9883\n",
      "Epoch 146/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.0645 - acc: 0.9791\n",
      "Epoch 00146: val_loss did not improve from 0.03988\n",
      "40200/40200 [==============================] - 5s 118us/sample - loss: 0.0644 - acc: 0.9791 - val_loss: 0.0408 - val_acc: 0.9880\n",
      "Epoch 147/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.0638 - acc: 0.9792\n",
      "Epoch 00147: val_loss did not improve from 0.03988\n",
      "40200/40200 [==============================] - 5s 119us/sample - loss: 0.0637 - acc: 0.9792 - val_loss: 0.0422 - val_acc: 0.9872\n",
      "Epoch 148/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.0654 - acc: 0.9786\n",
      "Epoch 00148: val_loss did not improve from 0.03988\n",
      "40200/40200 [==============================] - 5s 125us/sample - loss: 0.0654 - acc: 0.9786 - val_loss: 0.0403 - val_acc: 0.9878\n",
      "Epoch 149/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.0673 - acc: 0.9781\n",
      "Epoch 00149: val_loss did not improve from 0.03988\n",
      "40200/40200 [==============================] - 5s 125us/sample - loss: 0.0672 - acc: 0.9782 - val_loss: 0.0405 - val_acc: 0.9880\n",
      "Epoch 150/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.0691 - acc: 0.9775\n",
      "Epoch 00150: val_loss did not improve from 0.03988\n",
      "40200/40200 [==============================] - 5s 125us/sample - loss: 0.0690 - acc: 0.9776 - val_loss: 0.0420 - val_acc: 0.9878\n",
      "Epoch 151/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.0660 - acc: 0.9795\n",
      "Epoch 00151: val_loss did not improve from 0.03988\n",
      "40200/40200 [==============================] - 5s 125us/sample - loss: 0.0660 - acc: 0.9795 - val_loss: 0.0454 - val_acc: 0.9868\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 152/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.0633 - acc: 0.9798\n",
      "Epoch 00152: val_loss did not improve from 0.03988\n",
      "40200/40200 [==============================] - 5s 125us/sample - loss: 0.0640 - acc: 0.9796 - val_loss: 0.0434 - val_acc: 0.9879\n",
      "Epoch 153/500\n",
      "39744/40200 [============================>.] - ETA: 0s - loss: 0.0635 - acc: 0.9799\n",
      "Epoch 00153: val_loss did not improve from 0.03988\n",
      "40200/40200 [==============================] - 5s 126us/sample - loss: 0.0635 - acc: 0.9799 - val_loss: 0.0416 - val_acc: 0.9878\n",
      "Epoch 154/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.0632 - acc: 0.9793\n",
      "Epoch 00154: val_loss did not improve from 0.03988\n",
      "40200/40200 [==============================] - 5s 125us/sample - loss: 0.0635 - acc: 0.9793 - val_loss: 0.0409 - val_acc: 0.9883\n",
      "Epoch 155/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.0638 - acc: 0.9799\n",
      "Epoch 00155: val_loss did not improve from 0.03988\n",
      "40200/40200 [==============================] - 5s 124us/sample - loss: 0.0643 - acc: 0.9798 - val_loss: 0.0420 - val_acc: 0.9877\n",
      "Epoch 156/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.0651 - acc: 0.9791\n",
      "Epoch 00156: val_loss did not improve from 0.03988\n",
      "40200/40200 [==============================] - 5s 124us/sample - loss: 0.0650 - acc: 0.9792 - val_loss: 0.0405 - val_acc: 0.9881\n",
      "Epoch 157/500\n",
      "39744/40200 [============================>.] - ETA: 0s - loss: 0.0582 - acc: 0.9808\n",
      "Epoch 00157: val_loss did not improve from 0.03988\n",
      "40200/40200 [==============================] - 5s 126us/sample - loss: 0.0582 - acc: 0.9808 - val_loss: 0.0418 - val_acc: 0.9879\n",
      "Epoch 158/500\n",
      "39680/40200 [============================>.] - ETA: 0s - loss: 0.0640 - acc: 0.9795\n",
      "Epoch 00158: val_loss did not improve from 0.03988\n",
      "40200/40200 [==============================] - 5s 118us/sample - loss: 0.0639 - acc: 0.9796 - val_loss: 0.0409 - val_acc: 0.9879\n",
      "Epoch 159/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.0626 - acc: 0.9795\n",
      "Epoch 00159: val_loss did not improve from 0.03988\n",
      "40200/40200 [==============================] - 5s 119us/sample - loss: 0.0627 - acc: 0.9794 - val_loss: 0.0403 - val_acc: 0.9882\n",
      "Epoch 160/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.0612 - acc: 0.9799\n",
      "Epoch 00160: val_loss did not improve from 0.03988\n",
      "40200/40200 [==============================] - 5s 126us/sample - loss: 0.0615 - acc: 0.9798 - val_loss: 0.0411 - val_acc: 0.9883\n",
      "Epoch 161/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.0636 - acc: 0.9789\n",
      "Epoch 00161: val_loss did not improve from 0.03988\n",
      "40200/40200 [==============================] - 5s 125us/sample - loss: 0.0635 - acc: 0.9790 - val_loss: 0.0438 - val_acc: 0.9865\n",
      "Epoch 162/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.0612 - acc: 0.9804\n",
      "Epoch 00162: val_loss did not improve from 0.03988\n",
      "40200/40200 [==============================] - 5s 125us/sample - loss: 0.0614 - acc: 0.9804 - val_loss: 0.0434 - val_acc: 0.9883\n",
      "Epoch 163/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.0600 - acc: 0.9807\n",
      "Epoch 00163: val_loss did not improve from 0.03988\n",
      "40200/40200 [==============================] - 5s 126us/sample - loss: 0.0599 - acc: 0.9807 - val_loss: 0.0442 - val_acc: 0.9874\n",
      "Epoch 164/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.0607 - acc: 0.9798\n",
      "Epoch 00164: val_loss did not improve from 0.03988\n",
      "40200/40200 [==============================] - 5s 125us/sample - loss: 0.0606 - acc: 0.9798 - val_loss: 0.0424 - val_acc: 0.9883\n",
      "Epoch 165/500\n",
      "39744/40200 [============================>.] - ETA: 0s - loss: 0.0615 - acc: 0.9804\n",
      "Epoch 00165: val_loss did not improve from 0.03988\n",
      "40200/40200 [==============================] - 5s 126us/sample - loss: 0.0617 - acc: 0.9803 - val_loss: 0.0410 - val_acc: 0.9881\n",
      "Epoch 166/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.0614 - acc: 0.9798\n",
      "Epoch 00166: val_loss did not improve from 0.03988\n",
      "40200/40200 [==============================] - 5s 126us/sample - loss: 0.0612 - acc: 0.9799 - val_loss: 0.0415 - val_acc: 0.9880\n",
      "Epoch 167/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.0642 - acc: 0.9795\n",
      "Epoch 00167: val_loss improved from 0.03988 to 0.03916, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_3_conv_checkpoint/167-0.0392.hdf5\n",
      "40200/40200 [==============================] - 5s 125us/sample - loss: 0.0642 - acc: 0.9795 - val_loss: 0.0392 - val_acc: 0.9885\n",
      "Epoch 168/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.0575 - acc: 0.9816\n",
      "Epoch 00168: val_loss did not improve from 0.03916\n",
      "40200/40200 [==============================] - 5s 125us/sample - loss: 0.0577 - acc: 0.9815 - val_loss: 0.0413 - val_acc: 0.9878\n",
      "Epoch 169/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.0583 - acc: 0.9806\n",
      "Epoch 00169: val_loss did not improve from 0.03916\n",
      "40200/40200 [==============================] - 5s 126us/sample - loss: 0.0589 - acc: 0.9805 - val_loss: 0.0421 - val_acc: 0.9882\n",
      "Epoch 170/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.0633 - acc: 0.9801\n",
      "Epoch 00170: val_loss did not improve from 0.03916\n",
      "40200/40200 [==============================] - 5s 118us/sample - loss: 0.0632 - acc: 0.9801 - val_loss: 0.0398 - val_acc: 0.9883\n",
      "Epoch 171/500\n",
      "39744/40200 [============================>.] - ETA: 0s - loss: 0.0611 - acc: 0.9800\n",
      "Epoch 00171: val_loss did not improve from 0.03916\n",
      "40200/40200 [==============================] - 5s 120us/sample - loss: 0.0612 - acc: 0.9799 - val_loss: 0.0397 - val_acc: 0.9883\n",
      "Epoch 172/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.0608 - acc: 0.9805\n",
      "Epoch 00172: val_loss did not improve from 0.03916\n",
      "40200/40200 [==============================] - 5s 125us/sample - loss: 0.0610 - acc: 0.9804 - val_loss: 0.0410 - val_acc: 0.9883\n",
      "Epoch 173/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.0613 - acc: 0.9806\n",
      "Epoch 00173: val_loss did not improve from 0.03916\n",
      "40200/40200 [==============================] - 5s 126us/sample - loss: 0.0613 - acc: 0.9805 - val_loss: 0.0430 - val_acc: 0.9876\n",
      "Epoch 174/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.0610 - acc: 0.9803\n",
      "Epoch 00174: val_loss improved from 0.03916 to 0.03900, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_3_conv_checkpoint/174-0.0390.hdf5\n",
      "40200/40200 [==============================] - 5s 125us/sample - loss: 0.0610 - acc: 0.9803 - val_loss: 0.0390 - val_acc: 0.9882\n",
      "Epoch 175/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.0564 - acc: 0.9819\n",
      "Epoch 00175: val_loss did not improve from 0.03900\n",
      "40200/40200 [==============================] - 5s 125us/sample - loss: 0.0566 - acc: 0.9819 - val_loss: 0.0401 - val_acc: 0.9879\n",
      "Epoch 176/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.0607 - acc: 0.9812\n",
      "Epoch 00176: val_loss did not improve from 0.03900\n",
      "40200/40200 [==============================] - 5s 125us/sample - loss: 0.0606 - acc: 0.9812 - val_loss: 0.0418 - val_acc: 0.9878\n",
      "Epoch 177/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.0581 - acc: 0.9815\n",
      "Epoch 00177: val_loss did not improve from 0.03900\n",
      "40200/40200 [==============================] - 5s 125us/sample - loss: 0.0580 - acc: 0.9815 - val_loss: 0.0396 - val_acc: 0.9881\n",
      "Epoch 178/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.0591 - acc: 0.9805\n",
      "Epoch 00178: val_loss did not improve from 0.03900\n",
      "40200/40200 [==============================] - 5s 125us/sample - loss: 0.0591 - acc: 0.9804 - val_loss: 0.0429 - val_acc: 0.9879\n",
      "Epoch 179/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.0584 - acc: 0.9814\n",
      "Epoch 00179: val_loss improved from 0.03900 to 0.03877, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_3_conv_checkpoint/179-0.0388.hdf5\n",
      "40200/40200 [==============================] - 5s 127us/sample - loss: 0.0584 - acc: 0.9814 - val_loss: 0.0388 - val_acc: 0.9888\n",
      "Epoch 180/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.0591 - acc: 0.9814\n",
      "Epoch 00180: val_loss did not improve from 0.03877\n",
      "40200/40200 [==============================] - 5s 126us/sample - loss: 0.0591 - acc: 0.9813 - val_loss: 0.0405 - val_acc: 0.9884\n",
      "Epoch 181/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.0587 - acc: 0.9810\n",
      "Epoch 00181: val_loss did not improve from 0.03877\n",
      "40200/40200 [==============================] - 5s 121us/sample - loss: 0.0585 - acc: 0.9811 - val_loss: 0.0394 - val_acc: 0.9886\n",
      "Epoch 182/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.0567 - acc: 0.9810\n",
      "Epoch 00182: val_loss did not improve from 0.03877\n",
      "40200/40200 [==============================] - 5s 115us/sample - loss: 0.0567 - acc: 0.9810 - val_loss: 0.0432 - val_acc: 0.9882\n",
      "Epoch 183/500\n",
      "39744/40200 [============================>.] - ETA: 0s - loss: 0.0605 - acc: 0.9802\n",
      "Epoch 00183: val_loss did not improve from 0.03877\n",
      "40200/40200 [==============================] - 5s 124us/sample - loss: 0.0604 - acc: 0.9802 - val_loss: 0.0396 - val_acc: 0.9889\n",
      "Epoch 184/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.0568 - acc: 0.9815\n",
      "Epoch 00184: val_loss did not improve from 0.03877\n",
      "40200/40200 [==============================] - 5s 125us/sample - loss: 0.0568 - acc: 0.9815 - val_loss: 0.0399 - val_acc: 0.9886\n",
      "Epoch 185/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.0583 - acc: 0.9810\n",
      "Epoch 00185: val_loss did not improve from 0.03877\n",
      "40200/40200 [==============================] - 5s 124us/sample - loss: 0.0581 - acc: 0.9811 - val_loss: 0.0399 - val_acc: 0.9881\n",
      "Epoch 186/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.0570 - acc: 0.9818\n",
      "Epoch 00186: val_loss did not improve from 0.03877\n",
      "40200/40200 [==============================] - 5s 125us/sample - loss: 0.0570 - acc: 0.9818 - val_loss: 0.0389 - val_acc: 0.9890\n",
      "Epoch 187/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.0580 - acc: 0.9810\n",
      "Epoch 00187: val_loss did not improve from 0.03877\n",
      "40200/40200 [==============================] - 5s 126us/sample - loss: 0.0579 - acc: 0.9810 - val_loss: 0.0406 - val_acc: 0.9884\n",
      "Epoch 188/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.0564 - acc: 0.9813\n",
      "Epoch 00188: val_loss did not improve from 0.03877\n",
      "40200/40200 [==============================] - 5s 124us/sample - loss: 0.0564 - acc: 0.9813 - val_loss: 0.0427 - val_acc: 0.9874\n",
      "Epoch 189/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.0580 - acc: 0.9806\n",
      "Epoch 00189: val_loss did not improve from 0.03877\n",
      "40200/40200 [==============================] - 5s 125us/sample - loss: 0.0577 - acc: 0.9807 - val_loss: 0.0402 - val_acc: 0.9886\n",
      "Epoch 190/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.0553 - acc: 0.9824\n",
      "Epoch 00190: val_loss did not improve from 0.03877\n",
      "40200/40200 [==============================] - 5s 126us/sample - loss: 0.0552 - acc: 0.9824 - val_loss: 0.0405 - val_acc: 0.9880\n",
      "Epoch 191/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.0565 - acc: 0.9811\n",
      "Epoch 00191: val_loss did not improve from 0.03877\n",
      "40200/40200 [==============================] - 5s 126us/sample - loss: 0.0565 - acc: 0.9811 - val_loss: 0.0398 - val_acc: 0.9882\n",
      "Epoch 192/500\n",
      "39744/40200 [============================>.] - ETA: 0s - loss: 0.0551 - acc: 0.9823\n",
      "Epoch 00192: val_loss did not improve from 0.03877\n",
      "40200/40200 [==============================] - 5s 125us/sample - loss: 0.0549 - acc: 0.9823 - val_loss: 0.0410 - val_acc: 0.9884\n",
      "Epoch 193/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.0572 - acc: 0.9820\n",
      "Epoch 00193: val_loss did not improve from 0.03877\n",
      "40200/40200 [==============================] - 5s 118us/sample - loss: 0.0578 - acc: 0.9818 - val_loss: 0.0413 - val_acc: 0.9885\n",
      "Epoch 194/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.0575 - acc: 0.9821\n",
      "Epoch 00194: val_loss did not improve from 0.03877\n",
      "40200/40200 [==============================] - 5s 116us/sample - loss: 0.0573 - acc: 0.9821 - val_loss: 0.0398 - val_acc: 0.9891\n",
      "Epoch 195/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.0615 - acc: 0.9806\n",
      "Epoch 00195: val_loss did not improve from 0.03877\n",
      "40200/40200 [==============================] - 5s 125us/sample - loss: 0.0615 - acc: 0.9806 - val_loss: 0.0393 - val_acc: 0.9888\n",
      "Epoch 196/500\n",
      "39744/40200 [============================>.] - ETA: 0s - loss: 0.0569 - acc: 0.9812\n",
      "Epoch 00196: val_loss did not improve from 0.03877\n",
      "40200/40200 [==============================] - 5s 127us/sample - loss: 0.0572 - acc: 0.9812 - val_loss: 0.0410 - val_acc: 0.9885\n",
      "Epoch 197/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.0550 - acc: 0.9823\n",
      "Epoch 00197: val_loss did not improve from 0.03877\n",
      "40200/40200 [==============================] - 5s 124us/sample - loss: 0.0549 - acc: 0.9823 - val_loss: 0.0388 - val_acc: 0.9887\n",
      "Epoch 198/500\n",
      "39744/40200 [============================>.] - ETA: 0s - loss: 0.0557 - acc: 0.9816\n",
      "Epoch 00198: val_loss did not improve from 0.03877\n",
      "40200/40200 [==============================] - 5s 126us/sample - loss: 0.0557 - acc: 0.9815 - val_loss: 0.0403 - val_acc: 0.9884\n",
      "Epoch 199/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.0556 - acc: 0.9807\n",
      "Epoch 00199: val_loss did not improve from 0.03877\n",
      "40200/40200 [==============================] - 5s 124us/sample - loss: 0.0557 - acc: 0.9806 - val_loss: 0.0416 - val_acc: 0.9883\n",
      "Epoch 200/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.0560 - acc: 0.9819\n",
      "Epoch 00200: val_loss did not improve from 0.03877\n",
      "40200/40200 [==============================] - 5s 127us/sample - loss: 0.0560 - acc: 0.9819 - val_loss: 0.0404 - val_acc: 0.9883\n",
      "Epoch 201/500\n",
      "39744/40200 [============================>.] - ETA: 0s - loss: 0.0545 - acc: 0.9826\n",
      "Epoch 00201: val_loss did not improve from 0.03877\n",
      "40200/40200 [==============================] - 5s 125us/sample - loss: 0.0548 - acc: 0.9825 - val_loss: 0.0402 - val_acc: 0.9884\n",
      "Epoch 202/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.0546 - acc: 0.9811\n",
      "Epoch 00202: val_loss did not improve from 0.03877\n",
      "40200/40200 [==============================] - 5s 125us/sample - loss: 0.0544 - acc: 0.9812 - val_loss: 0.0418 - val_acc: 0.9881\n",
      "Epoch 203/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.0547 - acc: 0.9823\n",
      "Epoch 00203: val_loss did not improve from 0.03877\n",
      "40200/40200 [==============================] - 5s 125us/sample - loss: 0.0546 - acc: 0.9823 - val_loss: 0.0424 - val_acc: 0.9887\n",
      "Epoch 204/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.0542 - acc: 0.9824\n",
      "Epoch 00204: val_loss did not improve from 0.03877\n",
      "40200/40200 [==============================] - 5s 124us/sample - loss: 0.0542 - acc: 0.9824 - val_loss: 0.0406 - val_acc: 0.9884\n",
      "Epoch 205/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.0551 - acc: 0.9825\n",
      "Epoch 00205: val_loss did not improve from 0.03877\n",
      "40200/40200 [==============================] - 5s 121us/sample - loss: 0.0552 - acc: 0.9825 - val_loss: 0.0408 - val_acc: 0.9885\n",
      "Epoch 206/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.0524 - acc: 0.9819\n",
      "Epoch 00206: val_loss did not improve from 0.03877\n",
      "40200/40200 [==============================] - 5s 114us/sample - loss: 0.0524 - acc: 0.9820 - val_loss: 0.0413 - val_acc: 0.9884\n",
      "Epoch 207/500\n",
      "39744/40200 [============================>.] - ETA: 0s - loss: 0.0553 - acc: 0.9813\n",
      "Epoch 00207: val_loss did not improve from 0.03877\n",
      "40200/40200 [==============================] - 5s 121us/sample - loss: 0.0551 - acc: 0.9813 - val_loss: 0.0393 - val_acc: 0.9884\n",
      "Epoch 208/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.0535 - acc: 0.9832\n",
      "Epoch 00208: val_loss did not improve from 0.03877\n",
      "40200/40200 [==============================] - 5s 126us/sample - loss: 0.0535 - acc: 0.9832 - val_loss: 0.0412 - val_acc: 0.9885\n",
      "Epoch 209/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.0536 - acc: 0.9828\n",
      "Epoch 00209: val_loss did not improve from 0.03877\n",
      "40200/40200 [==============================] - 5s 125us/sample - loss: 0.0537 - acc: 0.9828 - val_loss: 0.0410 - val_acc: 0.9882\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 210/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.0524 - acc: 0.9825\n",
      "Epoch 00210: val_loss did not improve from 0.03877\n",
      "40200/40200 [==============================] - 5s 124us/sample - loss: 0.0522 - acc: 0.9826 - val_loss: 0.0419 - val_acc: 0.9881\n",
      "Epoch 211/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.0550 - acc: 0.9824\n",
      "Epoch 00211: val_loss did not improve from 0.03877\n",
      "40200/40200 [==============================] - 5s 126us/sample - loss: 0.0547 - acc: 0.9825 - val_loss: 0.0406 - val_acc: 0.9888\n",
      "Epoch 212/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.0529 - acc: 0.9826\n",
      "Epoch 00212: val_loss did not improve from 0.03877\n",
      "40200/40200 [==============================] - 5s 122us/sample - loss: 0.0531 - acc: 0.9825 - val_loss: 0.0404 - val_acc: 0.9884\n",
      "Epoch 213/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.0516 - acc: 0.9831\n",
      "Epoch 00213: val_loss did not improve from 0.03877\n",
      "40200/40200 [==============================] - 5s 126us/sample - loss: 0.0517 - acc: 0.9831 - val_loss: 0.0415 - val_acc: 0.9888\n",
      "Epoch 214/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.0523 - acc: 0.9839\n",
      "Epoch 00214: val_loss did not improve from 0.03877\n",
      "40200/40200 [==============================] - 5s 125us/sample - loss: 0.0523 - acc: 0.9839 - val_loss: 0.0397 - val_acc: 0.9889\n",
      "Epoch 215/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.0550 - acc: 0.9819\n",
      "Epoch 00215: val_loss did not improve from 0.03877\n",
      "40200/40200 [==============================] - 5s 124us/sample - loss: 0.0552 - acc: 0.9819 - val_loss: 0.0413 - val_acc: 0.9883\n",
      "Epoch 216/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.0540 - acc: 0.9826\n",
      "Epoch 00216: val_loss improved from 0.03877 to 0.03852, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_3_conv_checkpoint/216-0.0385.hdf5\n",
      "40200/40200 [==============================] - 5s 125us/sample - loss: 0.0538 - acc: 0.9827 - val_loss: 0.0385 - val_acc: 0.9886\n",
      "Epoch 217/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.0547 - acc: 0.9818\n",
      "Epoch 00217: val_loss did not improve from 0.03852\n",
      "40200/40200 [==============================] - 5s 125us/sample - loss: 0.0551 - acc: 0.9817 - val_loss: 0.0394 - val_acc: 0.9889\n",
      "Epoch 218/500\n",
      "39680/40200 [============================>.] - ETA: 0s - loss: 0.0499 - acc: 0.9835\n",
      "Epoch 00218: val_loss did not improve from 0.03852\n",
      "40200/40200 [==============================] - 5s 116us/sample - loss: 0.0501 - acc: 0.9834 - val_loss: 0.0418 - val_acc: 0.9879\n",
      "Epoch 219/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.0533 - acc: 0.9824\n",
      "Epoch 00219: val_loss did not improve from 0.03852\n",
      "40200/40200 [==============================] - 5s 121us/sample - loss: 0.0532 - acc: 0.9824 - val_loss: 0.0422 - val_acc: 0.9880\n",
      "Epoch 220/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.0516 - acc: 0.9829\n",
      "Epoch 00220: val_loss did not improve from 0.03852\n",
      "40200/40200 [==============================] - 5s 125us/sample - loss: 0.0516 - acc: 0.9829 - val_loss: 0.0428 - val_acc: 0.9882\n",
      "Epoch 221/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.0542 - acc: 0.9831\n",
      "Epoch 00221: val_loss did not improve from 0.03852\n",
      "40200/40200 [==============================] - 5s 126us/sample - loss: 0.0541 - acc: 0.9831 - val_loss: 0.0402 - val_acc: 0.9885\n",
      "Epoch 222/500\n",
      "39744/40200 [============================>.] - ETA: 0s - loss: 0.0560 - acc: 0.9819\n",
      "Epoch 00222: val_loss did not improve from 0.03852\n",
      "40200/40200 [==============================] - 5s 124us/sample - loss: 0.0561 - acc: 0.9819 - val_loss: 0.0386 - val_acc: 0.9895\n",
      "Epoch 223/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.0517 - acc: 0.9827\n",
      "Epoch 00223: val_loss did not improve from 0.03852\n",
      "40200/40200 [==============================] - 5s 118us/sample - loss: 0.0517 - acc: 0.9827 - val_loss: 0.0405 - val_acc: 0.9885\n",
      "Epoch 224/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.0537 - acc: 0.9824\n",
      "Epoch 00224: val_loss did not improve from 0.03852\n",
      "40200/40200 [==============================] - 5s 117us/sample - loss: 0.0537 - acc: 0.9825 - val_loss: 0.0398 - val_acc: 0.9889\n",
      "Epoch 225/500\n",
      "39680/40200 [============================>.] - ETA: 0s - loss: 0.0525 - acc: 0.9831\n",
      "Epoch 00225: val_loss did not improve from 0.03852\n",
      "40200/40200 [==============================] - 5s 118us/sample - loss: 0.0525 - acc: 0.9831 - val_loss: 0.0403 - val_acc: 0.9888\n",
      "Epoch 226/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.0533 - acc: 0.9824\n",
      "Epoch 00226: val_loss did not improve from 0.03852\n",
      "40200/40200 [==============================] - 5s 116us/sample - loss: 0.0533 - acc: 0.9824 - val_loss: 0.0394 - val_acc: 0.9888\n",
      "Epoch 227/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.0512 - acc: 0.9834\n",
      "Epoch 00227: val_loss did not improve from 0.03852\n",
      "40200/40200 [==============================] - 5s 119us/sample - loss: 0.0512 - acc: 0.9835 - val_loss: 0.0425 - val_acc: 0.9877\n",
      "Epoch 228/500\n",
      "39744/40200 [============================>.] - ETA: 0s - loss: 0.0523 - acc: 0.9831\n",
      "Epoch 00228: val_loss did not improve from 0.03852\n",
      "40200/40200 [==============================] - 5s 116us/sample - loss: 0.0525 - acc: 0.9831 - val_loss: 0.0439 - val_acc: 0.9873\n",
      "Epoch 229/500\n",
      "39744/40200 [============================>.] - ETA: 0s - loss: 0.0500 - acc: 0.9843\n",
      "Epoch 00229: val_loss did not improve from 0.03852\n",
      "40200/40200 [==============================] - 5s 116us/sample - loss: 0.0503 - acc: 0.9842 - val_loss: 0.0398 - val_acc: 0.9885\n",
      "Epoch 230/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.0498 - acc: 0.9828\n",
      "Epoch 00230: val_loss did not improve from 0.03852\n",
      "40200/40200 [==============================] - 5s 113us/sample - loss: 0.0499 - acc: 0.9828 - val_loss: 0.0391 - val_acc: 0.9884\n",
      "Epoch 231/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.0491 - acc: 0.9836\n",
      "Epoch 00231: val_loss did not improve from 0.03852\n",
      "40200/40200 [==============================] - 5s 114us/sample - loss: 0.0491 - acc: 0.9836 - val_loss: 0.0407 - val_acc: 0.9883\n",
      "Epoch 232/500\n",
      "39680/40200 [============================>.] - ETA: 0s - loss: 0.0513 - acc: 0.9833\n",
      "Epoch 00232: val_loss did not improve from 0.03852\n",
      "40200/40200 [==============================] - 5s 116us/sample - loss: 0.0511 - acc: 0.9833 - val_loss: 0.0439 - val_acc: 0.9873\n",
      "Epoch 233/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.0516 - acc: 0.9827\n",
      "Epoch 00233: val_loss did not improve from 0.03852\n",
      "40200/40200 [==============================] - 5s 117us/sample - loss: 0.0516 - acc: 0.9827 - val_loss: 0.0400 - val_acc: 0.9885\n",
      "Epoch 234/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.0519 - acc: 0.9830\n",
      "Epoch 00234: val_loss did not improve from 0.03852\n",
      "40200/40200 [==============================] - 5s 117us/sample - loss: 0.0521 - acc: 0.9829 - val_loss: 0.0401 - val_acc: 0.9882\n",
      "Epoch 235/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.0511 - acc: 0.9843\n",
      "Epoch 00235: val_loss did not improve from 0.03852\n",
      "40200/40200 [==============================] - 5s 116us/sample - loss: 0.0508 - acc: 0.9844 - val_loss: 0.0405 - val_acc: 0.9887\n",
      "Epoch 236/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.0478 - acc: 0.9841\n",
      "Epoch 00236: val_loss did not improve from 0.03852\n",
      "40200/40200 [==============================] - 5s 116us/sample - loss: 0.0478 - acc: 0.9841 - val_loss: 0.0411 - val_acc: 0.9884\n",
      "Epoch 237/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.0517 - acc: 0.9831\n",
      "Epoch 00237: val_loss did not improve from 0.03852\n",
      "40200/40200 [==============================] - 5s 115us/sample - loss: 0.0516 - acc: 0.9831 - val_loss: 0.0403 - val_acc: 0.9888\n",
      "Epoch 238/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.0511 - acc: 0.9828\n",
      "Epoch 00238: val_loss did not improve from 0.03852\n",
      "40200/40200 [==============================] - 5s 117us/sample - loss: 0.0509 - acc: 0.9829 - val_loss: 0.0396 - val_acc: 0.9890\n",
      "Epoch 239/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.0499 - acc: 0.9840\n",
      "Epoch 00239: val_loss did not improve from 0.03852\n",
      "40200/40200 [==============================] - 5s 115us/sample - loss: 0.0498 - acc: 0.9841 - val_loss: 0.0398 - val_acc: 0.9888\n",
      "Epoch 240/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.0503 - acc: 0.9841\n",
      "Epoch 00240: val_loss did not improve from 0.03852\n",
      "40200/40200 [==============================] - 5s 118us/sample - loss: 0.0504 - acc: 0.9840 - val_loss: 0.0389 - val_acc: 0.9886\n",
      "Epoch 241/500\n",
      "39744/40200 [============================>.] - ETA: 0s - loss: 0.0512 - acc: 0.9832\n",
      "Epoch 00241: val_loss did not improve from 0.03852\n",
      "40200/40200 [==============================] - 5s 116us/sample - loss: 0.0513 - acc: 0.9831 - val_loss: 0.0417 - val_acc: 0.9882\n",
      "Epoch 242/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.0513 - acc: 0.9834\n",
      "Epoch 00242: val_loss did not improve from 0.03852\n",
      "40200/40200 [==============================] - 5s 115us/sample - loss: 0.0511 - acc: 0.9834 - val_loss: 0.0397 - val_acc: 0.9888\n",
      "Epoch 243/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.0503 - acc: 0.9832\n",
      "Epoch 00243: val_loss did not improve from 0.03852\n",
      "40200/40200 [==============================] - 5s 122us/sample - loss: 0.0502 - acc: 0.9833 - val_loss: 0.0400 - val_acc: 0.9885\n",
      "Epoch 244/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.0501 - acc: 0.9839\n",
      "Epoch 00244: val_loss did not improve from 0.03852\n",
      "40200/40200 [==============================] - 5s 115us/sample - loss: 0.0503 - acc: 0.9838 - val_loss: 0.0407 - val_acc: 0.9889\n",
      "Epoch 245/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.0523 - acc: 0.9825\n",
      "Epoch 00245: val_loss did not improve from 0.03852\n",
      "40200/40200 [==============================] - 5s 125us/sample - loss: 0.0522 - acc: 0.9826 - val_loss: 0.0395 - val_acc: 0.9885\n",
      "Epoch 246/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.0503 - acc: 0.9834\n",
      "Epoch 00246: val_loss did not improve from 0.03852\n",
      "40200/40200 [==============================] - 5s 126us/sample - loss: 0.0503 - acc: 0.9834 - val_loss: 0.0417 - val_acc: 0.9886\n",
      "Epoch 247/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.0481 - acc: 0.9847\n",
      "Epoch 00247: val_loss did not improve from 0.03852\n",
      "40200/40200 [==============================] - 5s 125us/sample - loss: 0.0480 - acc: 0.9847 - val_loss: 0.0400 - val_acc: 0.9889\n",
      "Epoch 248/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.0471 - acc: 0.9842\n",
      "Epoch 00248: val_loss did not improve from 0.03852\n",
      "40200/40200 [==============================] - 5s 125us/sample - loss: 0.0472 - acc: 0.9842 - val_loss: 0.0407 - val_acc: 0.9885\n",
      "Epoch 249/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.0479 - acc: 0.9845\n",
      "Epoch 00249: val_loss did not improve from 0.03852\n",
      "40200/40200 [==============================] - 5s 126us/sample - loss: 0.0479 - acc: 0.9846 - val_loss: 0.0405 - val_acc: 0.9886\n",
      "Epoch 250/500\n",
      "39744/40200 [============================>.] - ETA: 0s - loss: 0.0506 - acc: 0.9836\n",
      "Epoch 00250: val_loss did not improve from 0.03852\n",
      "40200/40200 [==============================] - 5s 124us/sample - loss: 0.0512 - acc: 0.9835 - val_loss: 0.0387 - val_acc: 0.9888\n",
      "Epoch 251/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.0505 - acc: 0.9835\n",
      "Epoch 00251: val_loss did not improve from 0.03852\n",
      "40200/40200 [==============================] - 5s 121us/sample - loss: 0.0504 - acc: 0.9835 - val_loss: 0.0395 - val_acc: 0.9890\n",
      "Epoch 252/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.0467 - acc: 0.9837\n",
      "Epoch 00252: val_loss did not improve from 0.03852\n",
      "40200/40200 [==============================] - 5s 122us/sample - loss: 0.0467 - acc: 0.9837 - val_loss: 0.0440 - val_acc: 0.9884\n",
      "Epoch 253/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.0486 - acc: 0.9836\n",
      "Epoch 00253: val_loss did not improve from 0.03852\n",
      "40200/40200 [==============================] - 5s 121us/sample - loss: 0.0486 - acc: 0.9836 - val_loss: 0.0401 - val_acc: 0.9891\n",
      "Epoch 254/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.0489 - acc: 0.9841\n",
      "Epoch 00254: val_loss did not improve from 0.03852\n",
      "40200/40200 [==============================] - 5s 124us/sample - loss: 0.0489 - acc: 0.9841 - val_loss: 0.0394 - val_acc: 0.9892\n",
      "Epoch 255/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.0498 - acc: 0.9847\n",
      "Epoch 00255: val_loss did not improve from 0.03852\n",
      "40200/40200 [==============================] - 5s 126us/sample - loss: 0.0499 - acc: 0.9847 - val_loss: 0.0403 - val_acc: 0.9885\n",
      "Epoch 256/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.0487 - acc: 0.9841\n",
      "Epoch 00256: val_loss did not improve from 0.03852\n",
      "40200/40200 [==============================] - 5s 126us/sample - loss: 0.0487 - acc: 0.9841 - val_loss: 0.0419 - val_acc: 0.9888\n",
      "Epoch 257/500\n",
      "39744/40200 [============================>.] - ETA: 0s - loss: 0.0490 - acc: 0.9831\n",
      "Epoch 00257: val_loss did not improve from 0.03852\n",
      "40200/40200 [==============================] - 5s 125us/sample - loss: 0.0491 - acc: 0.9831 - val_loss: 0.0408 - val_acc: 0.9892\n",
      "Epoch 258/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.0476 - acc: 0.9844\n",
      "Epoch 00258: val_loss did not improve from 0.03852\n",
      "40200/40200 [==============================] - 5s 124us/sample - loss: 0.0476 - acc: 0.9844 - val_loss: 0.0407 - val_acc: 0.9885\n",
      "Epoch 259/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.0503 - acc: 0.9837\n",
      "Epoch 00259: val_loss improved from 0.03852 to 0.03786, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_3_conv_checkpoint/259-0.0379.hdf5\n",
      "40200/40200 [==============================] - 5s 126us/sample - loss: 0.0502 - acc: 0.9837 - val_loss: 0.0379 - val_acc: 0.9890\n",
      "Epoch 260/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.0481 - acc: 0.9836\n",
      "Epoch 00260: val_loss did not improve from 0.03786\n",
      "40200/40200 [==============================] - 5s 121us/sample - loss: 0.0480 - acc: 0.9837 - val_loss: 0.0381 - val_acc: 0.9892\n",
      "Epoch 261/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.0495 - acc: 0.9846\n",
      "Epoch 00261: val_loss did not improve from 0.03786\n",
      "40200/40200 [==============================] - 5s 115us/sample - loss: 0.0494 - acc: 0.9847 - val_loss: 0.0401 - val_acc: 0.9887\n",
      "Epoch 262/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.0526 - acc: 0.9832\n",
      "Epoch 00262: val_loss did not improve from 0.03786\n",
      "40200/40200 [==============================] - 5s 124us/sample - loss: 0.0526 - acc: 0.9832 - val_loss: 0.0383 - val_acc: 0.9888\n",
      "Epoch 263/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.0507 - acc: 0.9834\n",
      "Epoch 00263: val_loss did not improve from 0.03786\n",
      "40200/40200 [==============================] - 5s 126us/sample - loss: 0.0508 - acc: 0.9834 - val_loss: 0.0395 - val_acc: 0.9890\n",
      "Epoch 264/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.0493 - acc: 0.9840\n",
      "Epoch 00264: val_loss did not improve from 0.03786\n",
      "40200/40200 [==============================] - 5s 125us/sample - loss: 0.0493 - acc: 0.9840 - val_loss: 0.0386 - val_acc: 0.9890\n",
      "Epoch 265/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.0468 - acc: 0.9848\n",
      "Epoch 00265: val_loss did not improve from 0.03786\n",
      "40200/40200 [==============================] - 5s 125us/sample - loss: 0.0467 - acc: 0.9848 - val_loss: 0.0405 - val_acc: 0.9887\n",
      "Epoch 266/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.0491 - acc: 0.9838\n",
      "Epoch 00266: val_loss did not improve from 0.03786\n",
      "40200/40200 [==============================] - 5s 125us/sample - loss: 0.0491 - acc: 0.9838 - val_loss: 0.0410 - val_acc: 0.9890\n",
      "Epoch 267/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.0475 - acc: 0.9844\n",
      "Epoch 00267: val_loss did not improve from 0.03786\n",
      "40200/40200 [==============================] - 5s 125us/sample - loss: 0.0477 - acc: 0.9844 - val_loss: 0.0387 - val_acc: 0.9885\n",
      "Epoch 268/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.0482 - acc: 0.9845\n",
      "Epoch 00268: val_loss did not improve from 0.03786\n",
      "40200/40200 [==============================] - 5s 125us/sample - loss: 0.0483 - acc: 0.9846 - val_loss: 0.0399 - val_acc: 0.9886\n",
      "Epoch 269/500\n",
      "39744/40200 [============================>.] - ETA: 0s - loss: 0.0495 - acc: 0.9838\n",
      "Epoch 00269: val_loss did not improve from 0.03786\n",
      "40200/40200 [==============================] - 5s 125us/sample - loss: 0.0495 - acc: 0.9838 - val_loss: 0.0405 - val_acc: 0.9885\n",
      "Epoch 270/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.0468 - acc: 0.9848\n",
      "Epoch 00270: val_loss did not improve from 0.03786\n",
      "40200/40200 [==============================] - 5s 125us/sample - loss: 0.0468 - acc: 0.9848 - val_loss: 0.0384 - val_acc: 0.9893\n",
      "Epoch 271/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.0464 - acc: 0.9845\n",
      "Epoch 00271: val_loss did not improve from 0.03786\n",
      "40200/40200 [==============================] - 5s 124us/sample - loss: 0.0464 - acc: 0.9845 - val_loss: 0.0399 - val_acc: 0.9890\n",
      "Epoch 272/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.0500 - acc: 0.9832\n",
      "Epoch 00272: val_loss did not improve from 0.03786\n",
      "40200/40200 [==============================] - 5s 125us/sample - loss: 0.0500 - acc: 0.9832 - val_loss: 0.0395 - val_acc: 0.9886\n",
      "Epoch 273/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.0456 - acc: 0.9850\n",
      "Epoch 00273: val_loss did not improve from 0.03786\n",
      "40200/40200 [==============================] - 5s 124us/sample - loss: 0.0457 - acc: 0.9850 - val_loss: 0.0395 - val_acc: 0.9888\n",
      "Epoch 274/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.0492 - acc: 0.9840\n",
      "Epoch 00274: val_loss did not improve from 0.03786\n",
      "40200/40200 [==============================] - 5s 125us/sample - loss: 0.0492 - acc: 0.9841 - val_loss: 0.0405 - val_acc: 0.9886\n",
      "Epoch 275/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.0491 - acc: 0.9841\n",
      "Epoch 00275: val_loss did not improve from 0.03786\n",
      "40200/40200 [==============================] - 5s 124us/sample - loss: 0.0490 - acc: 0.9842 - val_loss: 0.0403 - val_acc: 0.9886\n",
      "Epoch 276/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.0473 - acc: 0.9845\n",
      "Epoch 00276: val_loss did not improve from 0.03786\n",
      "40200/40200 [==============================] - 5s 125us/sample - loss: 0.0472 - acc: 0.9845 - val_loss: 0.0380 - val_acc: 0.9892\n",
      "Epoch 277/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.0460 - acc: 0.9845\n",
      "Epoch 00277: val_loss did not improve from 0.03786\n",
      "40200/40200 [==============================] - 5s 125us/sample - loss: 0.0460 - acc: 0.9846 - val_loss: 0.0391 - val_acc: 0.9890\n",
      "Epoch 278/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.0496 - acc: 0.9838\n",
      "Epoch 00278: val_loss did not improve from 0.03786\n",
      "40200/40200 [==============================] - 5s 126us/sample - loss: 0.0495 - acc: 0.9839 - val_loss: 0.0403 - val_acc: 0.9887\n",
      "Epoch 279/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.0468 - acc: 0.9843\n",
      "Epoch 00279: val_loss did not improve from 0.03786\n",
      "40200/40200 [==============================] - 5s 125us/sample - loss: 0.0468 - acc: 0.9843 - val_loss: 0.0432 - val_acc: 0.9883\n",
      "Epoch 280/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.0461 - acc: 0.9852\n",
      "Epoch 00280: val_loss did not improve from 0.03786\n",
      "40200/40200 [==============================] - 5s 124us/sample - loss: 0.0461 - acc: 0.9851 - val_loss: 0.0409 - val_acc: 0.9883\n",
      "Epoch 281/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.0472 - acc: 0.9849\n",
      "Epoch 00281: val_loss did not improve from 0.03786\n",
      "40200/40200 [==============================] - 5s 125us/sample - loss: 0.0473 - acc: 0.9849 - val_loss: 0.0421 - val_acc: 0.9883\n",
      "Epoch 282/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.0445 - acc: 0.9850\n",
      "Epoch 00282: val_loss did not improve from 0.03786\n",
      "40200/40200 [==============================] - 5s 125us/sample - loss: 0.0446 - acc: 0.9851 - val_loss: 0.0417 - val_acc: 0.9887\n",
      "Epoch 283/500\n",
      "39744/40200 [============================>.] - ETA: 0s - loss: 0.0469 - acc: 0.9848\n",
      "Epoch 00283: val_loss did not improve from 0.03786\n",
      "40200/40200 [==============================] - 5s 125us/sample - loss: 0.0468 - acc: 0.9849 - val_loss: 0.0438 - val_acc: 0.9883\n",
      "Epoch 284/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.0478 - acc: 0.9838\n",
      "Epoch 00284: val_loss did not improve from 0.03786\n",
      "40200/40200 [==============================] - 5s 125us/sample - loss: 0.0477 - acc: 0.9838 - val_loss: 0.0409 - val_acc: 0.9881\n",
      "Epoch 285/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.0461 - acc: 0.9848\n",
      "Epoch 00285: val_loss did not improve from 0.03786\n",
      "40200/40200 [==============================] - 5s 125us/sample - loss: 0.0459 - acc: 0.9849 - val_loss: 0.0406 - val_acc: 0.9889\n",
      "Epoch 286/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.0456 - acc: 0.9849\n",
      "Epoch 00286: val_loss did not improve from 0.03786\n",
      "40200/40200 [==============================] - 5s 125us/sample - loss: 0.0453 - acc: 0.9850 - val_loss: 0.0419 - val_acc: 0.9889\n",
      "Epoch 287/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.0466 - acc: 0.9849\n",
      "Epoch 00287: val_loss did not improve from 0.03786\n",
      "40200/40200 [==============================] - 5s 125us/sample - loss: 0.0466 - acc: 0.9849 - val_loss: 0.0440 - val_acc: 0.9877\n",
      "Epoch 288/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.0464 - acc: 0.9850\n",
      "Epoch 00288: val_loss did not improve from 0.03786\n",
      "40200/40200 [==============================] - 5s 123us/sample - loss: 0.0464 - acc: 0.9850 - val_loss: 0.0388 - val_acc: 0.9892\n",
      "Epoch 289/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.0467 - acc: 0.9840\n",
      "Epoch 00289: val_loss did not improve from 0.03786\n",
      "40200/40200 [==============================] - 5s 126us/sample - loss: 0.0469 - acc: 0.9839 - val_loss: 0.0399 - val_acc: 0.9885\n",
      "Epoch 290/500\n",
      "39680/40200 [============================>.] - ETA: 0s - loss: 0.0483 - acc: 0.9845\n",
      "Epoch 00290: val_loss did not improve from 0.03786\n",
      "40200/40200 [==============================] - 5s 124us/sample - loss: 0.0481 - acc: 0.9845 - val_loss: 0.0398 - val_acc: 0.9886\n",
      "Epoch 291/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.0479 - acc: 0.9849\n",
      "Epoch 00291: val_loss did not improve from 0.03786\n",
      "40200/40200 [==============================] - 5s 126us/sample - loss: 0.0479 - acc: 0.9849 - val_loss: 0.0422 - val_acc: 0.9885\n",
      "Epoch 292/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.0480 - acc: 0.9840\n",
      "Epoch 00292: val_loss did not improve from 0.03786\n",
      "40200/40200 [==============================] - 5s 124us/sample - loss: 0.0482 - acc: 0.9839 - val_loss: 0.0393 - val_acc: 0.9891\n",
      "Epoch 293/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.0486 - acc: 0.9841\n",
      "Epoch 00293: val_loss did not improve from 0.03786\n",
      "40200/40200 [==============================] - 5s 126us/sample - loss: 0.0487 - acc: 0.9841 - val_loss: 0.0407 - val_acc: 0.9887\n",
      "Epoch 294/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.0445 - acc: 0.9856\n",
      "Epoch 00294: val_loss did not improve from 0.03786\n",
      "40200/40200 [==============================] - 5s 125us/sample - loss: 0.0448 - acc: 0.9855 - val_loss: 0.0386 - val_acc: 0.9894\n",
      "Epoch 295/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.0456 - acc: 0.9843\n",
      "Epoch 00295: val_loss did not improve from 0.03786\n",
      "40200/40200 [==============================] - 5s 126us/sample - loss: 0.0455 - acc: 0.9843 - val_loss: 0.0439 - val_acc: 0.9883\n",
      "Epoch 296/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.0461 - acc: 0.9851\n",
      "Epoch 00296: val_loss did not improve from 0.03786\n",
      "40200/40200 [==============================] - 5s 126us/sample - loss: 0.0460 - acc: 0.9851 - val_loss: 0.0392 - val_acc: 0.9891\n",
      "Epoch 297/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.0451 - acc: 0.9854\n",
      "Epoch 00297: val_loss did not improve from 0.03786\n",
      "40200/40200 [==============================] - 5s 125us/sample - loss: 0.0450 - acc: 0.9854 - val_loss: 0.0393 - val_acc: 0.9891\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 298/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.0468 - acc: 0.9849\n",
      "Epoch 00298: val_loss did not improve from 0.03786\n",
      "40200/40200 [==============================] - 5s 126us/sample - loss: 0.0467 - acc: 0.9850 - val_loss: 0.0399 - val_acc: 0.9889\n",
      "Epoch 299/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.0449 - acc: 0.9851\n",
      "Epoch 00299: val_loss did not improve from 0.03786\n",
      "40200/40200 [==============================] - 5s 124us/sample - loss: 0.0448 - acc: 0.9851 - val_loss: 0.0413 - val_acc: 0.9891\n",
      "Epoch 300/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.0451 - acc: 0.9848\n",
      "Epoch 00300: val_loss did not improve from 0.03786\n",
      "40200/40200 [==============================] - 5s 125us/sample - loss: 0.0451 - acc: 0.9848 - val_loss: 0.0411 - val_acc: 0.9887\n",
      "Epoch 301/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.0473 - acc: 0.9844\n",
      "Epoch 00301: val_loss did not improve from 0.03786\n",
      "40200/40200 [==============================] - 5s 125us/sample - loss: 0.0472 - acc: 0.9845 - val_loss: 0.0414 - val_acc: 0.9883\n",
      "Epoch 302/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.0428 - acc: 0.9856\n",
      "Epoch 00302: val_loss did not improve from 0.03786\n",
      "40200/40200 [==============================] - 5s 125us/sample - loss: 0.0428 - acc: 0.9856 - val_loss: 0.0405 - val_acc: 0.9883\n",
      "Epoch 303/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.0461 - acc: 0.9847\n",
      "Epoch 00303: val_loss did not improve from 0.03786\n",
      "40200/40200 [==============================] - 5s 125us/sample - loss: 0.0461 - acc: 0.9847 - val_loss: 0.0405 - val_acc: 0.9888\n",
      "Epoch 304/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.0460 - acc: 0.9845\n",
      "Epoch 00304: val_loss did not improve from 0.03786\n",
      "40200/40200 [==============================] - 5s 125us/sample - loss: 0.0460 - acc: 0.9844 - val_loss: 0.0407 - val_acc: 0.9882\n",
      "Epoch 305/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.0472 - acc: 0.9842\n",
      "Epoch 00305: val_loss did not improve from 0.03786\n",
      "40200/40200 [==============================] - 5s 124us/sample - loss: 0.0472 - acc: 0.9842 - val_loss: 0.0402 - val_acc: 0.9886\n",
      "Epoch 306/500\n",
      "39744/40200 [============================>.] - ETA: 0s - loss: 0.0464 - acc: 0.9852\n",
      "Epoch 00306: val_loss did not improve from 0.03786\n",
      "40200/40200 [==============================] - 5s 125us/sample - loss: 0.0465 - acc: 0.9852 - val_loss: 0.0396 - val_acc: 0.9889\n",
      "Epoch 307/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.0460 - acc: 0.9848\n",
      "Epoch 00307: val_loss improved from 0.03786 to 0.03758, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_3_conv_checkpoint/307-0.0376.hdf5\n",
      "40200/40200 [==============================] - 5s 126us/sample - loss: 0.0459 - acc: 0.9849 - val_loss: 0.0376 - val_acc: 0.9891\n",
      "Epoch 308/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.0442 - acc: 0.9855\n",
      "Epoch 00308: val_loss did not improve from 0.03758\n",
      "40200/40200 [==============================] - 5s 125us/sample - loss: 0.0443 - acc: 0.9855 - val_loss: 0.0433 - val_acc: 0.9881\n",
      "Epoch 309/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.0457 - acc: 0.9850\n",
      "Epoch 00309: val_loss did not improve from 0.03758\n",
      "40200/40200 [==============================] - 5s 125us/sample - loss: 0.0456 - acc: 0.9851 - val_loss: 0.0393 - val_acc: 0.9889\n",
      "Epoch 310/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.0448 - acc: 0.9852\n",
      "Epoch 00310: val_loss did not improve from 0.03758\n",
      "40200/40200 [==============================] - 5s 125us/sample - loss: 0.0447 - acc: 0.9853 - val_loss: 0.0393 - val_acc: 0.9888\n",
      "Epoch 311/500\n",
      "39744/40200 [============================>.] - ETA: 0s - loss: 0.0466 - acc: 0.9849\n",
      "Epoch 00311: val_loss did not improve from 0.03758\n",
      "40200/40200 [==============================] - 5s 125us/sample - loss: 0.0467 - acc: 0.9848 - val_loss: 0.0389 - val_acc: 0.9889\n",
      "Epoch 312/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.0448 - acc: 0.9862\n",
      "Epoch 00312: val_loss did not improve from 0.03758\n",
      "40200/40200 [==============================] - 5s 125us/sample - loss: 0.0448 - acc: 0.9862 - val_loss: 0.0404 - val_acc: 0.9890\n",
      "Epoch 313/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.0448 - acc: 0.9854\n",
      "Epoch 00313: val_loss did not improve from 0.03758\n",
      "40200/40200 [==============================] - 5s 125us/sample - loss: 0.0449 - acc: 0.9854 - val_loss: 0.0408 - val_acc: 0.9887\n",
      "Epoch 314/500\n",
      "39744/40200 [============================>.] - ETA: 0s - loss: 0.0441 - acc: 0.9852\n",
      "Epoch 00314: val_loss did not improve from 0.03758\n",
      "40200/40200 [==============================] - 5s 125us/sample - loss: 0.0445 - acc: 0.9851 - val_loss: 0.0426 - val_acc: 0.9887\n",
      "Epoch 315/500\n",
      "39744/40200 [============================>.] - ETA: 0s - loss: 0.0424 - acc: 0.9856\n",
      "Epoch 00315: val_loss did not improve from 0.03758\n",
      "40200/40200 [==============================] - 5s 126us/sample - loss: 0.0424 - acc: 0.9855 - val_loss: 0.0409 - val_acc: 0.9893\n",
      "Epoch 316/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.0479 - acc: 0.9843\n",
      "Epoch 00316: val_loss did not improve from 0.03758\n",
      "40200/40200 [==============================] - 5s 124us/sample - loss: 0.0478 - acc: 0.9843 - val_loss: 0.0407 - val_acc: 0.9886\n",
      "Epoch 317/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.0444 - acc: 0.9849\n",
      "Epoch 00317: val_loss did not improve from 0.03758\n",
      "40200/40200 [==============================] - 5s 126us/sample - loss: 0.0445 - acc: 0.9849 - val_loss: 0.0409 - val_acc: 0.9886\n",
      "Epoch 318/500\n",
      "39744/40200 [============================>.] - ETA: 0s - loss: 0.0468 - acc: 0.9845\n",
      "Epoch 00318: val_loss did not improve from 0.03758\n",
      "40200/40200 [==============================] - 5s 125us/sample - loss: 0.0470 - acc: 0.9845 - val_loss: 0.0383 - val_acc: 0.9889\n",
      "Epoch 319/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.0435 - acc: 0.9859\n",
      "Epoch 00319: val_loss did not improve from 0.03758\n",
      "40200/40200 [==============================] - 5s 125us/sample - loss: 0.0434 - acc: 0.9859 - val_loss: 0.0409 - val_acc: 0.9886\n",
      "Epoch 320/500\n",
      "39744/40200 [============================>.] - ETA: 0s - loss: 0.0439 - acc: 0.9852\n",
      "Epoch 00320: val_loss did not improve from 0.03758\n",
      "40200/40200 [==============================] - 5s 125us/sample - loss: 0.0437 - acc: 0.9852 - val_loss: 0.0402 - val_acc: 0.9892\n",
      "Epoch 321/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.0430 - acc: 0.9861\n",
      "Epoch 00321: val_loss did not improve from 0.03758\n",
      "40200/40200 [==============================] - 5s 125us/sample - loss: 0.0430 - acc: 0.9861 - val_loss: 0.0406 - val_acc: 0.9889\n",
      "Epoch 322/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.0455 - acc: 0.9850\n",
      "Epoch 00322: val_loss did not improve from 0.03758\n",
      "40200/40200 [==============================] - 5s 124us/sample - loss: 0.0453 - acc: 0.9850 - val_loss: 0.0408 - val_acc: 0.9890\n",
      "Epoch 323/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.0427 - acc: 0.9855\n",
      "Epoch 00323: val_loss did not improve from 0.03758\n",
      "40200/40200 [==============================] - 5s 125us/sample - loss: 0.0427 - acc: 0.9856 - val_loss: 0.0436 - val_acc: 0.9884\n",
      "Epoch 324/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.0437 - acc: 0.9855\n",
      "Epoch 00324: val_loss did not improve from 0.03758\n",
      "40200/40200 [==============================] - 5s 124us/sample - loss: 0.0437 - acc: 0.9855 - val_loss: 0.0397 - val_acc: 0.9888\n",
      "Epoch 325/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.0442 - acc: 0.9857\n",
      "Epoch 00325: val_loss did not improve from 0.03758\n",
      "40200/40200 [==============================] - 5s 123us/sample - loss: 0.0442 - acc: 0.9857 - val_loss: 0.0411 - val_acc: 0.9894\n",
      "Epoch 326/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.0459 - acc: 0.9848\n",
      "Epoch 00326: val_loss did not improve from 0.03758\n",
      "40200/40200 [==============================] - 5s 125us/sample - loss: 0.0458 - acc: 0.9849 - val_loss: 0.0414 - val_acc: 0.9891\n",
      "Epoch 327/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.0434 - acc: 0.9853\n",
      "Epoch 00327: val_loss did not improve from 0.03758\n",
      "40200/40200 [==============================] - 5s 125us/sample - loss: 0.0433 - acc: 0.9853 - val_loss: 0.0401 - val_acc: 0.9893\n",
      "Epoch 328/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.0434 - acc: 0.9859\n",
      "Epoch 00328: val_loss did not improve from 0.03758\n",
      "40200/40200 [==============================] - 5s 125us/sample - loss: 0.0435 - acc: 0.9859 - val_loss: 0.0407 - val_acc: 0.9890\n",
      "Epoch 329/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.0439 - acc: 0.9855\n",
      "Epoch 00329: val_loss did not improve from 0.03758\n",
      "40200/40200 [==============================] - 5s 124us/sample - loss: 0.0438 - acc: 0.9855 - val_loss: 0.0415 - val_acc: 0.9891\n",
      "Epoch 330/500\n",
      "39744/40200 [============================>.] - ETA: 0s - loss: 0.0452 - acc: 0.9849\n",
      "Epoch 00330: val_loss did not improve from 0.03758\n",
      "40200/40200 [==============================] - 5s 125us/sample - loss: 0.0451 - acc: 0.9849 - val_loss: 0.0413 - val_acc: 0.9889\n",
      "Epoch 331/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.0435 - acc: 0.9856\n",
      "Epoch 00331: val_loss did not improve from 0.03758\n",
      "40200/40200 [==============================] - 5s 124us/sample - loss: 0.0435 - acc: 0.9856 - val_loss: 0.0425 - val_acc: 0.9888\n",
      "Epoch 332/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.0453 - acc: 0.9851\n",
      "Epoch 00332: val_loss did not improve from 0.03758\n",
      "40200/40200 [==============================] - 5s 124us/sample - loss: 0.0453 - acc: 0.9851 - val_loss: 0.0397 - val_acc: 0.9892\n",
      "Epoch 333/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.0467 - acc: 0.9847\n",
      "Epoch 00333: val_loss did not improve from 0.03758\n",
      "40200/40200 [==============================] - 5s 124us/sample - loss: 0.0465 - acc: 0.9848 - val_loss: 0.0396 - val_acc: 0.9888\n",
      "Epoch 334/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.0435 - acc: 0.9857\n",
      "Epoch 00334: val_loss did not improve from 0.03758\n",
      "40200/40200 [==============================] - 5s 126us/sample - loss: 0.0435 - acc: 0.9856 - val_loss: 0.0404 - val_acc: 0.9892\n",
      "Epoch 335/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.0445 - acc: 0.9847\n",
      "Epoch 00335: val_loss did not improve from 0.03758\n",
      "40200/40200 [==============================] - 5s 124us/sample - loss: 0.0443 - acc: 0.9848 - val_loss: 0.0397 - val_acc: 0.9891\n",
      "Epoch 336/500\n",
      "39744/40200 [============================>.] - ETA: 0s - loss: 0.0419 - acc: 0.9862\n",
      "Epoch 00336: val_loss did not improve from 0.03758\n",
      "40200/40200 [==============================] - 5s 126us/sample - loss: 0.0420 - acc: 0.9862 - val_loss: 0.0413 - val_acc: 0.9890\n",
      "Epoch 337/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.0432 - acc: 0.9857\n",
      "Epoch 00337: val_loss did not improve from 0.03758\n",
      "40200/40200 [==============================] - 5s 126us/sample - loss: 0.0431 - acc: 0.9857 - val_loss: 0.0409 - val_acc: 0.9892\n",
      "Epoch 338/500\n",
      "39744/40200 [============================>.] - ETA: 0s - loss: 0.0438 - acc: 0.9858\n",
      "Epoch 00338: val_loss did not improve from 0.03758\n",
      "40200/40200 [==============================] - 5s 125us/sample - loss: 0.0439 - acc: 0.9858 - val_loss: 0.0407 - val_acc: 0.9891\n",
      "Epoch 339/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.0431 - acc: 0.9859\n",
      "Epoch 00339: val_loss did not improve from 0.03758\n",
      "40200/40200 [==============================] - 5s 124us/sample - loss: 0.0431 - acc: 0.9859 - val_loss: 0.0408 - val_acc: 0.9890\n",
      "Epoch 340/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.0424 - acc: 0.9856\n",
      "Epoch 00340: val_loss did not improve from 0.03758\n",
      "40200/40200 [==============================] - 5s 126us/sample - loss: 0.0426 - acc: 0.9855 - val_loss: 0.0406 - val_acc: 0.9893\n",
      "Epoch 341/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.0432 - acc: 0.9856\n",
      "Epoch 00341: val_loss did not improve from 0.03758\n",
      "40200/40200 [==============================] - 5s 124us/sample - loss: 0.0432 - acc: 0.9856 - val_loss: 0.0394 - val_acc: 0.9889\n",
      "Epoch 342/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.0440 - acc: 0.9856\n",
      "Epoch 00342: val_loss did not improve from 0.03758\n",
      "40200/40200 [==============================] - 5s 125us/sample - loss: 0.0443 - acc: 0.9855 - val_loss: 0.0411 - val_acc: 0.9890\n",
      "Epoch 343/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.0441 - acc: 0.9849\n",
      "Epoch 00343: val_loss did not improve from 0.03758\n",
      "40200/40200 [==============================] - 5s 124us/sample - loss: 0.0443 - acc: 0.9848 - val_loss: 0.0387 - val_acc: 0.9895\n",
      "Epoch 344/500\n",
      "39744/40200 [============================>.] - ETA: 0s - loss: 0.0446 - acc: 0.9855\n",
      "Epoch 00344: val_loss did not improve from 0.03758\n",
      "40200/40200 [==============================] - 5s 125us/sample - loss: 0.0444 - acc: 0.9856 - val_loss: 0.0393 - val_acc: 0.9896\n",
      "Epoch 345/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.0440 - acc: 0.9859\n",
      "Epoch 00345: val_loss did not improve from 0.03758\n",
      "40200/40200 [==============================] - 5s 125us/sample - loss: 0.0442 - acc: 0.9859 - val_loss: 0.0427 - val_acc: 0.9894\n",
      "Epoch 346/500\n",
      "39744/40200 [============================>.] - ETA: 0s - loss: 0.0434 - acc: 0.9854\n",
      "Epoch 00346: val_loss did not improve from 0.03758\n",
      "40200/40200 [==============================] - 5s 124us/sample - loss: 0.0436 - acc: 0.9854 - val_loss: 0.0417 - val_acc: 0.9887\n",
      "Epoch 347/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.0434 - acc: 0.9855\n",
      "Epoch 00347: val_loss did not improve from 0.03758\n",
      "40200/40200 [==============================] - 5s 125us/sample - loss: 0.0436 - acc: 0.9854 - val_loss: 0.0421 - val_acc: 0.9887\n",
      "Epoch 348/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.0428 - acc: 0.9861\n",
      "Epoch 00348: val_loss did not improve from 0.03758\n",
      "40200/40200 [==============================] - 5s 126us/sample - loss: 0.0426 - acc: 0.9862 - val_loss: 0.0400 - val_acc: 0.9888\n",
      "Epoch 349/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.0438 - acc: 0.9858\n",
      "Epoch 00349: val_loss did not improve from 0.03758\n",
      "40200/40200 [==============================] - 5s 126us/sample - loss: 0.0438 - acc: 0.9858 - val_loss: 0.0406 - val_acc: 0.9893\n",
      "Epoch 350/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.0428 - acc: 0.9857\n",
      "Epoch 00350: val_loss did not improve from 0.03758\n",
      "40200/40200 [==============================] - 5s 124us/sample - loss: 0.0428 - acc: 0.9857 - val_loss: 0.0408 - val_acc: 0.9894\n",
      "Epoch 351/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.0424 - acc: 0.9859\n",
      "Epoch 00351: val_loss did not improve from 0.03758\n",
      "40200/40200 [==============================] - 5s 124us/sample - loss: 0.0423 - acc: 0.9859 - val_loss: 0.0403 - val_acc: 0.9890\n",
      "Epoch 352/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.0420 - acc: 0.9866\n",
      "Epoch 00352: val_loss did not improve from 0.03758\n",
      "40200/40200 [==============================] - 5s 125us/sample - loss: 0.0419 - acc: 0.9866 - val_loss: 0.0423 - val_acc: 0.9892\n",
      "Epoch 353/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.0420 - acc: 0.9863\n",
      "Epoch 00353: val_loss did not improve from 0.03758\n",
      "40200/40200 [==============================] - 5s 125us/sample - loss: 0.0420 - acc: 0.9863 - val_loss: 0.0414 - val_acc: 0.9893\n",
      "Epoch 354/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.0401 - acc: 0.9860\n",
      "Epoch 00354: val_loss did not improve from 0.03758\n",
      "40200/40200 [==============================] - 5s 124us/sample - loss: 0.0401 - acc: 0.9860 - val_loss: 0.0432 - val_acc: 0.9889\n",
      "Epoch 355/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.0447 - acc: 0.9849\n",
      "Epoch 00355: val_loss did not improve from 0.03758\n",
      "40200/40200 [==============================] - 5s 125us/sample - loss: 0.0448 - acc: 0.9848 - val_loss: 0.0389 - val_acc: 0.9894\n",
      "Epoch 356/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.0438 - acc: 0.9858\n",
      "Epoch 00356: val_loss did not improve from 0.03758\n",
      "40200/40200 [==============================] - 5s 124us/sample - loss: 0.0438 - acc: 0.9858 - val_loss: 0.0419 - val_acc: 0.9890\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 357/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.0433 - acc: 0.9853\n",
      "Epoch 00357: val_loss did not improve from 0.03758\n",
      "40200/40200 [==============================] - 5s 125us/sample - loss: 0.0434 - acc: 0.9853 - val_loss: 0.0433 - val_acc: 0.9887\n",
      "\n",
      "vis_2D_CNN_custom_ch_16_DO_075_DO_3_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 96us/sample - loss: 0.0316 - acc: 0.9902\n",
      "Loss: 0.031557436333539954 Accuracy: 0.9902\n",
      "\n",
      "Train on 40200 samples, validate on 19800 samples\n",
      "Epoch 1/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 8.4968 - acc: 0.1652\n",
      "Epoch 00001: val_loss improved from inf to 1.76053, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_4_conv_checkpoint/001-1.7605.hdf5\n",
      "40200/40200 [==============================] - 7s 185us/sample - loss: 8.4954 - acc: 0.1652 - val_loss: 1.7605 - val_acc: 0.4536\n",
      "Epoch 2/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 1.8937 - acc: 0.3259\n",
      "Epoch 00002: val_loss improved from 1.76053 to 1.24486, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_4_conv_checkpoint/002-1.2449.hdf5\n",
      "40200/40200 [==============================] - 6s 143us/sample - loss: 1.8936 - acc: 0.3259 - val_loss: 1.2449 - val_acc: 0.6651\n",
      "Epoch 3/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 1.5869 - acc: 0.4459\n",
      "Epoch 00003: val_loss improved from 1.24486 to 0.86630, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_4_conv_checkpoint/003-0.8663.hdf5\n",
      "40200/40200 [==============================] - 6s 143us/sample - loss: 1.5861 - acc: 0.4463 - val_loss: 0.8663 - val_acc: 0.7868\n",
      "Epoch 4/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 1.3327 - acc: 0.5439\n",
      "Epoch 00004: val_loss improved from 0.86630 to 0.63186, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_4_conv_checkpoint/004-0.6319.hdf5\n",
      "40200/40200 [==============================] - 6s 142us/sample - loss: 1.3323 - acc: 0.5442 - val_loss: 0.6319 - val_acc: 0.8616\n",
      "Epoch 5/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 1.1456 - acc: 0.6096\n",
      "Epoch 00005: val_loss improved from 0.63186 to 0.45145, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_4_conv_checkpoint/005-0.4514.hdf5\n",
      "40200/40200 [==============================] - 6s 141us/sample - loss: 1.1451 - acc: 0.6096 - val_loss: 0.4514 - val_acc: 0.8908\n",
      "Epoch 6/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 1.0086 - acc: 0.6590\n",
      "Epoch 00006: val_loss improved from 0.45145 to 0.38538, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_4_conv_checkpoint/006-0.3854.hdf5\n",
      "40200/40200 [==============================] - 6s 141us/sample - loss: 1.0078 - acc: 0.6591 - val_loss: 0.3854 - val_acc: 0.9088\n",
      "Epoch 7/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.9099 - acc: 0.6941\n",
      "Epoch 00007: val_loss improved from 0.38538 to 0.31881, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_4_conv_checkpoint/007-0.3188.hdf5\n",
      "40200/40200 [==============================] - 6s 141us/sample - loss: 0.9098 - acc: 0.6941 - val_loss: 0.3188 - val_acc: 0.9210\n",
      "Epoch 8/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.8205 - acc: 0.7282\n",
      "Epoch 00008: val_loss improved from 0.31881 to 0.26833, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_4_conv_checkpoint/008-0.2683.hdf5\n",
      "40200/40200 [==============================] - 6s 141us/sample - loss: 0.8206 - acc: 0.7284 - val_loss: 0.2683 - val_acc: 0.9313\n",
      "Epoch 9/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.7546 - acc: 0.7505\n",
      "Epoch 00009: val_loss improved from 0.26833 to 0.24157, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_4_conv_checkpoint/009-0.2416.hdf5\n",
      "40200/40200 [==============================] - 6s 141us/sample - loss: 0.7539 - acc: 0.7507 - val_loss: 0.2416 - val_acc: 0.9365\n",
      "Epoch 10/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.7000 - acc: 0.7699\n",
      "Epoch 00010: val_loss improved from 0.24157 to 0.21444, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_4_conv_checkpoint/010-0.2144.hdf5\n",
      "40200/40200 [==============================] - 6s 141us/sample - loss: 0.6993 - acc: 0.7700 - val_loss: 0.2144 - val_acc: 0.9426\n",
      "Epoch 11/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.6469 - acc: 0.7858\n",
      "Epoch 00011: val_loss improved from 0.21444 to 0.19580, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_4_conv_checkpoint/011-0.1958.hdf5\n",
      "40200/40200 [==============================] - 6s 141us/sample - loss: 0.6470 - acc: 0.7858 - val_loss: 0.1958 - val_acc: 0.9487\n",
      "Epoch 12/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.6001 - acc: 0.8023\n",
      "Epoch 00012: val_loss improved from 0.19580 to 0.18144, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_4_conv_checkpoint/012-0.1814.hdf5\n",
      "40200/40200 [==============================] - 6s 142us/sample - loss: 0.5994 - acc: 0.8026 - val_loss: 0.1814 - val_acc: 0.9514\n",
      "Epoch 13/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.5644 - acc: 0.8104\n",
      "Epoch 00013: val_loss improved from 0.18144 to 0.16811, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_4_conv_checkpoint/013-0.1681.hdf5\n",
      "40200/40200 [==============================] - 6s 141us/sample - loss: 0.5644 - acc: 0.8103 - val_loss: 0.1681 - val_acc: 0.9546\n",
      "Epoch 14/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.5290 - acc: 0.8249\n",
      "Epoch 00014: val_loss improved from 0.16811 to 0.15716, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_4_conv_checkpoint/014-0.1572.hdf5\n",
      "40200/40200 [==============================] - 6s 140us/sample - loss: 0.5289 - acc: 0.8249 - val_loss: 0.1572 - val_acc: 0.9559\n",
      "Epoch 15/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.5075 - acc: 0.8333\n",
      "Epoch 00015: val_loss improved from 0.15716 to 0.14845, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_4_conv_checkpoint/015-0.1485.hdf5\n",
      "40200/40200 [==============================] - 6s 141us/sample - loss: 0.5075 - acc: 0.8333 - val_loss: 0.1485 - val_acc: 0.9587\n",
      "Epoch 16/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.4718 - acc: 0.8445\n",
      "Epoch 00016: val_loss improved from 0.14845 to 0.14358, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_4_conv_checkpoint/016-0.1436.hdf5\n",
      "40200/40200 [==============================] - 6s 140us/sample - loss: 0.4715 - acc: 0.8446 - val_loss: 0.1436 - val_acc: 0.9600\n",
      "Epoch 17/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.4490 - acc: 0.8528\n",
      "Epoch 00017: val_loss improved from 0.14358 to 0.12908, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_4_conv_checkpoint/017-0.1291.hdf5\n",
      "40200/40200 [==============================] - 6s 140us/sample - loss: 0.4489 - acc: 0.8528 - val_loss: 0.1291 - val_acc: 0.9625\n",
      "Epoch 18/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.4277 - acc: 0.8618\n",
      "Epoch 00018: val_loss improved from 0.12908 to 0.12134, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_4_conv_checkpoint/018-0.1213.hdf5\n",
      "40200/40200 [==============================] - 6s 140us/sample - loss: 0.4277 - acc: 0.8618 - val_loss: 0.1213 - val_acc: 0.9651\n",
      "Epoch 19/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.4037 - acc: 0.8693\n",
      "Epoch 00019: val_loss improved from 0.12134 to 0.11743, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_4_conv_checkpoint/019-0.1174.hdf5\n",
      "40200/40200 [==============================] - 6s 140us/sample - loss: 0.4032 - acc: 0.8697 - val_loss: 0.1174 - val_acc: 0.9661\n",
      "Epoch 20/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.3853 - acc: 0.8740\n",
      "Epoch 00020: val_loss improved from 0.11743 to 0.10940, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_4_conv_checkpoint/020-0.1094.hdf5\n",
      "40200/40200 [==============================] - 6s 141us/sample - loss: 0.3854 - acc: 0.8741 - val_loss: 0.1094 - val_acc: 0.9675\n",
      "Epoch 21/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.3769 - acc: 0.8804\n",
      "Epoch 00021: val_loss did not improve from 0.10940\n",
      "40200/40200 [==============================] - 6s 139us/sample - loss: 0.3764 - acc: 0.8805 - val_loss: 0.1100 - val_acc: 0.9673\n",
      "Epoch 22/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.3451 - acc: 0.8883\n",
      "Epoch 00022: val_loss improved from 0.10940 to 0.10113, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_4_conv_checkpoint/022-0.1011.hdf5\n",
      "40200/40200 [==============================] - 6s 142us/sample - loss: 0.3450 - acc: 0.8883 - val_loss: 0.1011 - val_acc: 0.9692\n",
      "Epoch 23/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.3361 - acc: 0.8926\n",
      "Epoch 00023: val_loss did not improve from 0.10113\n",
      "40200/40200 [==============================] - 6s 139us/sample - loss: 0.3364 - acc: 0.8928 - val_loss: 0.1051 - val_acc: 0.9688\n",
      "Epoch 24/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.3241 - acc: 0.8953\n",
      "Epoch 00024: val_loss improved from 0.10113 to 0.09588, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_4_conv_checkpoint/024-0.0959.hdf5\n",
      "40200/40200 [==============================] - 6s 141us/sample - loss: 0.3241 - acc: 0.8953 - val_loss: 0.0959 - val_acc: 0.9711\n",
      "Epoch 25/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.3146 - acc: 0.9000\n",
      "Epoch 00025: val_loss improved from 0.09588 to 0.09344, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_4_conv_checkpoint/025-0.0934.hdf5\n",
      "40200/40200 [==============================] - 6s 141us/sample - loss: 0.3144 - acc: 0.9000 - val_loss: 0.0934 - val_acc: 0.9718\n",
      "Epoch 26/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.2939 - acc: 0.9057\n",
      "Epoch 00026: val_loss improved from 0.09344 to 0.09194, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_4_conv_checkpoint/026-0.0919.hdf5\n",
      "40200/40200 [==============================] - 6s 142us/sample - loss: 0.2945 - acc: 0.9056 - val_loss: 0.0919 - val_acc: 0.9714\n",
      "Epoch 27/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.2894 - acc: 0.9076\n",
      "Epoch 00027: val_loss improved from 0.09194 to 0.08756, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_4_conv_checkpoint/027-0.0876.hdf5\n",
      "40200/40200 [==============================] - 6s 140us/sample - loss: 0.2896 - acc: 0.9075 - val_loss: 0.0876 - val_acc: 0.9740\n",
      "Epoch 28/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.2786 - acc: 0.9119\n",
      "Epoch 00028: val_loss improved from 0.08756 to 0.08253, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_4_conv_checkpoint/028-0.0825.hdf5\n",
      "40200/40200 [==============================] - 6s 141us/sample - loss: 0.2783 - acc: 0.9120 - val_loss: 0.0825 - val_acc: 0.9749\n",
      "Epoch 29/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.2707 - acc: 0.9134\n",
      "Epoch 00029: val_loss did not improve from 0.08253\n",
      "40200/40200 [==============================] - 6s 140us/sample - loss: 0.2707 - acc: 0.9134 - val_loss: 0.0854 - val_acc: 0.9745\n",
      "Epoch 30/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.2567 - acc: 0.9183\n",
      "Epoch 00030: val_loss improved from 0.08253 to 0.07812, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_4_conv_checkpoint/030-0.0781.hdf5\n",
      "40200/40200 [==============================] - 6s 140us/sample - loss: 0.2570 - acc: 0.9182 - val_loss: 0.0781 - val_acc: 0.9755\n",
      "Epoch 31/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.2503 - acc: 0.9193\n",
      "Epoch 00031: val_loss did not improve from 0.07812\n",
      "40200/40200 [==============================] - 6s 141us/sample - loss: 0.2503 - acc: 0.9193 - val_loss: 0.0798 - val_acc: 0.9768\n",
      "Epoch 32/500\n",
      "39744/40200 [============================>.] - ETA: 0s - loss: 0.2523 - acc: 0.9207\n",
      "Epoch 00032: val_loss improved from 0.07812 to 0.07713, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_4_conv_checkpoint/032-0.0771.hdf5\n",
      "40200/40200 [==============================] - 6s 142us/sample - loss: 0.2520 - acc: 0.9208 - val_loss: 0.0771 - val_acc: 0.9768\n",
      "Epoch 33/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.2406 - acc: 0.9227\n",
      "Epoch 00033: val_loss improved from 0.07713 to 0.07652, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_4_conv_checkpoint/033-0.0765.hdf5\n",
      "40200/40200 [==============================] - 6s 141us/sample - loss: 0.2409 - acc: 0.9227 - val_loss: 0.0765 - val_acc: 0.9767\n",
      "Epoch 34/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.2311 - acc: 0.9267\n",
      "Epoch 00034: val_loss improved from 0.07652 to 0.07403, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_4_conv_checkpoint/034-0.0740.hdf5\n",
      "40200/40200 [==============================] - 6s 140us/sample - loss: 0.2309 - acc: 0.9267 - val_loss: 0.0740 - val_acc: 0.9786\n",
      "Epoch 35/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.2284 - acc: 0.9276\n",
      "Epoch 00035: val_loss improved from 0.07403 to 0.07356, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_4_conv_checkpoint/035-0.0736.hdf5\n",
      "40200/40200 [==============================] - 6s 140us/sample - loss: 0.2289 - acc: 0.9275 - val_loss: 0.0736 - val_acc: 0.9780\n",
      "Epoch 36/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.2218 - acc: 0.9291\n",
      "Epoch 00036: val_loss did not improve from 0.07356\n",
      "40200/40200 [==============================] - 6s 142us/sample - loss: 0.2219 - acc: 0.9291 - val_loss: 0.0736 - val_acc: 0.9785\n",
      "Epoch 37/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.2165 - acc: 0.9313\n",
      "Epoch 00037: val_loss improved from 0.07356 to 0.06974, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_4_conv_checkpoint/037-0.0697.hdf5\n",
      "40200/40200 [==============================] - 6s 142us/sample - loss: 0.2166 - acc: 0.9313 - val_loss: 0.0697 - val_acc: 0.9788\n",
      "Epoch 38/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.2130 - acc: 0.9322\n",
      "Epoch 00038: val_loss did not improve from 0.06974\n",
      "40200/40200 [==============================] - 6s 139us/sample - loss: 0.2129 - acc: 0.9323 - val_loss: 0.0701 - val_acc: 0.9792\n",
      "Epoch 39/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.2096 - acc: 0.9322\n",
      "Epoch 00039: val_loss improved from 0.06974 to 0.06822, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_4_conv_checkpoint/039-0.0682.hdf5\n",
      "40200/40200 [==============================] - 6s 142us/sample - loss: 0.2095 - acc: 0.9323 - val_loss: 0.0682 - val_acc: 0.9802\n",
      "Epoch 40/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.1997 - acc: 0.9370\n",
      "Epoch 00040: val_loss did not improve from 0.06822\n",
      "40200/40200 [==============================] - 6s 138us/sample - loss: 0.1996 - acc: 0.9370 - val_loss: 0.0693 - val_acc: 0.9796\n",
      "Epoch 41/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.1984 - acc: 0.9370\n",
      "Epoch 00041: val_loss improved from 0.06822 to 0.06629, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_4_conv_checkpoint/041-0.0663.hdf5\n",
      "40200/40200 [==============================] - 6s 140us/sample - loss: 0.1991 - acc: 0.9371 - val_loss: 0.0663 - val_acc: 0.9806\n",
      "Epoch 42/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.1896 - acc: 0.9401\n",
      "Epoch 00042: val_loss improved from 0.06629 to 0.06559, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_4_conv_checkpoint/042-0.0656.hdf5\n",
      "40200/40200 [==============================] - 6s 140us/sample - loss: 0.1898 - acc: 0.9400 - val_loss: 0.0656 - val_acc: 0.9807\n",
      "Epoch 43/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.1892 - acc: 0.9405\n",
      "Epoch 00043: val_loss improved from 0.06559 to 0.06407, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_4_conv_checkpoint/043-0.0641.hdf5\n",
      "40200/40200 [==============================] - 6s 142us/sample - loss: 0.1890 - acc: 0.9407 - val_loss: 0.0641 - val_acc: 0.9816\n",
      "Epoch 44/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.1860 - acc: 0.9419\n",
      "Epoch 00044: val_loss improved from 0.06407 to 0.06233, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_4_conv_checkpoint/044-0.0623.hdf5\n",
      "40200/40200 [==============================] - 6s 142us/sample - loss: 0.1861 - acc: 0.9419 - val_loss: 0.0623 - val_acc: 0.9816\n",
      "Epoch 45/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.1768 - acc: 0.9439\n",
      "Epoch 00045: val_loss did not improve from 0.06233\n",
      "40200/40200 [==============================] - 6s 141us/sample - loss: 0.1772 - acc: 0.9438 - val_loss: 0.0639 - val_acc: 0.9819\n",
      "Epoch 46/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.1826 - acc: 0.9441\n",
      "Epoch 00046: val_loss did not improve from 0.06233\n",
      "40200/40200 [==============================] - 6s 139us/sample - loss: 0.1827 - acc: 0.9440 - val_loss: 0.0642 - val_acc: 0.9822\n",
      "Epoch 47/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.1688 - acc: 0.9478\n",
      "Epoch 00047: val_loss did not improve from 0.06233\n",
      "40200/40200 [==============================] - 6s 140us/sample - loss: 0.1689 - acc: 0.9477 - val_loss: 0.0669 - val_acc: 0.9812\n",
      "Epoch 48/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.1656 - acc: 0.9476\n",
      "Epoch 00048: val_loss improved from 0.06233 to 0.06180, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_4_conv_checkpoint/048-0.0618.hdf5\n",
      "40200/40200 [==============================] - 6s 142us/sample - loss: 0.1654 - acc: 0.9476 - val_loss: 0.0618 - val_acc: 0.9825\n",
      "Epoch 49/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.1636 - acc: 0.9486\n",
      "Epoch 00049: val_loss did not improve from 0.06180\n",
      "40200/40200 [==============================] - 6s 141us/sample - loss: 0.1635 - acc: 0.9487 - val_loss: 0.0648 - val_acc: 0.9819\n",
      "Epoch 50/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.1587 - acc: 0.9498\n",
      "Epoch 00050: val_loss did not improve from 0.06180\n",
      "40200/40200 [==============================] - 6s 141us/sample - loss: 0.1587 - acc: 0.9498 - val_loss: 0.0646 - val_acc: 0.9823\n",
      "Epoch 51/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.1547 - acc: 0.9516\n",
      "Epoch 00051: val_loss did not improve from 0.06180\n",
      "40200/40200 [==============================] - 6s 141us/sample - loss: 0.1546 - acc: 0.9515 - val_loss: 0.0622 - val_acc: 0.9826\n",
      "Epoch 52/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.1545 - acc: 0.9527\n",
      "Epoch 00052: val_loss improved from 0.06180 to 0.06077, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_4_conv_checkpoint/052-0.0608.hdf5\n",
      "40200/40200 [==============================] - 6s 141us/sample - loss: 0.1544 - acc: 0.9527 - val_loss: 0.0608 - val_acc: 0.9825\n",
      "Epoch 53/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.1554 - acc: 0.9524\n",
      "Epoch 00053: val_loss improved from 0.06077 to 0.05853, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_4_conv_checkpoint/053-0.0585.hdf5\n",
      "40200/40200 [==============================] - 6s 141us/sample - loss: 0.1554 - acc: 0.9524 - val_loss: 0.0585 - val_acc: 0.9834\n",
      "Epoch 54/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.1489 - acc: 0.9521\n",
      "Epoch 00054: val_loss did not improve from 0.05853\n",
      "40200/40200 [==============================] - 6s 141us/sample - loss: 0.1491 - acc: 0.9520 - val_loss: 0.0598 - val_acc: 0.9831\n",
      "Epoch 55/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.1463 - acc: 0.9547\n",
      "Epoch 00055: val_loss did not improve from 0.05853\n",
      "40200/40200 [==============================] - 6s 139us/sample - loss: 0.1467 - acc: 0.9545 - val_loss: 0.0599 - val_acc: 0.9829\n",
      "Epoch 56/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.1413 - acc: 0.9563\n",
      "Epoch 00056: val_loss did not improve from 0.05853\n",
      "40200/40200 [==============================] - 6s 139us/sample - loss: 0.1414 - acc: 0.9563 - val_loss: 0.0643 - val_acc: 0.9826\n",
      "Epoch 57/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.1466 - acc: 0.9542\n",
      "Epoch 00057: val_loss improved from 0.05853 to 0.05842, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_4_conv_checkpoint/057-0.0584.hdf5\n",
      "40200/40200 [==============================] - 6s 141us/sample - loss: 0.1465 - acc: 0.9543 - val_loss: 0.0584 - val_acc: 0.9831\n",
      "Epoch 58/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.1421 - acc: 0.9560\n",
      "Epoch 00058: val_loss did not improve from 0.05842\n",
      "40200/40200 [==============================] - 6s 142us/sample - loss: 0.1420 - acc: 0.9561 - val_loss: 0.0586 - val_acc: 0.9833\n",
      "Epoch 59/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.1347 - acc: 0.9580\n",
      "Epoch 00059: val_loss improved from 0.05842 to 0.05576, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_4_conv_checkpoint/059-0.0558.hdf5\n",
      "40200/40200 [==============================] - 6s 143us/sample - loss: 0.1347 - acc: 0.9580 - val_loss: 0.0558 - val_acc: 0.9845\n",
      "Epoch 60/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.1377 - acc: 0.9578\n",
      "Epoch 00060: val_loss did not improve from 0.05576\n",
      "40200/40200 [==============================] - 6s 138us/sample - loss: 0.1374 - acc: 0.9579 - val_loss: 0.0580 - val_acc: 0.9842\n",
      "Epoch 61/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.1344 - acc: 0.9582\n",
      "Epoch 00061: val_loss did not improve from 0.05576\n",
      "40200/40200 [==============================] - 6s 141us/sample - loss: 0.1340 - acc: 0.9583 - val_loss: 0.0592 - val_acc: 0.9841\n",
      "Epoch 62/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.1341 - acc: 0.9590\n",
      "Epoch 00062: val_loss did not improve from 0.05576\n",
      "40200/40200 [==============================] - 6s 139us/sample - loss: 0.1342 - acc: 0.9590 - val_loss: 0.0581 - val_acc: 0.9841\n",
      "Epoch 63/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.1290 - acc: 0.9599\n",
      "Epoch 00063: val_loss did not improve from 0.05576\n",
      "40200/40200 [==============================] - 6s 140us/sample - loss: 0.1288 - acc: 0.9600 - val_loss: 0.0560 - val_acc: 0.9851\n",
      "Epoch 64/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.1285 - acc: 0.9588\n",
      "Epoch 00064: val_loss improved from 0.05576 to 0.05377, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_4_conv_checkpoint/064-0.0538.hdf5\n",
      "40200/40200 [==============================] - 6s 141us/sample - loss: 0.1284 - acc: 0.9589 - val_loss: 0.0538 - val_acc: 0.9847\n",
      "Epoch 65/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.1266 - acc: 0.9601\n",
      "Epoch 00065: val_loss did not improve from 0.05377\n",
      "40200/40200 [==============================] - 6s 139us/sample - loss: 0.1270 - acc: 0.9601 - val_loss: 0.0566 - val_acc: 0.9843\n",
      "Epoch 66/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.1272 - acc: 0.9606\n",
      "Epoch 00066: val_loss improved from 0.05377 to 0.05374, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_4_conv_checkpoint/066-0.0537.hdf5\n",
      "40200/40200 [==============================] - 6s 142us/sample - loss: 0.1273 - acc: 0.9606 - val_loss: 0.0537 - val_acc: 0.9854\n",
      "Epoch 67/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.1235 - acc: 0.9613\n",
      "Epoch 00067: val_loss did not improve from 0.05374\n",
      "40200/40200 [==============================] - 6s 141us/sample - loss: 0.1232 - acc: 0.9614 - val_loss: 0.0545 - val_acc: 0.9851\n",
      "Epoch 68/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.1232 - acc: 0.9619\n",
      "Epoch 00068: val_loss improved from 0.05374 to 0.05269, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_4_conv_checkpoint/068-0.0527.hdf5\n",
      "40200/40200 [==============================] - 6s 140us/sample - loss: 0.1231 - acc: 0.9619 - val_loss: 0.0527 - val_acc: 0.9850\n",
      "Epoch 69/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.1194 - acc: 0.9625\n",
      "Epoch 00069: val_loss did not improve from 0.05269\n",
      "40200/40200 [==============================] - 6s 138us/sample - loss: 0.1192 - acc: 0.9625 - val_loss: 0.0572 - val_acc: 0.9840\n",
      "Epoch 70/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.1192 - acc: 0.9623\n",
      "Epoch 00070: val_loss did not improve from 0.05269\n",
      "40200/40200 [==============================] - 6s 140us/sample - loss: 0.1192 - acc: 0.9623 - val_loss: 0.0563 - val_acc: 0.9850\n",
      "Epoch 71/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.1171 - acc: 0.9644\n",
      "Epoch 00071: val_loss improved from 0.05269 to 0.05155, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_4_conv_checkpoint/071-0.0515.hdf5\n",
      "40200/40200 [==============================] - 6s 140us/sample - loss: 0.1171 - acc: 0.9644 - val_loss: 0.0515 - val_acc: 0.9859\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.1165 - acc: 0.9632\n",
      "Epoch 00072: val_loss did not improve from 0.05155\n",
      "40200/40200 [==============================] - 6s 141us/sample - loss: 0.1165 - acc: 0.9632 - val_loss: 0.0543 - val_acc: 0.9842\n",
      "Epoch 73/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.1135 - acc: 0.9638\n",
      "Epoch 00073: val_loss improved from 0.05155 to 0.05046, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_4_conv_checkpoint/073-0.0505.hdf5\n",
      "40200/40200 [==============================] - 6s 142us/sample - loss: 0.1136 - acc: 0.9638 - val_loss: 0.0505 - val_acc: 0.9854\n",
      "Epoch 74/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.1103 - acc: 0.9662\n",
      "Epoch 00074: val_loss did not improve from 0.05046\n",
      "40200/40200 [==============================] - 6s 140us/sample - loss: 0.1109 - acc: 0.9660 - val_loss: 0.0541 - val_acc: 0.9856\n",
      "Epoch 75/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.1123 - acc: 0.9642\n",
      "Epoch 00075: val_loss did not improve from 0.05046\n",
      "40200/40200 [==============================] - 6s 139us/sample - loss: 0.1123 - acc: 0.9642 - val_loss: 0.0526 - val_acc: 0.9855\n",
      "Epoch 76/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.1060 - acc: 0.9657\n",
      "Epoch 00076: val_loss did not improve from 0.05046\n",
      "40200/40200 [==============================] - 6s 140us/sample - loss: 0.1060 - acc: 0.9656 - val_loss: 0.0517 - val_acc: 0.9855\n",
      "Epoch 77/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.1063 - acc: 0.9655\n",
      "Epoch 00077: val_loss did not improve from 0.05046\n",
      "40200/40200 [==============================] - 6s 141us/sample - loss: 0.1060 - acc: 0.9656 - val_loss: 0.0522 - val_acc: 0.9855\n",
      "Epoch 78/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.1095 - acc: 0.9655\n",
      "Epoch 00078: val_loss did not improve from 0.05046\n",
      "40200/40200 [==============================] - 6s 139us/sample - loss: 0.1098 - acc: 0.9655 - val_loss: 0.0530 - val_acc: 0.9864\n",
      "Epoch 79/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.1050 - acc: 0.9664\n",
      "Epoch 00079: val_loss did not improve from 0.05046\n",
      "40200/40200 [==============================] - 6s 139us/sample - loss: 0.1050 - acc: 0.9663 - val_loss: 0.0515 - val_acc: 0.9853\n",
      "Epoch 80/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.1054 - acc: 0.9675\n",
      "Epoch 00080: val_loss did not improve from 0.05046\n",
      "40200/40200 [==============================] - 6s 139us/sample - loss: 0.1055 - acc: 0.9675 - val_loss: 0.0530 - val_acc: 0.9856\n",
      "Epoch 81/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.1038 - acc: 0.9682\n",
      "Epoch 00081: val_loss did not improve from 0.05046\n",
      "40200/40200 [==============================] - 6s 139us/sample - loss: 0.1037 - acc: 0.9682 - val_loss: 0.0526 - val_acc: 0.9862\n",
      "Epoch 82/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.1008 - acc: 0.9686\n",
      "Epoch 00082: val_loss did not improve from 0.05046\n",
      "40200/40200 [==============================] - 6s 138us/sample - loss: 0.1007 - acc: 0.9687 - val_loss: 0.0524 - val_acc: 0.9861\n",
      "Epoch 83/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.1023 - acc: 0.9680\n",
      "Epoch 00083: val_loss did not improve from 0.05046\n",
      "40200/40200 [==============================] - 6s 140us/sample - loss: 0.1023 - acc: 0.9680 - val_loss: 0.0522 - val_acc: 0.9861\n",
      "Epoch 84/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.0979 - acc: 0.9689\n",
      "Epoch 00084: val_loss improved from 0.05046 to 0.04969, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_4_conv_checkpoint/084-0.0497.hdf5\n",
      "40200/40200 [==============================] - 6s 142us/sample - loss: 0.0981 - acc: 0.9688 - val_loss: 0.0497 - val_acc: 0.9865\n",
      "Epoch 85/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.0988 - acc: 0.9687\n",
      "Epoch 00085: val_loss did not improve from 0.04969\n",
      "40200/40200 [==============================] - 6s 141us/sample - loss: 0.0984 - acc: 0.9689 - val_loss: 0.0533 - val_acc: 0.9864\n",
      "Epoch 86/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.1039 - acc: 0.9669\n",
      "Epoch 00086: val_loss did not improve from 0.04969\n",
      "40200/40200 [==============================] - 6s 139us/sample - loss: 0.1038 - acc: 0.9669 - val_loss: 0.0510 - val_acc: 0.9865\n",
      "Epoch 87/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.0952 - acc: 0.9697\n",
      "Epoch 00087: val_loss did not improve from 0.04969\n",
      "40200/40200 [==============================] - 6s 139us/sample - loss: 0.0952 - acc: 0.9697 - val_loss: 0.0533 - val_acc: 0.9862\n",
      "Epoch 88/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.0978 - acc: 0.9684\n",
      "Epoch 00088: val_loss did not improve from 0.04969\n",
      "40200/40200 [==============================] - 6s 139us/sample - loss: 0.0981 - acc: 0.9684 - val_loss: 0.0545 - val_acc: 0.9855\n",
      "Epoch 89/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.0990 - acc: 0.9691\n",
      "Epoch 00089: val_loss did not improve from 0.04969\n",
      "40200/40200 [==============================] - 6s 140us/sample - loss: 0.0989 - acc: 0.9691 - val_loss: 0.0510 - val_acc: 0.9861\n",
      "Epoch 90/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.0944 - acc: 0.9705\n",
      "Epoch 00090: val_loss improved from 0.04969 to 0.04916, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_4_conv_checkpoint/090-0.0492.hdf5\n",
      "40200/40200 [==============================] - 6s 141us/sample - loss: 0.0942 - acc: 0.9705 - val_loss: 0.0492 - val_acc: 0.9864\n",
      "Epoch 91/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.0948 - acc: 0.9693\n",
      "Epoch 00091: val_loss did not improve from 0.04916\n",
      "40200/40200 [==============================] - 6s 139us/sample - loss: 0.0951 - acc: 0.9693 - val_loss: 0.0494 - val_acc: 0.9863\n",
      "Epoch 92/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.0921 - acc: 0.9699\n",
      "Epoch 00092: val_loss did not improve from 0.04916\n",
      "40200/40200 [==============================] - 6s 140us/sample - loss: 0.0920 - acc: 0.9699 - val_loss: 0.0505 - val_acc: 0.9863\n",
      "Epoch 93/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.0943 - acc: 0.9689\n",
      "Epoch 00093: val_loss did not improve from 0.04916\n",
      "40200/40200 [==============================] - 6s 139us/sample - loss: 0.0942 - acc: 0.9688 - val_loss: 0.0499 - val_acc: 0.9861\n",
      "Epoch 94/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.0923 - acc: 0.9707\n",
      "Epoch 00094: val_loss did not improve from 0.04916\n",
      "40200/40200 [==============================] - 6s 140us/sample - loss: 0.0921 - acc: 0.9707 - val_loss: 0.0502 - val_acc: 0.9869\n",
      "Epoch 95/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.0885 - acc: 0.9723\n",
      "Epoch 00095: val_loss improved from 0.04916 to 0.04868, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_4_conv_checkpoint/095-0.0487.hdf5\n",
      "40200/40200 [==============================] - 6s 139us/sample - loss: 0.0884 - acc: 0.9723 - val_loss: 0.0487 - val_acc: 0.9873\n",
      "Epoch 96/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.0881 - acc: 0.9711\n",
      "Epoch 00096: val_loss did not improve from 0.04868\n",
      "40200/40200 [==============================] - 6s 140us/sample - loss: 0.0880 - acc: 0.9711 - val_loss: 0.0516 - val_acc: 0.9870\n",
      "Epoch 97/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.0911 - acc: 0.9709\n",
      "Epoch 00097: val_loss did not improve from 0.04868\n",
      "40200/40200 [==============================] - 6s 138us/sample - loss: 0.0910 - acc: 0.9709 - val_loss: 0.0509 - val_acc: 0.9872\n",
      "Epoch 98/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.0855 - acc: 0.9727\n",
      "Epoch 00098: val_loss did not improve from 0.04868\n",
      "40200/40200 [==============================] - 6s 142us/sample - loss: 0.0855 - acc: 0.9727 - val_loss: 0.0525 - val_acc: 0.9870\n",
      "Epoch 99/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.0851 - acc: 0.9722\n",
      "Epoch 00099: val_loss did not improve from 0.04868\n",
      "40200/40200 [==============================] - 6s 138us/sample - loss: 0.0850 - acc: 0.9722 - val_loss: 0.0518 - val_acc: 0.9868\n",
      "Epoch 100/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.0867 - acc: 0.9727\n",
      "Epoch 00100: val_loss did not improve from 0.04868\n",
      "40200/40200 [==============================] - 6s 140us/sample - loss: 0.0870 - acc: 0.9727 - val_loss: 0.0550 - val_acc: 0.9870\n",
      "Epoch 101/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.0897 - acc: 0.9718\n",
      "Epoch 00101: val_loss improved from 0.04868 to 0.04863, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_4_conv_checkpoint/101-0.0486.hdf5\n",
      "40200/40200 [==============================] - 6s 142us/sample - loss: 0.0900 - acc: 0.9717 - val_loss: 0.0486 - val_acc: 0.9862\n",
      "Epoch 102/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.0872 - acc: 0.9718\n",
      "Epoch 00102: val_loss did not improve from 0.04863\n",
      "40200/40200 [==============================] - 6s 140us/sample - loss: 0.0869 - acc: 0.9718 - val_loss: 0.0493 - val_acc: 0.9861\n",
      "Epoch 103/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.0870 - acc: 0.9722\n",
      "Epoch 00103: val_loss did not improve from 0.04863\n",
      "40200/40200 [==============================] - 6s 140us/sample - loss: 0.0872 - acc: 0.9722 - val_loss: 0.0550 - val_acc: 0.9862\n",
      "Epoch 104/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.0808 - acc: 0.9743\n",
      "Epoch 00104: val_loss did not improve from 0.04863\n",
      "40200/40200 [==============================] - 6s 138us/sample - loss: 0.0809 - acc: 0.9744 - val_loss: 0.0562 - val_acc: 0.9868\n",
      "Epoch 105/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.0820 - acc: 0.9738\n",
      "Epoch 00105: val_loss did not improve from 0.04863\n",
      "40200/40200 [==============================] - 6s 139us/sample - loss: 0.0821 - acc: 0.9736 - val_loss: 0.0508 - val_acc: 0.9868\n",
      "Epoch 106/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.0851 - acc: 0.9715\n",
      "Epoch 00106: val_loss did not improve from 0.04863\n",
      "40200/40200 [==============================] - 6s 141us/sample - loss: 0.0848 - acc: 0.9715 - val_loss: 0.0509 - val_acc: 0.9870\n",
      "Epoch 107/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.0819 - acc: 0.9744\n",
      "Epoch 00107: val_loss improved from 0.04863 to 0.04727, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_4_conv_checkpoint/107-0.0473.hdf5\n",
      "40200/40200 [==============================] - 6s 141us/sample - loss: 0.0820 - acc: 0.9743 - val_loss: 0.0473 - val_acc: 0.9869\n",
      "Epoch 108/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.0807 - acc: 0.9737\n",
      "Epoch 00108: val_loss did not improve from 0.04727\n",
      "40200/40200 [==============================] - 6s 140us/sample - loss: 0.0804 - acc: 0.9738 - val_loss: 0.0525 - val_acc: 0.9866\n",
      "Epoch 109/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.0809 - acc: 0.9732\n",
      "Epoch 00109: val_loss did not improve from 0.04727\n",
      "40200/40200 [==============================] - 6s 140us/sample - loss: 0.0809 - acc: 0.9732 - val_loss: 0.0502 - val_acc: 0.9864\n",
      "Epoch 110/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.0797 - acc: 0.9746\n",
      "Epoch 00110: val_loss did not improve from 0.04727\n",
      "40200/40200 [==============================] - 6s 140us/sample - loss: 0.0796 - acc: 0.9746 - val_loss: 0.0484 - val_acc: 0.9873\n",
      "Epoch 111/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.0808 - acc: 0.9739\n",
      "Epoch 00111: val_loss did not improve from 0.04727\n",
      "40200/40200 [==============================] - 6s 140us/sample - loss: 0.0808 - acc: 0.9738 - val_loss: 0.0501 - val_acc: 0.9869\n",
      "Epoch 112/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.0796 - acc: 0.9745\n",
      "Epoch 00112: val_loss did not improve from 0.04727\n",
      "40200/40200 [==============================] - 6s 140us/sample - loss: 0.0796 - acc: 0.9746 - val_loss: 0.0503 - val_acc: 0.9875\n",
      "Epoch 113/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.0784 - acc: 0.9747\n",
      "Epoch 00113: val_loss did not improve from 0.04727\n",
      "40200/40200 [==============================] - 6s 141us/sample - loss: 0.0783 - acc: 0.9747 - val_loss: 0.0480 - val_acc: 0.9874\n",
      "Epoch 114/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.0811 - acc: 0.9734\n",
      "Epoch 00114: val_loss did not improve from 0.04727\n",
      "40200/40200 [==============================] - 6s 141us/sample - loss: 0.0810 - acc: 0.9734 - val_loss: 0.0501 - val_acc: 0.9877\n",
      "Epoch 115/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.0738 - acc: 0.9760\n",
      "Epoch 00115: val_loss did not improve from 0.04727\n",
      "40200/40200 [==============================] - 6s 141us/sample - loss: 0.0738 - acc: 0.9760 - val_loss: 0.0521 - val_acc: 0.9874\n",
      "Epoch 116/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.0771 - acc: 0.9749\n",
      "Epoch 00116: val_loss did not improve from 0.04727\n",
      "40200/40200 [==============================] - 6s 140us/sample - loss: 0.0767 - acc: 0.9750 - val_loss: 0.0494 - val_acc: 0.9870\n",
      "Epoch 117/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.0765 - acc: 0.9756\n",
      "Epoch 00117: val_loss did not improve from 0.04727\n",
      "40200/40200 [==============================] - 6s 139us/sample - loss: 0.0762 - acc: 0.9756 - val_loss: 0.0482 - val_acc: 0.9866\n",
      "Epoch 118/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.0762 - acc: 0.9756\n",
      "Epoch 00118: val_loss did not improve from 0.04727\n",
      "40200/40200 [==============================] - 6s 139us/sample - loss: 0.0764 - acc: 0.9756 - val_loss: 0.0525 - val_acc: 0.9871\n",
      "Epoch 119/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.0767 - acc: 0.9756\n",
      "Epoch 00119: val_loss did not improve from 0.04727\n",
      "40200/40200 [==============================] - 6s 140us/sample - loss: 0.0768 - acc: 0.9757 - val_loss: 0.0486 - val_acc: 0.9876\n",
      "Epoch 120/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.0753 - acc: 0.9758\n",
      "Epoch 00120: val_loss did not improve from 0.04727\n",
      "40200/40200 [==============================] - 6s 141us/sample - loss: 0.0755 - acc: 0.9758 - val_loss: 0.0500 - val_acc: 0.9869\n",
      "Epoch 121/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.0755 - acc: 0.9757\n",
      "Epoch 00121: val_loss did not improve from 0.04727\n",
      "40200/40200 [==============================] - 6s 138us/sample - loss: 0.0757 - acc: 0.9757 - val_loss: 0.0508 - val_acc: 0.9869\n",
      "Epoch 122/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.0731 - acc: 0.9770\n",
      "Epoch 00122: val_loss did not improve from 0.04727\n",
      "40200/40200 [==============================] - 6s 138us/sample - loss: 0.0731 - acc: 0.9770 - val_loss: 0.0496 - val_acc: 0.9875\n",
      "Epoch 123/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.0731 - acc: 0.9759\n",
      "Epoch 00123: val_loss did not improve from 0.04727\n",
      "40200/40200 [==============================] - 6s 138us/sample - loss: 0.0731 - acc: 0.9759 - val_loss: 0.0488 - val_acc: 0.9878\n",
      "Epoch 124/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.0748 - acc: 0.9751\n",
      "Epoch 00124: val_loss did not improve from 0.04727\n",
      "40200/40200 [==============================] - 6s 140us/sample - loss: 0.0751 - acc: 0.9751 - val_loss: 0.0491 - val_acc: 0.9869\n",
      "Epoch 125/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.0733 - acc: 0.9755\n",
      "Epoch 00125: val_loss did not improve from 0.04727\n",
      "40200/40200 [==============================] - 6s 139us/sample - loss: 0.0732 - acc: 0.9755 - val_loss: 0.0489 - val_acc: 0.9879\n",
      "Epoch 126/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.0709 - acc: 0.9774\n",
      "Epoch 00126: val_loss did not improve from 0.04727\n",
      "40200/40200 [==============================] - 6s 140us/sample - loss: 0.0709 - acc: 0.9774 - val_loss: 0.0514 - val_acc: 0.9866\n",
      "Epoch 127/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.0728 - acc: 0.9769\n",
      "Epoch 00127: val_loss did not improve from 0.04727\n",
      "40200/40200 [==============================] - 6s 140us/sample - loss: 0.0728 - acc: 0.9769 - val_loss: 0.0495 - val_acc: 0.9876\n",
      "Epoch 128/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.0723 - acc: 0.9765\n",
      "Epoch 00128: val_loss did not improve from 0.04727\n",
      "40200/40200 [==============================] - 6s 139us/sample - loss: 0.0723 - acc: 0.9765 - val_loss: 0.0495 - val_acc: 0.9871\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 129/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.0709 - acc: 0.9777\n",
      "Epoch 00129: val_loss did not improve from 0.04727\n",
      "40200/40200 [==============================] - 6s 139us/sample - loss: 0.0712 - acc: 0.9777 - val_loss: 0.0483 - val_acc: 0.9869\n",
      "Epoch 130/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.0727 - acc: 0.9769\n",
      "Epoch 00130: val_loss did not improve from 0.04727\n",
      "40200/40200 [==============================] - 6s 139us/sample - loss: 0.0726 - acc: 0.9770 - val_loss: 0.0527 - val_acc: 0.9874\n",
      "Epoch 131/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.0718 - acc: 0.9764\n",
      "Epoch 00131: val_loss did not improve from 0.04727\n",
      "40200/40200 [==============================] - 6s 140us/sample - loss: 0.0718 - acc: 0.9764 - val_loss: 0.0522 - val_acc: 0.9873\n",
      "Epoch 132/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.0692 - acc: 0.9779\n",
      "Epoch 00132: val_loss did not improve from 0.04727\n",
      "40200/40200 [==============================] - 6s 138us/sample - loss: 0.0695 - acc: 0.9778 - val_loss: 0.0494 - val_acc: 0.9881\n",
      "Epoch 133/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.0693 - acc: 0.9777\n",
      "Epoch 00133: val_loss did not improve from 0.04727\n",
      "40200/40200 [==============================] - 6s 141us/sample - loss: 0.0693 - acc: 0.9777 - val_loss: 0.0518 - val_acc: 0.9872\n",
      "Epoch 134/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.0672 - acc: 0.9779\n",
      "Epoch 00134: val_loss did not improve from 0.04727\n",
      "40200/40200 [==============================] - 6s 140us/sample - loss: 0.0673 - acc: 0.9779 - val_loss: 0.0483 - val_acc: 0.9877\n",
      "Epoch 135/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.0693 - acc: 0.9780\n",
      "Epoch 00135: val_loss did not improve from 0.04727\n",
      "40200/40200 [==============================] - 6s 141us/sample - loss: 0.0693 - acc: 0.9780 - val_loss: 0.0555 - val_acc: 0.9864\n",
      "Epoch 136/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.0662 - acc: 0.9783\n",
      "Epoch 00136: val_loss did not improve from 0.04727\n",
      "40200/40200 [==============================] - 6s 139us/sample - loss: 0.0661 - acc: 0.9783 - val_loss: 0.0557 - val_acc: 0.9862\n",
      "Epoch 137/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.0688 - acc: 0.9788\n",
      "Epoch 00137: val_loss did not improve from 0.04727\n",
      "40200/40200 [==============================] - 6s 141us/sample - loss: 0.0687 - acc: 0.9788 - val_loss: 0.0559 - val_acc: 0.9867\n",
      "Epoch 138/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.0653 - acc: 0.9784\n",
      "Epoch 00138: val_loss did not improve from 0.04727\n",
      "40200/40200 [==============================] - 6s 140us/sample - loss: 0.0654 - acc: 0.9784 - val_loss: 0.0576 - val_acc: 0.9865\n",
      "Epoch 139/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.0666 - acc: 0.9784\n",
      "Epoch 00139: val_loss did not improve from 0.04727\n",
      "40200/40200 [==============================] - 6s 141us/sample - loss: 0.0665 - acc: 0.9784 - val_loss: 0.0487 - val_acc: 0.9885\n",
      "Epoch 140/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.0651 - acc: 0.9776\n",
      "Epoch 00140: val_loss did not improve from 0.04727\n",
      "40200/40200 [==============================] - 6s 140us/sample - loss: 0.0650 - acc: 0.9776 - val_loss: 0.0532 - val_acc: 0.9867\n",
      "Epoch 141/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.0648 - acc: 0.9786\n",
      "Epoch 00141: val_loss did not improve from 0.04727\n",
      "40200/40200 [==============================] - 6s 140us/sample - loss: 0.0645 - acc: 0.9787 - val_loss: 0.0522 - val_acc: 0.9865\n",
      "Epoch 142/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.0652 - acc: 0.9788\n",
      "Epoch 00142: val_loss did not improve from 0.04727\n",
      "40200/40200 [==============================] - 6s 140us/sample - loss: 0.0652 - acc: 0.9788 - val_loss: 0.0515 - val_acc: 0.9875\n",
      "Epoch 143/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.0626 - acc: 0.9799\n",
      "Epoch 00143: val_loss did not improve from 0.04727\n",
      "40200/40200 [==============================] - 6s 140us/sample - loss: 0.0625 - acc: 0.9799 - val_loss: 0.0535 - val_acc: 0.9879\n",
      "Epoch 144/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.0654 - acc: 0.9793\n",
      "Epoch 00144: val_loss did not improve from 0.04727\n",
      "40200/40200 [==============================] - 6s 139us/sample - loss: 0.0653 - acc: 0.9793 - val_loss: 0.0497 - val_acc: 0.9877\n",
      "Epoch 145/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.0643 - acc: 0.9791\n",
      "Epoch 00145: val_loss did not improve from 0.04727\n",
      "40200/40200 [==============================] - 6s 141us/sample - loss: 0.0644 - acc: 0.9791 - val_loss: 0.0501 - val_acc: 0.9871\n",
      "Epoch 146/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.0620 - acc: 0.9794\n",
      "Epoch 00146: val_loss did not improve from 0.04727\n",
      "40200/40200 [==============================] - 6s 141us/sample - loss: 0.0621 - acc: 0.9794 - val_loss: 0.0553 - val_acc: 0.9873\n",
      "Epoch 147/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.0638 - acc: 0.9795\n",
      "Epoch 00147: val_loss did not improve from 0.04727\n",
      "40200/40200 [==============================] - 6s 140us/sample - loss: 0.0638 - acc: 0.9795 - val_loss: 0.0551 - val_acc: 0.9868\n",
      "Epoch 148/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.0600 - acc: 0.9795\n",
      "Epoch 00148: val_loss did not improve from 0.04727\n",
      "40200/40200 [==============================] - 6s 140us/sample - loss: 0.0601 - acc: 0.9795 - val_loss: 0.0548 - val_acc: 0.9871\n",
      "Epoch 149/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.0630 - acc: 0.9804\n",
      "Epoch 00149: val_loss did not improve from 0.04727\n",
      "40200/40200 [==============================] - 6s 138us/sample - loss: 0.0629 - acc: 0.9804 - val_loss: 0.0479 - val_acc: 0.9877\n",
      "Epoch 150/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.0634 - acc: 0.9794\n",
      "Epoch 00150: val_loss did not improve from 0.04727\n",
      "40200/40200 [==============================] - 6s 140us/sample - loss: 0.0633 - acc: 0.9794 - val_loss: 0.0535 - val_acc: 0.9881\n",
      "Epoch 151/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.0601 - acc: 0.9808\n",
      "Epoch 00151: val_loss did not improve from 0.04727\n",
      "40200/40200 [==============================] - 6s 139us/sample - loss: 0.0605 - acc: 0.9808 - val_loss: 0.0542 - val_acc: 0.9875\n",
      "Epoch 152/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.0574 - acc: 0.9812\n",
      "Epoch 00152: val_loss did not improve from 0.04727\n",
      "40200/40200 [==============================] - 6s 140us/sample - loss: 0.0574 - acc: 0.9813 - val_loss: 0.0515 - val_acc: 0.9886\n",
      "Epoch 153/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.0610 - acc: 0.9793\n",
      "Epoch 00153: val_loss did not improve from 0.04727\n",
      "40200/40200 [==============================] - 6s 140us/sample - loss: 0.0611 - acc: 0.9792 - val_loss: 0.0562 - val_acc: 0.9877\n",
      "Epoch 154/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.0613 - acc: 0.9797\n",
      "Epoch 00154: val_loss did not improve from 0.04727\n",
      "40200/40200 [==============================] - 6s 140us/sample - loss: 0.0612 - acc: 0.9797 - val_loss: 0.0522 - val_acc: 0.9880\n",
      "Epoch 155/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.0616 - acc: 0.9803\n",
      "Epoch 00155: val_loss did not improve from 0.04727\n",
      "40200/40200 [==============================] - 6s 139us/sample - loss: 0.0616 - acc: 0.9803 - val_loss: 0.0565 - val_acc: 0.9878\n",
      "Epoch 156/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.0590 - acc: 0.9807\n",
      "Epoch 00156: val_loss did not improve from 0.04727\n",
      "40200/40200 [==============================] - 6s 140us/sample - loss: 0.0589 - acc: 0.9807 - val_loss: 0.0598 - val_acc: 0.9875\n",
      "Epoch 157/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.0583 - acc: 0.9814\n",
      "Epoch 00157: val_loss did not improve from 0.04727\n",
      "40200/40200 [==============================] - 6s 139us/sample - loss: 0.0586 - acc: 0.9813 - val_loss: 0.0538 - val_acc: 0.9877\n",
      "\n",
      "vis_2D_CNN_custom_ch_16_DO_075_DO_4_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 106us/sample - loss: 0.0354 - acc: 0.9891\n",
      "Loss: 0.03535740399944334 Accuracy: 0.9891\n",
      "\n",
      "Train on 40200 samples, validate on 19800 samples\n",
      "Epoch 1/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 4.9831 - acc: 0.2565\n",
      "Epoch 00001: val_loss improved from inf to 1.26036, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_5_conv_checkpoint/001-1.2604.hdf5\n",
      "40200/40200 [==============================] - 9s 212us/sample - loss: 4.9771 - acc: 0.2569 - val_loss: 1.2604 - val_acc: 0.6588\n",
      "Epoch 2/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 1.4214 - acc: 0.5127\n",
      "Epoch 00002: val_loss improved from 1.26036 to 0.61066, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_5_conv_checkpoint/002-0.6107.hdf5\n",
      "40200/40200 [==============================] - 6s 157us/sample - loss: 1.4207 - acc: 0.5128 - val_loss: 0.6107 - val_acc: 0.8483\n",
      "Epoch 3/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 1.0225 - acc: 0.6490\n",
      "Epoch 00003: val_loss improved from 0.61066 to 0.35082, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_5_conv_checkpoint/003-0.3508.hdf5\n",
      "40200/40200 [==============================] - 6s 155us/sample - loss: 1.0218 - acc: 0.6493 - val_loss: 0.3508 - val_acc: 0.9108\n",
      "Epoch 4/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.7909 - acc: 0.7298\n",
      "Epoch 00004: val_loss improved from 0.35082 to 0.24024, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_5_conv_checkpoint/004-0.2402.hdf5\n",
      "40200/40200 [==============================] - 6s 157us/sample - loss: 0.7906 - acc: 0.7298 - val_loss: 0.2402 - val_acc: 0.9345\n",
      "Epoch 5/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.6431 - acc: 0.7847\n",
      "Epoch 00005: val_loss improved from 0.24024 to 0.19548, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_5_conv_checkpoint/005-0.1955.hdf5\n",
      "40200/40200 [==============================] - 6s 157us/sample - loss: 0.6424 - acc: 0.7850 - val_loss: 0.1955 - val_acc: 0.9470\n",
      "Epoch 6/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.5394 - acc: 0.8203\n",
      "Epoch 00006: val_loss improved from 0.19548 to 0.17235, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_5_conv_checkpoint/006-0.1724.hdf5\n",
      "40200/40200 [==============================] - 6s 157us/sample - loss: 0.5390 - acc: 0.8204 - val_loss: 0.1724 - val_acc: 0.9515\n",
      "Epoch 7/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.4789 - acc: 0.8432\n",
      "Epoch 00007: val_loss improved from 0.17235 to 0.14581, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_5_conv_checkpoint/007-0.1458.hdf5\n",
      "40200/40200 [==============================] - 6s 158us/sample - loss: 0.4789 - acc: 0.8432 - val_loss: 0.1458 - val_acc: 0.9571\n",
      "Epoch 8/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.4267 - acc: 0.8602\n",
      "Epoch 00008: val_loss improved from 0.14581 to 0.12931, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_5_conv_checkpoint/008-0.1293.hdf5\n",
      "40200/40200 [==============================] - 6s 155us/sample - loss: 0.4267 - acc: 0.8602 - val_loss: 0.1293 - val_acc: 0.9633\n",
      "Epoch 9/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.3771 - acc: 0.8769\n",
      "Epoch 00009: val_loss improved from 0.12931 to 0.12119, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_5_conv_checkpoint/009-0.1212.hdf5\n",
      "40200/40200 [==============================] - 6s 155us/sample - loss: 0.3773 - acc: 0.8769 - val_loss: 0.1212 - val_acc: 0.9653\n",
      "Epoch 10/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.3553 - acc: 0.8859\n",
      "Epoch 00010: val_loss improved from 0.12119 to 0.11673, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_5_conv_checkpoint/010-0.1167.hdf5\n",
      "40200/40200 [==============================] - 6s 157us/sample - loss: 0.3551 - acc: 0.8860 - val_loss: 0.1167 - val_acc: 0.9667\n",
      "Epoch 11/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.3213 - acc: 0.8964\n",
      "Epoch 00011: val_loss improved from 0.11673 to 0.10584, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_5_conv_checkpoint/011-0.1058.hdf5\n",
      "40200/40200 [==============================] - 6s 156us/sample - loss: 0.3205 - acc: 0.8967 - val_loss: 0.1058 - val_acc: 0.9687\n",
      "Epoch 12/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.2969 - acc: 0.9024\n",
      "Epoch 00012: val_loss improved from 0.10584 to 0.10343, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_5_conv_checkpoint/012-0.1034.hdf5\n",
      "40200/40200 [==============================] - 6s 154us/sample - loss: 0.2967 - acc: 0.9025 - val_loss: 0.1034 - val_acc: 0.9700\n",
      "Epoch 13/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.2776 - acc: 0.9097\n",
      "Epoch 00013: val_loss improved from 0.10343 to 0.09710, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_5_conv_checkpoint/013-0.0971.hdf5\n",
      "40200/40200 [==============================] - 6s 156us/sample - loss: 0.2775 - acc: 0.9097 - val_loss: 0.0971 - val_acc: 0.9732\n",
      "Epoch 14/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.2617 - acc: 0.9150\n",
      "Epoch 00014: val_loss improved from 0.09710 to 0.09526, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_5_conv_checkpoint/014-0.0953.hdf5\n",
      "40200/40200 [==============================] - 6s 155us/sample - loss: 0.2618 - acc: 0.9150 - val_loss: 0.0953 - val_acc: 0.9722\n",
      "Epoch 15/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.2454 - acc: 0.9192\n",
      "Epoch 00015: val_loss improved from 0.09526 to 0.08720, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_5_conv_checkpoint/015-0.0872.hdf5\n",
      "40200/40200 [==============================] - 6s 154us/sample - loss: 0.2455 - acc: 0.9192 - val_loss: 0.0872 - val_acc: 0.9739\n",
      "Epoch 16/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.2376 - acc: 0.9211\n",
      "Epoch 00016: val_loss improved from 0.08720 to 0.08531, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_5_conv_checkpoint/016-0.0853.hdf5\n",
      "40200/40200 [==============================] - 6s 157us/sample - loss: 0.2375 - acc: 0.9211 - val_loss: 0.0853 - val_acc: 0.9763\n",
      "Epoch 17/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.2305 - acc: 0.9232\n",
      "Epoch 00017: val_loss improved from 0.08531 to 0.07815, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_5_conv_checkpoint/017-0.0782.hdf5\n",
      "40200/40200 [==============================] - 6s 157us/sample - loss: 0.2305 - acc: 0.9232 - val_loss: 0.0782 - val_acc: 0.9771\n",
      "Epoch 18/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.2204 - acc: 0.9259\n",
      "Epoch 00018: val_loss did not improve from 0.07815\n",
      "40200/40200 [==============================] - 6s 157us/sample - loss: 0.2206 - acc: 0.9259 - val_loss: 0.0799 - val_acc: 0.9779\n",
      "Epoch 19/500\n",
      "39744/40200 [============================>.] - ETA: 0s - loss: 0.2182 - acc: 0.9272\n",
      "Epoch 00019: val_loss did not improve from 0.07815\n",
      "40200/40200 [==============================] - 6s 156us/sample - loss: 0.2184 - acc: 0.9271 - val_loss: 0.0825 - val_acc: 0.9779\n",
      "Epoch 20/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.2048 - acc: 0.9305\n",
      "Epoch 00020: val_loss improved from 0.07815 to 0.07418, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_5_conv_checkpoint/020-0.0742.hdf5\n",
      "40200/40200 [==============================] - 6s 156us/sample - loss: 0.2048 - acc: 0.9304 - val_loss: 0.0742 - val_acc: 0.9796\n",
      "Epoch 21/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.1926 - acc: 0.9348\n",
      "Epoch 00021: val_loss did not improve from 0.07418\n",
      "40200/40200 [==============================] - 6s 155us/sample - loss: 0.1925 - acc: 0.9348 - val_loss: 0.0756 - val_acc: 0.9793\n",
      "Epoch 22/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.1836 - acc: 0.9374\n",
      "Epoch 00022: val_loss improved from 0.07418 to 0.07235, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_5_conv_checkpoint/022-0.0723.hdf5\n",
      "40200/40200 [==============================] - 6s 157us/sample - loss: 0.1839 - acc: 0.9373 - val_loss: 0.0723 - val_acc: 0.9810\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.1830 - acc: 0.9375\n",
      "Epoch 00023: val_loss improved from 0.07235 to 0.06891, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_5_conv_checkpoint/023-0.0689.hdf5\n",
      "40200/40200 [==============================] - 6s 157us/sample - loss: 0.1832 - acc: 0.9375 - val_loss: 0.0689 - val_acc: 0.9813\n",
      "Epoch 24/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.1754 - acc: 0.9409\n",
      "Epoch 00024: val_loss did not improve from 0.06891\n",
      "40200/40200 [==============================] - 6s 155us/sample - loss: 0.1753 - acc: 0.9408 - val_loss: 0.0701 - val_acc: 0.9805\n",
      "Epoch 25/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.1742 - acc: 0.9399\n",
      "Epoch 00025: val_loss did not improve from 0.06891\n",
      "40200/40200 [==============================] - 6s 154us/sample - loss: 0.1742 - acc: 0.9399 - val_loss: 0.0704 - val_acc: 0.9816\n",
      "Epoch 26/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.1669 - acc: 0.9422\n",
      "Epoch 00026: val_loss improved from 0.06891 to 0.06415, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_5_conv_checkpoint/026-0.0641.hdf5\n",
      "40200/40200 [==============================] - 6s 157us/sample - loss: 0.1667 - acc: 0.9422 - val_loss: 0.0641 - val_acc: 0.9836\n",
      "Epoch 27/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.1591 - acc: 0.9440\n",
      "Epoch 00027: val_loss did not improve from 0.06415\n",
      "40200/40200 [==============================] - 6s 156us/sample - loss: 0.1590 - acc: 0.9441 - val_loss: 0.0683 - val_acc: 0.9826\n",
      "Epoch 28/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.1529 - acc: 0.9466\n",
      "Epoch 00028: val_loss did not improve from 0.06415\n",
      "40200/40200 [==============================] - 6s 154us/sample - loss: 0.1526 - acc: 0.9466 - val_loss: 0.0710 - val_acc: 0.9818\n",
      "Epoch 29/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.1481 - acc: 0.9479\n",
      "Epoch 00029: val_loss did not improve from 0.06415\n",
      "40200/40200 [==============================] - 6s 155us/sample - loss: 0.1480 - acc: 0.9479 - val_loss: 0.0668 - val_acc: 0.9837\n",
      "Epoch 30/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.1455 - acc: 0.9499\n",
      "Epoch 00030: val_loss improved from 0.06415 to 0.06405, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_5_conv_checkpoint/030-0.0640.hdf5\n",
      "40200/40200 [==============================] - 6s 156us/sample - loss: 0.1455 - acc: 0.9499 - val_loss: 0.0640 - val_acc: 0.9831\n",
      "Epoch 31/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.1448 - acc: 0.9494\n",
      "Epoch 00031: val_loss did not improve from 0.06405\n",
      "40200/40200 [==============================] - 6s 155us/sample - loss: 0.1451 - acc: 0.9493 - val_loss: 0.0692 - val_acc: 0.9824\n",
      "Epoch 32/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.1320 - acc: 0.9538\n",
      "Epoch 00032: val_loss did not improve from 0.06405\n",
      "40200/40200 [==============================] - 6s 154us/sample - loss: 0.1319 - acc: 0.9538 - val_loss: 0.0684 - val_acc: 0.9839\n",
      "Epoch 33/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.1350 - acc: 0.9535\n",
      "Epoch 00033: val_loss improved from 0.06405 to 0.06349, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_5_conv_checkpoint/033-0.0635.hdf5\n",
      "40200/40200 [==============================] - 6s 156us/sample - loss: 0.1346 - acc: 0.9536 - val_loss: 0.0635 - val_acc: 0.9845\n",
      "Epoch 34/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.1281 - acc: 0.9541\n",
      "Epoch 00034: val_loss did not improve from 0.06349\n",
      "40200/40200 [==============================] - 6s 155us/sample - loss: 0.1282 - acc: 0.9541 - val_loss: 0.0667 - val_acc: 0.9834\n",
      "Epoch 35/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.1247 - acc: 0.9560\n",
      "Epoch 00035: val_loss did not improve from 0.06349\n",
      "40200/40200 [==============================] - 6s 156us/sample - loss: 0.1249 - acc: 0.9559 - val_loss: 0.0680 - val_acc: 0.9852\n",
      "Epoch 36/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.1251 - acc: 0.9558\n",
      "Epoch 00036: val_loss did not improve from 0.06349\n",
      "40200/40200 [==============================] - 6s 156us/sample - loss: 0.1251 - acc: 0.9558 - val_loss: 0.0686 - val_acc: 0.9835\n",
      "Epoch 37/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.1210 - acc: 0.9565\n",
      "Epoch 00037: val_loss did not improve from 0.06349\n",
      "40200/40200 [==============================] - 6s 155us/sample - loss: 0.1208 - acc: 0.9566 - val_loss: 0.0658 - val_acc: 0.9843\n",
      "Epoch 38/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.1212 - acc: 0.9578\n",
      "Epoch 00038: val_loss did not improve from 0.06349\n",
      "40200/40200 [==============================] - 6s 155us/sample - loss: 0.1212 - acc: 0.9578 - val_loss: 0.0653 - val_acc: 0.9847\n",
      "Epoch 39/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.1166 - acc: 0.9575\n",
      "Epoch 00039: val_loss improved from 0.06349 to 0.06019, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_5_conv_checkpoint/039-0.0602.hdf5\n",
      "40200/40200 [==============================] - 6s 157us/sample - loss: 0.1166 - acc: 0.9576 - val_loss: 0.0602 - val_acc: 0.9852\n",
      "Epoch 40/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.1152 - acc: 0.9593\n",
      "Epoch 00040: val_loss did not improve from 0.06019\n",
      "40200/40200 [==============================] - 6s 154us/sample - loss: 0.1151 - acc: 0.9594 - val_loss: 0.0615 - val_acc: 0.9840\n",
      "Epoch 41/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.1173 - acc: 0.9582\n",
      "Epoch 00041: val_loss did not improve from 0.06019\n",
      "40200/40200 [==============================] - 6s 153us/sample - loss: 0.1172 - acc: 0.9583 - val_loss: 0.0650 - val_acc: 0.9852\n",
      "Epoch 42/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.1140 - acc: 0.9588\n",
      "Epoch 00042: val_loss did not improve from 0.06019\n",
      "40200/40200 [==============================] - 6s 154us/sample - loss: 0.1140 - acc: 0.9588 - val_loss: 0.0628 - val_acc: 0.9849\n",
      "Epoch 43/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.1123 - acc: 0.9595\n",
      "Epoch 00043: val_loss did not improve from 0.06019\n",
      "40200/40200 [==============================] - 6s 156us/sample - loss: 0.1125 - acc: 0.9595 - val_loss: 0.0659 - val_acc: 0.9849\n",
      "Epoch 44/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.1094 - acc: 0.9607\n",
      "Epoch 00044: val_loss did not improve from 0.06019\n",
      "40200/40200 [==============================] - 6s 155us/sample - loss: 0.1094 - acc: 0.9607 - val_loss: 0.0620 - val_acc: 0.9862\n",
      "Epoch 45/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.1048 - acc: 0.9609\n",
      "Epoch 00045: val_loss improved from 0.06019 to 0.05863, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_5_conv_checkpoint/045-0.0586.hdf5\n",
      "40200/40200 [==============================] - 6s 157us/sample - loss: 0.1048 - acc: 0.9609 - val_loss: 0.0586 - val_acc: 0.9865\n",
      "Epoch 46/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.1052 - acc: 0.9620\n",
      "Epoch 00046: val_loss did not improve from 0.05863\n",
      "40200/40200 [==============================] - 6s 157us/sample - loss: 0.1052 - acc: 0.9620 - val_loss: 0.0587 - val_acc: 0.9870\n",
      "Epoch 47/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.1016 - acc: 0.9624\n",
      "Epoch 00047: val_loss improved from 0.05863 to 0.05828, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_5_conv_checkpoint/047-0.0583.hdf5\n",
      "40200/40200 [==============================] - 6s 158us/sample - loss: 0.1019 - acc: 0.9623 - val_loss: 0.0583 - val_acc: 0.9856\n",
      "Epoch 48/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.1031 - acc: 0.9636\n",
      "Epoch 00048: val_loss did not improve from 0.05828\n",
      "40200/40200 [==============================] - 6s 155us/sample - loss: 0.1030 - acc: 0.9637 - val_loss: 0.0600 - val_acc: 0.9863\n",
      "Epoch 49/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.0974 - acc: 0.9642\n",
      "Epoch 00049: val_loss did not improve from 0.05828\n",
      "40200/40200 [==============================] - 6s 155us/sample - loss: 0.0974 - acc: 0.9642 - val_loss: 0.0666 - val_acc: 0.9857\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.1003 - acc: 0.9634\n",
      "Epoch 00050: val_loss improved from 0.05828 to 0.05795, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_5_conv_checkpoint/050-0.0580.hdf5\n",
      "40200/40200 [==============================] - 6s 154us/sample - loss: 0.1002 - acc: 0.9635 - val_loss: 0.0580 - val_acc: 0.9865\n",
      "Epoch 51/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.0951 - acc: 0.9646\n",
      "Epoch 00051: val_loss improved from 0.05795 to 0.05720, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_075_DO_5_conv_checkpoint/051-0.0572.hdf5\n",
      "40200/40200 [==============================] - 6s 156us/sample - loss: 0.0951 - acc: 0.9646 - val_loss: 0.0572 - val_acc: 0.9875\n",
      "Epoch 52/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.0934 - acc: 0.9659\n",
      "Epoch 00052: val_loss did not improve from 0.05720\n",
      "40200/40200 [==============================] - 6s 155us/sample - loss: 0.0934 - acc: 0.9660 - val_loss: 0.0668 - val_acc: 0.9860\n",
      "Epoch 53/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.0946 - acc: 0.9655\n",
      "Epoch 00053: val_loss did not improve from 0.05720\n",
      "40200/40200 [==============================] - 6s 157us/sample - loss: 0.0944 - acc: 0.9656 - val_loss: 0.0585 - val_acc: 0.9871\n",
      "Epoch 54/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.0912 - acc: 0.9653\n",
      "Epoch 00054: val_loss did not improve from 0.05720\n",
      "40200/40200 [==============================] - 6s 154us/sample - loss: 0.0913 - acc: 0.9652 - val_loss: 0.0601 - val_acc: 0.9869\n",
      "Epoch 55/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.0911 - acc: 0.9657\n",
      "Epoch 00055: val_loss did not improve from 0.05720\n",
      "40200/40200 [==============================] - 6s 155us/sample - loss: 0.0912 - acc: 0.9657 - val_loss: 0.0648 - val_acc: 0.9866\n",
      "Epoch 56/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.0889 - acc: 0.9668\n",
      "Epoch 00056: val_loss did not improve from 0.05720\n",
      "40200/40200 [==============================] - 6s 157us/sample - loss: 0.0887 - acc: 0.9668 - val_loss: 0.0657 - val_acc: 0.9865\n",
      "Epoch 57/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.0910 - acc: 0.9659\n",
      "Epoch 00057: val_loss did not improve from 0.05720\n",
      "40200/40200 [==============================] - 6s 157us/sample - loss: 0.0912 - acc: 0.9658 - val_loss: 0.0615 - val_acc: 0.9872\n",
      "Epoch 58/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.0877 - acc: 0.9676\n",
      "Epoch 00058: val_loss did not improve from 0.05720\n",
      "40200/40200 [==============================] - 6s 156us/sample - loss: 0.0878 - acc: 0.9676 - val_loss: 0.0599 - val_acc: 0.9871\n",
      "Epoch 59/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.0884 - acc: 0.9661\n",
      "Epoch 00059: val_loss did not improve from 0.05720\n",
      "40200/40200 [==============================] - 6s 154us/sample - loss: 0.0884 - acc: 0.9661 - val_loss: 0.0654 - val_acc: 0.9877\n",
      "Epoch 60/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.0857 - acc: 0.9671\n",
      "Epoch 00060: val_loss did not improve from 0.05720\n",
      "40200/40200 [==============================] - 6s 154us/sample - loss: 0.0857 - acc: 0.9671 - val_loss: 0.0678 - val_acc: 0.9867\n",
      "Epoch 61/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.0849 - acc: 0.9675\n",
      "Epoch 00061: val_loss did not improve from 0.05720\n",
      "40200/40200 [==============================] - 6s 155us/sample - loss: 0.0848 - acc: 0.9675 - val_loss: 0.0658 - val_acc: 0.9875\n",
      "Epoch 62/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.0823 - acc: 0.9686\n",
      "Epoch 00062: val_loss did not improve from 0.05720\n",
      "40200/40200 [==============================] - 6s 155us/sample - loss: 0.0824 - acc: 0.9686 - val_loss: 0.0650 - val_acc: 0.9876\n",
      "Epoch 63/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.0862 - acc: 0.9678\n",
      "Epoch 00063: val_loss did not improve from 0.05720\n",
      "40200/40200 [==============================] - 6s 156us/sample - loss: 0.0865 - acc: 0.9676 - val_loss: 0.0654 - val_acc: 0.9872\n",
      "Epoch 64/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.0792 - acc: 0.9702\n",
      "Epoch 00064: val_loss did not improve from 0.05720\n",
      "40200/40200 [==============================] - 6s 153us/sample - loss: 0.0792 - acc: 0.9702 - val_loss: 0.0667 - val_acc: 0.9873\n",
      "Epoch 65/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.0813 - acc: 0.9690\n",
      "Epoch 00065: val_loss did not improve from 0.05720\n",
      "40200/40200 [==============================] - 6s 155us/sample - loss: 0.0813 - acc: 0.9691 - val_loss: 0.0687 - val_acc: 0.9867\n",
      "Epoch 66/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.0836 - acc: 0.9668\n",
      "Epoch 00066: val_loss did not improve from 0.05720\n",
      "40200/40200 [==============================] - 6s 155us/sample - loss: 0.0835 - acc: 0.9668 - val_loss: 0.0654 - val_acc: 0.9882\n",
      "Epoch 67/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.0820 - acc: 0.9684\n",
      "Epoch 00067: val_loss did not improve from 0.05720\n",
      "40200/40200 [==============================] - 6s 156us/sample - loss: 0.0819 - acc: 0.9684 - val_loss: 0.0626 - val_acc: 0.9877\n",
      "Epoch 68/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.0788 - acc: 0.9701\n",
      "Epoch 00068: val_loss did not improve from 0.05720\n",
      "40200/40200 [==============================] - 6s 154us/sample - loss: 0.0786 - acc: 0.9702 - val_loss: 0.0624 - val_acc: 0.9872\n",
      "Epoch 69/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.0774 - acc: 0.9702\n",
      "Epoch 00069: val_loss did not improve from 0.05720\n",
      "40200/40200 [==============================] - 6s 154us/sample - loss: 0.0774 - acc: 0.9702 - val_loss: 0.0631 - val_acc: 0.9873\n",
      "Epoch 70/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.0790 - acc: 0.9695\n",
      "Epoch 00070: val_loss did not improve from 0.05720\n",
      "40200/40200 [==============================] - 6s 154us/sample - loss: 0.0791 - acc: 0.9695 - val_loss: 0.0598 - val_acc: 0.9880\n",
      "Epoch 71/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.0737 - acc: 0.9711\n",
      "Epoch 00071: val_loss did not improve from 0.05720\n",
      "40200/40200 [==============================] - 6s 154us/sample - loss: 0.0737 - acc: 0.9711 - val_loss: 0.0634 - val_acc: 0.9878\n",
      "Epoch 72/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.0750 - acc: 0.9706\n",
      "Epoch 00072: val_loss did not improve from 0.05720\n",
      "40200/40200 [==============================] - 6s 154us/sample - loss: 0.0751 - acc: 0.9704 - val_loss: 0.0661 - val_acc: 0.9872\n",
      "Epoch 73/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.0766 - acc: 0.9700\n",
      "Epoch 00073: val_loss did not improve from 0.05720\n",
      "40200/40200 [==============================] - 6s 154us/sample - loss: 0.0766 - acc: 0.9700 - val_loss: 0.0680 - val_acc: 0.9870\n",
      "Epoch 74/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.0758 - acc: 0.9709\n",
      "Epoch 00074: val_loss did not improve from 0.05720\n",
      "40200/40200 [==============================] - 6s 155us/sample - loss: 0.0757 - acc: 0.9709 - val_loss: 0.0661 - val_acc: 0.9879\n",
      "Epoch 75/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.0753 - acc: 0.9702\n",
      "Epoch 00075: val_loss did not improve from 0.05720\n",
      "40200/40200 [==============================] - 6s 155us/sample - loss: 0.0753 - acc: 0.9703 - val_loss: 0.0660 - val_acc: 0.9882\n",
      "Epoch 76/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.0750 - acc: 0.9701\n",
      "Epoch 00076: val_loss did not improve from 0.05720\n",
      "40200/40200 [==============================] - 6s 156us/sample - loss: 0.0750 - acc: 0.9701 - val_loss: 0.0633 - val_acc: 0.9891\n",
      "Epoch 77/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.0741 - acc: 0.9702\n",
      "Epoch 00077: val_loss did not improve from 0.05720\n",
      "40200/40200 [==============================] - 6s 156us/sample - loss: 0.0739 - acc: 0.9702 - val_loss: 0.0648 - val_acc: 0.9887\n",
      "Epoch 78/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.0719 - acc: 0.9713\n",
      "Epoch 00078: val_loss did not improve from 0.05720\n",
      "40200/40200 [==============================] - 6s 155us/sample - loss: 0.0719 - acc: 0.9713 - val_loss: 0.0668 - val_acc: 0.9884\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.0716 - acc: 0.9711\n",
      "Epoch 00079: val_loss did not improve from 0.05720\n",
      "40200/40200 [==============================] - 6s 154us/sample - loss: 0.0715 - acc: 0.9712 - val_loss: 0.0726 - val_acc: 0.9875\n",
      "Epoch 80/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.0702 - acc: 0.9723\n",
      "Epoch 00080: val_loss did not improve from 0.05720\n",
      "40200/40200 [==============================] - 6s 157us/sample - loss: 0.0701 - acc: 0.9724 - val_loss: 0.0697 - val_acc: 0.9869\n",
      "Epoch 81/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.0755 - acc: 0.9702\n",
      "Epoch 00081: val_loss did not improve from 0.05720\n",
      "40200/40200 [==============================] - 6s 154us/sample - loss: 0.0756 - acc: 0.9702 - val_loss: 0.0700 - val_acc: 0.9870\n",
      "Epoch 82/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.0711 - acc: 0.9717\n",
      "Epoch 00082: val_loss did not improve from 0.05720\n",
      "40200/40200 [==============================] - 6s 154us/sample - loss: 0.0711 - acc: 0.9717 - val_loss: 0.0726 - val_acc: 0.9875\n",
      "Epoch 83/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.0711 - acc: 0.9712\n",
      "Epoch 00083: val_loss did not improve from 0.05720\n",
      "40200/40200 [==============================] - 6s 152us/sample - loss: 0.0710 - acc: 0.9712 - val_loss: 0.0661 - val_acc: 0.9883\n",
      "Epoch 84/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.0694 - acc: 0.9729\n",
      "Epoch 00084: val_loss did not improve from 0.05720\n",
      "40200/40200 [==============================] - 6s 155us/sample - loss: 0.0697 - acc: 0.9728 - val_loss: 0.0737 - val_acc: 0.9877\n",
      "Epoch 85/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.0705 - acc: 0.9726\n",
      "Epoch 00085: val_loss did not improve from 0.05720\n",
      "40200/40200 [==============================] - 6s 155us/sample - loss: 0.0705 - acc: 0.9727 - val_loss: 0.0753 - val_acc: 0.9874\n",
      "Epoch 86/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.0668 - acc: 0.9733\n",
      "Epoch 00086: val_loss did not improve from 0.05720\n",
      "40200/40200 [==============================] - 6s 156us/sample - loss: 0.0668 - acc: 0.9733 - val_loss: 0.0794 - val_acc: 0.9860\n",
      "Epoch 87/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.0717 - acc: 0.9723\n",
      "Epoch 00087: val_loss did not improve from 0.05720\n",
      "40200/40200 [==============================] - 6s 155us/sample - loss: 0.0718 - acc: 0.9722 - val_loss: 0.0694 - val_acc: 0.9877\n",
      "Epoch 88/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.0695 - acc: 0.9723\n",
      "Epoch 00088: val_loss did not improve from 0.05720\n",
      "40200/40200 [==============================] - 6s 155us/sample - loss: 0.0694 - acc: 0.9723 - val_loss: 0.0685 - val_acc: 0.9889\n",
      "Epoch 89/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.0678 - acc: 0.9734\n",
      "Epoch 00089: val_loss did not improve from 0.05720\n",
      "40200/40200 [==============================] - 6s 154us/sample - loss: 0.0679 - acc: 0.9734 - val_loss: 0.0690 - val_acc: 0.9881\n",
      "Epoch 90/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.0655 - acc: 0.9738\n",
      "Epoch 00090: val_loss did not improve from 0.05720\n",
      "40200/40200 [==============================] - 6s 154us/sample - loss: 0.0656 - acc: 0.9737 - val_loss: 0.0734 - val_acc: 0.9880\n",
      "Epoch 91/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.0637 - acc: 0.9745\n",
      "Epoch 00091: val_loss did not improve from 0.05720\n",
      "40200/40200 [==============================] - 6s 156us/sample - loss: 0.0638 - acc: 0.9745 - val_loss: 0.0717 - val_acc: 0.9882\n",
      "Epoch 92/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.0664 - acc: 0.9733\n",
      "Epoch 00092: val_loss did not improve from 0.05720\n",
      "40200/40200 [==============================] - 6s 155us/sample - loss: 0.0665 - acc: 0.9733 - val_loss: 0.0687 - val_acc: 0.9884\n",
      "Epoch 93/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.0654 - acc: 0.9736\n",
      "Epoch 00093: val_loss did not improve from 0.05720\n",
      "40200/40200 [==============================] - 6s 156us/sample - loss: 0.0654 - acc: 0.9737 - val_loss: 0.0752 - val_acc: 0.9879\n",
      "Epoch 94/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.0655 - acc: 0.9745\n",
      "Epoch 00094: val_loss did not improve from 0.05720\n",
      "40200/40200 [==============================] - 6s 155us/sample - loss: 0.0655 - acc: 0.9745 - val_loss: 0.0669 - val_acc: 0.9892\n",
      "Epoch 95/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.0646 - acc: 0.9738\n",
      "Epoch 00095: val_loss did not improve from 0.05720\n",
      "40200/40200 [==============================] - 6s 154us/sample - loss: 0.0648 - acc: 0.9737 - val_loss: 0.0713 - val_acc: 0.9875\n",
      "Epoch 96/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.0660 - acc: 0.9726\n",
      "Epoch 00096: val_loss did not improve from 0.05720\n",
      "40200/40200 [==============================] - 6s 155us/sample - loss: 0.0660 - acc: 0.9726 - val_loss: 0.0735 - val_acc: 0.9878\n",
      "Epoch 97/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.0684 - acc: 0.9730\n",
      "Epoch 00097: val_loss did not improve from 0.05720\n",
      "40200/40200 [==============================] - 6s 153us/sample - loss: 0.0687 - acc: 0.9729 - val_loss: 0.0747 - val_acc: 0.9885\n",
      "Epoch 98/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.0650 - acc: 0.9743\n",
      "Epoch 00098: val_loss did not improve from 0.05720\n",
      "40200/40200 [==============================] - 6s 157us/sample - loss: 0.0650 - acc: 0.9743 - val_loss: 0.0763 - val_acc: 0.9883\n",
      "Epoch 99/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.0629 - acc: 0.9750\n",
      "Epoch 00099: val_loss did not improve from 0.05720\n",
      "40200/40200 [==============================] - 6s 153us/sample - loss: 0.0628 - acc: 0.9750 - val_loss: 0.0876 - val_acc: 0.9873\n",
      "Epoch 100/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.0657 - acc: 0.9745\n",
      "Epoch 00100: val_loss did not improve from 0.05720\n",
      "40200/40200 [==============================] - 6s 156us/sample - loss: 0.0655 - acc: 0.9746 - val_loss: 0.0820 - val_acc: 0.9865\n",
      "Epoch 101/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.0631 - acc: 0.9744\n",
      "Epoch 00101: val_loss did not improve from 0.05720\n",
      "40200/40200 [==============================] - 6s 154us/sample - loss: 0.0631 - acc: 0.9744 - val_loss: 0.0755 - val_acc: 0.9886\n",
      "\n",
      "vis_2D_CNN_custom_ch_16_DO_075_DO_5_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 117us/sample - loss: 0.0425 - acc: 0.9910\n",
      "Loss: 0.04253646352121232 Accuracy: 0.991\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 6):\n",
    "    base = 'vis_2D_CNN_custom_ch_16_DO_075_DO'\n",
    "    model_name = base+'_{}_conv'.format(i)\n",
    "    model = build_2d_cnn_custom_ch_16_DO(conv_num=i)\n",
    "#         model.summary()\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=1e-4),\n",
    "          metrics=['accuracy'])\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    os.makedirs(model_path, exist_ok=True)\n",
    "    model_filename = model_path+'{epoch:03d}-{val_loss:.4f}.hdf5'\n",
    "    checkpointer = ModelCheckpoint(filepath = model_filename, monitor = \"val_loss\", \n",
    "                                   verbose=1, save_best_only=True)\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=50)\n",
    "    hist = model.fit(x_train, y_train, batch_size=64, epochs=500, \n",
    "                     validation_data=[x_val, y_val], shuffle=True, \n",
    "                     callbacks = [checkpointer, early_stopping])\n",
    "\n",
    "    print()\n",
    "    print(model_name, 'Model')\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "    ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
    "    ax.plot(hist.history['acc'], 'b', label='train acc')\n",
    "    ax.plot(hist.history['val_acc'], 'g', label='val acc')\n",
    "    ax.set_xlabel('epoch')\n",
    "    ax.set_ylabel('loss')\n",
    "    ax.legend(loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    png_path = 'visualization/learning_curve/'\n",
    "    filename = model_name+'.png'\n",
    "    os.makedirs(png_path, exist_ok=True)\n",
    "    fig.savefig(png_path+filename, transparent=True)\n",
    "\n",
    "    model.save(model_path+'000_last.hdf5')\n",
    "    del(model)\n",
    "\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    model_filename = model_path + sorted(os.listdir(model_path))[-1]\n",
    "    model = load_model(model_filename)\n",
    "    [loss, accuracy] = model.evaluate(x_test, y_test)\n",
    "    print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "    print()\n",
    "\n",
    "    del(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "vis_2D_CNN_custom_ch_16_DO_075_DO_1_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 28, 28, 16)        160       \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 28, 28, 16)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                31370     \n",
      "=================================================================\n",
      "Total params: 31,530\n",
      "Trainable params: 31,530\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "10000/10000 [==============================] - 1s 101us/sample - loss: 0.0625 - acc: 0.9828\n",
      "Loss: 0.0625295720718801 Accuracy: 0.9828\n",
      "\n",
      "vis_2D_CNN_custom_ch_16_DO_075_DO_2_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_7 (InputLayer)         (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 28, 28, 16)        160       \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 28, 28, 16)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 14, 14, 16)        2320      \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_17 (MaxPooling (None, 7, 7, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                7850      \n",
      "=================================================================\n",
      "Total params: 10,330\n",
      "Trainable params: 10,330\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "10000/10000 [==============================] - 1s 108us/sample - loss: 0.0361 - acc: 0.9875\n",
      "Loss: 0.0361479557828512 Accuracy: 0.9875\n",
      "\n",
      "vis_2D_CNN_custom_ch_16_DO_075_DO_3_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_8 (InputLayer)         (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 28, 28, 16)        160       \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 28, 28, 16)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_18 (MaxPooling (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 14, 14, 16)        2320      \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_19 (MaxPooling (None, 7, 7, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 7, 7, 32)          4640      \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 7, 7, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_20 (MaxPooling (None, 4, 4, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 12,250\n",
      "Trainable params: 12,250\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "10000/10000 [==============================] - 1s 117us/sample - loss: 0.0316 - acc: 0.9902\n",
      "Loss: 0.031557436333539954 Accuracy: 0.9902\n",
      "\n",
      "vis_2D_CNN_custom_ch_16_DO_075_DO_4_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_9 (InputLayer)         (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 28, 28, 16)        160       \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 28, 28, 16)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_21 (MaxPooling (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_22 (Conv2D)           (None, 14, 14, 16)        2320      \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_22 (MaxPooling (None, 7, 7, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 7, 7, 32)          4640      \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 7, 7, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_23 (MaxPooling (None, 4, 4, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_24 (Conv2D)           (None, 4, 4, 32)          9248      \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 4, 4, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_24 (MaxPooling (None, 2, 2, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 17,658\n",
      "Trainable params: 17,658\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "10000/10000 [==============================] - 1s 123us/sample - loss: 0.0354 - acc: 0.9891\n",
      "Loss: 0.03535740399944334 Accuracy: 0.9891\n",
      "\n",
      "vis_2D_CNN_custom_ch_16_DO_075_DO_5_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_10 (InputLayer)        (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_25 (Conv2D)           (None, 28, 28, 16)        160       \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 28, 28, 16)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_25 (MaxPooling (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_26 (Conv2D)           (None, 14, 14, 16)        2320      \n",
      "_________________________________________________________________\n",
      "activation_26 (Activation)   (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_26 (MaxPooling (None, 7, 7, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_27 (Conv2D)           (None, 7, 7, 32)          4640      \n",
      "_________________________________________________________________\n",
      "activation_27 (Activation)   (None, 7, 7, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_27 (MaxPooling (None, 4, 4, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_28 (Conv2D)           (None, 4, 4, 32)          9248      \n",
      "_________________________________________________________________\n",
      "activation_28 (Activation)   (None, 4, 4, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_28 (MaxPooling (None, 2, 2, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_29 (Conv2D)           (None, 2, 2, 64)          18496     \n",
      "_________________________________________________________________\n",
      "activation_29 (Activation)   (None, 2, 2, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_29 (MaxPooling (None, 1, 1, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 35,514\n",
      "Trainable params: 35,514\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 134us/sample - loss: 0.0425 - acc: 0.9910\n",
      "Loss: 0.04253646352121232 Accuracy: 0.991\n"
     ]
    }
   ],
   "source": [
    "log_dir = 'log'\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "base = 'vis_2D_CNN_custom_ch_16_DO_075_DO'\n",
    "\n",
    "with open(path.join(log_dir, base), 'w') as log_file:\n",
    "    for i in range(1, 6):\n",
    "        model_name = base+'_{}_conv'.format(i)\n",
    "        print()\n",
    "        print(model_name, 'Model')\n",
    "        model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "        model_filename = model_path + sorted(os.listdir(model_path))[-1]\n",
    "\n",
    "        model = load_model(model_filename)\n",
    "        model.summary()\n",
    "\n",
    "        [loss, accuracy] = model.evaluate(x_test, y_test)\n",
    "        print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "\n",
    "        del(model)\n",
    "\n",
    "        log_file.write('\\t'.join([model_name, str(accuracy), str(loss)])+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "vis_2D_CNN_custom_ch_16_DO_075_DO_1_conv Model\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 28, 28, 16)        160       \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 28, 28, 16)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                31370     \n",
      "=================================================================\n",
      "Total params: 31,530\n",
      "Trainable params: 31,530\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'x_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-f7f0cb7a6253>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0;34m[\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loss:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Accuracy:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x_test' is not defined"
     ]
    }
   ],
   "source": [
    "for i in range(1, 6):\n",
    "    model_name = base+'_{}_conv'.format(i)\n",
    "    print()\n",
    "    print(model_name, 'Model')\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    model_filename = model_path + '000_last.hdf5'\n",
    "\n",
    "    model = load_model(model_filename)\n",
    "    model.summary()\n",
    "\n",
    "    [loss, accuracy] = model.evaluate(x_test, y_test)\n",
    "    print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "\n",
    "    del(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

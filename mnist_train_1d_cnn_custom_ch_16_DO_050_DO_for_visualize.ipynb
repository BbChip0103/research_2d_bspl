{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import os.path as path\n",
    "import itertools\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.layers import Input,InputLayer, Dense, Activation, BatchNormalization, Flatten, Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D, Dropout\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,LearningRateScheduler, \\\n",
    "                                        EarlyStopping\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from  tensorflow.keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '6'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = mnist.load_data(path='mnist.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = data[0][0][:,:,:,np.newaxis]\n",
    "y_data = data[0][1]\n",
    "x_test = data[1][0][:,:,:,np.newaxis]\n",
    "y_test = data[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((40200, 28, 28, 1),\n",
       " (40200, 10),\n",
       " (19800, 28, 28, 1),\n",
       " (19800, 10),\n",
       " (10000, 28, 28, 1),\n",
       " (10000, 10))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(x_data, y_data, test_size=0.33, random_state=42, stratify=y_data)\n",
    "y_train = to_categorical(y_train)\n",
    "y_val = to_categorical(y_val)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "x_train.shape, y_train.shape, x_val.shape, y_val.shape, x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=uint8)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_list = np.unique(data[1][1])\n",
    "y_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = x_test[0].shape\n",
    "output_size = y_list.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_2d_cnn_custom_ch_16_DO(conv_num=1):\n",
    "    input_layer = Input(shape=input_shape)\n",
    "    x = input_layer\n",
    "\n",
    "    for i in range(conv_num):\n",
    "        x = Conv2D(kernel_size=3, filters=16*(2**(i//2)), strides=(1,1), padding='same')(x)\n",
    "#         x = BatchNormalization()(x)\n",
    "        x = Activation('relu')(x)\n",
    "        x = MaxPooling2D(pool_size=2, strides=(2,2), padding='same')(x)\n",
    "\n",
    "    x = Flatten()(x)\n",
    "  \n",
    "    x = Dropout(0.5)(x)\n",
    "    output_layer = Dense(output_size, activation='softmax')(x)\n",
    "    \n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 28, 28, 16)        160       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 28, 28, 16)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                31370     \n",
      "=================================================================\n",
      "Total params: 31,530\n",
      "Trainable params: 31,530\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 16)        160       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 28, 28, 16)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 14, 14, 16)        2320      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 7, 7, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                7850      \n",
      "=================================================================\n",
      "Total params: 10,330\n",
      "Trainable params: 10,330\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 28, 28, 16)        160       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 28, 28, 16)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 14, 14, 16)        2320      \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 7, 7, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 7, 7, 32)          4640      \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 7, 7, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 4, 4, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 12,250\n",
      "Trainable params: 12,250\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 28, 28, 16)        160       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 28, 28, 16)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 14, 14, 16)        2320      \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 7, 7, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 7, 7, 32)          4640      \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 7, 7, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 4, 4, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 4, 4, 32)          9248      \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 4, 4, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 2, 2, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 17,658\n",
      "Trainable params: 17,658\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 28, 28, 16)        160       \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 28, 28, 16)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 14, 14, 16)        2320      \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 7, 7, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 7, 7, 32)          4640      \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 7, 7, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 4, 4, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 4, 4, 32)          9248      \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 4, 4, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 2, 2, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 2, 2, 64)          18496     \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 2, 2, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 1, 1, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 35,514\n",
      "Trainable params: 35,514\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 6):\n",
    "    model = build_2d_cnn_custom_ch_16_DO(conv_num=i)\n",
    "    model.summary()\n",
    "    del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 40200 samples, validate on 19800 samples\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 7.2609 - acc: 0.4919\n",
      "Epoch 00001: val_loss improved from inf to 2.25284, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_1_conv_checkpoint/001-2.2528.hdf5\n",
      "40200/40200 [==============================] - 6s 144us/sample - loss: 7.2530 - acc: 0.4924 - val_loss: 2.2528 - val_acc: 0.8170\n",
      "Epoch 2/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 3.0318 - acc: 0.7680\n",
      "Epoch 00002: val_loss improved from 2.25284 to 1.37876, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_1_conv_checkpoint/002-1.3788.hdf5\n",
      "40200/40200 [==============================] - 4s 98us/sample - loss: 3.0238 - acc: 0.7685 - val_loss: 1.3788 - val_acc: 0.8865\n",
      "Epoch 3/500\n",
      "39744/40200 [============================>.] - ETA: 0s - loss: 2.0791 - acc: 0.8331\n",
      "Epoch 00003: val_loss improved from 1.37876 to 1.10506, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_1_conv_checkpoint/003-1.1051.hdf5\n",
      "40200/40200 [==============================] - 4s 100us/sample - loss: 2.0807 - acc: 0.8329 - val_loss: 1.1051 - val_acc: 0.9071\n",
      "Epoch 4/500\n",
      "39616/40200 [============================>.] - ETA: 0s - loss: 1.6491 - acc: 0.8644\n",
      "Epoch 00004: val_loss improved from 1.10506 to 0.92225, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_1_conv_checkpoint/004-0.9222.hdf5\n",
      "40200/40200 [==============================] - 4s 98us/sample - loss: 1.6415 - acc: 0.8648 - val_loss: 0.9222 - val_acc: 0.9218\n",
      "Epoch 5/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 1.3734 - acc: 0.8843\n",
      "Epoch 00005: val_loss improved from 0.92225 to 0.77109, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_1_conv_checkpoint/005-0.7711.hdf5\n",
      "40200/40200 [==============================] - 4s 103us/sample - loss: 1.3734 - acc: 0.8843 - val_loss: 0.7711 - val_acc: 0.9315\n",
      "Epoch 6/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 1.1676 - acc: 0.8973\n",
      "Epoch 00006: val_loss improved from 0.77109 to 0.65846, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_1_conv_checkpoint/006-0.6585.hdf5\n",
      "40200/40200 [==============================] - 4s 97us/sample - loss: 1.1673 - acc: 0.8973 - val_loss: 0.6585 - val_acc: 0.9398\n",
      "Epoch 7/500\n",
      "39616/40200 [============================>.] - ETA: 0s - loss: 0.9824 - acc: 0.9091\n",
      "Epoch 00007: val_loss improved from 0.65846 to 0.56485, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_1_conv_checkpoint/007-0.5649.hdf5\n",
      "40200/40200 [==============================] - 4s 90us/sample - loss: 0.9819 - acc: 0.9092 - val_loss: 0.5649 - val_acc: 0.9456\n",
      "Epoch 8/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.8380 - acc: 0.9170\n",
      "Epoch 00008: val_loss improved from 0.56485 to 0.48723, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_1_conv_checkpoint/008-0.4872.hdf5\n",
      "40200/40200 [==============================] - 4s 98us/sample - loss: 0.8388 - acc: 0.9170 - val_loss: 0.4872 - val_acc: 0.9512\n",
      "Epoch 9/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.7252 - acc: 0.9240\n",
      "Epoch 00009: val_loss improved from 0.48723 to 0.43010, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_1_conv_checkpoint/009-0.4301.hdf5\n",
      "40200/40200 [==============================] - 4s 98us/sample - loss: 0.7244 - acc: 0.9241 - val_loss: 0.4301 - val_acc: 0.9534\n",
      "Epoch 10/500\n",
      "39744/40200 [============================>.] - ETA: 0s - loss: 0.6463 - acc: 0.9290\n",
      "Epoch 00010: val_loss improved from 0.43010 to 0.37920, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_1_conv_checkpoint/010-0.3792.hdf5\n",
      "40200/40200 [==============================] - 4s 97us/sample - loss: 0.6480 - acc: 0.9290 - val_loss: 0.3792 - val_acc: 0.9556\n",
      "Epoch 11/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.5767 - acc: 0.9312\n",
      "Epoch 00011: val_loss improved from 0.37920 to 0.31804, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_1_conv_checkpoint/011-0.3180.hdf5\n",
      "40200/40200 [==============================] - 4s 101us/sample - loss: 0.5762 - acc: 0.9312 - val_loss: 0.3180 - val_acc: 0.9596\n",
      "Epoch 12/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.4988 - acc: 0.9357\n",
      "Epoch 00012: val_loss improved from 0.31804 to 0.27307, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_1_conv_checkpoint/012-0.2731.hdf5\n",
      "40200/40200 [==============================] - 4s 96us/sample - loss: 0.4981 - acc: 0.9357 - val_loss: 0.2731 - val_acc: 0.9624\n",
      "Epoch 13/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.4291 - acc: 0.9389\n",
      "Epoch 00013: val_loss improved from 0.27307 to 0.23301, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_1_conv_checkpoint/013-0.2330.hdf5\n",
      "40200/40200 [==============================] - 4s 98us/sample - loss: 0.4293 - acc: 0.9389 - val_loss: 0.2330 - val_acc: 0.9638\n",
      "Epoch 14/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.3673 - acc: 0.9430\n",
      "Epoch 00014: val_loss improved from 0.23301 to 0.20624, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_1_conv_checkpoint/014-0.2062.hdf5\n",
      "40200/40200 [==============================] - 4s 100us/sample - loss: 0.3672 - acc: 0.9431 - val_loss: 0.2062 - val_acc: 0.9655\n",
      "Epoch 15/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.3295 - acc: 0.9444\n",
      "Epoch 00015: val_loss improved from 0.20624 to 0.17881, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_1_conv_checkpoint/015-0.1788.hdf5\n",
      "40200/40200 [==============================] - 4s 94us/sample - loss: 0.3291 - acc: 0.9445 - val_loss: 0.1788 - val_acc: 0.9674\n",
      "Epoch 16/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.2803 - acc: 0.9459\n",
      "Epoch 00016: val_loss improved from 0.17881 to 0.15693, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_1_conv_checkpoint/016-0.1569.hdf5\n",
      "40200/40200 [==============================] - 4s 99us/sample - loss: 0.2813 - acc: 0.9459 - val_loss: 0.1569 - val_acc: 0.9687\n",
      "Epoch 17/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.2467 - acc: 0.9499\n",
      "Epoch 00017: val_loss improved from 0.15693 to 0.13912, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_1_conv_checkpoint/017-0.1391.hdf5\n",
      "40200/40200 [==============================] - 4s 95us/sample - loss: 0.2466 - acc: 0.9499 - val_loss: 0.1391 - val_acc: 0.9698\n",
      "Epoch 18/500\n",
      "39680/40200 [============================>.] - ETA: 0s - loss: 0.2160 - acc: 0.9537\n",
      "Epoch 00018: val_loss improved from 0.13912 to 0.12650, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_1_conv_checkpoint/018-0.1265.hdf5\n",
      "40200/40200 [==============================] - 4s 96us/sample - loss: 0.2152 - acc: 0.9538 - val_loss: 0.1265 - val_acc: 0.9709\n",
      "Epoch 19/500\n",
      "39744/40200 [============================>.] - ETA: 0s - loss: 0.1912 - acc: 0.9535\n",
      "Epoch 00019: val_loss improved from 0.12650 to 0.11576, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_1_conv_checkpoint/019-0.1158.hdf5\n",
      "40200/40200 [==============================] - 4s 96us/sample - loss: 0.1914 - acc: 0.9535 - val_loss: 0.1158 - val_acc: 0.9712\n",
      "Epoch 20/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.1728 - acc: 0.9554\n",
      "Epoch 00020: val_loss improved from 0.11576 to 0.11027, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_1_conv_checkpoint/020-0.1103.hdf5\n",
      "40200/40200 [==============================] - 4s 95us/sample - loss: 0.1726 - acc: 0.9555 - val_loss: 0.1103 - val_acc: 0.9709\n",
      "Epoch 21/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.1570 - acc: 0.9583\n",
      "Epoch 00021: val_loss improved from 0.11027 to 0.10547, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_1_conv_checkpoint/021-0.1055.hdf5\n",
      "40200/40200 [==============================] - 4s 98us/sample - loss: 0.1568 - acc: 0.9584 - val_loss: 0.1055 - val_acc: 0.9720\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.1445 - acc: 0.9606\n",
      "Epoch 00022: val_loss improved from 0.10547 to 0.09968, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_1_conv_checkpoint/022-0.0997.hdf5\n",
      "40200/40200 [==============================] - 4s 95us/sample - loss: 0.1446 - acc: 0.9605 - val_loss: 0.0997 - val_acc: 0.9725\n",
      "Epoch 23/500\n",
      "39680/40200 [============================>.] - ETA: 0s - loss: 0.1343 - acc: 0.9616\n",
      "Epoch 00023: val_loss improved from 0.09968 to 0.09706, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_1_conv_checkpoint/023-0.0971.hdf5\n",
      "40200/40200 [==============================] - 3s 86us/sample - loss: 0.1345 - acc: 0.9616 - val_loss: 0.0971 - val_acc: 0.9744\n",
      "Epoch 24/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.1245 - acc: 0.9650\n",
      "Epoch 00024: val_loss improved from 0.09706 to 0.09445, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_1_conv_checkpoint/024-0.0945.hdf5\n",
      "40200/40200 [==============================] - 4s 94us/sample - loss: 0.1243 - acc: 0.9650 - val_loss: 0.0945 - val_acc: 0.9736\n",
      "Epoch 25/500\n",
      "39744/40200 [============================>.] - ETA: 0s - loss: 0.1168 - acc: 0.9652\n",
      "Epoch 00025: val_loss improved from 0.09445 to 0.09234, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_1_conv_checkpoint/025-0.0923.hdf5\n",
      "40200/40200 [==============================] - 4s 101us/sample - loss: 0.1164 - acc: 0.9652 - val_loss: 0.0923 - val_acc: 0.9754\n",
      "Epoch 26/500\n",
      "39552/40200 [============================>.] - ETA: 0s - loss: 0.1154 - acc: 0.9658\n",
      "Epoch 00026: val_loss improved from 0.09234 to 0.08877, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_1_conv_checkpoint/026-0.0888.hdf5\n",
      "40200/40200 [==============================] - 4s 94us/sample - loss: 0.1153 - acc: 0.9659 - val_loss: 0.0888 - val_acc: 0.9754\n",
      "Epoch 27/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.1097 - acc: 0.9672\n",
      "Epoch 00027: val_loss improved from 0.08877 to 0.08714, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_1_conv_checkpoint/027-0.0871.hdf5\n",
      "40200/40200 [==============================] - 4s 98us/sample - loss: 0.1102 - acc: 0.9671 - val_loss: 0.0871 - val_acc: 0.9758\n",
      "Epoch 28/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.1013 - acc: 0.9696\n",
      "Epoch 00028: val_loss improved from 0.08714 to 0.08608, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_1_conv_checkpoint/028-0.0861.hdf5\n",
      "40200/40200 [==============================] - 4s 100us/sample - loss: 0.1020 - acc: 0.9695 - val_loss: 0.0861 - val_acc: 0.9766\n",
      "Epoch 29/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.0980 - acc: 0.9702\n",
      "Epoch 00029: val_loss improved from 0.08608 to 0.08380, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_1_conv_checkpoint/029-0.0838.hdf5\n",
      "40200/40200 [==============================] - 4s 97us/sample - loss: 0.0980 - acc: 0.9701 - val_loss: 0.0838 - val_acc: 0.9767\n",
      "Epoch 30/500\n",
      "39744/40200 [============================>.] - ETA: 0s - loss: 0.0963 - acc: 0.9715\n",
      "Epoch 00030: val_loss improved from 0.08380 to 0.08224, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_1_conv_checkpoint/030-0.0822.hdf5\n",
      "40200/40200 [==============================] - 4s 95us/sample - loss: 0.0961 - acc: 0.9715 - val_loss: 0.0822 - val_acc: 0.9766\n",
      "Epoch 31/500\n",
      "39680/40200 [============================>.] - ETA: 0s - loss: 0.0928 - acc: 0.9713\n",
      "Epoch 00031: val_loss improved from 0.08224 to 0.08043, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_1_conv_checkpoint/031-0.0804.hdf5\n",
      "40200/40200 [==============================] - 4s 96us/sample - loss: 0.0926 - acc: 0.9712 - val_loss: 0.0804 - val_acc: 0.9773\n",
      "Epoch 32/500\n",
      "39616/40200 [============================>.] - ETA: 0s - loss: 0.0898 - acc: 0.9719\n",
      "Epoch 00032: val_loss did not improve from 0.08043\n",
      "40200/40200 [==============================] - 4s 97us/sample - loss: 0.0895 - acc: 0.9719 - val_loss: 0.0808 - val_acc: 0.9766\n",
      "Epoch 33/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.0883 - acc: 0.9726\n",
      "Epoch 00033: val_loss improved from 0.08043 to 0.07861, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_1_conv_checkpoint/033-0.0786.hdf5\n",
      "40200/40200 [==============================] - 4s 94us/sample - loss: 0.0883 - acc: 0.9726 - val_loss: 0.0786 - val_acc: 0.9781\n",
      "Epoch 34/500\n",
      "39680/40200 [============================>.] - ETA: 0s - loss: 0.0837 - acc: 0.9737\n",
      "Epoch 00034: val_loss improved from 0.07861 to 0.07844, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_1_conv_checkpoint/034-0.0784.hdf5\n",
      "40200/40200 [==============================] - 4s 99us/sample - loss: 0.0835 - acc: 0.9737 - val_loss: 0.0784 - val_acc: 0.9777\n",
      "Epoch 35/500\n",
      "39680/40200 [============================>.] - ETA: 0s - loss: 0.0832 - acc: 0.9729\n",
      "Epoch 00035: val_loss did not improve from 0.07844\n",
      "40200/40200 [==============================] - 4s 94us/sample - loss: 0.0829 - acc: 0.9729 - val_loss: 0.0789 - val_acc: 0.9783\n",
      "Epoch 36/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.0788 - acc: 0.9751\n",
      "Epoch 00036: val_loss improved from 0.07844 to 0.07573, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_1_conv_checkpoint/036-0.0757.hdf5\n",
      "40200/40200 [==============================] - 4s 99us/sample - loss: 0.0786 - acc: 0.9752 - val_loss: 0.0757 - val_acc: 0.9784\n",
      "Epoch 37/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.0766 - acc: 0.9752\n",
      "Epoch 00037: val_loss did not improve from 0.07573\n",
      "40200/40200 [==============================] - 4s 99us/sample - loss: 0.0769 - acc: 0.9751 - val_loss: 0.0779 - val_acc: 0.9780\n",
      "Epoch 38/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.0772 - acc: 0.9753\n",
      "Epoch 00038: val_loss did not improve from 0.07573\n",
      "40200/40200 [==============================] - 4s 92us/sample - loss: 0.0775 - acc: 0.9753 - val_loss: 0.0779 - val_acc: 0.9780\n",
      "Epoch 39/500\n",
      "39616/40200 [============================>.] - ETA: 0s - loss: 0.0731 - acc: 0.9765\n",
      "Epoch 00039: val_loss improved from 0.07573 to 0.07491, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_1_conv_checkpoint/039-0.0749.hdf5\n",
      "40200/40200 [==============================] - 3s 84us/sample - loss: 0.0730 - acc: 0.9765 - val_loss: 0.0749 - val_acc: 0.9789\n",
      "Epoch 40/500\n",
      "39616/40200 [============================>.] - ETA: 0s - loss: 0.0735 - acc: 0.9762\n",
      "Epoch 00040: val_loss improved from 0.07491 to 0.07394, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_1_conv_checkpoint/040-0.0739.hdf5\n",
      "40200/40200 [==============================] - 4s 100us/sample - loss: 0.0735 - acc: 0.9763 - val_loss: 0.0739 - val_acc: 0.9792\n",
      "Epoch 41/500\n",
      "39680/40200 [============================>.] - ETA: 0s - loss: 0.0724 - acc: 0.9766\n",
      "Epoch 00041: val_loss did not improve from 0.07394\n",
      "40200/40200 [==============================] - 4s 94us/sample - loss: 0.0722 - acc: 0.9766 - val_loss: 0.0763 - val_acc: 0.9787\n",
      "Epoch 42/500\n",
      "39616/40200 [============================>.] - ETA: 0s - loss: 0.0718 - acc: 0.9768\n",
      "Epoch 00042: val_loss improved from 0.07394 to 0.07319, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_1_conv_checkpoint/042-0.0732.hdf5\n",
      "40200/40200 [==============================] - 4s 97us/sample - loss: 0.0718 - acc: 0.9768 - val_loss: 0.0732 - val_acc: 0.9796\n",
      "Epoch 43/500\n",
      "39616/40200 [============================>.] - ETA: 0s - loss: 0.0767 - acc: 0.9750\n",
      "Epoch 00043: val_loss improved from 0.07319 to 0.07298, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_1_conv_checkpoint/043-0.0730.hdf5\n",
      "40200/40200 [==============================] - 4s 97us/sample - loss: 0.0763 - acc: 0.9752 - val_loss: 0.0730 - val_acc: 0.9790\n",
      "Epoch 44/500\n",
      "39680/40200 [============================>.] - ETA: 0s - loss: 0.0692 - acc: 0.9771\n",
      "Epoch 00044: val_loss did not improve from 0.07298\n",
      "40200/40200 [==============================] - 4s 96us/sample - loss: 0.0689 - acc: 0.9771 - val_loss: 0.0759 - val_acc: 0.9793\n",
      "Epoch 45/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.0667 - acc: 0.9781\n",
      "Epoch 00045: val_loss did not improve from 0.07298\n",
      "40200/40200 [==============================] - 4s 98us/sample - loss: 0.0672 - acc: 0.9780 - val_loss: 0.0736 - val_acc: 0.9798\n",
      "Epoch 46/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.0670 - acc: 0.9782\n",
      "Epoch 00046: val_loss did not improve from 0.07298\n",
      "40200/40200 [==============================] - 4s 93us/sample - loss: 0.0672 - acc: 0.9781 - val_loss: 0.0742 - val_acc: 0.9796\n",
      "Epoch 47/500\n",
      "39680/40200 [============================>.] - ETA: 0s - loss: 0.0682 - acc: 0.9779\n",
      "Epoch 00047: val_loss improved from 0.07298 to 0.07278, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_1_conv_checkpoint/047-0.0728.hdf5\n",
      "40200/40200 [==============================] - 4s 98us/sample - loss: 0.0683 - acc: 0.9778 - val_loss: 0.0728 - val_acc: 0.9804\n",
      "Epoch 48/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.0665 - acc: 0.9788\n",
      "Epoch 00048: val_loss did not improve from 0.07278\n",
      "40200/40200 [==============================] - 4s 94us/sample - loss: 0.0667 - acc: 0.9788 - val_loss: 0.0728 - val_acc: 0.9800\n",
      "Epoch 49/500\n",
      "39616/40200 [============================>.] - ETA: 0s - loss: 0.0674 - acc: 0.9791\n",
      "Epoch 00049: val_loss improved from 0.07278 to 0.07228, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_1_conv_checkpoint/049-0.0723.hdf5\n",
      "40200/40200 [==============================] - 4s 95us/sample - loss: 0.0671 - acc: 0.9791 - val_loss: 0.0723 - val_acc: 0.9806\n",
      "Epoch 50/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.0654 - acc: 0.9783\n",
      "Epoch 00050: val_loss did not improve from 0.07228\n",
      "40200/40200 [==============================] - 4s 96us/sample - loss: 0.0656 - acc: 0.9783 - val_loss: 0.0726 - val_acc: 0.9798\n",
      "Epoch 51/500\n",
      "39680/40200 [============================>.] - ETA: 0s - loss: 0.0639 - acc: 0.9795\n",
      "Epoch 00051: val_loss improved from 0.07228 to 0.07216, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_1_conv_checkpoint/051-0.0722.hdf5\n",
      "40200/40200 [==============================] - 4s 96us/sample - loss: 0.0642 - acc: 0.9794 - val_loss: 0.0722 - val_acc: 0.9804\n",
      "Epoch 52/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.0648 - acc: 0.9786\n",
      "Epoch 00052: val_loss improved from 0.07216 to 0.07116, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_1_conv_checkpoint/052-0.0712.hdf5\n",
      "40200/40200 [==============================] - 4s 101us/sample - loss: 0.0649 - acc: 0.9786 - val_loss: 0.0712 - val_acc: 0.9804\n",
      "Epoch 53/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.0610 - acc: 0.9798\n",
      "Epoch 00053: val_loss did not improve from 0.07116\n",
      "40200/40200 [==============================] - 4s 97us/sample - loss: 0.0614 - acc: 0.9796 - val_loss: 0.0753 - val_acc: 0.9790\n",
      "Epoch 54/500\n",
      "39680/40200 [============================>.] - ETA: 0s - loss: 0.0618 - acc: 0.9804\n",
      "Epoch 00054: val_loss did not improve from 0.07116\n",
      "40200/40200 [==============================] - 4s 88us/sample - loss: 0.0618 - acc: 0.9804 - val_loss: 0.0729 - val_acc: 0.9803\n",
      "Epoch 55/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.0636 - acc: 0.9791\n",
      "Epoch 00055: val_loss did not improve from 0.07116\n",
      "40200/40200 [==============================] - 3s 87us/sample - loss: 0.0635 - acc: 0.9791 - val_loss: 0.0731 - val_acc: 0.9803\n",
      "Epoch 56/500\n",
      "39744/40200 [============================>.] - ETA: 0s - loss: 0.0600 - acc: 0.9807\n",
      "Epoch 00056: val_loss did not improve from 0.07116\n",
      "40200/40200 [==============================] - 4s 97us/sample - loss: 0.0597 - acc: 0.9807 - val_loss: 0.0725 - val_acc: 0.9796\n",
      "Epoch 57/500\n",
      "39744/40200 [============================>.] - ETA: 0s - loss: 0.0660 - acc: 0.9786\n",
      "Epoch 00057: val_loss did not improve from 0.07116\n",
      "40200/40200 [==============================] - 4s 95us/sample - loss: 0.0659 - acc: 0.9786 - val_loss: 0.0712 - val_acc: 0.9803\n",
      "Epoch 58/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.0637 - acc: 0.9795\n",
      "Epoch 00058: val_loss did not improve from 0.07116\n",
      "40200/40200 [==============================] - 4s 98us/sample - loss: 0.0634 - acc: 0.9796 - val_loss: 0.0726 - val_acc: 0.9797\n",
      "Epoch 59/500\n",
      "39616/40200 [============================>.] - ETA: 0s - loss: 0.0631 - acc: 0.9780\n",
      "Epoch 00059: val_loss did not improve from 0.07116\n",
      "40200/40200 [==============================] - 4s 99us/sample - loss: 0.0630 - acc: 0.9780 - val_loss: 0.0719 - val_acc: 0.9794\n",
      "Epoch 60/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.0594 - acc: 0.9799\n",
      "Epoch 00060: val_loss did not improve from 0.07116\n",
      "40200/40200 [==============================] - 4s 95us/sample - loss: 0.0595 - acc: 0.9799 - val_loss: 0.0720 - val_acc: 0.9804\n",
      "Epoch 61/500\n",
      "39616/40200 [============================>.] - ETA: 0s - loss: 0.0585 - acc: 0.9805\n",
      "Epoch 00061: val_loss did not improve from 0.07116\n",
      "40200/40200 [==============================] - 4s 96us/sample - loss: 0.0586 - acc: 0.9806 - val_loss: 0.0713 - val_acc: 0.9802\n",
      "Epoch 62/500\n",
      "39744/40200 [============================>.] - ETA: 0s - loss: 0.0597 - acc: 0.9809\n",
      "Epoch 00062: val_loss improved from 0.07116 to 0.07094, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_1_conv_checkpoint/062-0.0709.hdf5\n",
      "40200/40200 [==============================] - 4s 99us/sample - loss: 0.0598 - acc: 0.9809 - val_loss: 0.0709 - val_acc: 0.9810\n",
      "Epoch 63/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.0603 - acc: 0.9801\n",
      "Epoch 00063: val_loss did not improve from 0.07094\n",
      "40200/40200 [==============================] - 4s 96us/sample - loss: 0.0603 - acc: 0.9801 - val_loss: 0.0719 - val_acc: 0.9802\n",
      "Epoch 64/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.0564 - acc: 0.9819\n",
      "Epoch 00064: val_loss did not improve from 0.07094\n",
      "40200/40200 [==============================] - 4s 96us/sample - loss: 0.0562 - acc: 0.9819 - val_loss: 0.0724 - val_acc: 0.9808\n",
      "Epoch 65/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.0567 - acc: 0.9814\n",
      "Epoch 00065: val_loss did not improve from 0.07094\n",
      "40200/40200 [==============================] - 4s 94us/sample - loss: 0.0567 - acc: 0.9814 - val_loss: 0.0727 - val_acc: 0.9805\n",
      "Epoch 66/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.0569 - acc: 0.9813\n",
      "Epoch 00066: val_loss did not improve from 0.07094\n",
      "40200/40200 [==============================] - 4s 94us/sample - loss: 0.0570 - acc: 0.9812 - val_loss: 0.0726 - val_acc: 0.9801\n",
      "Epoch 67/500\n",
      "39680/40200 [============================>.] - ETA: 0s - loss: 0.0577 - acc: 0.9806\n",
      "Epoch 00067: val_loss did not improve from 0.07094\n",
      "40200/40200 [==============================] - 4s 94us/sample - loss: 0.0577 - acc: 0.9805 - val_loss: 0.0722 - val_acc: 0.9798\n",
      "Epoch 68/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.0585 - acc: 0.9804\n",
      "Epoch 00068: val_loss improved from 0.07094 to 0.07033, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_1_conv_checkpoint/068-0.0703.hdf5\n",
      "40200/40200 [==============================] - 4s 99us/sample - loss: 0.0585 - acc: 0.9804 - val_loss: 0.0703 - val_acc: 0.9814\n",
      "Epoch 69/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.0577 - acc: 0.9806\n",
      "Epoch 00069: val_loss did not improve from 0.07033\n",
      "40200/40200 [==============================] - 4s 94us/sample - loss: 0.0577 - acc: 0.9807 - val_loss: 0.0708 - val_acc: 0.9807\n",
      "Epoch 70/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.0548 - acc: 0.9816\n",
      "Epoch 00070: val_loss did not improve from 0.07033\n",
      "40200/40200 [==============================] - 4s 97us/sample - loss: 0.0548 - acc: 0.9816 - val_loss: 0.0722 - val_acc: 0.9811\n",
      "Epoch 71/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.0565 - acc: 0.9813\n",
      "Epoch 00071: val_loss did not improve from 0.07033\n",
      "40200/40200 [==============================] - 4s 101us/sample - loss: 0.0565 - acc: 0.9813 - val_loss: 0.0723 - val_acc: 0.9802\n",
      "Epoch 72/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.0587 - acc: 0.9808\n",
      "Epoch 00072: val_loss did not improve from 0.07033\n",
      "40200/40200 [==============================] - 4s 100us/sample - loss: 0.0587 - acc: 0.9808 - val_loss: 0.0718 - val_acc: 0.9806\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.0581 - acc: 0.9809\n",
      "Epoch 00073: val_loss did not improve from 0.07033\n",
      "40200/40200 [==============================] - 4s 95us/sample - loss: 0.0581 - acc: 0.9809 - val_loss: 0.0714 - val_acc: 0.9805\n",
      "Epoch 74/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.0566 - acc: 0.9814\n",
      "Epoch 00074: val_loss did not improve from 0.07033\n",
      "40200/40200 [==============================] - 4s 95us/sample - loss: 0.0565 - acc: 0.9814 - val_loss: 0.0712 - val_acc: 0.9808\n",
      "Epoch 75/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.0590 - acc: 0.9801\n",
      "Epoch 00075: val_loss did not improve from 0.07033\n",
      "40200/40200 [==============================] - 4s 94us/sample - loss: 0.0590 - acc: 0.9801 - val_loss: 0.0708 - val_acc: 0.9806\n",
      "Epoch 76/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.0546 - acc: 0.9816\n",
      "Epoch 00076: val_loss did not improve from 0.07033\n",
      "40200/40200 [==============================] - 3s 87us/sample - loss: 0.0546 - acc: 0.9816 - val_loss: 0.0719 - val_acc: 0.9814\n",
      "Epoch 77/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.0549 - acc: 0.9819\n",
      "Epoch 00077: val_loss improved from 0.07033 to 0.06942, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_1_conv_checkpoint/077-0.0694.hdf5\n",
      "40200/40200 [==============================] - 4s 88us/sample - loss: 0.0548 - acc: 0.9819 - val_loss: 0.0694 - val_acc: 0.9814\n",
      "Epoch 78/500\n",
      "39552/40200 [============================>.] - ETA: 0s - loss: 0.0565 - acc: 0.9813\n",
      "Epoch 00078: val_loss did not improve from 0.06942\n",
      "40200/40200 [==============================] - 4s 94us/sample - loss: 0.0571 - acc: 0.9810 - val_loss: 0.0717 - val_acc: 0.9806\n",
      "Epoch 79/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.0553 - acc: 0.9812\n",
      "Epoch 00079: val_loss did not improve from 0.06942\n",
      "40200/40200 [==============================] - 4s 95us/sample - loss: 0.0555 - acc: 0.9811 - val_loss: 0.0702 - val_acc: 0.9810\n",
      "Epoch 80/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.0542 - acc: 0.9822\n",
      "Epoch 00080: val_loss did not improve from 0.06942\n",
      "40200/40200 [==============================] - 4s 98us/sample - loss: 0.0541 - acc: 0.9823 - val_loss: 0.0706 - val_acc: 0.9814\n",
      "Epoch 81/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.0555 - acc: 0.9810\n",
      "Epoch 00081: val_loss did not improve from 0.06942\n",
      "40200/40200 [==============================] - 4s 93us/sample - loss: 0.0555 - acc: 0.9810 - val_loss: 0.0708 - val_acc: 0.9810\n",
      "Epoch 82/500\n",
      "39744/40200 [============================>.] - ETA: 0s - loss: 0.0559 - acc: 0.9824\n",
      "Epoch 00082: val_loss did not improve from 0.06942\n",
      "40200/40200 [==============================] - 4s 93us/sample - loss: 0.0557 - acc: 0.9824 - val_loss: 0.0713 - val_acc: 0.9804\n",
      "Epoch 83/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.0551 - acc: 0.9813\n",
      "Epoch 00083: val_loss did not improve from 0.06942\n",
      "40200/40200 [==============================] - 4s 98us/sample - loss: 0.0552 - acc: 0.9812 - val_loss: 0.0711 - val_acc: 0.9803\n",
      "Epoch 84/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.0553 - acc: 0.9815\n",
      "Epoch 00084: val_loss did not improve from 0.06942\n",
      "40200/40200 [==============================] - 4s 94us/sample - loss: 0.0552 - acc: 0.9816 - val_loss: 0.0696 - val_acc: 0.9817\n",
      "Epoch 85/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.0535 - acc: 0.9819\n",
      "Epoch 00085: val_loss did not improve from 0.06942\n",
      "40200/40200 [==============================] - 4s 96us/sample - loss: 0.0534 - acc: 0.9819 - val_loss: 0.0700 - val_acc: 0.9817\n",
      "Epoch 86/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.0532 - acc: 0.9826\n",
      "Epoch 00086: val_loss improved from 0.06942 to 0.06904, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_1_conv_checkpoint/086-0.0690.hdf5\n",
      "40200/40200 [==============================] - 4s 100us/sample - loss: 0.0529 - acc: 0.9826 - val_loss: 0.0690 - val_acc: 0.9814\n",
      "Epoch 87/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.0533 - acc: 0.9822\n",
      "Epoch 00087: val_loss improved from 0.06904 to 0.06875, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_1_conv_checkpoint/087-0.0688.hdf5\n",
      "40200/40200 [==============================] - 4s 96us/sample - loss: 0.0533 - acc: 0.9822 - val_loss: 0.0688 - val_acc: 0.9810\n",
      "Epoch 88/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.0523 - acc: 0.9821\n",
      "Epoch 00088: val_loss improved from 0.06875 to 0.06812, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_1_conv_checkpoint/088-0.0681.hdf5\n",
      "40200/40200 [==============================] - 4s 96us/sample - loss: 0.0523 - acc: 0.9821 - val_loss: 0.0681 - val_acc: 0.9817\n",
      "Epoch 89/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.0529 - acc: 0.9820\n",
      "Epoch 00089: val_loss did not improve from 0.06812\n",
      "40200/40200 [==============================] - 4s 96us/sample - loss: 0.0528 - acc: 0.9820 - val_loss: 0.0690 - val_acc: 0.9817\n",
      "Epoch 90/500\n",
      "39616/40200 [============================>.] - ETA: 0s - loss: 0.0500 - acc: 0.9834\n",
      "Epoch 00090: val_loss did not improve from 0.06812\n",
      "40200/40200 [==============================] - 4s 96us/sample - loss: 0.0499 - acc: 0.9834 - val_loss: 0.0705 - val_acc: 0.9810\n",
      "Epoch 91/500\n",
      "39680/40200 [============================>.] - ETA: 0s - loss: 0.0538 - acc: 0.9821\n",
      "Epoch 00091: val_loss did not improve from 0.06812\n",
      "40200/40200 [==============================] - 4s 98us/sample - loss: 0.0536 - acc: 0.9821 - val_loss: 0.0691 - val_acc: 0.9816\n",
      "Epoch 92/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.0526 - acc: 0.9822\n",
      "Epoch 00092: val_loss did not improve from 0.06812\n",
      "40200/40200 [==============================] - 3s 87us/sample - loss: 0.0526 - acc: 0.9822 - val_loss: 0.0701 - val_acc: 0.9813\n",
      "Epoch 93/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.0505 - acc: 0.9834\n",
      "Epoch 00093: val_loss did not improve from 0.06812\n",
      "40200/40200 [==============================] - 4s 90us/sample - loss: 0.0506 - acc: 0.9833 - val_loss: 0.0704 - val_acc: 0.9810\n",
      "Epoch 94/500\n",
      "39680/40200 [============================>.] - ETA: 0s - loss: 0.0505 - acc: 0.9831\n",
      "Epoch 00094: val_loss did not improve from 0.06812\n",
      "40200/40200 [==============================] - 4s 98us/sample - loss: 0.0508 - acc: 0.9830 - val_loss: 0.0719 - val_acc: 0.9809\n",
      "Epoch 95/500\n",
      "39616/40200 [============================>.] - ETA: 0s - loss: 0.0531 - acc: 0.9820\n",
      "Epoch 00095: val_loss did not improve from 0.06812\n",
      "40200/40200 [==============================] - 4s 98us/sample - loss: 0.0531 - acc: 0.9820 - val_loss: 0.0715 - val_acc: 0.9803\n",
      "Epoch 96/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.0503 - acc: 0.9834\n",
      "Epoch 00096: val_loss did not improve from 0.06812\n",
      "40200/40200 [==============================] - 4s 95us/sample - loss: 0.0503 - acc: 0.9834 - val_loss: 0.0707 - val_acc: 0.9811\n",
      "Epoch 97/500\n",
      "39744/40200 [============================>.] - ETA: 0s - loss: 0.0525 - acc: 0.9825\n",
      "Epoch 00097: val_loss did not improve from 0.06812\n",
      "40200/40200 [==============================] - 4s 97us/sample - loss: 0.0525 - acc: 0.9825 - val_loss: 0.0714 - val_acc: 0.9811\n",
      "Epoch 98/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.0500 - acc: 0.9832\n",
      "Epoch 00098: val_loss did not improve from 0.06812\n",
      "40200/40200 [==============================] - 4s 93us/sample - loss: 0.0500 - acc: 0.9832 - val_loss: 0.0686 - val_acc: 0.9816\n",
      "Epoch 99/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.0489 - acc: 0.9830\n",
      "Epoch 00099: val_loss did not improve from 0.06812\n",
      "40200/40200 [==============================] - 4s 94us/sample - loss: 0.0488 - acc: 0.9830 - val_loss: 0.0682 - val_acc: 0.9820\n",
      "Epoch 100/500\n",
      "39680/40200 [============================>.] - ETA: 0s - loss: 0.0515 - acc: 0.9819\n",
      "Epoch 00100: val_loss did not improve from 0.06812\n",
      "40200/40200 [==============================] - 4s 95us/sample - loss: 0.0517 - acc: 0.9819 - val_loss: 0.0698 - val_acc: 0.9816\n",
      "Epoch 101/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.0503 - acc: 0.9833\n",
      "Epoch 00101: val_loss did not improve from 0.06812\n",
      "40200/40200 [==============================] - 4s 96us/sample - loss: 0.0502 - acc: 0.9834 - val_loss: 0.0688 - val_acc: 0.9821\n",
      "Epoch 102/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.0540 - acc: 0.9827\n",
      "Epoch 00102: val_loss did not improve from 0.06812\n",
      "40200/40200 [==============================] - 4s 94us/sample - loss: 0.0541 - acc: 0.9827 - val_loss: 0.0698 - val_acc: 0.9817\n",
      "Epoch 103/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.0512 - acc: 0.9828\n",
      "Epoch 00103: val_loss did not improve from 0.06812\n",
      "40200/40200 [==============================] - 4s 95us/sample - loss: 0.0512 - acc: 0.9828 - val_loss: 0.0686 - val_acc: 0.9818\n",
      "Epoch 104/500\n",
      "39744/40200 [============================>.] - ETA: 0s - loss: 0.0501 - acc: 0.9831\n",
      "Epoch 00104: val_loss improved from 0.06812 to 0.06802, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_1_conv_checkpoint/104-0.0680.hdf5\n",
      "40200/40200 [==============================] - 4s 101us/sample - loss: 0.0500 - acc: 0.9832 - val_loss: 0.0680 - val_acc: 0.9828\n",
      "Epoch 105/500\n",
      "39680/40200 [============================>.] - ETA: 0s - loss: 0.0472 - acc: 0.9846\n",
      "Epoch 00105: val_loss did not improve from 0.06802\n",
      "40200/40200 [==============================] - 4s 95us/sample - loss: 0.0470 - acc: 0.9847 - val_loss: 0.0693 - val_acc: 0.9815\n",
      "Epoch 106/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.0511 - acc: 0.9829\n",
      "Epoch 00106: val_loss did not improve from 0.06802\n",
      "40200/40200 [==============================] - 4s 96us/sample - loss: 0.0511 - acc: 0.9829 - val_loss: 0.0705 - val_acc: 0.9817\n",
      "Epoch 107/500\n",
      "39616/40200 [============================>.] - ETA: 0s - loss: 0.0515 - acc: 0.9829\n",
      "Epoch 00107: val_loss did not improve from 0.06802\n",
      "40200/40200 [==============================] - 4s 95us/sample - loss: 0.0517 - acc: 0.9829 - val_loss: 0.0695 - val_acc: 0.9817\n",
      "Epoch 108/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.0493 - acc: 0.9838\n",
      "Epoch 00108: val_loss did not improve from 0.06802\n",
      "40200/40200 [==============================] - 3s 84us/sample - loss: 0.0493 - acc: 0.9839 - val_loss: 0.0710 - val_acc: 0.9817\n",
      "Epoch 109/500\n",
      "39680/40200 [============================>.] - ETA: 0s - loss: 0.0493 - acc: 0.9837\n",
      "Epoch 00109: val_loss did not improve from 0.06802\n",
      "40200/40200 [==============================] - 4s 91us/sample - loss: 0.0495 - acc: 0.9836 - val_loss: 0.0687 - val_acc: 0.9820\n",
      "Epoch 110/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.0524 - acc: 0.9828\n",
      "Epoch 00110: val_loss did not improve from 0.06802\n",
      "40200/40200 [==============================] - 4s 97us/sample - loss: 0.0523 - acc: 0.9828 - val_loss: 0.0693 - val_acc: 0.9819\n",
      "Epoch 111/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.0512 - acc: 0.9826\n",
      "Epoch 00111: val_loss did not improve from 0.06802\n",
      "40200/40200 [==============================] - 4s 97us/sample - loss: 0.0513 - acc: 0.9826 - val_loss: 0.0695 - val_acc: 0.9815\n",
      "Epoch 112/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.0511 - acc: 0.9828\n",
      "Epoch 00112: val_loss did not improve from 0.06802\n",
      "40200/40200 [==============================] - 4s 98us/sample - loss: 0.0510 - acc: 0.9828 - val_loss: 0.0701 - val_acc: 0.9819\n",
      "Epoch 113/500\n",
      "39552/40200 [============================>.] - ETA: 0s - loss: 0.0511 - acc: 0.9829\n",
      "Epoch 00113: val_loss did not improve from 0.06802\n",
      "40200/40200 [==============================] - 4s 95us/sample - loss: 0.0510 - acc: 0.9829 - val_loss: 0.0703 - val_acc: 0.9806\n",
      "Epoch 114/500\n",
      "39680/40200 [============================>.] - ETA: 0s - loss: 0.0490 - acc: 0.9839\n",
      "Epoch 00114: val_loss did not improve from 0.06802\n",
      "40200/40200 [==============================] - 4s 93us/sample - loss: 0.0489 - acc: 0.9839 - val_loss: 0.0702 - val_acc: 0.9817\n",
      "Epoch 115/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.0501 - acc: 0.9831\n",
      "Epoch 00115: val_loss did not improve from 0.06802\n",
      "40200/40200 [==============================] - 4s 98us/sample - loss: 0.0501 - acc: 0.9831 - val_loss: 0.0696 - val_acc: 0.9816\n",
      "Epoch 116/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.0501 - acc: 0.9828\n",
      "Epoch 00116: val_loss did not improve from 0.06802\n",
      "40200/40200 [==============================] - 4s 94us/sample - loss: 0.0503 - acc: 0.9828 - val_loss: 0.0694 - val_acc: 0.9825\n",
      "Epoch 117/500\n",
      "39616/40200 [============================>.] - ETA: 0s - loss: 0.0488 - acc: 0.9834\n",
      "Epoch 00117: val_loss did not improve from 0.06802\n",
      "40200/40200 [==============================] - 4s 98us/sample - loss: 0.0491 - acc: 0.9833 - val_loss: 0.0714 - val_acc: 0.9815\n",
      "Epoch 118/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.0466 - acc: 0.9838\n",
      "Epoch 00118: val_loss did not improve from 0.06802\n",
      "40200/40200 [==============================] - 4s 98us/sample - loss: 0.0465 - acc: 0.9838 - val_loss: 0.0696 - val_acc: 0.9823\n",
      "Epoch 119/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.0505 - acc: 0.9833\n",
      "Epoch 00119: val_loss did not improve from 0.06802\n",
      "40200/40200 [==============================] - 4s 100us/sample - loss: 0.0504 - acc: 0.9834 - val_loss: 0.0698 - val_acc: 0.9817\n",
      "Epoch 120/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.0474 - acc: 0.9841\n",
      "Epoch 00120: val_loss did not improve from 0.06802\n",
      "40200/40200 [==============================] - 4s 96us/sample - loss: 0.0474 - acc: 0.9841 - val_loss: 0.0702 - val_acc: 0.9817\n",
      "Epoch 121/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.0479 - acc: 0.9846\n",
      "Epoch 00121: val_loss did not improve from 0.06802\n",
      "40200/40200 [==============================] - 4s 98us/sample - loss: 0.0479 - acc: 0.9846 - val_loss: 0.0700 - val_acc: 0.9814\n",
      "Epoch 122/500\n",
      "39680/40200 [============================>.] - ETA: 0s - loss: 0.0477 - acc: 0.9843\n",
      "Epoch 00122: val_loss did not improve from 0.06802\n",
      "40200/40200 [==============================] - 4s 97us/sample - loss: 0.0478 - acc: 0.9843 - val_loss: 0.0715 - val_acc: 0.9815\n",
      "Epoch 123/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.0485 - acc: 0.9845\n",
      "Epoch 00123: val_loss did not improve from 0.06802\n",
      "40200/40200 [==============================] - 4s 97us/sample - loss: 0.0485 - acc: 0.9845 - val_loss: 0.0702 - val_acc: 0.9821\n",
      "Epoch 124/500\n",
      "39616/40200 [============================>.] - ETA: 0s - loss: 0.0490 - acc: 0.9837\n",
      "Epoch 00124: val_loss did not improve from 0.06802\n",
      "40200/40200 [==============================] - 3s 83us/sample - loss: 0.0491 - acc: 0.9836 - val_loss: 0.0705 - val_acc: 0.9818\n",
      "Epoch 125/500\n",
      "39616/40200 [============================>.] - ETA: 0s - loss: 0.0515 - acc: 0.9827\n",
      "Epoch 00125: val_loss did not improve from 0.06802\n",
      "40200/40200 [==============================] - 4s 92us/sample - loss: 0.0515 - acc: 0.9827 - val_loss: 0.0688 - val_acc: 0.9816\n",
      "Epoch 126/500\n",
      "39616/40200 [============================>.] - ETA: 0s - loss: 0.0477 - acc: 0.9839\n",
      "Epoch 00126: val_loss did not improve from 0.06802\n",
      "40200/40200 [==============================] - 4s 100us/sample - loss: 0.0485 - acc: 0.9838 - val_loss: 0.0689 - val_acc: 0.9823\n",
      "Epoch 127/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.0456 - acc: 0.9846\n",
      "Epoch 00127: val_loss did not improve from 0.06802\n",
      "40200/40200 [==============================] - 4s 95us/sample - loss: 0.0456 - acc: 0.9846 - val_loss: 0.0680 - val_acc: 0.9824\n",
      "Epoch 128/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.0474 - acc: 0.9849\n",
      "Epoch 00128: val_loss did not improve from 0.06802\n",
      "40200/40200 [==============================] - 4s 96us/sample - loss: 0.0473 - acc: 0.9849 - val_loss: 0.0689 - val_acc: 0.9819\n",
      "Epoch 129/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.0494 - acc: 0.9835\n",
      "Epoch 00129: val_loss did not improve from 0.06802\n",
      "40200/40200 [==============================] - 4s 99us/sample - loss: 0.0494 - acc: 0.9835 - val_loss: 0.0693 - val_acc: 0.9815\n",
      "Epoch 130/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.0452 - acc: 0.9854\n",
      "Epoch 00130: val_loss did not improve from 0.06802\n",
      "40200/40200 [==============================] - 4s 95us/sample - loss: 0.0453 - acc: 0.9853 - val_loss: 0.0689 - val_acc: 0.9819\n",
      "Epoch 131/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.0459 - acc: 0.9846\n",
      "Epoch 00131: val_loss did not improve from 0.06802\n",
      "40200/40200 [==============================] - 4s 96us/sample - loss: 0.0459 - acc: 0.9847 - val_loss: 0.0681 - val_acc: 0.9820\n",
      "Epoch 132/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.0477 - acc: 0.9836\n",
      "Epoch 00132: val_loss did not improve from 0.06802\n",
      "40200/40200 [==============================] - 4s 97us/sample - loss: 0.0477 - acc: 0.9837 - val_loss: 0.0686 - val_acc: 0.9824\n",
      "Epoch 133/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.0476 - acc: 0.9835\n",
      "Epoch 00133: val_loss did not improve from 0.06802\n",
      "40200/40200 [==============================] - 4s 93us/sample - loss: 0.0476 - acc: 0.9835 - val_loss: 0.0690 - val_acc: 0.9821\n",
      "Epoch 134/500\n",
      "39616/40200 [============================>.] - ETA: 0s - loss: 0.0484 - acc: 0.9841\n",
      "Epoch 00134: val_loss did not improve from 0.06802\n",
      "40200/40200 [==============================] - 4s 98us/sample - loss: 0.0483 - acc: 0.9841 - val_loss: 0.0691 - val_acc: 0.9819\n",
      "Epoch 135/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.0479 - acc: 0.9840\n",
      "Epoch 00135: val_loss did not improve from 0.06802\n",
      "40200/40200 [==============================] - 4s 94us/sample - loss: 0.0479 - acc: 0.9840 - val_loss: 0.0699 - val_acc: 0.9818\n",
      "Epoch 136/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.0474 - acc: 0.9842\n",
      "Epoch 00136: val_loss did not improve from 0.06802\n",
      "40200/40200 [==============================] - 4s 95us/sample - loss: 0.0477 - acc: 0.9842 - val_loss: 0.0685 - val_acc: 0.9821\n",
      "Epoch 137/500\n",
      "39616/40200 [============================>.] - ETA: 0s - loss: 0.0490 - acc: 0.9832\n",
      "Epoch 00137: val_loss did not improve from 0.06802\n",
      "40200/40200 [==============================] - 4s 94us/sample - loss: 0.0495 - acc: 0.9832 - val_loss: 0.0682 - val_acc: 0.9812\n",
      "Epoch 138/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.0466 - acc: 0.9847\n",
      "Epoch 00138: val_loss did not improve from 0.06802\n",
      "40200/40200 [==============================] - 4s 94us/sample - loss: 0.0465 - acc: 0.9848 - val_loss: 0.0688 - val_acc: 0.9821\n",
      "Epoch 139/500\n",
      "39744/40200 [============================>.] - ETA: 0s - loss: 0.0456 - acc: 0.9847\n",
      "Epoch 00139: val_loss did not improve from 0.06802\n",
      "40200/40200 [==============================] - 4s 95us/sample - loss: 0.0456 - acc: 0.9847 - val_loss: 0.0703 - val_acc: 0.9818\n",
      "Epoch 140/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.0447 - acc: 0.9845\n",
      "Epoch 00140: val_loss did not improve from 0.06802\n",
      "40200/40200 [==============================] - 3s 83us/sample - loss: 0.0447 - acc: 0.9845 - val_loss: 0.0690 - val_acc: 0.9820\n",
      "Epoch 141/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.0470 - acc: 0.9836\n",
      "Epoch 00141: val_loss did not improve from 0.06802\n",
      "40200/40200 [==============================] - 4s 91us/sample - loss: 0.0469 - acc: 0.9836 - val_loss: 0.0691 - val_acc: 0.9816\n",
      "Epoch 142/500\n",
      "39680/40200 [============================>.] - ETA: 0s - loss: 0.0465 - acc: 0.9845\n",
      "Epoch 00142: val_loss did not improve from 0.06802\n",
      "40200/40200 [==============================] - 4s 93us/sample - loss: 0.0464 - acc: 0.9845 - val_loss: 0.0687 - val_acc: 0.9821\n",
      "Epoch 143/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.0485 - acc: 0.9844\n",
      "Epoch 00143: val_loss improved from 0.06802 to 0.06722, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_1_conv_checkpoint/143-0.0672.hdf5\n",
      "40200/40200 [==============================] - 4s 96us/sample - loss: 0.0486 - acc: 0.9844 - val_loss: 0.0672 - val_acc: 0.9828\n",
      "Epoch 144/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.0483 - acc: 0.9838\n",
      "Epoch 00144: val_loss did not improve from 0.06722\n",
      "40200/40200 [==============================] - 4s 94us/sample - loss: 0.0483 - acc: 0.9838 - val_loss: 0.0687 - val_acc: 0.9818\n",
      "Epoch 145/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.0470 - acc: 0.9840\n",
      "Epoch 00145: val_loss did not improve from 0.06722\n",
      "40200/40200 [==============================] - 4s 94us/sample - loss: 0.0470 - acc: 0.9840 - val_loss: 0.0681 - val_acc: 0.9825\n",
      "Epoch 146/500\n",
      "39616/40200 [============================>.] - ETA: 0s - loss: 0.0453 - acc: 0.9856\n",
      "Epoch 00146: val_loss did not improve from 0.06722\n",
      "40200/40200 [==============================] - 4s 98us/sample - loss: 0.0451 - acc: 0.9857 - val_loss: 0.0677 - val_acc: 0.9822\n",
      "Epoch 147/500\n",
      "39744/40200 [============================>.] - ETA: 0s - loss: 0.0456 - acc: 0.9840\n",
      "Epoch 00147: val_loss did not improve from 0.06722\n",
      "40200/40200 [==============================] - 4s 96us/sample - loss: 0.0455 - acc: 0.9840 - val_loss: 0.0680 - val_acc: 0.9817\n",
      "Epoch 148/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.0476 - acc: 0.9843\n",
      "Epoch 00148: val_loss did not improve from 0.06722\n",
      "40200/40200 [==============================] - 4s 96us/sample - loss: 0.0475 - acc: 0.9844 - val_loss: 0.0686 - val_acc: 0.9817\n",
      "Epoch 149/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.0452 - acc: 0.9851\n",
      "Epoch 00149: val_loss did not improve from 0.06722\n",
      "40200/40200 [==============================] - 4s 94us/sample - loss: 0.0452 - acc: 0.9851 - val_loss: 0.0693 - val_acc: 0.9815\n",
      "Epoch 150/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.0442 - acc: 0.9849\n",
      "Epoch 00150: val_loss did not improve from 0.06722\n",
      "40200/40200 [==============================] - 4s 96us/sample - loss: 0.0441 - acc: 0.9849 - val_loss: 0.0693 - val_acc: 0.9823\n",
      "Epoch 151/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.0472 - acc: 0.9840\n",
      "Epoch 00151: val_loss did not improve from 0.06722\n",
      "40200/40200 [==============================] - 4s 93us/sample - loss: 0.0471 - acc: 0.9841 - val_loss: 0.0705 - val_acc: 0.9821\n",
      "Epoch 152/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.0465 - acc: 0.9845\n",
      "Epoch 00152: val_loss did not improve from 0.06722\n",
      "40200/40200 [==============================] - 4s 94us/sample - loss: 0.0465 - acc: 0.9845 - val_loss: 0.0706 - val_acc: 0.9819\n",
      "Epoch 153/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.0440 - acc: 0.9853\n",
      "Epoch 00153: val_loss did not improve from 0.06722\n",
      "40200/40200 [==============================] - 4s 94us/sample - loss: 0.0441 - acc: 0.9853 - val_loss: 0.0703 - val_acc: 0.9817\n",
      "Epoch 154/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.0448 - acc: 0.9852\n",
      "Epoch 00154: val_loss did not improve from 0.06722\n",
      "40200/40200 [==============================] - 4s 98us/sample - loss: 0.0449 - acc: 0.9852 - val_loss: 0.0689 - val_acc: 0.9819\n",
      "Epoch 155/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.0456 - acc: 0.9843\n",
      "Epoch 00155: val_loss did not improve from 0.06722\n",
      "40200/40200 [==============================] - 4s 93us/sample - loss: 0.0457 - acc: 0.9842 - val_loss: 0.0686 - val_acc: 0.9816\n",
      "Epoch 156/500\n",
      "39680/40200 [============================>.] - ETA: 0s - loss: 0.0461 - acc: 0.9848\n",
      "Epoch 00156: val_loss did not improve from 0.06722\n",
      "40200/40200 [==============================] - 3s 86us/sample - loss: 0.0459 - acc: 0.9848 - val_loss: 0.0675 - val_acc: 0.9819\n",
      "Epoch 157/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.0450 - acc: 0.9849\n",
      "Epoch 00157: val_loss did not improve from 0.06722\n",
      "40200/40200 [==============================] - 4s 88us/sample - loss: 0.0449 - acc: 0.9849 - val_loss: 0.0707 - val_acc: 0.9821\n",
      "Epoch 158/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.0448 - acc: 0.9851\n",
      "Epoch 00158: val_loss did not improve from 0.06722\n",
      "40200/40200 [==============================] - 4s 96us/sample - loss: 0.0448 - acc: 0.9851 - val_loss: 0.0686 - val_acc: 0.9826\n",
      "Epoch 159/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.0466 - acc: 0.9851\n",
      "Epoch 00159: val_loss improved from 0.06722 to 0.06683, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_1_conv_checkpoint/159-0.0668.hdf5\n",
      "40200/40200 [==============================] - 4s 94us/sample - loss: 0.0468 - acc: 0.9850 - val_loss: 0.0668 - val_acc: 0.9823\n",
      "Epoch 160/500\n",
      "39680/40200 [============================>.] - ETA: 0s - loss: 0.0463 - acc: 0.9843\n",
      "Epoch 00160: val_loss did not improve from 0.06683\n",
      "40200/40200 [==============================] - 4s 94us/sample - loss: 0.0462 - acc: 0.9844 - val_loss: 0.0683 - val_acc: 0.9822\n",
      "Epoch 161/500\n",
      "39680/40200 [============================>.] - ETA: 0s - loss: 0.0445 - acc: 0.9853\n",
      "Epoch 00161: val_loss did not improve from 0.06683\n",
      "40200/40200 [==============================] - 4s 94us/sample - loss: 0.0445 - acc: 0.9853 - val_loss: 0.0672 - val_acc: 0.9826\n",
      "Epoch 162/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.0466 - acc: 0.9840\n",
      "Epoch 00162: val_loss did not improve from 0.06683\n",
      "40200/40200 [==============================] - 4s 95us/sample - loss: 0.0466 - acc: 0.9840 - val_loss: 0.0673 - val_acc: 0.9824\n",
      "Epoch 163/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.0461 - acc: 0.9848\n",
      "Epoch 00163: val_loss did not improve from 0.06683\n",
      "40200/40200 [==============================] - 4s 93us/sample - loss: 0.0461 - acc: 0.9848 - val_loss: 0.0681 - val_acc: 0.9818\n",
      "Epoch 164/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.0458 - acc: 0.9843\n",
      "Epoch 00164: val_loss improved from 0.06683 to 0.06648, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_1_conv_checkpoint/164-0.0665.hdf5\n",
      "40200/40200 [==============================] - 4s 96us/sample - loss: 0.0458 - acc: 0.9842 - val_loss: 0.0665 - val_acc: 0.9827\n",
      "Epoch 165/500\n",
      "39744/40200 [============================>.] - ETA: 0s - loss: 0.0464 - acc: 0.9848\n",
      "Epoch 00165: val_loss improved from 0.06648 to 0.06492, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_1_conv_checkpoint/165-0.0649.hdf5\n",
      "40200/40200 [==============================] - 4s 98us/sample - loss: 0.0466 - acc: 0.9847 - val_loss: 0.0649 - val_acc: 0.9832\n",
      "Epoch 166/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.0428 - acc: 0.9843\n",
      "Epoch 00166: val_loss did not improve from 0.06492\n",
      "40200/40200 [==============================] - 4s 95us/sample - loss: 0.0429 - acc: 0.9843 - val_loss: 0.0671 - val_acc: 0.9824\n",
      "Epoch 167/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.0434 - acc: 0.9854\n",
      "Epoch 00167: val_loss did not improve from 0.06492\n",
      "40200/40200 [==============================] - 4s 93us/sample - loss: 0.0434 - acc: 0.9854 - val_loss: 0.0666 - val_acc: 0.9825\n",
      "Epoch 168/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.0458 - acc: 0.9840\n",
      "Epoch 00168: val_loss did not improve from 0.06492\n",
      "40200/40200 [==============================] - 4s 97us/sample - loss: 0.0457 - acc: 0.9841 - val_loss: 0.0685 - val_acc: 0.9827\n",
      "Epoch 169/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.0455 - acc: 0.9843\n",
      "Epoch 00169: val_loss did not improve from 0.06492\n",
      "40200/40200 [==============================] - 4s 94us/sample - loss: 0.0455 - acc: 0.9843 - val_loss: 0.0696 - val_acc: 0.9825\n",
      "Epoch 170/500\n",
      "39616/40200 [============================>.] - ETA: 0s - loss: 0.0422 - acc: 0.9853\n",
      "Epoch 00170: val_loss did not improve from 0.06492\n",
      "40200/40200 [==============================] - 4s 95us/sample - loss: 0.0422 - acc: 0.9854 - val_loss: 0.0675 - val_acc: 0.9827\n",
      "Epoch 171/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.0428 - acc: 0.9854\n",
      "Epoch 00171: val_loss did not improve from 0.06492\n",
      "40200/40200 [==============================] - 4s 95us/sample - loss: 0.0428 - acc: 0.9853 - val_loss: 0.0683 - val_acc: 0.9826\n",
      "Epoch 172/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.0480 - acc: 0.9841\n",
      "Epoch 00172: val_loss did not improve from 0.06492\n",
      "40200/40200 [==============================] - 3s 86us/sample - loss: 0.0479 - acc: 0.9841 - val_loss: 0.0690 - val_acc: 0.9827\n",
      "Epoch 173/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.0433 - acc: 0.9856\n",
      "Epoch 00173: val_loss did not improve from 0.06492\n",
      "40200/40200 [==============================] - 4s 89us/sample - loss: 0.0434 - acc: 0.9856 - val_loss: 0.0677 - val_acc: 0.9823\n",
      "Epoch 174/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.0424 - acc: 0.9861\n",
      "Epoch 00174: val_loss did not improve from 0.06492\n",
      "40200/40200 [==============================] - 4s 93us/sample - loss: 0.0424 - acc: 0.9861 - val_loss: 0.0679 - val_acc: 0.9826\n",
      "Epoch 175/500\n",
      "39680/40200 [============================>.] - ETA: 0s - loss: 0.0443 - acc: 0.9847\n",
      "Epoch 00175: val_loss did not improve from 0.06492\n",
      "40200/40200 [==============================] - 4s 98us/sample - loss: 0.0443 - acc: 0.9846 - val_loss: 0.0686 - val_acc: 0.9823\n",
      "Epoch 176/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.0435 - acc: 0.9858\n",
      "Epoch 00176: val_loss did not improve from 0.06492\n",
      "40200/40200 [==============================] - 4s 95us/sample - loss: 0.0435 - acc: 0.9857 - val_loss: 0.0683 - val_acc: 0.9824\n",
      "Epoch 177/500\n",
      "39552/40200 [============================>.] - ETA: 0s - loss: 0.0464 - acc: 0.9836\n",
      "Epoch 00177: val_loss did not improve from 0.06492\n",
      "40200/40200 [==============================] - 4s 94us/sample - loss: 0.0461 - acc: 0.9838 - val_loss: 0.0681 - val_acc: 0.9823\n",
      "Epoch 178/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.0443 - acc: 0.9849\n",
      "Epoch 00178: val_loss did not improve from 0.06492\n",
      "40200/40200 [==============================] - 4s 94us/sample - loss: 0.0443 - acc: 0.9849 - val_loss: 0.0683 - val_acc: 0.9823\n",
      "Epoch 179/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.0452 - acc: 0.9857\n",
      "Epoch 00179: val_loss did not improve from 0.06492\n",
      "40200/40200 [==============================] - 4s 94us/sample - loss: 0.0455 - acc: 0.9856 - val_loss: 0.0662 - val_acc: 0.9819\n",
      "Epoch 180/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.0445 - acc: 0.9854\n",
      "Epoch 00180: val_loss did not improve from 0.06492\n",
      "40200/40200 [==============================] - 4s 94us/sample - loss: 0.0445 - acc: 0.9854 - val_loss: 0.0677 - val_acc: 0.9819\n",
      "Epoch 181/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.0447 - acc: 0.9852\n",
      "Epoch 00181: val_loss did not improve from 0.06492\n",
      "40200/40200 [==============================] - 4s 97us/sample - loss: 0.0445 - acc: 0.9853 - val_loss: 0.0683 - val_acc: 0.9822\n",
      "Epoch 182/500\n",
      "39616/40200 [============================>.] - ETA: 0s - loss: 0.0435 - acc: 0.9850\n",
      "Epoch 00182: val_loss did not improve from 0.06492\n",
      "40200/40200 [==============================] - 4s 100us/sample - loss: 0.0436 - acc: 0.9850 - val_loss: 0.0677 - val_acc: 0.9822\n",
      "Epoch 183/500\n",
      "39680/40200 [============================>.] - ETA: 0s - loss: 0.0394 - acc: 0.9869\n",
      "Epoch 00183: val_loss did not improve from 0.06492\n",
      "40200/40200 [==============================] - 4s 95us/sample - loss: 0.0398 - acc: 0.9868 - val_loss: 0.0677 - val_acc: 0.9823\n",
      "Epoch 184/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.0438 - acc: 0.9851\n",
      "Epoch 00184: val_loss did not improve from 0.06492\n",
      "40200/40200 [==============================] - 4s 95us/sample - loss: 0.0438 - acc: 0.9851 - val_loss: 0.0685 - val_acc: 0.9824\n",
      "Epoch 185/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.0414 - acc: 0.9859\n",
      "Epoch 00185: val_loss did not improve from 0.06492\n",
      "40200/40200 [==============================] - 4s 97us/sample - loss: 0.0414 - acc: 0.9859 - val_loss: 0.0692 - val_acc: 0.9824\n",
      "Epoch 186/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.0459 - acc: 0.9843\n",
      "Epoch 00186: val_loss did not improve from 0.06492\n",
      "40200/40200 [==============================] - 4s 97us/sample - loss: 0.0457 - acc: 0.9844 - val_loss: 0.0681 - val_acc: 0.9819\n",
      "Epoch 187/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.0425 - acc: 0.9862\n",
      "Epoch 00187: val_loss did not improve from 0.06492\n",
      "40200/40200 [==============================] - 4s 93us/sample - loss: 0.0426 - acc: 0.9862 - val_loss: 0.0675 - val_acc: 0.9819\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 188/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.0429 - acc: 0.9856\n",
      "Epoch 00188: val_loss did not improve from 0.06492\n",
      "40200/40200 [==============================] - 3s 82us/sample - loss: 0.0428 - acc: 0.9856 - val_loss: 0.0692 - val_acc: 0.9821\n",
      "Epoch 189/500\n",
      "39552/40200 [============================>.] - ETA: 0s - loss: 0.0431 - acc: 0.9855\n",
      "Epoch 00189: val_loss did not improve from 0.06492\n",
      "40200/40200 [==============================] - 4s 92us/sample - loss: 0.0432 - acc: 0.9855 - val_loss: 0.0701 - val_acc: 0.9818\n",
      "Epoch 190/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.0426 - acc: 0.9854\n",
      "Epoch 00190: val_loss did not improve from 0.06492\n",
      "40200/40200 [==============================] - 4s 93us/sample - loss: 0.0426 - acc: 0.9854 - val_loss: 0.0683 - val_acc: 0.9823\n",
      "Epoch 191/500\n",
      "39680/40200 [============================>.] - ETA: 0s - loss: 0.0426 - acc: 0.9859\n",
      "Epoch 00191: val_loss did not improve from 0.06492\n",
      "40200/40200 [==============================] - 4s 97us/sample - loss: 0.0427 - acc: 0.9859 - val_loss: 0.0677 - val_acc: 0.9827\n",
      "Epoch 192/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.0447 - acc: 0.9843\n",
      "Epoch 00192: val_loss did not improve from 0.06492\n",
      "40200/40200 [==============================] - 4s 92us/sample - loss: 0.0445 - acc: 0.9844 - val_loss: 0.0672 - val_acc: 0.9821\n",
      "Epoch 193/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.0435 - acc: 0.9856\n",
      "Epoch 00193: val_loss did not improve from 0.06492\n",
      "40200/40200 [==============================] - 4s 94us/sample - loss: 0.0434 - acc: 0.9856 - val_loss: 0.0712 - val_acc: 0.9820\n",
      "Epoch 194/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.0422 - acc: 0.9858\n",
      "Epoch 00194: val_loss did not improve from 0.06492\n",
      "40200/40200 [==============================] - 4s 95us/sample - loss: 0.0422 - acc: 0.9858 - val_loss: 0.0690 - val_acc: 0.9823\n",
      "Epoch 195/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.0455 - acc: 0.9847\n",
      "Epoch 00195: val_loss did not improve from 0.06492\n",
      "40200/40200 [==============================] - 4s 96us/sample - loss: 0.0456 - acc: 0.9846 - val_loss: 0.0672 - val_acc: 0.9824\n",
      "Epoch 196/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.0419 - acc: 0.9859\n",
      "Epoch 00196: val_loss did not improve from 0.06492\n",
      "40200/40200 [==============================] - 4s 93us/sample - loss: 0.0419 - acc: 0.9858 - val_loss: 0.0680 - val_acc: 0.9821\n",
      "Epoch 197/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.0446 - acc: 0.9854\n",
      "Epoch 00197: val_loss did not improve from 0.06492\n",
      "40200/40200 [==============================] - 4s 96us/sample - loss: 0.0448 - acc: 0.9852 - val_loss: 0.0680 - val_acc: 0.9822\n",
      "Epoch 198/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.0436 - acc: 0.9853\n",
      "Epoch 00198: val_loss did not improve from 0.06492\n",
      "40200/40200 [==============================] - 4s 94us/sample - loss: 0.0436 - acc: 0.9853 - val_loss: 0.0705 - val_acc: 0.9818\n",
      "Epoch 199/500\n",
      "39680/40200 [============================>.] - ETA: 0s - loss: 0.0430 - acc: 0.9852\n",
      "Epoch 00199: val_loss did not improve from 0.06492\n",
      "40200/40200 [==============================] - 4s 94us/sample - loss: 0.0431 - acc: 0.9851 - val_loss: 0.0674 - val_acc: 0.9827\n",
      "Epoch 200/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.0451 - acc: 0.9848\n",
      "Epoch 00200: val_loss did not improve from 0.06492\n",
      "40200/40200 [==============================] - 4s 94us/sample - loss: 0.0450 - acc: 0.9849 - val_loss: 0.0690 - val_acc: 0.9824\n",
      "Epoch 201/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.0435 - acc: 0.9854\n",
      "Epoch 00201: val_loss did not improve from 0.06492\n",
      "40200/40200 [==============================] - 4s 95us/sample - loss: 0.0433 - acc: 0.9855 - val_loss: 0.0687 - val_acc: 0.9816\n",
      "Epoch 202/500\n",
      "39616/40200 [============================>.] - ETA: 0s - loss: 0.0430 - acc: 0.9852\n",
      "Epoch 00202: val_loss did not improve from 0.06492\n",
      "40200/40200 [==============================] - 4s 97us/sample - loss: 0.0433 - acc: 0.9850 - val_loss: 0.0673 - val_acc: 0.9820\n",
      "Epoch 203/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.0451 - acc: 0.9853\n",
      "Epoch 00203: val_loss did not improve from 0.06492\n",
      "40200/40200 [==============================] - 4s 95us/sample - loss: 0.0453 - acc: 0.9851 - val_loss: 0.0704 - val_acc: 0.9817\n",
      "Epoch 204/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.0444 - acc: 0.9851\n",
      "Epoch 00204: val_loss did not improve from 0.06492\n",
      "40200/40200 [==============================] - 4s 88us/sample - loss: 0.0445 - acc: 0.9851 - val_loss: 0.0670 - val_acc: 0.9822\n",
      "Epoch 205/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.0408 - acc: 0.9865\n",
      "Epoch 00205: val_loss did not improve from 0.06492\n",
      "40200/40200 [==============================] - 4s 90us/sample - loss: 0.0408 - acc: 0.9866 - val_loss: 0.0698 - val_acc: 0.9826\n",
      "Epoch 206/500\n",
      "39616/40200 [============================>.] - ETA: 0s - loss: 0.0410 - acc: 0.9858\n",
      "Epoch 00206: val_loss did not improve from 0.06492\n",
      "40200/40200 [==============================] - 4s 94us/sample - loss: 0.0418 - acc: 0.9857 - val_loss: 0.0687 - val_acc: 0.9823\n",
      "Epoch 207/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.0443 - acc: 0.9855\n",
      "Epoch 00207: val_loss did not improve from 0.06492\n",
      "40200/40200 [==============================] - 4s 94us/sample - loss: 0.0444 - acc: 0.9855 - val_loss: 0.0707 - val_acc: 0.9815\n",
      "Epoch 208/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.0431 - acc: 0.9854\n",
      "Epoch 00208: val_loss did not improve from 0.06492\n",
      "40200/40200 [==============================] - 4s 94us/sample - loss: 0.0431 - acc: 0.9854 - val_loss: 0.0683 - val_acc: 0.9824\n",
      "Epoch 209/500\n",
      "39616/40200 [============================>.] - ETA: 0s - loss: 0.0421 - acc: 0.9858\n",
      "Epoch 00209: val_loss did not improve from 0.06492\n",
      "40200/40200 [==============================] - 4s 95us/sample - loss: 0.0420 - acc: 0.9858 - val_loss: 0.0691 - val_acc: 0.9823\n",
      "Epoch 210/500\n",
      "39744/40200 [============================>.] - ETA: 0s - loss: 0.0407 - acc: 0.9859\n",
      "Epoch 00210: val_loss did not improve from 0.06492\n",
      "40200/40200 [==============================] - 4s 98us/sample - loss: 0.0408 - acc: 0.9859 - val_loss: 0.0706 - val_acc: 0.9816\n",
      "Epoch 211/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.0417 - acc: 0.9860\n",
      "Epoch 00211: val_loss did not improve from 0.06492\n",
      "40200/40200 [==============================] - 4s 94us/sample - loss: 0.0417 - acc: 0.9860 - val_loss: 0.0699 - val_acc: 0.9826\n",
      "Epoch 212/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.0421 - acc: 0.9861\n",
      "Epoch 00212: val_loss did not improve from 0.06492\n",
      "40200/40200 [==============================] - 4s 94us/sample - loss: 0.0420 - acc: 0.9861 - val_loss: 0.0685 - val_acc: 0.9824\n",
      "Epoch 213/500\n",
      "39680/40200 [============================>.] - ETA: 0s - loss: 0.0432 - acc: 0.9852\n",
      "Epoch 00213: val_loss did not improve from 0.06492\n",
      "40200/40200 [==============================] - 4s 96us/sample - loss: 0.0431 - acc: 0.9851 - val_loss: 0.0703 - val_acc: 0.9813\n",
      "Epoch 214/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.0462 - acc: 0.9843\n",
      "Epoch 00214: val_loss did not improve from 0.06492\n",
      "40200/40200 [==============================] - 4s 93us/sample - loss: 0.0461 - acc: 0.9843 - val_loss: 0.0682 - val_acc: 0.9822\n",
      "Epoch 215/500\n",
      "39616/40200 [============================>.] - ETA: 0s - loss: 0.0437 - acc: 0.9852\n",
      "Epoch 00215: val_loss did not improve from 0.06492\n",
      "40200/40200 [==============================] - 4s 93us/sample - loss: 0.0443 - acc: 0.9851 - val_loss: 0.0677 - val_acc: 0.9823\n",
      "\n",
      "vis_2D_CNN_custom_ch_16_DO_050_DO_1_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 76us/sample - loss: 0.0694 - acc: 0.9835\n",
      "Loss: 0.06943656803121558 Accuracy: 0.9835\n",
      "\n",
      "Train on 40200 samples, validate on 19800 samples\n",
      "Epoch 1/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 9.7664 - acc: 0.2980\n",
      "Epoch 00001: val_loss improved from inf to 2.20813, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_2_conv_checkpoint/001-2.2081.hdf5\n",
      "40200/40200 [==============================] - 5s 135us/sample - loss: 9.7463 - acc: 0.2988 - val_loss: 2.2081 - val_acc: 0.7166\n",
      "Epoch 2/500\n",
      "39744/40200 [============================>.] - ETA: 0s - loss: 2.6650 - acc: 0.5979\n",
      "Epoch 00002: val_loss improved from 2.20813 to 0.61356, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_2_conv_checkpoint/002-0.6136.hdf5\n",
      "40200/40200 [==============================] - 5s 116us/sample - loss: 2.6513 - acc: 0.5981 - val_loss: 0.6136 - val_acc: 0.8134\n",
      "Epoch 3/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 1.1086 - acc: 0.6818\n",
      "Epoch 00003: val_loss improved from 0.61356 to 0.43603, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_2_conv_checkpoint/003-0.4360.hdf5\n",
      "40200/40200 [==============================] - 4s 110us/sample - loss: 1.1074 - acc: 0.6820 - val_loss: 0.4360 - val_acc: 0.8612\n",
      "Epoch 4/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.7666 - acc: 0.7620\n",
      "Epoch 00004: val_loss improved from 0.43603 to 0.32619, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_2_conv_checkpoint/004-0.3262.hdf5\n",
      "40200/40200 [==============================] - 4s 106us/sample - loss: 0.7660 - acc: 0.7621 - val_loss: 0.3262 - val_acc: 0.8980\n",
      "Epoch 5/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.5894 - acc: 0.8154\n",
      "Epoch 00005: val_loss improved from 0.32619 to 0.26011, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_2_conv_checkpoint/005-0.2601.hdf5\n",
      "40200/40200 [==============================] - 5s 116us/sample - loss: 0.5886 - acc: 0.8157 - val_loss: 0.2601 - val_acc: 0.9195\n",
      "Epoch 6/500\n",
      "39744/40200 [============================>.] - ETA: 0s - loss: 0.4721 - acc: 0.8516\n",
      "Epoch 00006: val_loss improved from 0.26011 to 0.21391, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_2_conv_checkpoint/006-0.2139.hdf5\n",
      "40200/40200 [==============================] - 5s 115us/sample - loss: 0.4716 - acc: 0.8515 - val_loss: 0.2139 - val_acc: 0.9347\n",
      "Epoch 7/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.3968 - acc: 0.8749\n",
      "Epoch 00007: val_loss improved from 0.21391 to 0.18348, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_2_conv_checkpoint/007-0.1835.hdf5\n",
      "40200/40200 [==============================] - 5s 112us/sample - loss: 0.3967 - acc: 0.8749 - val_loss: 0.1835 - val_acc: 0.9445\n",
      "Epoch 8/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.3402 - acc: 0.8923\n",
      "Epoch 00008: val_loss improved from 0.18348 to 0.15943, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_2_conv_checkpoint/008-0.1594.hdf5\n",
      "40200/40200 [==============================] - 5s 115us/sample - loss: 0.3401 - acc: 0.8923 - val_loss: 0.1594 - val_acc: 0.9521\n",
      "Epoch 9/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.2964 - acc: 0.9067\n",
      "Epoch 00009: val_loss improved from 0.15943 to 0.14290, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_2_conv_checkpoint/009-0.1429.hdf5\n",
      "40200/40200 [==============================] - 5s 114us/sample - loss: 0.2960 - acc: 0.9068 - val_loss: 0.1429 - val_acc: 0.9566\n",
      "Epoch 10/500\n",
      "39680/40200 [============================>.] - ETA: 0s - loss: 0.2660 - acc: 0.9149\n",
      "Epoch 00010: val_loss improved from 0.14290 to 0.13051, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_2_conv_checkpoint/010-0.1305.hdf5\n",
      "40200/40200 [==============================] - 5s 114us/sample - loss: 0.2649 - acc: 0.9153 - val_loss: 0.1305 - val_acc: 0.9602\n",
      "Epoch 11/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.2410 - acc: 0.9231\n",
      "Epoch 00011: val_loss improved from 0.13051 to 0.11723, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_2_conv_checkpoint/011-0.1172.hdf5\n",
      "40200/40200 [==============================] - 5s 115us/sample - loss: 0.2410 - acc: 0.9231 - val_loss: 0.1172 - val_acc: 0.9637\n",
      "Epoch 12/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.2240 - acc: 0.9294\n",
      "Epoch 00012: val_loss improved from 0.11723 to 0.10920, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_2_conv_checkpoint/012-0.1092.hdf5\n",
      "40200/40200 [==============================] - 5s 114us/sample - loss: 0.2237 - acc: 0.9295 - val_loss: 0.1092 - val_acc: 0.9660\n",
      "Epoch 13/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.2022 - acc: 0.9359\n",
      "Epoch 00013: val_loss improved from 0.10920 to 0.10237, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_2_conv_checkpoint/013-0.1024.hdf5\n",
      "40200/40200 [==============================] - 5s 116us/sample - loss: 0.2023 - acc: 0.9359 - val_loss: 0.1024 - val_acc: 0.9685\n",
      "Epoch 14/500\n",
      "39680/40200 [============================>.] - ETA: 0s - loss: 0.1843 - acc: 0.9414\n",
      "Epoch 00014: val_loss improved from 0.10237 to 0.09361, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_2_conv_checkpoint/014-0.0936.hdf5\n",
      "40200/40200 [==============================] - 5s 112us/sample - loss: 0.1839 - acc: 0.9416 - val_loss: 0.0936 - val_acc: 0.9705\n",
      "Epoch 15/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.1719 - acc: 0.9449\n",
      "Epoch 00015: val_loss improved from 0.09361 to 0.08762, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_2_conv_checkpoint/015-0.0876.hdf5\n",
      "40200/40200 [==============================] - 5s 113us/sample - loss: 0.1716 - acc: 0.9450 - val_loss: 0.0876 - val_acc: 0.9726\n",
      "Epoch 16/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.1616 - acc: 0.9486\n",
      "Epoch 00016: val_loss improved from 0.08762 to 0.08489, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_2_conv_checkpoint/016-0.0849.hdf5\n",
      "40200/40200 [==============================] - 5s 112us/sample - loss: 0.1615 - acc: 0.9487 - val_loss: 0.0849 - val_acc: 0.9739\n",
      "Epoch 17/500\n",
      "39680/40200 [============================>.] - ETA: 0s - loss: 0.1526 - acc: 0.9509\n",
      "Epoch 00017: val_loss improved from 0.08489 to 0.07890, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_2_conv_checkpoint/017-0.0789.hdf5\n",
      "40200/40200 [==============================] - 4s 107us/sample - loss: 0.1523 - acc: 0.9511 - val_loss: 0.0789 - val_acc: 0.9753\n",
      "Epoch 18/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.1439 - acc: 0.9549\n",
      "Epoch 00018: val_loss improved from 0.07890 to 0.07647, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_2_conv_checkpoint/018-0.0765.hdf5\n",
      "40200/40200 [==============================] - 5s 113us/sample - loss: 0.1440 - acc: 0.9549 - val_loss: 0.0765 - val_acc: 0.9755\n",
      "Epoch 19/500\n",
      "39680/40200 [============================>.] - ETA: 0s - loss: 0.1382 - acc: 0.9561\n",
      "Epoch 00019: val_loss improved from 0.07647 to 0.07429, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_2_conv_checkpoint/019-0.0743.hdf5\n",
      "40200/40200 [==============================] - 5s 113us/sample - loss: 0.1380 - acc: 0.9561 - val_loss: 0.0743 - val_acc: 0.9765\n",
      "Epoch 20/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.1349 - acc: 0.9562\n",
      "Epoch 00020: val_loss improved from 0.07429 to 0.06972, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_2_conv_checkpoint/020-0.0697.hdf5\n",
      "40200/40200 [==============================] - 5s 116us/sample - loss: 0.1348 - acc: 0.9562 - val_loss: 0.0697 - val_acc: 0.9776\n",
      "Epoch 21/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.1210 - acc: 0.9615\n",
      "Epoch 00021: val_loss improved from 0.06972 to 0.06835, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_2_conv_checkpoint/021-0.0683.hdf5\n",
      "40200/40200 [==============================] - 5s 114us/sample - loss: 0.1211 - acc: 0.9616 - val_loss: 0.0683 - val_acc: 0.9782\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/500\n",
      "39680/40200 [============================>.] - ETA: 0s - loss: 0.1194 - acc: 0.9619\n",
      "Epoch 00022: val_loss improved from 0.06835 to 0.06569, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_2_conv_checkpoint/022-0.0657.hdf5\n",
      "40200/40200 [==============================] - 4s 112us/sample - loss: 0.1192 - acc: 0.9621 - val_loss: 0.0657 - val_acc: 0.9802\n",
      "Epoch 23/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.1186 - acc: 0.9625\n",
      "Epoch 00023: val_loss improved from 0.06569 to 0.06326, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_2_conv_checkpoint/023-0.0633.hdf5\n",
      "40200/40200 [==============================] - 5s 115us/sample - loss: 0.1185 - acc: 0.9625 - val_loss: 0.0633 - val_acc: 0.9805\n",
      "Epoch 24/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.1140 - acc: 0.9631\n",
      "Epoch 00024: val_loss did not improve from 0.06326\n",
      "40200/40200 [==============================] - 5s 113us/sample - loss: 0.1139 - acc: 0.9632 - val_loss: 0.0636 - val_acc: 0.9804\n",
      "Epoch 25/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.1123 - acc: 0.9647\n",
      "Epoch 00025: val_loss improved from 0.06326 to 0.06019, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_2_conv_checkpoint/025-0.0602.hdf5\n",
      "40200/40200 [==============================] - 5s 114us/sample - loss: 0.1123 - acc: 0.9647 - val_loss: 0.0602 - val_acc: 0.9816\n",
      "Epoch 26/500\n",
      "39744/40200 [============================>.] - ETA: 0s - loss: 0.1036 - acc: 0.9669\n",
      "Epoch 00026: val_loss improved from 0.06019 to 0.06018, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_2_conv_checkpoint/026-0.0602.hdf5\n",
      "40200/40200 [==============================] - 5s 113us/sample - loss: 0.1034 - acc: 0.9669 - val_loss: 0.0602 - val_acc: 0.9813\n",
      "Epoch 27/500\n",
      "39680/40200 [============================>.] - ETA: 0s - loss: 0.1001 - acc: 0.9680\n",
      "Epoch 00027: val_loss improved from 0.06018 to 0.05732, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_2_conv_checkpoint/027-0.0573.hdf5\n",
      "40200/40200 [==============================] - 5s 112us/sample - loss: 0.1002 - acc: 0.9680 - val_loss: 0.0573 - val_acc: 0.9819\n",
      "Epoch 28/500\n",
      "39744/40200 [============================>.] - ETA: 0s - loss: 0.0970 - acc: 0.9686\n",
      "Epoch 00028: val_loss improved from 0.05732 to 0.05595, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_2_conv_checkpoint/028-0.0559.hdf5\n",
      "40200/40200 [==============================] - 4s 112us/sample - loss: 0.0972 - acc: 0.9685 - val_loss: 0.0559 - val_acc: 0.9828\n",
      "Epoch 29/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.0961 - acc: 0.9690\n",
      "Epoch 00029: val_loss did not improve from 0.05595\n",
      "40200/40200 [==============================] - 4s 109us/sample - loss: 0.0961 - acc: 0.9690 - val_loss: 0.0561 - val_acc: 0.9829\n",
      "Epoch 30/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.0972 - acc: 0.9690\n",
      "Epoch 00030: val_loss improved from 0.05595 to 0.05592, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_2_conv_checkpoint/030-0.0559.hdf5\n",
      "40200/40200 [==============================] - 4s 101us/sample - loss: 0.0969 - acc: 0.9690 - val_loss: 0.0559 - val_acc: 0.9830\n",
      "Epoch 31/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.0902 - acc: 0.9707\n",
      "Epoch 00031: val_loss improved from 0.05592 to 0.05418, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_2_conv_checkpoint/031-0.0542.hdf5\n",
      "40200/40200 [==============================] - 4s 109us/sample - loss: 0.0901 - acc: 0.9708 - val_loss: 0.0542 - val_acc: 0.9836\n",
      "Epoch 32/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.0883 - acc: 0.9707\n",
      "Epoch 00032: val_loss improved from 0.05418 to 0.05312, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_2_conv_checkpoint/032-0.0531.hdf5\n",
      "40200/40200 [==============================] - 5s 113us/sample - loss: 0.0882 - acc: 0.9707 - val_loss: 0.0531 - val_acc: 0.9839\n",
      "Epoch 33/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.0857 - acc: 0.9724\n",
      "Epoch 00033: val_loss did not improve from 0.05312\n",
      "40200/40200 [==============================] - 5s 112us/sample - loss: 0.0858 - acc: 0.9723 - val_loss: 0.0532 - val_acc: 0.9835\n",
      "Epoch 34/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.0852 - acc: 0.9732\n",
      "Epoch 00034: val_loss improved from 0.05312 to 0.05114, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_2_conv_checkpoint/034-0.0511.hdf5\n",
      "40200/40200 [==============================] - 5s 112us/sample - loss: 0.0852 - acc: 0.9732 - val_loss: 0.0511 - val_acc: 0.9843\n",
      "Epoch 35/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.0827 - acc: 0.9737\n",
      "Epoch 00035: val_loss did not improve from 0.05114\n",
      "40200/40200 [==============================] - 4s 110us/sample - loss: 0.0826 - acc: 0.9738 - val_loss: 0.0525 - val_acc: 0.9840\n",
      "Epoch 36/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.0849 - acc: 0.9733\n",
      "Epoch 00036: val_loss did not improve from 0.05114\n",
      "40200/40200 [==============================] - 4s 110us/sample - loss: 0.0846 - acc: 0.9734 - val_loss: 0.0530 - val_acc: 0.9836\n",
      "Epoch 37/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.0818 - acc: 0.9744\n",
      "Epoch 00037: val_loss improved from 0.05114 to 0.04978, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_2_conv_checkpoint/037-0.0498.hdf5\n",
      "40200/40200 [==============================] - 4s 110us/sample - loss: 0.0817 - acc: 0.9745 - val_loss: 0.0498 - val_acc: 0.9845\n",
      "Epoch 38/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.0802 - acc: 0.9739\n",
      "Epoch 00038: val_loss did not improve from 0.04978\n",
      "40200/40200 [==============================] - 4s 109us/sample - loss: 0.0802 - acc: 0.9739 - val_loss: 0.0498 - val_acc: 0.9843\n",
      "Epoch 39/500\n",
      "39680/40200 [============================>.] - ETA: 0s - loss: 0.0785 - acc: 0.9741\n",
      "Epoch 00039: val_loss improved from 0.04978 to 0.04881, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_2_conv_checkpoint/039-0.0488.hdf5\n",
      "40200/40200 [==============================] - 5s 113us/sample - loss: 0.0783 - acc: 0.9741 - val_loss: 0.0488 - val_acc: 0.9846\n",
      "Epoch 40/500\n",
      "39744/40200 [============================>.] - ETA: 0s - loss: 0.0780 - acc: 0.9753\n",
      "Epoch 00040: val_loss improved from 0.04881 to 0.04827, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_2_conv_checkpoint/040-0.0483.hdf5\n",
      "40200/40200 [==============================] - 5s 113us/sample - loss: 0.0781 - acc: 0.9753 - val_loss: 0.0483 - val_acc: 0.9851\n",
      "Epoch 41/500\n",
      "39680/40200 [============================>.] - ETA: 0s - loss: 0.0744 - acc: 0.9759\n",
      "Epoch 00041: val_loss did not improve from 0.04827\n",
      "40200/40200 [==============================] - 4s 112us/sample - loss: 0.0743 - acc: 0.9759 - val_loss: 0.0492 - val_acc: 0.9844\n",
      "Epoch 42/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.0738 - acc: 0.9762\n",
      "Epoch 00042: val_loss improved from 0.04827 to 0.04823, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_2_conv_checkpoint/042-0.0482.hdf5\n",
      "40200/40200 [==============================] - 5s 113us/sample - loss: 0.0738 - acc: 0.9761 - val_loss: 0.0482 - val_acc: 0.9854\n",
      "Epoch 43/500\n",
      "39744/40200 [============================>.] - ETA: 0s - loss: 0.0753 - acc: 0.9764\n",
      "Epoch 00043: val_loss improved from 0.04823 to 0.04795, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_2_conv_checkpoint/043-0.0480.hdf5\n",
      "40200/40200 [==============================] - 5s 112us/sample - loss: 0.0756 - acc: 0.9763 - val_loss: 0.0480 - val_acc: 0.9854\n",
      "Epoch 44/500\n",
      "39616/40200 [============================>.] - ETA: 0s - loss: 0.0709 - acc: 0.9766\n",
      "Epoch 00044: val_loss improved from 0.04795 to 0.04759, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_2_conv_checkpoint/044-0.0476.hdf5\n",
      "40200/40200 [==============================] - 4s 101us/sample - loss: 0.0709 - acc: 0.9766 - val_loss: 0.0476 - val_acc: 0.9853\n",
      "Epoch 45/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.0722 - acc: 0.9768\n",
      "Epoch 00045: val_loss improved from 0.04759 to 0.04701, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_2_conv_checkpoint/045-0.0470.hdf5\n",
      "40200/40200 [==============================] - 4s 110us/sample - loss: 0.0721 - acc: 0.9769 - val_loss: 0.0470 - val_acc: 0.9854\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.0705 - acc: 0.9772\n",
      "Epoch 00046: val_loss did not improve from 0.04701\n",
      "40200/40200 [==============================] - 4s 109us/sample - loss: 0.0704 - acc: 0.9772 - val_loss: 0.0473 - val_acc: 0.9859\n",
      "Epoch 47/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.0733 - acc: 0.9767\n",
      "Epoch 00047: val_loss improved from 0.04701 to 0.04667, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_2_conv_checkpoint/047-0.0467.hdf5\n",
      "40200/40200 [==============================] - 4s 111us/sample - loss: 0.0731 - acc: 0.9767 - val_loss: 0.0467 - val_acc: 0.9859\n",
      "Epoch 48/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.0718 - acc: 0.9764\n",
      "Epoch 00048: val_loss did not improve from 0.04667\n",
      "40200/40200 [==============================] - 4s 112us/sample - loss: 0.0719 - acc: 0.9764 - val_loss: 0.0491 - val_acc: 0.9847\n",
      "Epoch 49/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.0699 - acc: 0.9772\n",
      "Epoch 00049: val_loss improved from 0.04667 to 0.04614, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_2_conv_checkpoint/049-0.0461.hdf5\n",
      "40200/40200 [==============================] - 5s 112us/sample - loss: 0.0699 - acc: 0.9772 - val_loss: 0.0461 - val_acc: 0.9856\n",
      "Epoch 50/500\n",
      "39744/40200 [============================>.] - ETA: 0s - loss: 0.0696 - acc: 0.9770\n",
      "Epoch 00050: val_loss improved from 0.04614 to 0.04525, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_2_conv_checkpoint/050-0.0453.hdf5\n",
      "40200/40200 [==============================] - 4s 112us/sample - loss: 0.0698 - acc: 0.9770 - val_loss: 0.0453 - val_acc: 0.9858\n",
      "Epoch 51/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.0702 - acc: 0.9767\n",
      "Epoch 00051: val_loss did not improve from 0.04525\n",
      "40200/40200 [==============================] - 5s 112us/sample - loss: 0.0702 - acc: 0.9767 - val_loss: 0.0464 - val_acc: 0.9856\n",
      "Epoch 52/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.0699 - acc: 0.9774\n",
      "Epoch 00052: val_loss did not improve from 0.04525\n",
      "40200/40200 [==============================] - 4s 111us/sample - loss: 0.0699 - acc: 0.9774 - val_loss: 0.0458 - val_acc: 0.9858\n",
      "Epoch 53/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.0672 - acc: 0.9775\n",
      "Epoch 00053: val_loss did not improve from 0.04525\n",
      "40200/40200 [==============================] - 4s 110us/sample - loss: 0.0672 - acc: 0.9775 - val_loss: 0.0461 - val_acc: 0.9861\n",
      "Epoch 54/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.0660 - acc: 0.9778\n",
      "Epoch 00054: val_loss did not improve from 0.04525\n",
      "40200/40200 [==============================] - 4s 110us/sample - loss: 0.0661 - acc: 0.9778 - val_loss: 0.0454 - val_acc: 0.9859\n",
      "Epoch 55/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.0682 - acc: 0.9778\n",
      "Epoch 00055: val_loss did not improve from 0.04525\n",
      "40200/40200 [==============================] - 4s 111us/sample - loss: 0.0682 - acc: 0.9778 - val_loss: 0.0455 - val_acc: 0.9854\n",
      "Epoch 56/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.0616 - acc: 0.9796\n",
      "Epoch 00056: val_loss improved from 0.04525 to 0.04450, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_2_conv_checkpoint/056-0.0445.hdf5\n",
      "40200/40200 [==============================] - 4s 112us/sample - loss: 0.0617 - acc: 0.9796 - val_loss: 0.0445 - val_acc: 0.9859\n",
      "Epoch 57/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.0642 - acc: 0.9789\n",
      "Epoch 00057: val_loss improved from 0.04450 to 0.04379, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_2_conv_checkpoint/057-0.0438.hdf5\n",
      "40200/40200 [==============================] - 4s 110us/sample - loss: 0.0641 - acc: 0.9789 - val_loss: 0.0438 - val_acc: 0.9861\n",
      "Epoch 58/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.0602 - acc: 0.9800\n",
      "Epoch 00058: val_loss did not improve from 0.04379\n",
      "40200/40200 [==============================] - 4s 103us/sample - loss: 0.0604 - acc: 0.9800 - val_loss: 0.0473 - val_acc: 0.9855\n",
      "Epoch 59/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.0611 - acc: 0.9804\n",
      "Epoch 00059: val_loss did not improve from 0.04379\n",
      "40200/40200 [==============================] - 4s 110us/sample - loss: 0.0615 - acc: 0.9803 - val_loss: 0.0449 - val_acc: 0.9857\n",
      "Epoch 60/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.0618 - acc: 0.9800\n",
      "Epoch 00060: val_loss did not improve from 0.04379\n",
      "40200/40200 [==============================] - 4s 111us/sample - loss: 0.0620 - acc: 0.9800 - val_loss: 0.0443 - val_acc: 0.9860\n",
      "Epoch 61/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.0656 - acc: 0.9786\n",
      "Epoch 00061: val_loss improved from 0.04379 to 0.04376, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_2_conv_checkpoint/061-0.0438.hdf5\n",
      "40200/40200 [==============================] - 4s 112us/sample - loss: 0.0656 - acc: 0.9786 - val_loss: 0.0438 - val_acc: 0.9865\n",
      "Epoch 62/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.0627 - acc: 0.9796\n",
      "Epoch 00062: val_loss did not improve from 0.04376\n",
      "40200/40200 [==============================] - 4s 111us/sample - loss: 0.0626 - acc: 0.9797 - val_loss: 0.0446 - val_acc: 0.9867\n",
      "Epoch 63/500\n",
      "39744/40200 [============================>.] - ETA: 0s - loss: 0.0647 - acc: 0.9795\n",
      "Epoch 00063: val_loss did not improve from 0.04376\n",
      "40200/40200 [==============================] - 4s 110us/sample - loss: 0.0649 - acc: 0.9793 - val_loss: 0.0446 - val_acc: 0.9861\n",
      "Epoch 64/500\n",
      "39680/40200 [============================>.] - ETA: 0s - loss: 0.0600 - acc: 0.9797\n",
      "Epoch 00064: val_loss improved from 0.04376 to 0.04265, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_2_conv_checkpoint/064-0.0427.hdf5\n",
      "40200/40200 [==============================] - 4s 112us/sample - loss: 0.0602 - acc: 0.9796 - val_loss: 0.0427 - val_acc: 0.9864\n",
      "Epoch 65/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.0607 - acc: 0.9796\n",
      "Epoch 00065: val_loss did not improve from 0.04265\n",
      "40200/40200 [==============================] - 4s 112us/sample - loss: 0.0606 - acc: 0.9796 - val_loss: 0.0429 - val_acc: 0.9867\n",
      "Epoch 66/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.0603 - acc: 0.9803\n",
      "Epoch 00066: val_loss improved from 0.04265 to 0.04215, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_2_conv_checkpoint/066-0.0422.hdf5\n",
      "40200/40200 [==============================] - 4s 111us/sample - loss: 0.0604 - acc: 0.9802 - val_loss: 0.0422 - val_acc: 0.9868\n",
      "Epoch 67/500\n",
      "39680/40200 [============================>.] - ETA: 0s - loss: 0.0607 - acc: 0.9803\n",
      "Epoch 00067: val_loss did not improve from 0.04215\n",
      "40200/40200 [==============================] - 4s 111us/sample - loss: 0.0608 - acc: 0.9803 - val_loss: 0.0441 - val_acc: 0.9862\n",
      "Epoch 68/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.0568 - acc: 0.9810\n",
      "Epoch 00068: val_loss did not improve from 0.04215\n",
      "40200/40200 [==============================] - 5s 112us/sample - loss: 0.0570 - acc: 0.9810 - val_loss: 0.0435 - val_acc: 0.9860\n",
      "Epoch 69/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.0593 - acc: 0.9801\n",
      "Epoch 00069: val_loss did not improve from 0.04215\n",
      "40200/40200 [==============================] - 4s 111us/sample - loss: 0.0592 - acc: 0.9801 - val_loss: 0.0439 - val_acc: 0.9866\n",
      "Epoch 70/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.0563 - acc: 0.9812\n",
      "Epoch 00070: val_loss did not improve from 0.04215\n",
      "40200/40200 [==============================] - 4s 110us/sample - loss: 0.0564 - acc: 0.9811 - val_loss: 0.0451 - val_acc: 0.9859\n",
      "Epoch 71/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.0583 - acc: 0.9801\n",
      "Epoch 00071: val_loss did not improve from 0.04215\n",
      "40200/40200 [==============================] - 4s 100us/sample - loss: 0.0583 - acc: 0.9801 - val_loss: 0.0446 - val_acc: 0.9862\n",
      "Epoch 72/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.0558 - acc: 0.9815\n",
      "Epoch 00072: val_loss did not improve from 0.04215\n",
      "40200/40200 [==============================] - 4s 108us/sample - loss: 0.0561 - acc: 0.9815 - val_loss: 0.0452 - val_acc: 0.9854\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.0576 - acc: 0.9804\n",
      "Epoch 00073: val_loss did not improve from 0.04215\n",
      "40200/40200 [==============================] - 4s 111us/sample - loss: 0.0578 - acc: 0.9804 - val_loss: 0.0439 - val_acc: 0.9860\n",
      "Epoch 74/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.0575 - acc: 0.9811\n",
      "Epoch 00074: val_loss did not improve from 0.04215\n",
      "40200/40200 [==============================] - 4s 111us/sample - loss: 0.0576 - acc: 0.9811 - val_loss: 0.0433 - val_acc: 0.9863\n",
      "Epoch 75/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.0579 - acc: 0.9807\n",
      "Epoch 00075: val_loss did not improve from 0.04215\n",
      "40200/40200 [==============================] - 5s 113us/sample - loss: 0.0579 - acc: 0.9807 - val_loss: 0.0456 - val_acc: 0.9852\n",
      "Epoch 76/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.0546 - acc: 0.9818\n",
      "Epoch 00076: val_loss did not improve from 0.04215\n",
      "40200/40200 [==============================] - 4s 111us/sample - loss: 0.0547 - acc: 0.9819 - val_loss: 0.0426 - val_acc: 0.9867\n",
      "Epoch 77/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.0543 - acc: 0.9819\n",
      "Epoch 00077: val_loss did not improve from 0.04215\n",
      "40200/40200 [==============================] - 4s 111us/sample - loss: 0.0544 - acc: 0.9818 - val_loss: 0.0428 - val_acc: 0.9864\n",
      "Epoch 78/500\n",
      "39680/40200 [============================>.] - ETA: 0s - loss: 0.0553 - acc: 0.9814\n",
      "Epoch 00078: val_loss did not improve from 0.04215\n",
      "40200/40200 [==============================] - 4s 109us/sample - loss: 0.0552 - acc: 0.9814 - val_loss: 0.0440 - val_acc: 0.9859\n",
      "Epoch 79/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.0554 - acc: 0.9815\n",
      "Epoch 00079: val_loss did not improve from 0.04215\n",
      "40200/40200 [==============================] - 4s 110us/sample - loss: 0.0558 - acc: 0.9813 - val_loss: 0.0425 - val_acc: 0.9870\n",
      "Epoch 80/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.0563 - acc: 0.9809\n",
      "Epoch 00080: val_loss did not improve from 0.04215\n",
      "40200/40200 [==============================] - 4s 110us/sample - loss: 0.0563 - acc: 0.9809 - val_loss: 0.0432 - val_acc: 0.9861\n",
      "Epoch 81/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.0554 - acc: 0.9818\n",
      "Epoch 00081: val_loss did not improve from 0.04215\n",
      "40200/40200 [==============================] - 4s 111us/sample - loss: 0.0558 - acc: 0.9817 - val_loss: 0.0423 - val_acc: 0.9860\n",
      "Epoch 82/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.0548 - acc: 0.9821\n",
      "Epoch 00082: val_loss did not improve from 0.04215\n",
      "40200/40200 [==============================] - 4s 109us/sample - loss: 0.0547 - acc: 0.9821 - val_loss: 0.0437 - val_acc: 0.9860\n",
      "Epoch 83/500\n",
      "39744/40200 [============================>.] - ETA: 0s - loss: 0.0551 - acc: 0.9822\n",
      "Epoch 00083: val_loss did not improve from 0.04215\n",
      "40200/40200 [==============================] - 4s 109us/sample - loss: 0.0552 - acc: 0.9822 - val_loss: 0.0425 - val_acc: 0.9865\n",
      "Epoch 84/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.0530 - acc: 0.9829\n",
      "Epoch 00084: val_loss did not improve from 0.04215\n",
      "40200/40200 [==============================] - 4s 110us/sample - loss: 0.0530 - acc: 0.9829 - val_loss: 0.0425 - val_acc: 0.9862\n",
      "Epoch 85/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.0533 - acc: 0.9824\n",
      "Epoch 00085: val_loss improved from 0.04215 to 0.04179, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_2_conv_checkpoint/085-0.0418.hdf5\n",
      "40200/40200 [==============================] - 4s 100us/sample - loss: 0.0533 - acc: 0.9824 - val_loss: 0.0418 - val_acc: 0.9871\n",
      "Epoch 86/500\n",
      "39680/40200 [============================>.] - ETA: 0s - loss: 0.0544 - acc: 0.9821\n",
      "Epoch 00086: val_loss did not improve from 0.04179\n",
      "40200/40200 [==============================] - 4s 111us/sample - loss: 0.0544 - acc: 0.9821 - val_loss: 0.0439 - val_acc: 0.9858\n",
      "Epoch 87/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.0532 - acc: 0.9822\n",
      "Epoch 00087: val_loss did not improve from 0.04179\n",
      "40200/40200 [==============================] - 4s 111us/sample - loss: 0.0534 - acc: 0.9821 - val_loss: 0.0425 - val_acc: 0.9867\n",
      "Epoch 88/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.0537 - acc: 0.9820\n",
      "Epoch 00088: val_loss did not improve from 0.04179\n",
      "40200/40200 [==============================] - 5s 112us/sample - loss: 0.0535 - acc: 0.9820 - val_loss: 0.0426 - val_acc: 0.9869\n",
      "Epoch 89/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.0515 - acc: 0.9825\n",
      "Epoch 00089: val_loss did not improve from 0.04179\n",
      "40200/40200 [==============================] - 5s 112us/sample - loss: 0.0515 - acc: 0.9825 - val_loss: 0.0453 - val_acc: 0.9860\n",
      "Epoch 90/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.0511 - acc: 0.9831\n",
      "Epoch 00090: val_loss did not improve from 0.04179\n",
      "40200/40200 [==============================] - 4s 111us/sample - loss: 0.0511 - acc: 0.9831 - val_loss: 0.0434 - val_acc: 0.9868\n",
      "Epoch 91/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.0526 - acc: 0.9823\n",
      "Epoch 00091: val_loss did not improve from 0.04179\n",
      "40200/40200 [==============================] - 4s 110us/sample - loss: 0.0526 - acc: 0.9823 - val_loss: 0.0468 - val_acc: 0.9855\n",
      "Epoch 92/500\n",
      "39680/40200 [============================>.] - ETA: 0s - loss: 0.0508 - acc: 0.9827\n",
      "Epoch 00092: val_loss did not improve from 0.04179\n",
      "40200/40200 [==============================] - 4s 111us/sample - loss: 0.0510 - acc: 0.9825 - val_loss: 0.0429 - val_acc: 0.9860\n",
      "Epoch 93/500\n",
      "39680/40200 [============================>.] - ETA: 0s - loss: 0.0496 - acc: 0.9834\n",
      "Epoch 00093: val_loss did not improve from 0.04179\n",
      "40200/40200 [==============================] - 4s 111us/sample - loss: 0.0496 - acc: 0.9834 - val_loss: 0.0425 - val_acc: 0.9866\n",
      "Epoch 94/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.0511 - acc: 0.9828\n",
      "Epoch 00094: val_loss did not improve from 0.04179\n",
      "40200/40200 [==============================] - 4s 111us/sample - loss: 0.0510 - acc: 0.9829 - val_loss: 0.0434 - val_acc: 0.9860\n",
      "Epoch 95/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.0518 - acc: 0.9830\n",
      "Epoch 00095: val_loss improved from 0.04179 to 0.04150, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_2_conv_checkpoint/095-0.0415.hdf5\n",
      "40200/40200 [==============================] - 5s 112us/sample - loss: 0.0519 - acc: 0.9830 - val_loss: 0.0415 - val_acc: 0.9870\n",
      "Epoch 96/500\n",
      "39680/40200 [============================>.] - ETA: 0s - loss: 0.0514 - acc: 0.9830\n",
      "Epoch 00096: val_loss did not improve from 0.04150\n",
      "40200/40200 [==============================] - 4s 111us/sample - loss: 0.0514 - acc: 0.9831 - val_loss: 0.0420 - val_acc: 0.9864\n",
      "Epoch 97/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.0528 - acc: 0.9827\n",
      "Epoch 00097: val_loss did not improve from 0.04150\n",
      "40200/40200 [==============================] - 4s 112us/sample - loss: 0.0527 - acc: 0.9827 - val_loss: 0.0439 - val_acc: 0.9862\n",
      "Epoch 98/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.0504 - acc: 0.9835\n",
      "Epoch 00098: val_loss did not improve from 0.04150\n",
      "40200/40200 [==============================] - 4s 107us/sample - loss: 0.0504 - acc: 0.9835 - val_loss: 0.0436 - val_acc: 0.9866\n",
      "Epoch 99/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.0516 - acc: 0.9833\n",
      "Epoch 00099: val_loss did not improve from 0.04150\n",
      "40200/40200 [==============================] - 4s 102us/sample - loss: 0.0516 - acc: 0.9833 - val_loss: 0.0420 - val_acc: 0.9866\n",
      "Epoch 100/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.0524 - acc: 0.9830\n",
      "Epoch 00100: val_loss did not improve from 0.04150\n",
      "40200/40200 [==============================] - 4s 111us/sample - loss: 0.0524 - acc: 0.9830 - val_loss: 0.0426 - val_acc: 0.9863\n",
      "Epoch 101/500\n",
      "39744/40200 [============================>.] - ETA: 0s - loss: 0.0506 - acc: 0.9833\n",
      "Epoch 00101: val_loss improved from 0.04150 to 0.04097, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_2_conv_checkpoint/101-0.0410.hdf5\n",
      "40200/40200 [==============================] - 5s 112us/sample - loss: 0.0507 - acc: 0.9833 - val_loss: 0.0410 - val_acc: 0.9875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 102/500\n",
      "39680/40200 [============================>.] - ETA: 0s - loss: 0.0504 - acc: 0.9836\n",
      "Epoch 00102: val_loss did not improve from 0.04097\n",
      "40200/40200 [==============================] - 4s 111us/sample - loss: 0.0502 - acc: 0.9837 - val_loss: 0.0439 - val_acc: 0.9864\n",
      "Epoch 103/500\n",
      "39680/40200 [============================>.] - ETA: 0s - loss: 0.0504 - acc: 0.9825\n",
      "Epoch 00103: val_loss did not improve from 0.04097\n",
      "40200/40200 [==============================] - 4s 111us/sample - loss: 0.0504 - acc: 0.9825 - val_loss: 0.0412 - val_acc: 0.9868\n",
      "Epoch 104/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.0503 - acc: 0.9834\n",
      "Epoch 00104: val_loss did not improve from 0.04097\n",
      "40200/40200 [==============================] - 4s 109us/sample - loss: 0.0503 - acc: 0.9834 - val_loss: 0.0426 - val_acc: 0.9867\n",
      "Epoch 105/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.0492 - acc: 0.9834\n",
      "Epoch 00105: val_loss improved from 0.04097 to 0.04080, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_2_conv_checkpoint/105-0.0408.hdf5\n",
      "40200/40200 [==============================] - 5s 112us/sample - loss: 0.0491 - acc: 0.9834 - val_loss: 0.0408 - val_acc: 0.9870\n",
      "Epoch 106/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.0488 - acc: 0.9841\n",
      "Epoch 00106: val_loss did not improve from 0.04080\n",
      "40200/40200 [==============================] - 4s 112us/sample - loss: 0.0490 - acc: 0.9841 - val_loss: 0.0424 - val_acc: 0.9862\n",
      "Epoch 107/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.0488 - acc: 0.9828\n",
      "Epoch 00107: val_loss did not improve from 0.04080\n",
      "40200/40200 [==============================] - 5s 112us/sample - loss: 0.0486 - acc: 0.9829 - val_loss: 0.0421 - val_acc: 0.9865\n",
      "Epoch 108/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.0479 - acc: 0.9842\n",
      "Epoch 00108: val_loss did not improve from 0.04080\n",
      "40200/40200 [==============================] - 4s 111us/sample - loss: 0.0478 - acc: 0.9842 - val_loss: 0.0413 - val_acc: 0.9869\n",
      "Epoch 109/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.0492 - acc: 0.9838\n",
      "Epoch 00109: val_loss did not improve from 0.04080\n",
      "40200/40200 [==============================] - 4s 112us/sample - loss: 0.0491 - acc: 0.9838 - val_loss: 0.0414 - val_acc: 0.9868\n",
      "Epoch 110/500\n",
      "39744/40200 [============================>.] - ETA: 0s - loss: 0.0487 - acc: 0.9843\n",
      "Epoch 00110: val_loss did not improve from 0.04080\n",
      "40200/40200 [==============================] - 4s 111us/sample - loss: 0.0487 - acc: 0.9843 - val_loss: 0.0417 - val_acc: 0.9868\n",
      "Epoch 111/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.0471 - acc: 0.9838\n",
      "Epoch 00111: val_loss did not improve from 0.04080\n",
      "40200/40200 [==============================] - 5s 112us/sample - loss: 0.0471 - acc: 0.9838 - val_loss: 0.0430 - val_acc: 0.9872\n",
      "Epoch 112/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.0481 - acc: 0.9839\n",
      "Epoch 00112: val_loss improved from 0.04080 to 0.04039, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_2_conv_checkpoint/112-0.0404.hdf5\n",
      "40200/40200 [==============================] - 4s 106us/sample - loss: 0.0480 - acc: 0.9839 - val_loss: 0.0404 - val_acc: 0.9877\n",
      "Epoch 113/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.0464 - acc: 0.9845\n",
      "Epoch 00113: val_loss did not improve from 0.04039\n",
      "40200/40200 [==============================] - 4s 104us/sample - loss: 0.0469 - acc: 0.9844 - val_loss: 0.0413 - val_acc: 0.9869\n",
      "Epoch 114/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.0476 - acc: 0.9838\n",
      "Epoch 00114: val_loss improved from 0.04039 to 0.04036, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_2_conv_checkpoint/114-0.0404.hdf5\n",
      "40200/40200 [==============================] - 4s 111us/sample - loss: 0.0476 - acc: 0.9838 - val_loss: 0.0404 - val_acc: 0.9870\n",
      "Epoch 115/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.0485 - acc: 0.9835\n",
      "Epoch 00115: val_loss did not improve from 0.04036\n",
      "40200/40200 [==============================] - 4s 110us/sample - loss: 0.0484 - acc: 0.9836 - val_loss: 0.0404 - val_acc: 0.9878\n",
      "Epoch 116/500\n",
      "39680/40200 [============================>.] - ETA: 0s - loss: 0.0456 - acc: 0.9844\n",
      "Epoch 00116: val_loss did not improve from 0.04036\n",
      "40200/40200 [==============================] - 4s 106us/sample - loss: 0.0458 - acc: 0.9843 - val_loss: 0.0409 - val_acc: 0.9868\n",
      "Epoch 117/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.0480 - acc: 0.9829\n",
      "Epoch 00117: val_loss did not improve from 0.04036\n",
      "40200/40200 [==============================] - 4s 109us/sample - loss: 0.0479 - acc: 0.9829 - val_loss: 0.0435 - val_acc: 0.9863\n",
      "Epoch 118/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.0491 - acc: 0.9834\n",
      "Epoch 00118: val_loss did not improve from 0.04036\n",
      "40200/40200 [==============================] - 4s 111us/sample - loss: 0.0490 - acc: 0.9834 - val_loss: 0.0417 - val_acc: 0.9865\n",
      "Epoch 119/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.0496 - acc: 0.9831\n",
      "Epoch 00119: val_loss did not improve from 0.04036\n",
      "40200/40200 [==============================] - 4s 110us/sample - loss: 0.0496 - acc: 0.9831 - val_loss: 0.0419 - val_acc: 0.9868\n",
      "Epoch 120/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.0463 - acc: 0.9848\n",
      "Epoch 00120: val_loss did not improve from 0.04036\n",
      "40200/40200 [==============================] - 4s 111us/sample - loss: 0.0464 - acc: 0.9848 - val_loss: 0.0409 - val_acc: 0.9873\n",
      "Epoch 121/500\n",
      "39744/40200 [============================>.] - ETA: 0s - loss: 0.0475 - acc: 0.9843\n",
      "Epoch 00121: val_loss did not improve from 0.04036\n",
      "40200/40200 [==============================] - 4s 111us/sample - loss: 0.0474 - acc: 0.9844 - val_loss: 0.0411 - val_acc: 0.9870\n",
      "Epoch 122/500\n",
      "39744/40200 [============================>.] - ETA: 0s - loss: 0.0457 - acc: 0.9847\n",
      "Epoch 00122: val_loss did not improve from 0.04036\n",
      "40200/40200 [==============================] - 4s 112us/sample - loss: 0.0458 - acc: 0.9846 - val_loss: 0.0417 - val_acc: 0.9877\n",
      "Epoch 123/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.0449 - acc: 0.9852\n",
      "Epoch 00123: val_loss did not improve from 0.04036\n",
      "40200/40200 [==============================] - 4s 110us/sample - loss: 0.0448 - acc: 0.9852 - val_loss: 0.0419 - val_acc: 0.9871\n",
      "Epoch 124/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.0429 - acc: 0.9855\n",
      "Epoch 00124: val_loss did not improve from 0.04036\n",
      "40200/40200 [==============================] - 4s 110us/sample - loss: 0.0427 - acc: 0.9856 - val_loss: 0.0406 - val_acc: 0.9874\n",
      "Epoch 125/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.0482 - acc: 0.9844\n",
      "Epoch 00125: val_loss did not improve from 0.04036\n",
      "40200/40200 [==============================] - 5s 112us/sample - loss: 0.0482 - acc: 0.9844 - val_loss: 0.0406 - val_acc: 0.9869\n",
      "Epoch 126/500\n",
      "39616/40200 [============================>.] - ETA: 0s - loss: 0.0474 - acc: 0.9844\n",
      "Epoch 00126: val_loss did not improve from 0.04036\n",
      "40200/40200 [==============================] - 4s 101us/sample - loss: 0.0473 - acc: 0.9844 - val_loss: 0.0409 - val_acc: 0.9874\n",
      "Epoch 127/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.0467 - acc: 0.9848\n",
      "Epoch 00127: val_loss did not improve from 0.04036\n",
      "40200/40200 [==============================] - 4s 107us/sample - loss: 0.0467 - acc: 0.9848 - val_loss: 0.0405 - val_acc: 0.9871\n",
      "Epoch 128/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.0485 - acc: 0.9832\n",
      "Epoch 00128: val_loss improved from 0.04036 to 0.04016, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_2_conv_checkpoint/128-0.0402.hdf5\n",
      "40200/40200 [==============================] - 4s 112us/sample - loss: 0.0485 - acc: 0.9832 - val_loss: 0.0402 - val_acc: 0.9873\n",
      "Epoch 129/500\n",
      "39680/40200 [============================>.] - ETA: 0s - loss: 0.0454 - acc: 0.9846\n",
      "Epoch 00129: val_loss did not improve from 0.04016\n",
      "40200/40200 [==============================] - 4s 111us/sample - loss: 0.0457 - acc: 0.9844 - val_loss: 0.0425 - val_acc: 0.9872\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 130/500\n",
      "39680/40200 [============================>.] - ETA: 0s - loss: 0.0455 - acc: 0.9844\n",
      "Epoch 00130: val_loss did not improve from 0.04016\n",
      "40200/40200 [==============================] - 4s 110us/sample - loss: 0.0454 - acc: 0.9844 - val_loss: 0.0416 - val_acc: 0.9871\n",
      "Epoch 131/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.0434 - acc: 0.9858\n",
      "Epoch 00131: val_loss did not improve from 0.04016\n",
      "40200/40200 [==============================] - 4s 110us/sample - loss: 0.0433 - acc: 0.9858 - val_loss: 0.0429 - val_acc: 0.9870\n",
      "Epoch 132/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.0451 - acc: 0.9847\n",
      "Epoch 00132: val_loss did not improve from 0.04016\n",
      "40200/40200 [==============================] - 4s 110us/sample - loss: 0.0452 - acc: 0.9847 - val_loss: 0.0426 - val_acc: 0.9872\n",
      "Epoch 133/500\n",
      "39744/40200 [============================>.] - ETA: 0s - loss: 0.0435 - acc: 0.9852\n",
      "Epoch 00133: val_loss did not improve from 0.04016\n",
      "40200/40200 [==============================] - 4s 109us/sample - loss: 0.0439 - acc: 0.9851 - val_loss: 0.0418 - val_acc: 0.9874\n",
      "Epoch 134/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.0473 - acc: 0.9839\n",
      "Epoch 00134: val_loss did not improve from 0.04016\n",
      "40200/40200 [==============================] - 4s 111us/sample - loss: 0.0472 - acc: 0.9839 - val_loss: 0.0403 - val_acc: 0.9874\n",
      "Epoch 135/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.0456 - acc: 0.9841\n",
      "Epoch 00135: val_loss did not improve from 0.04016\n",
      "40200/40200 [==============================] - 4s 111us/sample - loss: 0.0455 - acc: 0.9841 - val_loss: 0.0408 - val_acc: 0.9872\n",
      "Epoch 136/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.0451 - acc: 0.9847\n",
      "Epoch 00136: val_loss did not improve from 0.04016\n",
      "40200/40200 [==============================] - 4s 111us/sample - loss: 0.0451 - acc: 0.9846 - val_loss: 0.0418 - val_acc: 0.9876\n",
      "Epoch 137/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.0430 - acc: 0.9858\n",
      "Epoch 00137: val_loss did not improve from 0.04016\n",
      "40200/40200 [==============================] - 4s 110us/sample - loss: 0.0429 - acc: 0.9858 - val_loss: 0.0421 - val_acc: 0.9874\n",
      "Epoch 138/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.0471 - acc: 0.9840\n",
      "Epoch 00138: val_loss did not improve from 0.04016\n",
      "40200/40200 [==============================] - 4s 111us/sample - loss: 0.0470 - acc: 0.9840 - val_loss: 0.0408 - val_acc: 0.9874\n",
      "Epoch 139/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.0449 - acc: 0.9848\n",
      "Epoch 00139: val_loss did not improve from 0.04016\n",
      "40200/40200 [==============================] - 4s 110us/sample - loss: 0.0449 - acc: 0.9848 - val_loss: 0.0416 - val_acc: 0.9868\n",
      "Epoch 140/500\n",
      "39744/40200 [============================>.] - ETA: 0s - loss: 0.0438 - acc: 0.9849\n",
      "Epoch 00140: val_loss did not improve from 0.04016\n",
      "40200/40200 [==============================] - 4s 102us/sample - loss: 0.0442 - acc: 0.9848 - val_loss: 0.0411 - val_acc: 0.9874\n",
      "Epoch 141/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.0467 - acc: 0.9847\n",
      "Epoch 00141: val_loss did not improve from 0.04016\n",
      "40200/40200 [==============================] - 4s 107us/sample - loss: 0.0468 - acc: 0.9847 - val_loss: 0.0406 - val_acc: 0.9873\n",
      "Epoch 142/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.0460 - acc: 0.9850\n",
      "Epoch 00142: val_loss did not improve from 0.04016\n",
      "40200/40200 [==============================] - 4s 110us/sample - loss: 0.0463 - acc: 0.9849 - val_loss: 0.0408 - val_acc: 0.9873\n",
      "Epoch 143/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.0432 - acc: 0.9852\n",
      "Epoch 00143: val_loss did not improve from 0.04016\n",
      "40200/40200 [==============================] - 4s 110us/sample - loss: 0.0432 - acc: 0.9852 - val_loss: 0.0405 - val_acc: 0.9875\n",
      "Epoch 144/500\n",
      "39744/40200 [============================>.] - ETA: 0s - loss: 0.0425 - acc: 0.9853\n",
      "Epoch 00144: val_loss did not improve from 0.04016\n",
      "40200/40200 [==============================] - 4s 110us/sample - loss: 0.0425 - acc: 0.9853 - val_loss: 0.0406 - val_acc: 0.9874\n",
      "Epoch 145/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.0423 - acc: 0.9860\n",
      "Epoch 00145: val_loss improved from 0.04016 to 0.03973, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_2_conv_checkpoint/145-0.0397.hdf5\n",
      "40200/40200 [==============================] - 4s 110us/sample - loss: 0.0425 - acc: 0.9860 - val_loss: 0.0397 - val_acc: 0.9878\n",
      "Epoch 146/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.0442 - acc: 0.9850\n",
      "Epoch 00146: val_loss did not improve from 0.03973\n",
      "40200/40200 [==============================] - 4s 111us/sample - loss: 0.0446 - acc: 0.9850 - val_loss: 0.0421 - val_acc: 0.9874\n",
      "Epoch 147/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.0425 - acc: 0.9863\n",
      "Epoch 00147: val_loss did not improve from 0.03973\n",
      "40200/40200 [==============================] - 5s 112us/sample - loss: 0.0428 - acc: 0.9863 - val_loss: 0.0404 - val_acc: 0.9873\n",
      "Epoch 148/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.0430 - acc: 0.9852\n",
      "Epoch 00148: val_loss did not improve from 0.03973\n",
      "40200/40200 [==============================] - 4s 111us/sample - loss: 0.0429 - acc: 0.9853 - val_loss: 0.0423 - val_acc: 0.9872\n",
      "Epoch 149/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.0444 - acc: 0.9854\n",
      "Epoch 00149: val_loss did not improve from 0.03973\n",
      "40200/40200 [==============================] - 4s 111us/sample - loss: 0.0444 - acc: 0.9854 - val_loss: 0.0428 - val_acc: 0.9872\n",
      "Epoch 150/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.0440 - acc: 0.9849\n",
      "Epoch 00150: val_loss did not improve from 0.03973\n",
      "40200/40200 [==============================] - 4s 109us/sample - loss: 0.0440 - acc: 0.9849 - val_loss: 0.0422 - val_acc: 0.9866\n",
      "Epoch 151/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.0420 - acc: 0.9861\n",
      "Epoch 00151: val_loss did not improve from 0.03973\n",
      "40200/40200 [==============================] - 4s 110us/sample - loss: 0.0419 - acc: 0.9861 - val_loss: 0.0413 - val_acc: 0.9875\n",
      "Epoch 152/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.0434 - acc: 0.9853\n",
      "Epoch 00152: val_loss did not improve from 0.03973\n",
      "40200/40200 [==============================] - 4s 110us/sample - loss: 0.0434 - acc: 0.9853 - val_loss: 0.0426 - val_acc: 0.9867\n",
      "Epoch 153/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.0451 - acc: 0.9857\n",
      "Epoch 00153: val_loss did not improve from 0.03973\n",
      "40200/40200 [==============================] - 4s 109us/sample - loss: 0.0452 - acc: 0.9856 - val_loss: 0.0410 - val_acc: 0.9869\n",
      "Epoch 154/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.0427 - acc: 0.9853\n",
      "Epoch 00154: val_loss did not improve from 0.03973\n",
      "40200/40200 [==============================] - 4s 100us/sample - loss: 0.0429 - acc: 0.9852 - val_loss: 0.0405 - val_acc: 0.9872\n",
      "Epoch 155/500\n",
      "39744/40200 [============================>.] - ETA: 0s - loss: 0.0416 - acc: 0.9863\n",
      "Epoch 00155: val_loss did not improve from 0.03973\n",
      "40200/40200 [==============================] - 4s 108us/sample - loss: 0.0418 - acc: 0.9862 - val_loss: 0.0418 - val_acc: 0.9870\n",
      "Epoch 156/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.0427 - acc: 0.9858\n",
      "Epoch 00156: val_loss did not improve from 0.03973\n",
      "40200/40200 [==============================] - 4s 110us/sample - loss: 0.0427 - acc: 0.9857 - val_loss: 0.0418 - val_acc: 0.9873\n",
      "Epoch 157/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.0446 - acc: 0.9855\n",
      "Epoch 00157: val_loss did not improve from 0.03973\n",
      "40200/40200 [==============================] - 4s 110us/sample - loss: 0.0448 - acc: 0.9854 - val_loss: 0.0401 - val_acc: 0.9874\n",
      "Epoch 158/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.0405 - acc: 0.9867\n",
      "Epoch 00158: val_loss did not improve from 0.03973\n",
      "40200/40200 [==============================] - 4s 110us/sample - loss: 0.0404 - acc: 0.9867 - val_loss: 0.0402 - val_acc: 0.9877\n",
      "Epoch 159/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.0445 - acc: 0.9851\n",
      "Epoch 00159: val_loss did not improve from 0.03973\n",
      "40200/40200 [==============================] - 4s 110us/sample - loss: 0.0445 - acc: 0.9851 - val_loss: 0.0403 - val_acc: 0.9873\n",
      "Epoch 160/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.0411 - acc: 0.9862\n",
      "Epoch 00160: val_loss did not improve from 0.03973\n",
      "40200/40200 [==============================] - 4s 110us/sample - loss: 0.0411 - acc: 0.9862 - val_loss: 0.0404 - val_acc: 0.9872\n",
      "Epoch 161/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.0414 - acc: 0.9864\n",
      "Epoch 00161: val_loss did not improve from 0.03973\n",
      "40200/40200 [==============================] - 4s 108us/sample - loss: 0.0414 - acc: 0.9864 - val_loss: 0.0431 - val_acc: 0.9867\n",
      "Epoch 162/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.0445 - acc: 0.9849\n",
      "Epoch 00162: val_loss did not improve from 0.03973\n",
      "40200/40200 [==============================] - 4s 111us/sample - loss: 0.0445 - acc: 0.9849 - val_loss: 0.0411 - val_acc: 0.9870\n",
      "Epoch 163/500\n",
      "39744/40200 [============================>.] - ETA: 0s - loss: 0.0422 - acc: 0.9856\n",
      "Epoch 00163: val_loss did not improve from 0.03973\n",
      "40200/40200 [==============================] - 4s 111us/sample - loss: 0.0421 - acc: 0.9856 - val_loss: 0.0422 - val_acc: 0.9869\n",
      "Epoch 164/500\n",
      "39680/40200 [============================>.] - ETA: 0s - loss: 0.0428 - acc: 0.9852\n",
      "Epoch 00164: val_loss did not improve from 0.03973\n",
      "40200/40200 [==============================] - 4s 111us/sample - loss: 0.0429 - acc: 0.9852 - val_loss: 0.0404 - val_acc: 0.9871\n",
      "Epoch 165/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.0411 - acc: 0.9863\n",
      "Epoch 00165: val_loss did not improve from 0.03973\n",
      "40200/40200 [==============================] - 4s 110us/sample - loss: 0.0409 - acc: 0.9863 - val_loss: 0.0416 - val_acc: 0.9867\n",
      "Epoch 166/500\n",
      "39744/40200 [============================>.] - ETA: 0s - loss: 0.0434 - acc: 0.9851\n",
      "Epoch 00166: val_loss did not improve from 0.03973\n",
      "40200/40200 [==============================] - 4s 111us/sample - loss: 0.0433 - acc: 0.9851 - val_loss: 0.0442 - val_acc: 0.9858\n",
      "Epoch 167/500\n",
      "39616/40200 [============================>.] - ETA: 0s - loss: 0.0408 - acc: 0.9861\n",
      "Epoch 00167: val_loss did not improve from 0.03973\n",
      "40200/40200 [==============================] - 4s 109us/sample - loss: 0.0406 - acc: 0.9862 - val_loss: 0.0421 - val_acc: 0.9868\n",
      "Epoch 168/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.0420 - acc: 0.9856\n",
      "Epoch 00168: val_loss did not improve from 0.03973\n",
      "40200/40200 [==============================] - 4s 102us/sample - loss: 0.0420 - acc: 0.9856 - val_loss: 0.0403 - val_acc: 0.9876\n",
      "Epoch 169/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.0418 - acc: 0.9856\n",
      "Epoch 00169: val_loss did not improve from 0.03973\n",
      "40200/40200 [==============================] - 4s 111us/sample - loss: 0.0418 - acc: 0.9856 - val_loss: 0.0413 - val_acc: 0.9878\n",
      "Epoch 170/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.0420 - acc: 0.9860\n",
      "Epoch 00170: val_loss did not improve from 0.03973\n",
      "40200/40200 [==============================] - 4s 110us/sample - loss: 0.0417 - acc: 0.9861 - val_loss: 0.0402 - val_acc: 0.9874\n",
      "Epoch 171/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.0411 - acc: 0.9862\n",
      "Epoch 00171: val_loss did not improve from 0.03973\n",
      "40200/40200 [==============================] - 4s 109us/sample - loss: 0.0412 - acc: 0.9862 - val_loss: 0.0408 - val_acc: 0.9876\n",
      "Epoch 172/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.0415 - acc: 0.9861\n",
      "Epoch 00172: val_loss improved from 0.03973 to 0.03946, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_2_conv_checkpoint/172-0.0395.hdf5\n",
      "40200/40200 [==============================] - 4s 112us/sample - loss: 0.0415 - acc: 0.9861 - val_loss: 0.0395 - val_acc: 0.9879\n",
      "Epoch 173/500\n",
      "39680/40200 [============================>.] - ETA: 0s - loss: 0.0453 - acc: 0.9847\n",
      "Epoch 00173: val_loss did not improve from 0.03946\n",
      "40200/40200 [==============================] - 4s 110us/sample - loss: 0.0454 - acc: 0.9846 - val_loss: 0.0414 - val_acc: 0.9875\n",
      "Epoch 174/500\n",
      "39680/40200 [============================>.] - ETA: 0s - loss: 0.0414 - acc: 0.9857\n",
      "Epoch 00174: val_loss did not improve from 0.03946\n",
      "40200/40200 [==============================] - 4s 111us/sample - loss: 0.0411 - acc: 0.9858 - val_loss: 0.0416 - val_acc: 0.9871\n",
      "Epoch 175/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.0426 - acc: 0.9858\n",
      "Epoch 00175: val_loss did not improve from 0.03946\n",
      "40200/40200 [==============================] - 4s 110us/sample - loss: 0.0425 - acc: 0.9858 - val_loss: 0.0405 - val_acc: 0.9874\n",
      "Epoch 176/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.0382 - acc: 0.9872\n",
      "Epoch 00176: val_loss did not improve from 0.03946\n",
      "40200/40200 [==============================] - 4s 112us/sample - loss: 0.0381 - acc: 0.9872 - val_loss: 0.0403 - val_acc: 0.9872\n",
      "Epoch 177/500\n",
      "39744/40200 [============================>.] - ETA: 0s - loss: 0.0413 - acc: 0.9860\n",
      "Epoch 00177: val_loss did not improve from 0.03946\n",
      "40200/40200 [==============================] - 4s 111us/sample - loss: 0.0413 - acc: 0.9860 - val_loss: 0.0402 - val_acc: 0.9877\n",
      "Epoch 178/500\n",
      "39680/40200 [============================>.] - ETA: 0s - loss: 0.0418 - acc: 0.9860\n",
      "Epoch 00178: val_loss did not improve from 0.03946\n",
      "40200/40200 [==============================] - 4s 110us/sample - loss: 0.0419 - acc: 0.9860 - val_loss: 0.0418 - val_acc: 0.9872\n",
      "Epoch 179/500\n",
      "39744/40200 [============================>.] - ETA: 0s - loss: 0.0411 - acc: 0.9862\n",
      "Epoch 00179: val_loss did not improve from 0.03946\n",
      "40200/40200 [==============================] - 4s 110us/sample - loss: 0.0410 - acc: 0.9862 - val_loss: 0.0415 - val_acc: 0.9874\n",
      "Epoch 180/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.0420 - acc: 0.9858\n",
      "Epoch 00180: val_loss did not improve from 0.03946\n",
      "40200/40200 [==============================] - 4s 111us/sample - loss: 0.0421 - acc: 0.9857 - val_loss: 0.0417 - val_acc: 0.9872\n",
      "Epoch 181/500\n",
      "39616/40200 [============================>.] - ETA: 0s - loss: 0.0415 - acc: 0.9859\n",
      "Epoch 00181: val_loss did not improve from 0.03946\n",
      "40200/40200 [==============================] - 4s 106us/sample - loss: 0.0413 - acc: 0.9860 - val_loss: 0.0403 - val_acc: 0.9872\n",
      "Epoch 182/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.0420 - acc: 0.9860\n",
      "Epoch 00182: val_loss did not improve from 0.03946\n",
      "40200/40200 [==============================] - 4s 102us/sample - loss: 0.0419 - acc: 0.9860 - val_loss: 0.0415 - val_acc: 0.9871\n",
      "Epoch 183/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.0392 - acc: 0.9869\n",
      "Epoch 00183: val_loss did not improve from 0.03946\n",
      "40200/40200 [==============================] - 4s 110us/sample - loss: 0.0391 - acc: 0.9869 - val_loss: 0.0428 - val_acc: 0.9870\n",
      "Epoch 184/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.0381 - acc: 0.9874\n",
      "Epoch 00184: val_loss did not improve from 0.03946\n",
      "40200/40200 [==============================] - 4s 110us/sample - loss: 0.0380 - acc: 0.9874 - val_loss: 0.0409 - val_acc: 0.9872\n",
      "Epoch 185/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.0418 - acc: 0.9857\n",
      "Epoch 00185: val_loss did not improve from 0.03946\n",
      "40200/40200 [==============================] - 4s 111us/sample - loss: 0.0420 - acc: 0.9855 - val_loss: 0.0411 - val_acc: 0.9875\n",
      "Epoch 186/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.0408 - acc: 0.9866\n",
      "Epoch 00186: val_loss did not improve from 0.03946\n",
      "40200/40200 [==============================] - 5s 112us/sample - loss: 0.0408 - acc: 0.9866 - val_loss: 0.0403 - val_acc: 0.9877\n",
      "Epoch 187/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.0392 - acc: 0.9863\n",
      "Epoch 00187: val_loss did not improve from 0.03946\n",
      "40200/40200 [==============================] - 4s 111us/sample - loss: 0.0392 - acc: 0.9863 - val_loss: 0.0427 - val_acc: 0.9877\n",
      "Epoch 188/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.0371 - acc: 0.9878\n",
      "Epoch 00188: val_loss did not improve from 0.03946\n",
      "40200/40200 [==============================] - 4s 112us/sample - loss: 0.0371 - acc: 0.9878 - val_loss: 0.0409 - val_acc: 0.9873\n",
      "Epoch 189/500\n",
      "39680/40200 [============================>.] - ETA: 0s - loss: 0.0399 - acc: 0.9866\n",
      "Epoch 00189: val_loss did not improve from 0.03946\n",
      "40200/40200 [==============================] - 4s 112us/sample - loss: 0.0404 - acc: 0.9864 - val_loss: 0.0420 - val_acc: 0.9876\n",
      "Epoch 190/500\n",
      "39744/40200 [============================>.] - ETA: 0s - loss: 0.0419 - acc: 0.9858\n",
      "Epoch 00190: val_loss did not improve from 0.03946\n",
      "40200/40200 [==============================] - 4s 110us/sample - loss: 0.0420 - acc: 0.9858 - val_loss: 0.0410 - val_acc: 0.9873\n",
      "Epoch 191/500\n",
      "39744/40200 [============================>.] - ETA: 0s - loss: 0.0381 - acc: 0.9873\n",
      "Epoch 00191: val_loss did not improve from 0.03946\n",
      "40200/40200 [==============================] - 4s 110us/sample - loss: 0.0383 - acc: 0.9872 - val_loss: 0.0414 - val_acc: 0.9875\n",
      "Epoch 192/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.0383 - acc: 0.9866\n",
      "Epoch 00192: val_loss did not improve from 0.03946\n",
      "40200/40200 [==============================] - 4s 112us/sample - loss: 0.0383 - acc: 0.9866 - val_loss: 0.0422 - val_acc: 0.9872\n",
      "Epoch 193/500\n",
      "39744/40200 [============================>.] - ETA: 0s - loss: 0.0401 - acc: 0.9864\n",
      "Epoch 00193: val_loss did not improve from 0.03946\n",
      "40200/40200 [==============================] - 4s 111us/sample - loss: 0.0400 - acc: 0.9864 - val_loss: 0.0412 - val_acc: 0.9872\n",
      "Epoch 194/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.0425 - acc: 0.9863\n",
      "Epoch 00194: val_loss did not improve from 0.03946\n",
      "40200/40200 [==============================] - 4s 110us/sample - loss: 0.0425 - acc: 0.9864 - val_loss: 0.0427 - val_acc: 0.9867\n",
      "Epoch 195/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.0388 - acc: 0.9867\n",
      "Epoch 00195: val_loss did not improve from 0.03946\n",
      "40200/40200 [==============================] - 4s 100us/sample - loss: 0.0388 - acc: 0.9867 - val_loss: 0.0411 - val_acc: 0.9873\n",
      "Epoch 196/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.0396 - acc: 0.9867\n",
      "Epoch 00196: val_loss did not improve from 0.03946\n",
      "40200/40200 [==============================] - 4s 108us/sample - loss: 0.0397 - acc: 0.9867 - val_loss: 0.0417 - val_acc: 0.9870\n",
      "Epoch 197/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.0415 - acc: 0.9862\n",
      "Epoch 00197: val_loss did not improve from 0.03946\n",
      "40200/40200 [==============================] - 4s 109us/sample - loss: 0.0415 - acc: 0.9862 - val_loss: 0.0414 - val_acc: 0.9870\n",
      "Epoch 198/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.0418 - acc: 0.9862\n",
      "Epoch 00198: val_loss did not improve from 0.03946\n",
      "40200/40200 [==============================] - 4s 111us/sample - loss: 0.0418 - acc: 0.9861 - val_loss: 0.0413 - val_acc: 0.9871\n",
      "Epoch 199/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.0415 - acc: 0.9855\n",
      "Epoch 00199: val_loss did not improve from 0.03946\n",
      "40200/40200 [==============================] - 4s 110us/sample - loss: 0.0414 - acc: 0.9855 - val_loss: 0.0408 - val_acc: 0.9874\n",
      "Epoch 200/500\n",
      "39680/40200 [============================>.] - ETA: 0s - loss: 0.0399 - acc: 0.9869\n",
      "Epoch 00200: val_loss did not improve from 0.03946\n",
      "40200/40200 [==============================] - 4s 111us/sample - loss: 0.0400 - acc: 0.9869 - val_loss: 0.0410 - val_acc: 0.9876\n",
      "Epoch 201/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.0400 - acc: 0.9863\n",
      "Epoch 00201: val_loss did not improve from 0.03946\n",
      "40200/40200 [==============================] - 4s 111us/sample - loss: 0.0400 - acc: 0.9864 - val_loss: 0.0413 - val_acc: 0.9878\n",
      "Epoch 202/500\n",
      "39744/40200 [============================>.] - ETA: 0s - loss: 0.0397 - acc: 0.9861\n",
      "Epoch 00202: val_loss did not improve from 0.03946\n",
      "40200/40200 [==============================] - 4s 111us/sample - loss: 0.0398 - acc: 0.9861 - val_loss: 0.0419 - val_acc: 0.9876\n",
      "Epoch 203/500\n",
      "39744/40200 [============================>.] - ETA: 0s - loss: 0.0405 - acc: 0.9860\n",
      "Epoch 00203: val_loss did not improve from 0.03946\n",
      "40200/40200 [==============================] - 4s 111us/sample - loss: 0.0405 - acc: 0.9860 - val_loss: 0.0420 - val_acc: 0.9874\n",
      "Epoch 204/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.0393 - acc: 0.9867\n",
      "Epoch 00204: val_loss did not improve from 0.03946\n",
      "40200/40200 [==============================] - 4s 112us/sample - loss: 0.0392 - acc: 0.9867 - val_loss: 0.0422 - val_acc: 0.9873\n",
      "Epoch 205/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.0408 - acc: 0.9861\n",
      "Epoch 00205: val_loss did not improve from 0.03946\n",
      "40200/40200 [==============================] - 4s 109us/sample - loss: 0.0411 - acc: 0.9860 - val_loss: 0.0419 - val_acc: 0.9877\n",
      "Epoch 206/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.0381 - acc: 0.9869\n",
      "Epoch 00206: val_loss did not improve from 0.03946\n",
      "40200/40200 [==============================] - 4s 111us/sample - loss: 0.0379 - acc: 0.9870 - val_loss: 0.0430 - val_acc: 0.9875\n",
      "Epoch 207/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.0390 - acc: 0.9868\n",
      "Epoch 00207: val_loss did not improve from 0.03946\n",
      "40200/40200 [==============================] - 4s 111us/sample - loss: 0.0389 - acc: 0.9868 - val_loss: 0.0421 - val_acc: 0.9876\n",
      "Epoch 208/500\n",
      "39744/40200 [============================>.] - ETA: 0s - loss: 0.0389 - acc: 0.9875\n",
      "Epoch 00208: val_loss did not improve from 0.03946\n",
      "40200/40200 [==============================] - 4s 111us/sample - loss: 0.0389 - acc: 0.9875 - val_loss: 0.0430 - val_acc: 0.9874\n",
      "Epoch 209/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.0417 - acc: 0.9855\n",
      "Epoch 00209: val_loss did not improve from 0.03946\n",
      "40200/40200 [==============================] - 4s 101us/sample - loss: 0.0416 - acc: 0.9855 - val_loss: 0.0423 - val_acc: 0.9873\n",
      "Epoch 210/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.0393 - acc: 0.9869\n",
      "Epoch 00210: val_loss did not improve from 0.03946\n",
      "40200/40200 [==============================] - 5s 112us/sample - loss: 0.0392 - acc: 0.9870 - val_loss: 0.0431 - val_acc: 0.9875\n",
      "Epoch 211/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.0370 - acc: 0.9873\n",
      "Epoch 00211: val_loss did not improve from 0.03946\n",
      "40200/40200 [==============================] - 4s 110us/sample - loss: 0.0370 - acc: 0.9873 - val_loss: 0.0435 - val_acc: 0.9870\n",
      "Epoch 212/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.0390 - acc: 0.9869\n",
      "Epoch 00212: val_loss did not improve from 0.03946\n",
      "40200/40200 [==============================] - 4s 110us/sample - loss: 0.0390 - acc: 0.9869 - val_loss: 0.0418 - val_acc: 0.9873\n",
      "Epoch 213/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.0390 - acc: 0.9864\n",
      "Epoch 00213: val_loss did not improve from 0.03946\n",
      "40200/40200 [==============================] - 4s 111us/sample - loss: 0.0390 - acc: 0.9865 - val_loss: 0.0421 - val_acc: 0.9873\n",
      "Epoch 214/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.0378 - acc: 0.9872\n",
      "Epoch 00214: val_loss did not improve from 0.03946\n",
      "40200/40200 [==============================] - 4s 111us/sample - loss: 0.0378 - acc: 0.9872 - val_loss: 0.0442 - val_acc: 0.9865\n",
      "Epoch 215/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.0382 - acc: 0.9872\n",
      "Epoch 00215: val_loss did not improve from 0.03946\n",
      "40200/40200 [==============================] - 4s 111us/sample - loss: 0.0382 - acc: 0.9872 - val_loss: 0.0437 - val_acc: 0.9869\n",
      "Epoch 216/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.0418 - acc: 0.9863\n",
      "Epoch 00216: val_loss did not improve from 0.03946\n",
      "40200/40200 [==============================] - 4s 111us/sample - loss: 0.0418 - acc: 0.9863 - val_loss: 0.0408 - val_acc: 0.9876\n",
      "Epoch 217/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.0393 - acc: 0.9872\n",
      "Epoch 00217: val_loss did not improve from 0.03946\n",
      "40200/40200 [==============================] - 4s 111us/sample - loss: 0.0392 - acc: 0.9872 - val_loss: 0.0443 - val_acc: 0.9868\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 218/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.0383 - acc: 0.9868\n",
      "Epoch 00218: val_loss did not improve from 0.03946\n",
      "40200/40200 [==============================] - 4s 109us/sample - loss: 0.0381 - acc: 0.9869 - val_loss: 0.0429 - val_acc: 0.9875\n",
      "Epoch 219/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.0365 - acc: 0.9878\n",
      "Epoch 00219: val_loss did not improve from 0.03946\n",
      "40200/40200 [==============================] - 4s 111us/sample - loss: 0.0365 - acc: 0.9878 - val_loss: 0.0435 - val_acc: 0.9869\n",
      "Epoch 220/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.0402 - acc: 0.9873\n",
      "Epoch 00220: val_loss did not improve from 0.03946\n",
      "40200/40200 [==============================] - 4s 111us/sample - loss: 0.0400 - acc: 0.9874 - val_loss: 0.0415 - val_acc: 0.9879\n",
      "Epoch 221/500\n",
      "39680/40200 [============================>.] - ETA: 0s - loss: 0.0381 - acc: 0.9869\n",
      "Epoch 00221: val_loss did not improve from 0.03946\n",
      "40200/40200 [==============================] - 4s 112us/sample - loss: 0.0382 - acc: 0.9869 - val_loss: 0.0420 - val_acc: 0.9871\n",
      "Epoch 222/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.0390 - acc: 0.9869\n",
      "Epoch 00222: val_loss did not improve from 0.03946\n",
      "40200/40200 [==============================] - 4s 106us/sample - loss: 0.0390 - acc: 0.9869 - val_loss: 0.0416 - val_acc: 0.9873\n",
      "\n",
      "vis_2D_CNN_custom_ch_16_DO_050_DO_2_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 83us/sample - loss: 0.0342 - acc: 0.9893\n",
      "Loss: 0.03422784412406909 Accuracy: 0.9893\n",
      "\n",
      "Train on 40200 samples, validate on 19800 samples\n",
      "Epoch 1/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 7.7442 - acc: 0.3067\n",
      "Epoch 00001: val_loss improved from inf to 0.86643, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_3_conv_checkpoint/001-0.8664.hdf5\n",
      "40200/40200 [==============================] - 6s 158us/sample - loss: 7.6882 - acc: 0.3083 - val_loss: 0.8664 - val_acc: 0.7110\n",
      "Epoch 2/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 1.2664 - acc: 0.6050\n",
      "Epoch 00002: val_loss improved from 0.86643 to 0.49310, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_3_conv_checkpoint/002-0.4931.hdf5\n",
      "40200/40200 [==============================] - 5s 127us/sample - loss: 1.2645 - acc: 0.6054 - val_loss: 0.4931 - val_acc: 0.8453\n",
      "Epoch 3/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.7861 - acc: 0.7462\n",
      "Epoch 00003: val_loss improved from 0.49310 to 0.32960, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_3_conv_checkpoint/003-0.3296.hdf5\n",
      "40200/40200 [==============================] - 5s 127us/sample - loss: 0.7841 - acc: 0.7468 - val_loss: 0.3296 - val_acc: 0.8987\n",
      "Epoch 4/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.5763 - acc: 0.8160\n",
      "Epoch 00004: val_loss improved from 0.32960 to 0.25184, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_3_conv_checkpoint/004-0.2518.hdf5\n",
      "40200/40200 [==============================] - 5s 128us/sample - loss: 0.5764 - acc: 0.8159 - val_loss: 0.2518 - val_acc: 0.9210\n",
      "Epoch 5/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.4613 - acc: 0.8543\n",
      "Epoch 00005: val_loss improved from 0.25184 to 0.20959, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_3_conv_checkpoint/005-0.2096.hdf5\n",
      "40200/40200 [==============================] - 5s 127us/sample - loss: 0.4616 - acc: 0.8543 - val_loss: 0.2096 - val_acc: 0.9355\n",
      "Epoch 6/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.3784 - acc: 0.8805\n",
      "Epoch 00006: val_loss improved from 0.20959 to 0.17233, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_3_conv_checkpoint/006-0.1723.hdf5\n",
      "40200/40200 [==============================] - 5s 126us/sample - loss: 0.3781 - acc: 0.8805 - val_loss: 0.1723 - val_acc: 0.9455\n",
      "Epoch 7/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.3251 - acc: 0.8978\n",
      "Epoch 00007: val_loss improved from 0.17233 to 0.15589, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_3_conv_checkpoint/007-0.1559.hdf5\n",
      "40200/40200 [==============================] - 5s 127us/sample - loss: 0.3251 - acc: 0.8979 - val_loss: 0.1559 - val_acc: 0.9514\n",
      "Epoch 8/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.2804 - acc: 0.9102\n",
      "Epoch 00008: val_loss improved from 0.15589 to 0.13732, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_3_conv_checkpoint/008-0.1373.hdf5\n",
      "40200/40200 [==============================] - 5s 127us/sample - loss: 0.2808 - acc: 0.9100 - val_loss: 0.1373 - val_acc: 0.9588\n",
      "Epoch 9/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.2516 - acc: 0.9213\n",
      "Epoch 00009: val_loss improved from 0.13732 to 0.11872, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_3_conv_checkpoint/009-0.1187.hdf5\n",
      "40200/40200 [==============================] - 5s 127us/sample - loss: 0.2512 - acc: 0.9214 - val_loss: 0.1187 - val_acc: 0.9640\n",
      "Epoch 10/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.2207 - acc: 0.9311\n",
      "Epoch 00010: val_loss improved from 0.11872 to 0.11162, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_3_conv_checkpoint/010-0.1116.hdf5\n",
      "40200/40200 [==============================] - 5s 127us/sample - loss: 0.2210 - acc: 0.9310 - val_loss: 0.1116 - val_acc: 0.9654\n",
      "Epoch 11/500\n",
      "39680/40200 [============================>.] - ETA: 0s - loss: 0.2010 - acc: 0.9361\n",
      "Epoch 00011: val_loss improved from 0.11162 to 0.09952, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_3_conv_checkpoint/011-0.0995.hdf5\n",
      "40200/40200 [==============================] - 5s 119us/sample - loss: 0.2007 - acc: 0.9362 - val_loss: 0.0995 - val_acc: 0.9691\n",
      "Epoch 12/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.1817 - acc: 0.9432\n",
      "Epoch 00012: val_loss improved from 0.09952 to 0.09354, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_3_conv_checkpoint/012-0.0935.hdf5\n",
      "40200/40200 [==============================] - 5s 121us/sample - loss: 0.1819 - acc: 0.9430 - val_loss: 0.0935 - val_acc: 0.9717\n",
      "Epoch 13/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.1666 - acc: 0.9476\n",
      "Epoch 00013: val_loss improved from 0.09354 to 0.08549, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_3_conv_checkpoint/013-0.0855.hdf5\n",
      "40200/40200 [==============================] - 5s 128us/sample - loss: 0.1664 - acc: 0.9476 - val_loss: 0.0855 - val_acc: 0.9740\n",
      "Epoch 14/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.1583 - acc: 0.9517\n",
      "Epoch 00014: val_loss improved from 0.08549 to 0.07890, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_3_conv_checkpoint/014-0.0789.hdf5\n",
      "40200/40200 [==============================] - 5s 128us/sample - loss: 0.1583 - acc: 0.9516 - val_loss: 0.0789 - val_acc: 0.9755\n",
      "Epoch 15/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.1428 - acc: 0.9554\n",
      "Epoch 00015: val_loss improved from 0.07890 to 0.07546, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_3_conv_checkpoint/015-0.0755.hdf5\n",
      "40200/40200 [==============================] - 5s 128us/sample - loss: 0.1428 - acc: 0.9554 - val_loss: 0.0755 - val_acc: 0.9764\n",
      "Epoch 16/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.1370 - acc: 0.9576\n",
      "Epoch 00016: val_loss improved from 0.07546 to 0.07104, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_3_conv_checkpoint/016-0.0710.hdf5\n",
      "40200/40200 [==============================] - 5s 128us/sample - loss: 0.1371 - acc: 0.9575 - val_loss: 0.0710 - val_acc: 0.9778\n",
      "Epoch 17/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.1289 - acc: 0.9596\n",
      "Epoch 00017: val_loss improved from 0.07104 to 0.06822, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_3_conv_checkpoint/017-0.0682.hdf5\n",
      "40200/40200 [==============================] - 5s 128us/sample - loss: 0.1286 - acc: 0.9597 - val_loss: 0.0682 - val_acc: 0.9795\n",
      "Epoch 18/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.1203 - acc: 0.9632\n",
      "Epoch 00018: val_loss improved from 0.06822 to 0.06654, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_3_conv_checkpoint/018-0.0665.hdf5\n",
      "40200/40200 [==============================] - 5s 129us/sample - loss: 0.1201 - acc: 0.9632 - val_loss: 0.0665 - val_acc: 0.9797\n",
      "Epoch 19/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.1137 - acc: 0.9645\n",
      "Epoch 00019: val_loss improved from 0.06654 to 0.06243, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_3_conv_checkpoint/019-0.0624.hdf5\n",
      "40200/40200 [==============================] - 5s 129us/sample - loss: 0.1133 - acc: 0.9646 - val_loss: 0.0624 - val_acc: 0.9809\n",
      "Epoch 20/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.1098 - acc: 0.9652\n",
      "Epoch 00020: val_loss did not improve from 0.06243\n",
      "40200/40200 [==============================] - 5s 126us/sample - loss: 0.1100 - acc: 0.9652 - val_loss: 0.0628 - val_acc: 0.9809\n",
      "Epoch 21/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.1031 - acc: 0.9674\n",
      "Epoch 00021: val_loss improved from 0.06243 to 0.05929, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_3_conv_checkpoint/021-0.0593.hdf5\n",
      "40200/40200 [==============================] - 5s 128us/sample - loss: 0.1032 - acc: 0.9673 - val_loss: 0.0593 - val_acc: 0.9821\n",
      "Epoch 22/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.1025 - acc: 0.9680\n",
      "Epoch 00022: val_loss improved from 0.05929 to 0.05671, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_3_conv_checkpoint/022-0.0567.hdf5\n",
      "40200/40200 [==============================] - 5s 127us/sample - loss: 0.1026 - acc: 0.9679 - val_loss: 0.0567 - val_acc: 0.9834\n",
      "Epoch 23/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.0951 - acc: 0.9695\n",
      "Epoch 00023: val_loss improved from 0.05671 to 0.05639, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_3_conv_checkpoint/023-0.0564.hdf5\n",
      "40200/40200 [==============================] - 5s 118us/sample - loss: 0.0951 - acc: 0.9695 - val_loss: 0.0564 - val_acc: 0.9827\n",
      "Epoch 24/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.0916 - acc: 0.9712\n",
      "Epoch 00024: val_loss improved from 0.05639 to 0.05539, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_3_conv_checkpoint/024-0.0554.hdf5\n",
      "40200/40200 [==============================] - 5s 125us/sample - loss: 0.0916 - acc: 0.9712 - val_loss: 0.0554 - val_acc: 0.9835\n",
      "Epoch 25/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.0870 - acc: 0.9733\n",
      "Epoch 00025: val_loss did not improve from 0.05539\n",
      "40200/40200 [==============================] - 5s 126us/sample - loss: 0.0871 - acc: 0.9733 - val_loss: 0.0571 - val_acc: 0.9829\n",
      "Epoch 26/500\n",
      "39744/40200 [============================>.] - ETA: 0s - loss: 0.0895 - acc: 0.9710\n",
      "Epoch 00026: val_loss improved from 0.05539 to 0.05234, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_3_conv_checkpoint/026-0.0523.hdf5\n",
      "40200/40200 [==============================] - 5s 129us/sample - loss: 0.0893 - acc: 0.9710 - val_loss: 0.0523 - val_acc: 0.9840\n",
      "Epoch 27/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.0837 - acc: 0.9735\n",
      "Epoch 00027: val_loss improved from 0.05234 to 0.05220, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_3_conv_checkpoint/027-0.0522.hdf5\n",
      "40200/40200 [==============================] - 5s 129us/sample - loss: 0.0834 - acc: 0.9736 - val_loss: 0.0522 - val_acc: 0.9838\n",
      "Epoch 28/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.0790 - acc: 0.9750\n",
      "Epoch 00028: val_loss improved from 0.05220 to 0.05039, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_3_conv_checkpoint/028-0.0504.hdf5\n",
      "40200/40200 [==============================] - 5s 127us/sample - loss: 0.0791 - acc: 0.9750 - val_loss: 0.0504 - val_acc: 0.9843\n",
      "Epoch 29/500\n",
      "39744/40200 [============================>.] - ETA: 0s - loss: 0.0775 - acc: 0.9744\n",
      "Epoch 00029: val_loss improved from 0.05039 to 0.04945, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_3_conv_checkpoint/029-0.0494.hdf5\n",
      "40200/40200 [==============================] - 5s 127us/sample - loss: 0.0774 - acc: 0.9743 - val_loss: 0.0494 - val_acc: 0.9843\n",
      "Epoch 30/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.0749 - acc: 0.9766\n",
      "Epoch 00030: val_loss did not improve from 0.04945\n",
      "40200/40200 [==============================] - 5s 127us/sample - loss: 0.0750 - acc: 0.9765 - val_loss: 0.0503 - val_acc: 0.9842\n",
      "Epoch 31/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.0744 - acc: 0.9750\n",
      "Epoch 00031: val_loss did not improve from 0.04945\n",
      "40200/40200 [==============================] - 5s 123us/sample - loss: 0.0745 - acc: 0.9750 - val_loss: 0.0503 - val_acc: 0.9843\n",
      "Epoch 32/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.0719 - acc: 0.9767\n",
      "Epoch 00032: val_loss did not improve from 0.04945\n",
      "40200/40200 [==============================] - 5s 123us/sample - loss: 0.0718 - acc: 0.9767 - val_loss: 0.0495 - val_acc: 0.9847\n",
      "Epoch 33/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.0693 - acc: 0.9775\n",
      "Epoch 00033: val_loss improved from 0.04945 to 0.04709, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_3_conv_checkpoint/033-0.0471.hdf5\n",
      "40200/40200 [==============================] - 5s 128us/sample - loss: 0.0693 - acc: 0.9775 - val_loss: 0.0471 - val_acc: 0.9855\n",
      "Epoch 34/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.0652 - acc: 0.9785\n",
      "Epoch 00034: val_loss did not improve from 0.04709\n",
      "40200/40200 [==============================] - 5s 126us/sample - loss: 0.0654 - acc: 0.9785 - val_loss: 0.0484 - val_acc: 0.9848\n",
      "Epoch 35/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.0650 - acc: 0.9783\n",
      "Epoch 00035: val_loss improved from 0.04709 to 0.04653, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_3_conv_checkpoint/035-0.0465.hdf5\n",
      "40200/40200 [==============================] - 5s 119us/sample - loss: 0.0652 - acc: 0.9783 - val_loss: 0.0465 - val_acc: 0.9856\n",
      "Epoch 36/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.0648 - acc: 0.9790\n",
      "Epoch 00036: val_loss did not improve from 0.04653\n",
      "40200/40200 [==============================] - 5s 122us/sample - loss: 0.0646 - acc: 0.9791 - val_loss: 0.0471 - val_acc: 0.9856\n",
      "Epoch 37/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.0617 - acc: 0.9797\n",
      "Epoch 00037: val_loss improved from 0.04653 to 0.04465, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_3_conv_checkpoint/037-0.0447.hdf5\n",
      "40200/40200 [==============================] - 5s 128us/sample - loss: 0.0619 - acc: 0.9796 - val_loss: 0.0447 - val_acc: 0.9859\n",
      "Epoch 38/500\n",
      "39680/40200 [============================>.] - ETA: 0s - loss: 0.0586 - acc: 0.9818\n",
      "Epoch 00038: val_loss did not improve from 0.04465\n",
      "40200/40200 [==============================] - 5s 127us/sample - loss: 0.0586 - acc: 0.9816 - val_loss: 0.0450 - val_acc: 0.9856\n",
      "Epoch 39/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.0609 - acc: 0.9804\n",
      "Epoch 00039: val_loss improved from 0.04465 to 0.04463, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_3_conv_checkpoint/039-0.0446.hdf5\n",
      "40200/40200 [==============================] - 5s 129us/sample - loss: 0.0609 - acc: 0.9804 - val_loss: 0.0446 - val_acc: 0.9865\n",
      "Epoch 40/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.0565 - acc: 0.9818\n",
      "Epoch 00040: val_loss improved from 0.04463 to 0.04299, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_3_conv_checkpoint/040-0.0430.hdf5\n",
      "40200/40200 [==============================] - 5s 128us/sample - loss: 0.0563 - acc: 0.9818 - val_loss: 0.0430 - val_acc: 0.9868\n",
      "Epoch 41/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.0566 - acc: 0.9812\n",
      "Epoch 00041: val_loss did not improve from 0.04299\n",
      "40200/40200 [==============================] - 5s 127us/sample - loss: 0.0566 - acc: 0.9812 - val_loss: 0.0439 - val_acc: 0.9865\n",
      "Epoch 42/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.0567 - acc: 0.9819\n",
      "Epoch 00042: val_loss did not improve from 0.04299\n",
      "40200/40200 [==============================] - 5s 126us/sample - loss: 0.0567 - acc: 0.9819 - val_loss: 0.0444 - val_acc: 0.9870\n",
      "Epoch 43/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.0546 - acc: 0.9822\n",
      "Epoch 00043: val_loss did not improve from 0.04299\n",
      "40200/40200 [==============================] - 5s 128us/sample - loss: 0.0543 - acc: 0.9823 - val_loss: 0.0438 - val_acc: 0.9866\n",
      "Epoch 44/500\n",
      "39744/40200 [============================>.] - ETA: 0s - loss: 0.0550 - acc: 0.9812\n",
      "Epoch 00044: val_loss improved from 0.04299 to 0.04252, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_3_conv_checkpoint/044-0.0425.hdf5\n",
      "40200/40200 [==============================] - 5s 128us/sample - loss: 0.0549 - acc: 0.9812 - val_loss: 0.0425 - val_acc: 0.9875\n",
      "Epoch 45/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.0513 - acc: 0.9833\n",
      "Epoch 00045: val_loss did not improve from 0.04252\n",
      "40200/40200 [==============================] - 5s 127us/sample - loss: 0.0513 - acc: 0.9833 - val_loss: 0.0475 - val_acc: 0.9849\n",
      "Epoch 46/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.0512 - acc: 0.9835\n",
      "Epoch 00046: val_loss improved from 0.04252 to 0.04183, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_3_conv_checkpoint/046-0.0418.hdf5\n",
      "40200/40200 [==============================] - 5s 127us/sample - loss: 0.0511 - acc: 0.9836 - val_loss: 0.0418 - val_acc: 0.9870\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.0501 - acc: 0.9838\n",
      "Epoch 00047: val_loss did not improve from 0.04183\n",
      "40200/40200 [==============================] - 5s 116us/sample - loss: 0.0501 - acc: 0.9838 - val_loss: 0.0426 - val_acc: 0.9877\n",
      "Epoch 48/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.0508 - acc: 0.9829\n",
      "Epoch 00048: val_loss did not improve from 0.04183\n",
      "40200/40200 [==============================] - 5s 124us/sample - loss: 0.0508 - acc: 0.9828 - val_loss: 0.0429 - val_acc: 0.9871\n",
      "Epoch 49/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.0504 - acc: 0.9840\n",
      "Epoch 00049: val_loss did not improve from 0.04183\n",
      "40200/40200 [==============================] - 5s 126us/sample - loss: 0.0501 - acc: 0.9841 - val_loss: 0.0451 - val_acc: 0.9862\n",
      "Epoch 50/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.0477 - acc: 0.9850\n",
      "Epoch 00050: val_loss did not improve from 0.04183\n",
      "40200/40200 [==============================] - 5s 126us/sample - loss: 0.0476 - acc: 0.9851 - val_loss: 0.0436 - val_acc: 0.9866\n",
      "Epoch 51/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.0463 - acc: 0.9842\n",
      "Epoch 00051: val_loss improved from 0.04183 to 0.04148, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_3_conv_checkpoint/051-0.0415.hdf5\n",
      "40200/40200 [==============================] - 5s 127us/sample - loss: 0.0463 - acc: 0.9842 - val_loss: 0.0415 - val_acc: 0.9873\n",
      "Epoch 52/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.0478 - acc: 0.9847\n",
      "Epoch 00052: val_loss improved from 0.04148 to 0.04122, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_3_conv_checkpoint/052-0.0412.hdf5\n",
      "40200/40200 [==============================] - 5s 128us/sample - loss: 0.0478 - acc: 0.9847 - val_loss: 0.0412 - val_acc: 0.9871\n",
      "Epoch 53/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.0479 - acc: 0.9834\n",
      "Epoch 00053: val_loss improved from 0.04122 to 0.04037, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_3_conv_checkpoint/053-0.0404.hdf5\n",
      "40200/40200 [==============================] - 5s 129us/sample - loss: 0.0479 - acc: 0.9834 - val_loss: 0.0404 - val_acc: 0.9873\n",
      "Epoch 54/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.0461 - acc: 0.9847\n",
      "Epoch 00054: val_loss did not improve from 0.04037\n",
      "40200/40200 [==============================] - 5s 129us/sample - loss: 0.0462 - acc: 0.9847 - val_loss: 0.0416 - val_acc: 0.9876\n",
      "Epoch 55/500\n",
      "39680/40200 [============================>.] - ETA: 0s - loss: 0.0469 - acc: 0.9845\n",
      "Epoch 00055: val_loss did not improve from 0.04037\n",
      "40200/40200 [==============================] - 5s 127us/sample - loss: 0.0469 - acc: 0.9844 - val_loss: 0.0418 - val_acc: 0.9873\n",
      "Epoch 56/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.0436 - acc: 0.9857\n",
      "Epoch 00056: val_loss did not improve from 0.04037\n",
      "40200/40200 [==============================] - 5s 128us/sample - loss: 0.0436 - acc: 0.9858 - val_loss: 0.0409 - val_acc: 0.9876\n",
      "Epoch 57/500\n",
      "39744/40200 [============================>.] - ETA: 0s - loss: 0.0434 - acc: 0.9856\n",
      "Epoch 00057: val_loss did not improve from 0.04037\n",
      "40200/40200 [==============================] - 5s 128us/sample - loss: 0.0440 - acc: 0.9854 - val_loss: 0.0415 - val_acc: 0.9873\n",
      "Epoch 58/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.0425 - acc: 0.9862\n",
      "Epoch 00058: val_loss did not improve from 0.04037\n",
      "40200/40200 [==============================] - 5s 128us/sample - loss: 0.0425 - acc: 0.9862 - val_loss: 0.0419 - val_acc: 0.9874\n",
      "Epoch 59/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.0452 - acc: 0.9849\n",
      "Epoch 00059: val_loss did not improve from 0.04037\n",
      "40200/40200 [==============================] - 5s 114us/sample - loss: 0.0450 - acc: 0.9850 - val_loss: 0.0406 - val_acc: 0.9878\n",
      "Epoch 60/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.0401 - acc: 0.9864\n",
      "Epoch 00060: val_loss did not improve from 0.04037\n",
      "40200/40200 [==============================] - 5s 127us/sample - loss: 0.0400 - acc: 0.9865 - val_loss: 0.0415 - val_acc: 0.9882\n",
      "Epoch 61/500\n",
      "39744/40200 [============================>.] - ETA: 0s - loss: 0.0395 - acc: 0.9869\n",
      "Epoch 00061: val_loss improved from 0.04037 to 0.03931, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_3_conv_checkpoint/061-0.0393.hdf5\n",
      "40200/40200 [==============================] - 5s 126us/sample - loss: 0.0396 - acc: 0.9869 - val_loss: 0.0393 - val_acc: 0.9876\n",
      "Epoch 62/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.0417 - acc: 0.9860\n",
      "Epoch 00062: val_loss did not improve from 0.03931\n",
      "40200/40200 [==============================] - 5s 127us/sample - loss: 0.0418 - acc: 0.9859 - val_loss: 0.0397 - val_acc: 0.9877\n",
      "Epoch 63/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.0381 - acc: 0.9869\n",
      "Epoch 00063: val_loss did not improve from 0.03931\n",
      "40200/40200 [==============================] - 5s 129us/sample - loss: 0.0380 - acc: 0.9870 - val_loss: 0.0397 - val_acc: 0.9880\n",
      "Epoch 64/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.0409 - acc: 0.9865\n",
      "Epoch 00064: val_loss did not improve from 0.03931\n",
      "40200/40200 [==============================] - 5s 127us/sample - loss: 0.0410 - acc: 0.9865 - val_loss: 0.0414 - val_acc: 0.9873\n",
      "Epoch 65/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.0385 - acc: 0.9873\n",
      "Epoch 00065: val_loss did not improve from 0.03931\n",
      "40200/40200 [==============================] - 5s 127us/sample - loss: 0.0388 - acc: 0.9873 - val_loss: 0.0404 - val_acc: 0.9887\n",
      "Epoch 66/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.0367 - acc: 0.9877\n",
      "Epoch 00066: val_loss did not improve from 0.03931\n",
      "40200/40200 [==============================] - 5s 125us/sample - loss: 0.0368 - acc: 0.9877 - val_loss: 0.0433 - val_acc: 0.9879\n",
      "Epoch 67/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.0376 - acc: 0.9875\n",
      "Epoch 00067: val_loss did not improve from 0.03931\n",
      "40200/40200 [==============================] - 5s 127us/sample - loss: 0.0379 - acc: 0.9875 - val_loss: 0.0401 - val_acc: 0.9881\n",
      "Epoch 68/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.0374 - acc: 0.9874\n",
      "Epoch 00068: val_loss did not improve from 0.03931\n",
      "40200/40200 [==============================] - 5s 126us/sample - loss: 0.0374 - acc: 0.9873 - val_loss: 0.0406 - val_acc: 0.9881\n",
      "Epoch 69/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.0381 - acc: 0.9876\n",
      "Epoch 00069: val_loss did not improve from 0.03931\n",
      "40200/40200 [==============================] - 5s 126us/sample - loss: 0.0380 - acc: 0.9876 - val_loss: 0.0401 - val_acc: 0.9879\n",
      "Epoch 70/500\n",
      "39744/40200 [============================>.] - ETA: 0s - loss: 0.0376 - acc: 0.9872\n",
      "Epoch 00070: val_loss did not improve from 0.03931\n",
      "40200/40200 [==============================] - 5s 125us/sample - loss: 0.0377 - acc: 0.9873 - val_loss: 0.0401 - val_acc: 0.9889\n",
      "Epoch 71/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.0361 - acc: 0.9878\n",
      "Epoch 00071: val_loss did not improve from 0.03931\n",
      "40200/40200 [==============================] - 5s 115us/sample - loss: 0.0359 - acc: 0.9879 - val_loss: 0.0401 - val_acc: 0.9882\n",
      "Epoch 72/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.0344 - acc: 0.9888\n",
      "Epoch 00072: val_loss did not improve from 0.03931\n",
      "40200/40200 [==============================] - 5s 128us/sample - loss: 0.0344 - acc: 0.9888 - val_loss: 0.0401 - val_acc: 0.9886\n",
      "Epoch 73/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.0351 - acc: 0.9884\n",
      "Epoch 00073: val_loss did not improve from 0.03931\n",
      "40200/40200 [==============================] - 5s 128us/sample - loss: 0.0351 - acc: 0.9884 - val_loss: 0.0413 - val_acc: 0.9880\n",
      "Epoch 74/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.0335 - acc: 0.9892\n",
      "Epoch 00074: val_loss did not improve from 0.03931\n",
      "40200/40200 [==============================] - 5s 127us/sample - loss: 0.0335 - acc: 0.9892 - val_loss: 0.0404 - val_acc: 0.9888\n",
      "Epoch 75/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.0335 - acc: 0.9886\n",
      "Epoch 00075: val_loss did not improve from 0.03931\n",
      "40200/40200 [==============================] - 5s 127us/sample - loss: 0.0335 - acc: 0.9886 - val_loss: 0.0430 - val_acc: 0.9879\n",
      "Epoch 76/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.0312 - acc: 0.9892\n",
      "Epoch 00076: val_loss did not improve from 0.03931\n",
      "40200/40200 [==============================] - 5s 126us/sample - loss: 0.0311 - acc: 0.9892 - val_loss: 0.0415 - val_acc: 0.9884\n",
      "Epoch 77/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.0320 - acc: 0.9891\n",
      "Epoch 00077: val_loss improved from 0.03931 to 0.03908, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_3_conv_checkpoint/077-0.0391.hdf5\n",
      "40200/40200 [==============================] - 5s 127us/sample - loss: 0.0320 - acc: 0.9891 - val_loss: 0.0391 - val_acc: 0.9887\n",
      "Epoch 78/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.0322 - acc: 0.9896\n",
      "Epoch 00078: val_loss did not improve from 0.03908\n",
      "40200/40200 [==============================] - 5s 126us/sample - loss: 0.0322 - acc: 0.9897 - val_loss: 0.0404 - val_acc: 0.9887\n",
      "Epoch 79/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.0331 - acc: 0.9886\n",
      "Epoch 00079: val_loss did not improve from 0.03908\n",
      "40200/40200 [==============================] - 5s 127us/sample - loss: 0.0331 - acc: 0.9887 - val_loss: 0.0396 - val_acc: 0.9889\n",
      "Epoch 80/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.0311 - acc: 0.9894\n",
      "Epoch 00080: val_loss did not improve from 0.03908\n",
      "40200/40200 [==============================] - 5s 128us/sample - loss: 0.0311 - acc: 0.9894 - val_loss: 0.0401 - val_acc: 0.9888\n",
      "Epoch 81/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.0346 - acc: 0.9886\n",
      "Epoch 00081: val_loss did not improve from 0.03908\n",
      "40200/40200 [==============================] - 5s 127us/sample - loss: 0.0346 - acc: 0.9886 - val_loss: 0.0409 - val_acc: 0.9882\n",
      "Epoch 82/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.0319 - acc: 0.9891\n",
      "Epoch 00082: val_loss did not improve from 0.03908\n",
      "40200/40200 [==============================] - 5s 126us/sample - loss: 0.0318 - acc: 0.9892 - val_loss: 0.0393 - val_acc: 0.9887\n",
      "Epoch 83/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.0313 - acc: 0.9894\n",
      "Epoch 00083: val_loss did not improve from 0.03908\n",
      "40200/40200 [==============================] - 5s 116us/sample - loss: 0.0312 - acc: 0.9895 - val_loss: 0.0405 - val_acc: 0.9889\n",
      "Epoch 84/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.0298 - acc: 0.9901\n",
      "Epoch 00084: val_loss improved from 0.03908 to 0.03865, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_3_conv_checkpoint/084-0.0387.hdf5\n",
      "40200/40200 [==============================] - 5s 127us/sample - loss: 0.0299 - acc: 0.9900 - val_loss: 0.0387 - val_acc: 0.9894\n",
      "Epoch 85/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.0318 - acc: 0.9893\n",
      "Epoch 00085: val_loss did not improve from 0.03865\n",
      "40200/40200 [==============================] - 5s 125us/sample - loss: 0.0318 - acc: 0.9893 - val_loss: 0.0406 - val_acc: 0.9886\n",
      "Epoch 86/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.0295 - acc: 0.9902\n",
      "Epoch 00086: val_loss did not improve from 0.03865\n",
      "40200/40200 [==============================] - 5s 123us/sample - loss: 0.0295 - acc: 0.9902 - val_loss: 0.0393 - val_acc: 0.9887\n",
      "Epoch 87/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.0306 - acc: 0.9898\n",
      "Epoch 00087: val_loss did not improve from 0.03865\n",
      "40200/40200 [==============================] - 5s 126us/sample - loss: 0.0306 - acc: 0.9898 - val_loss: 0.0396 - val_acc: 0.9889\n",
      "Epoch 88/500\n",
      "39744/40200 [============================>.] - ETA: 0s - loss: 0.0293 - acc: 0.9903\n",
      "Epoch 00088: val_loss did not improve from 0.03865\n",
      "40200/40200 [==============================] - 5s 127us/sample - loss: 0.0295 - acc: 0.9903 - val_loss: 0.0400 - val_acc: 0.9886\n",
      "Epoch 89/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.0308 - acc: 0.9892\n",
      "Epoch 00089: val_loss did not improve from 0.03865\n",
      "40200/40200 [==============================] - 5s 127us/sample - loss: 0.0307 - acc: 0.9893 - val_loss: 0.0407 - val_acc: 0.9884\n",
      "Epoch 90/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.0307 - acc: 0.9891\n",
      "Epoch 00090: val_loss did not improve from 0.03865\n",
      "40200/40200 [==============================] - 5s 128us/sample - loss: 0.0308 - acc: 0.9891 - val_loss: 0.0387 - val_acc: 0.9890\n",
      "Epoch 91/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.0300 - acc: 0.9899\n",
      "Epoch 00091: val_loss did not improve from 0.03865\n",
      "40200/40200 [==============================] - 5s 128us/sample - loss: 0.0301 - acc: 0.9899 - val_loss: 0.0394 - val_acc: 0.9888\n",
      "Epoch 92/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.0297 - acc: 0.9900\n",
      "Epoch 00092: val_loss did not improve from 0.03865\n",
      "40200/40200 [==============================] - 5s 127us/sample - loss: 0.0297 - acc: 0.9900 - val_loss: 0.0404 - val_acc: 0.9887\n",
      "Epoch 93/500\n",
      "39744/40200 [============================>.] - ETA: 0s - loss: 0.0286 - acc: 0.9897\n",
      "Epoch 00093: val_loss did not improve from 0.03865\n",
      "40200/40200 [==============================] - 5s 128us/sample - loss: 0.0286 - acc: 0.9898 - val_loss: 0.0406 - val_acc: 0.9888\n",
      "Epoch 94/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.0288 - acc: 0.9901\n",
      "Epoch 00094: val_loss did not improve from 0.03865\n",
      "40200/40200 [==============================] - 5s 127us/sample - loss: 0.0289 - acc: 0.9900 - val_loss: 0.0409 - val_acc: 0.9891\n",
      "Epoch 95/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.0267 - acc: 0.9908\n",
      "Epoch 00095: val_loss did not improve from 0.03865\n",
      "40200/40200 [==============================] - 5s 122us/sample - loss: 0.0266 - acc: 0.9908 - val_loss: 0.0408 - val_acc: 0.9890\n",
      "Epoch 96/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.0287 - acc: 0.9902\n",
      "Epoch 00096: val_loss did not improve from 0.03865\n",
      "40200/40200 [==============================] - 5s 126us/sample - loss: 0.0288 - acc: 0.9901 - val_loss: 0.0391 - val_acc: 0.9892\n",
      "Epoch 97/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.0291 - acc: 0.9902\n",
      "Epoch 00097: val_loss did not improve from 0.03865\n",
      "40200/40200 [==============================] - 5s 127us/sample - loss: 0.0290 - acc: 0.9902 - val_loss: 0.0393 - val_acc: 0.9885\n",
      "Epoch 98/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.0265 - acc: 0.9911\n",
      "Epoch 00098: val_loss did not improve from 0.03865\n",
      "40200/40200 [==============================] - 5s 127us/sample - loss: 0.0263 - acc: 0.9911 - val_loss: 0.0421 - val_acc: 0.9886\n",
      "Epoch 99/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.0275 - acc: 0.9904\n",
      "Epoch 00099: val_loss did not improve from 0.03865\n",
      "40200/40200 [==============================] - 5s 127us/sample - loss: 0.0275 - acc: 0.9904 - val_loss: 0.0405 - val_acc: 0.9885\n",
      "Epoch 100/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.0272 - acc: 0.9910\n",
      "Epoch 00100: val_loss did not improve from 0.03865\n",
      "40200/40200 [==============================] - 5s 127us/sample - loss: 0.0271 - acc: 0.9910 - val_loss: 0.0416 - val_acc: 0.9885\n",
      "Epoch 101/500\n",
      "39744/40200 [============================>.] - ETA: 0s - loss: 0.0261 - acc: 0.9915\n",
      "Epoch 00101: val_loss did not improve from 0.03865\n",
      "40200/40200 [==============================] - 5s 127us/sample - loss: 0.0263 - acc: 0.9914 - val_loss: 0.0408 - val_acc: 0.9894\n",
      "Epoch 102/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.0264 - acc: 0.9912\n",
      "Epoch 00102: val_loss did not improve from 0.03865\n",
      "40200/40200 [==============================] - 5s 127us/sample - loss: 0.0264 - acc: 0.9912 - val_loss: 0.0413 - val_acc: 0.9885\n",
      "Epoch 103/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.0270 - acc: 0.9914\n",
      "Epoch 00103: val_loss did not improve from 0.03865\n",
      "40200/40200 [==============================] - 5s 128us/sample - loss: 0.0271 - acc: 0.9913 - val_loss: 0.0442 - val_acc: 0.9880\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 104/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.0255 - acc: 0.9915\n",
      "Epoch 00104: val_loss did not improve from 0.03865\n",
      "40200/40200 [==============================] - 5s 128us/sample - loss: 0.0254 - acc: 0.9915 - val_loss: 0.0402 - val_acc: 0.9894\n",
      "Epoch 105/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.0283 - acc: 0.9905\n",
      "Epoch 00105: val_loss did not improve from 0.03865\n",
      "40200/40200 [==============================] - 5s 126us/sample - loss: 0.0284 - acc: 0.9904 - val_loss: 0.0403 - val_acc: 0.9889\n",
      "Epoch 106/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.0247 - acc: 0.9916\n",
      "Epoch 00106: val_loss did not improve from 0.03865\n",
      "40200/40200 [==============================] - 5s 125us/sample - loss: 0.0246 - acc: 0.9916 - val_loss: 0.0409 - val_acc: 0.9889\n",
      "Epoch 107/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.0267 - acc: 0.9907\n",
      "Epoch 00107: val_loss did not improve from 0.03865\n",
      "40200/40200 [==============================] - 5s 120us/sample - loss: 0.0267 - acc: 0.9908 - val_loss: 0.0403 - val_acc: 0.9889\n",
      "Epoch 108/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.0256 - acc: 0.9914\n",
      "Epoch 00108: val_loss did not improve from 0.03865\n",
      "40200/40200 [==============================] - 5s 126us/sample - loss: 0.0256 - acc: 0.9915 - val_loss: 0.0404 - val_acc: 0.9890\n",
      "Epoch 109/500\n",
      "39744/40200 [============================>.] - ETA: 0s - loss: 0.0247 - acc: 0.9916\n",
      "Epoch 00109: val_loss did not improve from 0.03865\n",
      "40200/40200 [==============================] - 5s 126us/sample - loss: 0.0246 - acc: 0.9916 - val_loss: 0.0405 - val_acc: 0.9887\n",
      "Epoch 110/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.0258 - acc: 0.9911\n",
      "Epoch 00110: val_loss did not improve from 0.03865\n",
      "40200/40200 [==============================] - 5s 125us/sample - loss: 0.0258 - acc: 0.9911 - val_loss: 0.0409 - val_acc: 0.9889\n",
      "Epoch 111/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.0259 - acc: 0.9909\n",
      "Epoch 00111: val_loss did not improve from 0.03865\n",
      "40200/40200 [==============================] - 5s 129us/sample - loss: 0.0259 - acc: 0.9909 - val_loss: 0.0424 - val_acc: 0.9885\n",
      "Epoch 112/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.0247 - acc: 0.9920\n",
      "Epoch 00112: val_loss did not improve from 0.03865\n",
      "40200/40200 [==============================] - 5s 127us/sample - loss: 0.0247 - acc: 0.9919 - val_loss: 0.0410 - val_acc: 0.9891\n",
      "Epoch 113/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.0253 - acc: 0.9910\n",
      "Epoch 00113: val_loss did not improve from 0.03865\n",
      "40200/40200 [==============================] - 5s 126us/sample - loss: 0.0254 - acc: 0.9910 - val_loss: 0.0420 - val_acc: 0.9887\n",
      "Epoch 114/500\n",
      "39744/40200 [============================>.] - ETA: 0s - loss: 0.0243 - acc: 0.9916\n",
      "Epoch 00114: val_loss did not improve from 0.03865\n",
      "40200/40200 [==============================] - 5s 126us/sample - loss: 0.0242 - acc: 0.9916 - val_loss: 0.0406 - val_acc: 0.9888\n",
      "Epoch 115/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.0246 - acc: 0.9914\n",
      "Epoch 00115: val_loss did not improve from 0.03865\n",
      "40200/40200 [==============================] - 5s 127us/sample - loss: 0.0246 - acc: 0.9914 - val_loss: 0.0391 - val_acc: 0.9892\n",
      "Epoch 116/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.0237 - acc: 0.9920\n",
      "Epoch 00116: val_loss did not improve from 0.03865\n",
      "40200/40200 [==============================] - 5s 127us/sample - loss: 0.0237 - acc: 0.9919 - val_loss: 0.0401 - val_acc: 0.9891\n",
      "Epoch 117/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.0241 - acc: 0.9919\n",
      "Epoch 00117: val_loss did not improve from 0.03865\n",
      "40200/40200 [==============================] - 5s 128us/sample - loss: 0.0241 - acc: 0.9919 - val_loss: 0.0404 - val_acc: 0.9886\n",
      "Epoch 118/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.0233 - acc: 0.9920\n",
      "Epoch 00118: val_loss did not improve from 0.03865\n",
      "40200/40200 [==============================] - 5s 125us/sample - loss: 0.0233 - acc: 0.9920 - val_loss: 0.0413 - val_acc: 0.9889\n",
      "Epoch 119/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.0237 - acc: 0.9924\n",
      "Epoch 00119: val_loss did not improve from 0.03865\n",
      "40200/40200 [==============================] - 5s 121us/sample - loss: 0.0236 - acc: 0.9923 - val_loss: 0.0398 - val_acc: 0.9891\n",
      "Epoch 120/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.0239 - acc: 0.9917\n",
      "Epoch 00120: val_loss did not improve from 0.03865\n",
      "40200/40200 [==============================] - 5s 128us/sample - loss: 0.0239 - acc: 0.9917 - val_loss: 0.0455 - val_acc: 0.9883\n",
      "Epoch 121/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.0225 - acc: 0.9922\n",
      "Epoch 00121: val_loss did not improve from 0.03865\n",
      "40200/40200 [==============================] - 5s 127us/sample - loss: 0.0225 - acc: 0.9922 - val_loss: 0.0417 - val_acc: 0.9886\n",
      "Epoch 122/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.0233 - acc: 0.9922\n",
      "Epoch 00122: val_loss did not improve from 0.03865\n",
      "40200/40200 [==============================] - 5s 126us/sample - loss: 0.0232 - acc: 0.9922 - val_loss: 0.0419 - val_acc: 0.9887\n",
      "Epoch 123/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.0246 - acc: 0.9915\n",
      "Epoch 00123: val_loss did not improve from 0.03865\n",
      "40200/40200 [==============================] - 5s 128us/sample - loss: 0.0247 - acc: 0.9915 - val_loss: 0.0402 - val_acc: 0.9890\n",
      "Epoch 124/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.0220 - acc: 0.9921\n",
      "Epoch 00124: val_loss did not improve from 0.03865\n",
      "40200/40200 [==============================] - 5s 129us/sample - loss: 0.0220 - acc: 0.9922 - val_loss: 0.0395 - val_acc: 0.9892\n",
      "Epoch 125/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.0228 - acc: 0.9925\n",
      "Epoch 00125: val_loss did not improve from 0.03865\n",
      "40200/40200 [==============================] - 5s 129us/sample - loss: 0.0228 - acc: 0.9925 - val_loss: 0.0414 - val_acc: 0.9891\n",
      "Epoch 126/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.0231 - acc: 0.9919\n",
      "Epoch 00126: val_loss did not improve from 0.03865\n",
      "40200/40200 [==============================] - 5s 127us/sample - loss: 0.0231 - acc: 0.9919 - val_loss: 0.0401 - val_acc: 0.9895\n",
      "Epoch 127/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.0228 - acc: 0.9921\n",
      "Epoch 00127: val_loss did not improve from 0.03865\n",
      "40200/40200 [==============================] - 5s 127us/sample - loss: 0.0227 - acc: 0.9921 - val_loss: 0.0420 - val_acc: 0.9893\n",
      "Epoch 128/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.0231 - acc: 0.9922\n",
      "Epoch 00128: val_loss did not improve from 0.03865\n",
      "40200/40200 [==============================] - 5s 126us/sample - loss: 0.0230 - acc: 0.9922 - val_loss: 0.0415 - val_acc: 0.9887\n",
      "Epoch 129/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.0227 - acc: 0.9918\n",
      "Epoch 00129: val_loss did not improve from 0.03865\n",
      "40200/40200 [==============================] - 5s 126us/sample - loss: 0.0227 - acc: 0.9918 - val_loss: 0.0411 - val_acc: 0.9886\n",
      "Epoch 130/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.0228 - acc: 0.9919\n",
      "Epoch 00130: val_loss did not improve from 0.03865\n",
      "40200/40200 [==============================] - 5s 117us/sample - loss: 0.0228 - acc: 0.9919 - val_loss: 0.0434 - val_acc: 0.9884\n",
      "Epoch 131/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.0248 - acc: 0.9916\n",
      "Epoch 00131: val_loss did not improve from 0.03865\n",
      "40200/40200 [==============================] - 5s 122us/sample - loss: 0.0248 - acc: 0.9916 - val_loss: 0.0418 - val_acc: 0.9890\n",
      "Epoch 132/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.0237 - acc: 0.9919\n",
      "Epoch 00132: val_loss did not improve from 0.03865\n",
      "40200/40200 [==============================] - 5s 125us/sample - loss: 0.0237 - acc: 0.9919 - val_loss: 0.0404 - val_acc: 0.9886\n",
      "Epoch 133/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.0208 - acc: 0.9927\n",
      "Epoch 00133: val_loss did not improve from 0.03865\n",
      "40200/40200 [==============================] - 5s 124us/sample - loss: 0.0208 - acc: 0.9927 - val_loss: 0.0423 - val_acc: 0.9889\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 134/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.0230 - acc: 0.9925\n",
      "Epoch 00134: val_loss did not improve from 0.03865\n",
      "40200/40200 [==============================] - 5s 127us/sample - loss: 0.0229 - acc: 0.9925 - val_loss: 0.0411 - val_acc: 0.9889\n",
      "\n",
      "vis_2D_CNN_custom_ch_16_DO_050_DO_3_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEKCAYAAAARnO4WAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzt3Xt8VPWd//HXZ2YSQiDhJqgFbXDbrdzDzeIi3qjWS0vtUkR/Wqvd1e2jrtW6a4vabm273drWbq27WkutLbbWS1HaeqlUWyi6XoGiUqVFFAuIkCBEAiHJzHx+f5wzyRAyQwKcZDJ5Px+Pw5w553vO93MOyWe+880532PujoiIFL9YdwcgIiJdQwlfRKSXUMIXEekllPBFRHoJJXwRkV5CCV9EpJdQwhcR6SWU8EVEeolIE76Zfd7M/mxmq83sHjMri7I+ERHJzaK609bMhgNPAaPdvcHM7gcedfef5trmsMMO86qqqkjiEREpRitWrKh196EdKZuIOJYE0NfMmoFy4K18hauqqli+fHnEIYmIFA8ze7OjZSPr0nH3TcBNwN+AzUCdu/+ubTkzu8zMlpvZ8pqamqjCERHp9SJL+GY2CPgYMBJ4D9DPzC5sW87d57v7FHefMnRoh76ViIjIAYjyj7YfAt5w9xp3bwYeBP4hwvpERCSPKPvw/wZMM7NyoAGYCXS6g765uZmNGzeyZ8+eQx1fr1BWVsaIESMoKSnp7lBEpJtFlvDd/TkzWwisBJLAn4D5nd3Pxo0bqaiooKqqCjM71GEWNXdn27ZtbNy4kZEjR3Z3OCLSzSK9Dt/dv+Lux7r7WHf/pLs3dnYfe/bsYciQIUr2B8DMGDJkiL4diQjQQ+60VbI/cDp3IpLRIxL+/jQ2vkUyWdfdYYiIFLSiSPhNTW+TTL4byb537NjBbbfddkDbnnXWWezYsaPD5W+44QZuuummA6pLRGR/iiLhRylfwk8mk3m3ffTRRxk4cGAUYYmIdFqRJHwDohkTaN68eaxbt47q6mquueYali5dyowZM5g1axajR48G4JxzzmHy5MmMGTOG+fNbL0SqqqqitraW9evXM2rUKC699FLGjBnD6aefTkNDQ956V61axbRp0xg/fjwf//jH2b59OwC33HILo0ePZvz48Zx33nkA/PGPf6S6uprq6momTpzIzp07IzkXItKzRT2WziG1du1V1Nev2md5KlWPWYJYrPODcfbvX837339zzvU33ngjq1evZtWqoN6lS5eycuVKVq9e3XKp45133sngwYNpaGhg6tSpzJ49myFDhrSJfS333HMPP/rRjzj33HN54IEHuPDCfW48bnHRRRfxP//zP5x00kn8x3/8B1/96le5+eabufHGG3njjTfo06dPS3fRTTfdxK233sr06dOpr6+nrEyDkorIvoqkhd+1jjvuuL2ua7/llluYMGEC06ZNY8OGDaxdu3afbUaOHEl1dTUAkydPZv369Tn3X1dXx44dOzjppJMA+NSnPsWyZcsAGD9+PBdccAE///nPSSSCz+vp06dz9dVXc8stt7Bjx46W5SIi2XpUZsjVEq+vf5F4fAB9+1Z1SRz9+vVrmV+6dClPPPEEzzzzDOXl5Zx88sntXvfep0+flvl4PL7fLp1cHnnkEZYtW8ZDDz3EN77xDV5++WXmzZvH2WefzaOPPsr06dNZvHgxxx577AHtX0SKV5G08KPrw6+oqMjbJ15XV8egQYMoLy9nzZo1PPvsswdd54ABAxg0aBBPPvkkAD/72c846aSTSKfTbNiwgVNOOYVvfetb1NXVUV9fz7p16xg3bhxf/OIXmTp1KmvWrDnoGESk+PSoFn5u0SX8IUOGMH36dMaOHcuZZ57J2Wefvdf6M844g9tvv51Ro0bxgQ98gGnTph2SehcsWMBnPvMZdu/ezTHHHMNPfvITUqkUF154IXV1dbg7n/vc5xg4cCBf/vKXWbJkCbFYjDFjxnDmmWcekhhEpLhE9sSrAzFlyhRv+wCUV199lVGjRuXdrr5+NfF4X/r2/bsow+uxOnIORaRnMrMV7j6lI2WLoktHoweIiOxfUST8KLt0RESKRdEk/ELqmhIRKURFkvBFRGR/iiThq0tHRGR/onyI+QfMbFXW9K6ZXRVRbSjhi4jkF+UjDv8CVAOYWRzYBCyKoq5Ce8hH//79qa+v7/ByEZGu0FVdOjOBde7+ZlQV6I+2IiL5dVXCPw+4J7rdRzs88q233tryPvOQkvr6embOnMmkSZMYN24cv/71rzu8T3fnmmuuYezYsYwbN4777rsPgM2bN3PiiSdSXV3N2LFjefLJJ0mlUlx88cUtZb/3ve8d8mMUkd4h8qEVzKwUmAVcm2P9ZcBlAEcffXT+nV11Fazad3jkPukGcId4eecDrK6Gm3MPjzx37lyuuuoqLr/8cgDuv/9+Fi9eTFlZGYsWLaKyspLa2lqmTZvGrFmzOtS99OCDD7Jq1SpefPFFamtrmTp1KieeeCK/+MUv+PCHP8z1119PKpVi9+7drFq1ik2bNrF69WqATj1BS0QkW1eMpXMmsNLdt7S30t3nA/MhGFqhC+LplIkTJ7J161beeustampqGDRoEEcddRTNzc1cd911LFu2jFgsxqZNm9iyZQtHHHHEfvf51FNPcf755xOPxzn88MM56aSTeOGFF5g6dSqf/vSnaW5u5pxzzqG6uppjjjmG119/nSuuuIKzzz6b008/vQuOWkSKUVck/PM5VN05OVriTQ2vkU430q/fmENSTVtz5sxh4cKFvP3228ydOxeAu+++m5qaGlasWEFJSQlVVVXtDovcGSeeeCLLli3jkUce4eKLL+bqq6/moosu4sUXX2Tx4sXcfvvt3H///dx5552H4rBEpJeJtA/fzPoBpwEPRllP1Jdlzp07l3vvvZeFCxcyZ84cIBgWediwYZSUlLBkyRLefLPjf4+eMWMG9913H6lUipqaGpYtW8Zxxx3Hm2++yeGHH86ll17KP//zP7Ny5Upqa2tJp9PMnj2b//zP/2TlypVRHaaIFLlIW/juvgsYst+CB82I8iKdMWPGsHPnToYPH86RRx4JwAUXXMBHP/pRxo0bx5QpUzr1wJGPf/zjPPPMM0yYMAEz49vf/jZHHHEECxYs4Dvf+Q4lJSX079+fu+66i02bNnHJJZeQTqcB+OY3vxnJMYpI8SuK4ZEbGl4nldpF//7jogyvx9LwyCLFq9cNj6w7bUVE9k8JX0SklyiKhF9oQyuIiBSiokj4AbXwRUTyKZKErwegiIjsT9EkfLXwRUTyK5KEH50dO3Zw2223HdC2Z511lsa+EZGCURQJP/ijbTQt/HwJP5lM5t320UcfZeDAgVGEJSLSaUWR8KMeHnndunVUV1dzzTXXsHTpUmbMmMGsWbMYPXo0AOeccw6TJ09mzJgxzJ8/v2XbqqoqamtrWb9+PaNGjeLSSy9lzJgxnH766TQ0NOxT10MPPcQHP/hBJk6cyIc+9CG2bAnGm6uvr+eSSy5h3LhxjB8/ngceeACAxx57jEmTJjFhwgRmzpwZyfGLSPHoisHTDpkcoyOTTh+GeyXxuBMk/47bz+jI3HjjjaxevZpVYcVLly5l5cqVrF69mpEjRwJw5513MnjwYBoaGpg6dSqzZ89myJC9R5RYu3Yt99xzDz/60Y8499xzeeCBB7jwwgv3KnPCCSfw7LPPYmbccccdfPvb3+a73/0uX//61xkwYAAvv/wyANu3b6empoZLL72UZcuWMXLkSN55551OHbeI9D49KuEXiuOOO64l2QPccsstLFoUPL1xw4YNrF27dp+EP3LkSKqrqwGYPHky69ev32e/GzduZO7cuWzevJmmpqaWOp544gnuvffelnKDBg3ioYce4sQTT2wpM3jw4EN6jCJSfHpUws/VEm9sfIempk307z+pS27C6tevX8v80qVLeeKJJ3jmmWcoLy/n5JNPbneY5D59+rTMx+Pxdrt0rrjiCq6++mpmzZrF0qVLueGGGyKJX0R6pyLqw4co+vErKirYuXNnzvV1dXUMGjSI8vJy1qxZw7PPPnvAddXV1TF8+HAAFixY0LL8tNNO2+sxi9u3b2fatGksW7aMN954A0BdOiKyX0WR8KNs1A8ZMoTp06czduxYrrnmmn3Wn3HGGSSTSUaNGsW8efOYNm3aAdd1ww03MGfOHCZPnsxhhx3WsvxLX/oS27dvZ+zYsUyYMIElS5YwdOhQ5s+fzz/+4z8yYcKElgeziIjkUhTDIzc1baGxcQP9+lUTi/WoXqouoeGRRYpXLx0eGXS3rYhIblE/4nCgmS00szVm9qqZHR9lfUr4IiK5Rd3/8X3gMXf/hJmVAuXRVKPhkUVE9ieyhG9mA4ATgYsB3L0JaIqotvBVLXwRkVyi7NIZCdQAPzGzP5nZHWbWb38bHYjMtfeF9AdoEZFCE2XCTwCTgB+4+0RgFzCvbSEzu8zMlpvZ8pqamgjDERHp3aJM+BuBje7+XPh+IcEHwF7cfb67T3H3KUOHDj3AqgqrS6d///7dHYKIyD4iS/ju/jawwcw+EC6aCbwSTW2FlfBFRApR1NfhXwHcbWYvAdXAf0VTTXQJf968eXsNa3DDDTdw0003UV9fz8yZM5k0aRLjxo3j17/+9X73lWsY5faGOc41JLKIyIGK9LJMd18FdOgOsI646rGrWPX2vuMjuydJpxuIxcoxi3dqn9VHVHPzGbnHR547dy5XXXUVl19+OQD3338/ixcvpqysjEWLFlFZWUltbS3Tpk1j1qxZeQdva28Y5XQ63e4wx+0NiSwicjA0DsF+TJw4ka1bt/LWW29RU1PDoEGDOOqoo2hubua6665j2bJlxGIxNm3axJYtWzjiiCNy7qu9YZRramraHea4vSGRRUQORo9K+Lla4snkuzQ0/JW+fT9AIlFxyOudM2cOCxcu5O23324ZpOzuu++mpqaGFStWUFJSQlVVVbvDImd0dBhlEZGoFMlYOtGaO3cu9957LwsXLmTOnDlAMJTxsGHDKCkpYcmSJbz55pt595FrGOVcwxy3NySyiMjBKJKEH+1VOmPGjGHnzp0MHz6cI488EoALLriA5cuXM27cOO666y6OPfbYvPvINYxyrmGO2xsSWUTkYBTF8MjJZD0NDWvo2/f9JBIDogyxR9LwyCLFq9cNj9x6ZUzhfHiJiBSaokj4GQX0ZUVEpOD0iIS//24ntfBzKaQuOxHpXgWf8MvKyti2bdt+EpcSfnvcnW3btlFWVtbdoYhIASj46/BHjBjBxo0byTeSZjrdTFNTLSUlEI9v6cLoCl9ZWRkjRozo7jBEpAAUfMIvKSlpuQs1l927X+P558/k2GN/xhFHXNhFkYmI9CwF36XTEZnxc9yT3RyJiEjhKpKEn/mikurWOEREClmRJHy18EVE9qdIEn7QwndXC19EJJciSfhq4YuI7E+RJPxMC18JX0Qkl0gvyzSz9cBOgr+mJjs6wE/nZVr46tIREcmlK67DP8Xda6OsQC18EZH9K7IuHbXwRURyiTrhO/A7M1thZpdFVYn+aCsisn9Rd+mc4O6bzGwY8LiZrXH3ZdkFwg+CywCOPvroA6okGA8/hm68EhHJLdIWvrtvCl+3AouA49opM9/dp7j7lKFDhx5wXWZxtfBFRPKILOGbWT8zq8jMA6cDq6OrL6E+fBGRPKLs0jkcWBQ+fjAB/MLdH4uqMrXwRUTyiyzhu/vrwISo9t+WWvgiIvkVxWWZAbXwRUTyKZqEH7TwlfBFRHIpooQfV5eOiEgeRZTw1cIXEcmniBJ+HN14JSKSWxElfLXwRUTyKbKErxa+iEguRZTwdVmmiEg+RZTw1cIXEcmnaBK+brwSEcmvaBK+WvgiIvkVUcJXC19EJJ8iSvgJdB2+iEhuRZTw1cIXEcmniBK+brwSEcmniBK+Bk8TEcmniBK+WvgiIvl0KOGb2ZVmVmmBH5vZSjM7vYPbxs3sT2b28MGFur96dFmmiEg+HW3hf9rd3yV4EPkg4JPAjR3c9krg1QOIrZP0R1sRkXw6mvAtfD0L+Jm7/zlrWe6NzEYAZwN3HFh4HacWvohIfh1N+CvM7HcECX+xmVUA6Q5sdzPwhXxlzewyM1tuZstramo6GE57+1ELX0Qkn44m/H8C5gFT3X03UAJckm8DM/sIsNXdV+Qr5+7z3X2Ku08ZOnRoB8Nprz7deCUikk9HE/7xwF/cfYeZXQh8CajbzzbTgVlmth64FzjVzH5+wJHuh1r4IiL5dTTh/wDYbWYTgH8D1gF35dvA3a919xHuXgWcB/zB3S88mGDzUR++iEh+HU34SXd34GPA/7r7rUBFdGF1nlr4IiL5JTpYbqeZXUtwOeYMM4sR9ON3iLsvBZZ2OrpO0I1XIiL5dbSFPxdoJLge/21gBPCdyKI6IBpaQUQknw4l/DDJ3w0MCK++2ePuefvwu5pa+CIi+XV0aIVzgeeBOcC5wHNm9okoA+ssDZ4mIpJfR/vwrye4Bn8rgJkNBZ4AFkYVWGephS8ikl9H+/BjmWQf2taJbbtE5sar4GIiERFpq6Mt/MfMbDFwT/h+LvBoNCEdGLN4OJcG4vmKioj0Sh1K+O5+jZnNJrh7FmC+uy+KLqzOC1r44J7KSv4iIpLR0RY+7v4A8ECEsRyUTJIP+vFLuzcYEZEClDfhm9lOoL1OcQPc3SsjieoAZLfwRURkX3kTvrsX1PAJ+WW38EVEpK2CutLmYKiFLyKSXxElfLXwRUTyKaKEn2nhK+GLiLSniBJ+5lJMdemIiLSniBK+WvgiIvkUUcLP9OGrhS8i0p7IEr6ZlZnZ82b2opn92cy+GlVdQX1q4YuI5NPhO20PQCNwqrvXm1kJ8JSZ/dbdn42iMl2WKSKSX2QJP3wGbn34tiScIhzKUpdliojkE2kfvpnFzWwVsBV43N2fi64utfBFRPKJNOG7e8rdqwmegXucmY1tW8bMLjOz5Wa2vKam5oDr0o1XIiL5dclVOu6+A1gCnNHOuvnuPsXdpwwdOvSA68i08HUdvohI+6K8SmeomQ0M5/sCpwFroqtPLXwRkXyivErnSGCBBZk4Btzv7g9HVZkuyxQRyS/Kq3ReAiZGtf+2dOOViEh+RXSnrVr4IiL5FE3Cb70OXy18EZH2FE3CVwtfRCS/Ikz4auGLiLSniBK+LssUEcmniBK+brwSEcmniBK+WvgiIvkUUcJXH76ISD5FlPDVwhcRyaeIEr5a+CIi+RRNwtcDUERE8iuahK8br0RE8iuihK+hFURE8imihK8WvohIPkWU8OPhnFr4IiLtKaKErxa+iEg+RZTwY4CpD19EJIcon2l7lJktMbNXzOzPZnZlVHW11hlXC19EJIcon2mbBP7N3VeaWQWwwswed/dXoqrQLKEWvohIDpG18N19s7uvDOd3Aq8Cw6OqL6AWvohILl3Sh29mVQQPNH8u2nrUwhcRySXyhG9m/YEHgKvc/d121l9mZsvNbHlNTc1B1qUWvohILpEmfDMrIUj2d7v7g+2Vcff57j7F3acMHTr0IOtLKOGLiOQQ5VU6BvwYeNXd/zuqevauM45uvBIRaV+ULfzpwCeBU81sVTidFWF9auGLiOQR2WWZ7v4UYFHtvz1BH75a+CIi7SmaO21BLXwRkXyKKuEH1+GrhS8i0p6iSvhq4YuI5FaECV8tfBGR9hRZwteNVyIiuRRZwk+g6/BFRNpXZAlfLXwRkVyKLOGrD19EJJciS/hq4YuI5FJkCV+XZYqI5FJUCV83XomI5FZUCV8tfBGR3Ios4auFLyKSS5El/ATuzd0dhohIQSqqhN+nzwj27FmvVr6ISDuKKuH3719NOr2bhoZ13R2KiEjBKbKEPwGA+voXuzkSEZHCE+Uzbe80s61mtjqqOtoqLx8NxKmvX9VVVYqI9BhRtvB/CpwR4f73EY+XUV5+rFr4IiLtiCzhu/sy4J2o9p9L//7V7NqlhC8i0lZkDzHvLv37T2Dr1rtpbt5GScmQDm3j7jQkG3in4R3ebXyXxmQje5J7aEyFr8lGGlONNKWaaE41k0wnaU6Hr6nmveaT6SRNqWaakklSaUilnHSKYD6dmXfSmXXpYF065cFr2lu3S4OnAXPicYC916XT4HjmKFqPBweHNI6HZdwJp2A+7a1lyKwL9+He+urhrj1cm1nXssxb62vdvp19tZRps4zsY8g+jvDV2l/XMtcSY5v4ssp7O9u1t459SuWOL/+yzu2r3XWWtc7aL59LZq255S7plmtN/n3nr/qQsPCA91tVOwW6ILxDw/d6oSw9hHdveyzyars94ZvZZcBlAEcfffRB7y/7D7eDBp1KQ3MDa2rX8ErNK/yt7m9s3bWVLbu2sGXXFrbu2sq23dt4p+EdGlONB103AKkEpMMp85u61y9X22VZ69ouy7vdIdqXtb5ae8sy27VdltmdG5a1rvXXtbWe1iWWKdLuunbj8/aPy2iNITNvWPid1Wj7775xtld3O9th4dfg7KOy8H3bZdlz7a/b671lxdXB//P2zxfhPlp51gfFXquC/2Q6ou0+D7bcXoG0CaH1g8TbHto+m+5vxYF9lHWxNv83/RIDu6Zaj/Aj28yqgIfdfWxHyk+ZMsWXL19+UHU2NW3hV384gmUNM1nxzi5e2PQCqazr8itKKzis7zDK04djDcNI1x9G4/bB1NcOZsdbg2ncWQHJsnDqE7ym+pCgDxXlfehfnqCiXwmV/RJU9i9hQEWCyn4llPdNUFaaoLTEKClhr6m0lH2W5VuevS6RgFQKmpqCFn2fPnuvz/fLFo9DLNb6mpk368QvqYgUNDNb4e5TOlK221v4B23PHvj85+GUU2iafQ7//fxP+OoLRtL/wNTh0/jC9C8w6chJWO1onltcxeIHy3nppdbNKyth5EgY816omgpVVcE0YgQMGhSsr6yEsrLuOkARkUMjsoRvZvcAJwOHmdlG4Cvu/uNDXlGfPvDQQ/j2d5id+hkP//VhTj1yGFceO4SPzniaX/0KvvsV+L//C1q3J5wA//VfMHUqVFfDYYcd8ohERApSZAnf3c+Pat97MYMZM1jw9mM8/Ncd3HTaTZxzeA2vvfYDLrooxc9/HueYY+B734OLLoLBg7skKhGRgtPzu3SAt/5hHJ/fdC8zhk3l88d/nj+vfpzPfvZ83ngjxte+BtddR3iVi4hI79Xjh1Zwd/6ldDGNCbizdA5GjC9+8TQ2b34ft956HV/+spK9iAgUQcLfsWcHG7yObzzTl/c9+1d++Uv47W9j/Pu//x+jRt3Irl1rujtEEZGC0OMT/qC+g3jh0hf4XPmp7Fi6iiuvhMmT4dprqzErZdOm/+3uEEVECkKPT/gAJfES4ifM4Guvnc/Wrc78+dC37zCGDTuPLVsWkEy+290hioh0u6JI+AB+wgzu5Tw+ftxbTJoULBsx4nOkUvW8+ebXuzc4EZECUDQJf2V8Kpt5D7Mql7Ysq6iYzHve8xk2bLiJmppfdV9wIiIFoGgS/sOLSzDSnPnGbcEYBKH3ve9mKiqmsGbNp9i9+7VujFBEpHsVTcJ/6CE4/v21DF37NNx3X8vyWKwPY8YsxCzBSy99mIaGN7oxShGR7lMUCf+tt2DFCvjIxYfBhAlw/fXQ2Dr6ZVnZexk//rckk9v5059msGvXq90YrYhI9yiKhP/II8HrR2fF4FvfgjfegNtv36tMZeVxVFf/EfckK1cez6ZNt+JZo2iKiBS7okj4Dz8M730vjBkDnH46zJwJX/86rFu3V7n+/ccxadLTVFRMYe3af2XFiils2/YYUQ4RLSJSKHp8wm9ogMcfh49+NBzj3Qy+//1g5fHHw3PP7VW+b99jmDDhcUaPvp/m5u28/PKZrFx5PFu2/IJkcmfXH4CISBfp8Qm/Tx948km44oqshWPGwNNPQ0UFnHIKfPObUFfXstrMGDZsDh/84F/5+7+fT3PzFl599QKefnoYq1fPZuvW+0ildnX9wYiIRCjSJ1511qF44tVetm6FT3866OSvrIR/+Rf47GeDJ5xkcU9TV/c0NTX3U1PzS5qa3sasDxUVk6msnEZl5fFUVk6jrGzEoYtNROQQ6MwTr4o74WesXAk33ggPPhhco/+hDwXdPVOmBAPvvOc9LUXdU9TVPUVt7UO8++4z7Ny5Avfgip+SkmH06zeOfv1GUVp6BKWlR1JePop+/caQSFQe+rhFRPZDCT+XDRvghz+ERYtgzZrWG7SOPDJI/FOmwOjRMHQoDBsGVVWkyxLU17/Iu+8+Q339Knbtepndu9eSStXttetEYhAlJYdRUjK05bW0dBglJcMoLT2c0tJhJBIDicXKicf7ha/lxGJlmPX4njUR6SYFk/DN7Azg+0AcuMPdb8xXPvKEn23XLli1CpYvDy7iX748+BBoez6OPDJI/gMHBtOgQTBwIOkBFSQroLGsnoayWhr71tNYvpum0ndpsh002Tb2eC1emsb3Mx5/LNaXeLySRGJg1jSAeLyCRKICd8e9CbM48fgAEonKcH0lsVgpZiWYJcKpZK/XWCz3urblIIbp6eYiPUpBJHwziwN/BU4DNgIvAOe7+yu5tunShN+enTuDa/i3bYPNm+H114P3tbWwY0cwbd8evO7s+BU9HotBnxK8NBFO8XCK4SUx0qWGxxy3JOlYCidJ2lKkY0mcJB43iMWCMjTjMfAYYOErQAzcsl7DKTO/T7l2lnkciMUgHk4WD6Z4DLM4FouDxSAWxywelG1ZHodYnFjKiO924nvSpPv1IV1ZBqUlQHzfDxMLAjaLhx8+4X5w3NPBKx5uFwu/CYUfShZvWWYWa3kP4DSDp7FYH+LxvkCitW7LOjm293sDSIM1NkFjMji+kjjEE5DIHG/mpFnLa7CLWNZ727uMEzQkHCwdvGLB/ymxeDBvhsUMt1j4PvPhG8wH68N1BPW5GeZhPWEd1qa+4LjC+XAyI+u9t7627Ie9t6GdfbetJzuPuAdxZS23zLkvKYHSUjyRwBMxLJ7InPlwX94635llmf1nT5nzlT1ltt3fBMH2iUTwBKVEInifSgU9A+n03vNt4+jsfN++MHs2B6IzCT/KRxweB7zLQSEZAAAIhUlEQVTm7q+HQd0LfAzImfC7XUUFjB/fsbLJZHDlT+YDIPuDoLGxdWpqwsJ5y17edkqlWqfMD1Nzeu/36TSeSkEqCekUnk5m/cBlfgjDHz5PQzr84c38QKZb5y3zg50OJktnfmDT4SQSnczHrASaBycomd0ceT1RJvzhwIas9xuBD7YtZGaXAZcBHH300RGGc4glEjBkSDB1Icsxf0hkPlgyU3aLJ/Oh0XZquzwehwEDgutld+8OPgiTyX3ryvHN0tPpvb8JZJULvo2m8XQS9zTuqeBuaU+G3wiCO6fNSjHipNO7SSZ34p7M2lfwrQEc83TWflubv15Wipckgg/NZLJ1SqVay7WEFn644lk38GXtzx2PhccTA880r1s+lLNaiB68ekuL0TGy3nvWPtPpljiChnlmPmzCW6aB37o882WgpaneUiZrPb7vskzM5i3fijzrfGXKtWyHt9aTXUc6Cc1NeFMT8VSCWCqBp5Ok0w2kvTn8ppb17cYsOKfmBN8vPOtLU+s8ljmftJzDlvnwG5Vl/sPMgn1lvpUZWCysK3OsmZ+/dPiNLJkK/v/TKdzSeMwhZsH/a8wgHgu/tFnLf0nLN6vW/yDI+ibj3kQq1RiezlISpQOpInrd/hBzd58PzIegS6ebw+ndYrGwG6Pk0OyvX79g6oR8H2LWgTJtlXaqdpHiFuXlIZuAo7LejwiXiYhIN4gy4b8AvN/MRppZKXAe8JsI6xMRkTwi69Jx96SZ/SuwmOCyzDvd/c9R1SciIvlF2ofv7o8Cj0ZZh4iIdIxu8RQR6SWU8EVEegklfBGRXkIJX0Sklyio0TLNrAZ48wA3PwyoPYThdJWeGHdPjBkUd1friXH3xJjf6+5DO1KwoBL+wTCz5R0dQKiQ9MS4e2LMoLi7Wk+MuyfG3Bnq0hER6SWU8EVEeoliSvjzuzuAA9QT4+6JMYPi7mo9Me6eGHOHFU0fvoiI5FdMLXwREcmjxyd8MzvDzP5iZq+Z2bzujicXMzvKzJaY2Stm9mczuzJcPtjMHjezteHroO6OtT1mFjezP5nZw+H7kWb2XHje7wtHRC0oZjbQzBaa2Roze9XMji/0821mnw9/Plab2T1mVlaI59rM7jSzrWa2OmtZu+fWAreE8b9kZpMKLO7vhD8jL5nZIjMbmLXu2jDuv5jZh7sn6kOnRyf88Lm5twJnAqOB881sdPdGlVMS+Dd3Hw1MAy4PY50H/N7d3w/8PnxfiK4EXs16/y3ge+7+PmA78E/dElV+3wcec/djgQkE8Rfs+Taz4cDngCnuPpZglNnzKMxz/VPgjDbLcp3bM4H3h9NlwA+6KMb2/JR9434cGOvu4wmew30tQPj7eR4wJtzmtjDn9Fg9OuGT9dxcd28CMs/NLTjuvtndV4bzOwmSz3CCeBeExRYA53RPhLmZ2QjgbOCO8L0BpwILwyIFF7eZDQBOBH4M4O5N7r6Dwj/fCaCvmSWAcmAzBXiu3X0Z8E6bxbnO7ceAuzzwLDDQzI7smkj31l7c7v47b3kOJs8SPKwJgrjvdfdGd38DeI0g5/RYPT3ht/fc3OHdFEuHmVkVMBF4Djjc3TeHq94GDu+msPK5GfgCrU83HwLsyPolKcTzPhKoAX4SdkXdYWb9KODz7e6bgJuAvxEk+jpgBYV/rjNyndue9Hv6aeC34XxPirtDenrC73HMrD/wAHCVu7+bvc5bn6ZdMMzsI8BWd1/R3bF0UgKYBPzA3ScCu2jTfVNo5zvs8/4YwYfVe4B+7Nv90CMU2rntCDO7nqDr9e7ujiUqPT3h96jn5ppZCUGyv9vdHwwXb8l8vQ1ft3ZXfDlMB2aZ2XqCLrNTCfrGB4bdDlCY530jsNHdnwvfLyT4ACjk8/0h4A13r3H3ZuBBgvNf6Oc6I9e5LfjfUzO7GPgIcIG3Xqte8HF3Vk9P+D3mublhv/ePgVfd/b+zVv0G+FQ4/yng110dWz7ufq27j3D3KoLz+wd3vwBYAnwiLFaIcb8NbDCzD4SLZgKvUNjn+2/ANDMrD39eMjEX9LnOkuvc/ga4KLxaZxpQl9X10+3M7AyCLstZ7r47a9VvgPPMrI+ZjST4o/Pz3RHjIePuPXoCziL4y/o64PrujidPnCcQfMV9CVgVTmcR9If/HlgLPAEM7u5Y8xzDycDD4fwxBD/8rwG/BPp0d3ztxFsNLA/P+a+AQYV+voGvAmuA1cDPgD6FeK6Bewj+ztBM8G3qn3KdW8AIrqZbB7xMcBVSIcX9GkFffeb38vas8teHcf8FOLO7z/vBTrrTVkSkl+jpXToiItJBSvgiIr2EEr6ISC+hhC8i0kso4YuI9BJK+CKHgJmdnBlJVKRQKeGLiPQSSvjSq5jZhWb2vJmtMrMfhuP815vZ98Jx6H9vZkPDstVm9mzWOOmZ8d3fZ2ZPmNmLZrbSzP4u3H3/rPH37w7vlhUpGEr40muY2ShgLjDd3auBFHABwSBly919DPBH4CvhJncBX/RgnPSXs5bfDdzq7hOAfyC4cxOCEVCvIng2wzEE4+CIFIzE/ouIFI2ZwGTghbDx3ZdggK80cF9Y5ufAg+F4+gPd/Y/h8gXAL82sAhju7osA3H0PQLi/5919Y/h+FVAFPBX9YYl0jBK+9CYGLHD3a/daaPblNuUOdLyRxqz5FPr9kgKjLh3pTX4PfMLMhkHLM1jfS/B7kBmN8v8BT7l7HbDdzGaEyz8J/NGDp5VtNLNzwn30MbPyLj0KkQOkFoj0Gu7+ipl9CfidmcUIRky8nODhKMeF67YS9PNDMMTv7WFCfx24JFz+SeCHZva1cB9zuvAwRA6YRsuUXs/M6t29f3fHIRI1demIiPQSauGLiPQSauGLiPQSSvgiIr2EEr6ISC+hhC8i0kso4YuI9BJK+CIivcT/B+WvQguwuWp8AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 102us/sample - loss: 0.0297 - acc: 0.9901\n",
      "Loss: 0.029699888637179175 Accuracy: 0.9901\n",
      "\n",
      "Train on 40200 samples, validate on 19800 samples\n",
      "Epoch 1/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 7.5763 - acc: 0.3043\n",
      "Epoch 00001: val_loss improved from inf to 1.03362, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_4_conv_checkpoint/001-1.0336.hdf5\n",
      "40200/40200 [==============================] - 8s 191us/sample - loss: 7.5655 - acc: 0.3046 - val_loss: 1.0336 - val_acc: 0.6720\n",
      "Epoch 2/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 1.2018 - acc: 0.6080\n",
      "Epoch 00002: val_loss improved from 1.03362 to 0.54994, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_4_conv_checkpoint/002-0.5499.hdf5\n",
      "40200/40200 [==============================] - 6s 144us/sample - loss: 1.2010 - acc: 0.6083 - val_loss: 0.5499 - val_acc: 0.8342\n",
      "Epoch 3/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.8032 - acc: 0.7415\n",
      "Epoch 00003: val_loss improved from 0.54994 to 0.36062, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_4_conv_checkpoint/003-0.3606.hdf5\n",
      "40200/40200 [==============================] - 6s 144us/sample - loss: 0.8023 - acc: 0.7419 - val_loss: 0.3606 - val_acc: 0.8932\n",
      "Epoch 4/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.6024 - acc: 0.8096\n",
      "Epoch 00004: val_loss improved from 0.36062 to 0.26680, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_4_conv_checkpoint/004-0.2668.hdf5\n",
      "40200/40200 [==============================] - 6s 146us/sample - loss: 0.6023 - acc: 0.8096 - val_loss: 0.2668 - val_acc: 0.9198\n",
      "Epoch 5/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.4825 - acc: 0.8484\n",
      "Epoch 00005: val_loss improved from 0.26680 to 0.22026, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_4_conv_checkpoint/005-0.2203.hdf5\n",
      "40200/40200 [==============================] - 6s 145us/sample - loss: 0.4820 - acc: 0.8486 - val_loss: 0.2203 - val_acc: 0.9351\n",
      "Epoch 6/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.4066 - acc: 0.8759\n",
      "Epoch 00006: val_loss improved from 0.22026 to 0.18647, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_4_conv_checkpoint/006-0.1865.hdf5\n",
      "40200/40200 [==============================] - 5s 135us/sample - loss: 0.4063 - acc: 0.8759 - val_loss: 0.1865 - val_acc: 0.9429\n",
      "Epoch 7/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.3471 - acc: 0.8949\n",
      "Epoch 00007: val_loss improved from 0.18647 to 0.16791, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_4_conv_checkpoint/007-0.1679.hdf5\n",
      "40200/40200 [==============================] - 6s 144us/sample - loss: 0.3470 - acc: 0.8949 - val_loss: 0.1679 - val_acc: 0.9492\n",
      "Epoch 8/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.3038 - acc: 0.9073\n",
      "Epoch 00008: val_loss improved from 0.16791 to 0.14611, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_4_conv_checkpoint/008-0.1461.hdf5\n",
      "40200/40200 [==============================] - 6s 143us/sample - loss: 0.3038 - acc: 0.9074 - val_loss: 0.1461 - val_acc: 0.9551\n",
      "Epoch 9/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.2691 - acc: 0.9188\n",
      "Epoch 00009: val_loss improved from 0.14611 to 0.13470, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_4_conv_checkpoint/009-0.1347.hdf5\n",
      "40200/40200 [==============================] - 6s 144us/sample - loss: 0.2696 - acc: 0.9188 - val_loss: 0.1347 - val_acc: 0.9596\n",
      "Epoch 10/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.2423 - acc: 0.9260\n",
      "Epoch 00010: val_loss improved from 0.13470 to 0.12490, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_4_conv_checkpoint/010-0.1249.hdf5\n",
      "40200/40200 [==============================] - 6s 143us/sample - loss: 0.2421 - acc: 0.9260 - val_loss: 0.1249 - val_acc: 0.9621\n",
      "Epoch 11/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.2243 - acc: 0.9326\n",
      "Epoch 00011: val_loss improved from 0.12490 to 0.11527, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_4_conv_checkpoint/011-0.1153.hdf5\n",
      "40200/40200 [==============================] - 6s 143us/sample - loss: 0.2241 - acc: 0.9326 - val_loss: 0.1153 - val_acc: 0.9654\n",
      "Epoch 12/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.2053 - acc: 0.9387\n",
      "Epoch 00012: val_loss improved from 0.11527 to 0.10139, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_4_conv_checkpoint/012-0.1014.hdf5\n",
      "40200/40200 [==============================] - 6s 145us/sample - loss: 0.2053 - acc: 0.9387 - val_loss: 0.1014 - val_acc: 0.9706\n",
      "Epoch 13/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.1848 - acc: 0.9431\n",
      "Epoch 00013: val_loss improved from 0.10139 to 0.09513, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_4_conv_checkpoint/013-0.0951.hdf5\n",
      "40200/40200 [==============================] - 6s 144us/sample - loss: 0.1848 - acc: 0.9431 - val_loss: 0.0951 - val_acc: 0.9720\n",
      "Epoch 14/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.1775 - acc: 0.9463\n",
      "Epoch 00014: val_loss improved from 0.09513 to 0.09136, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_4_conv_checkpoint/014-0.0914.hdf5\n",
      "40200/40200 [==============================] - 6s 144us/sample - loss: 0.1772 - acc: 0.9464 - val_loss: 0.0914 - val_acc: 0.9719\n",
      "Epoch 15/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.1668 - acc: 0.9494\n",
      "Epoch 00015: val_loss improved from 0.09136 to 0.08788, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_4_conv_checkpoint/015-0.0879.hdf5\n",
      "40200/40200 [==============================] - 6s 143us/sample - loss: 0.1668 - acc: 0.9495 - val_loss: 0.0879 - val_acc: 0.9745\n",
      "Epoch 16/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.1468 - acc: 0.9551\n",
      "Epoch 00016: val_loss improved from 0.08788 to 0.08726, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_4_conv_checkpoint/016-0.0873.hdf5\n",
      "40200/40200 [==============================] - 5s 134us/sample - loss: 0.1469 - acc: 0.9549 - val_loss: 0.0873 - val_acc: 0.9745\n",
      "Epoch 17/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.1407 - acc: 0.9579\n",
      "Epoch 00017: val_loss improved from 0.08726 to 0.07958, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_4_conv_checkpoint/017-0.0796.hdf5\n",
      "40200/40200 [==============================] - 6s 141us/sample - loss: 0.1407 - acc: 0.9579 - val_loss: 0.0796 - val_acc: 0.9758\n",
      "Epoch 18/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.1328 - acc: 0.9600\n",
      "Epoch 00018: val_loss improved from 0.07958 to 0.07548, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_4_conv_checkpoint/018-0.0755.hdf5\n",
      "40200/40200 [==============================] - 6s 143us/sample - loss: 0.1328 - acc: 0.9600 - val_loss: 0.0755 - val_acc: 0.9767\n",
      "Epoch 19/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.1248 - acc: 0.9623\n",
      "Epoch 00019: val_loss improved from 0.07548 to 0.07283, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_4_conv_checkpoint/019-0.0728.hdf5\n",
      "40200/40200 [==============================] - 6s 145us/sample - loss: 0.1249 - acc: 0.9623 - val_loss: 0.0728 - val_acc: 0.9782\n",
      "Epoch 20/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.1206 - acc: 0.9627\n",
      "Epoch 00020: val_loss improved from 0.07283 to 0.07185, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_4_conv_checkpoint/020-0.0718.hdf5\n",
      "40200/40200 [==============================] - 6s 145us/sample - loss: 0.1207 - acc: 0.9626 - val_loss: 0.0718 - val_acc: 0.9781\n",
      "Epoch 21/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.1147 - acc: 0.9643\n",
      "Epoch 00021: val_loss did not improve from 0.07185\n",
      "40200/40200 [==============================] - 6s 143us/sample - loss: 0.1146 - acc: 0.9644 - val_loss: 0.0773 - val_acc: 0.9776\n",
      "Epoch 22/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.1077 - acc: 0.9672\n",
      "Epoch 00022: val_loss improved from 0.07185 to 0.06746, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_4_conv_checkpoint/022-0.0675.hdf5\n",
      "40200/40200 [==============================] - 6s 143us/sample - loss: 0.1076 - acc: 0.9672 - val_loss: 0.0675 - val_acc: 0.9798\n",
      "Epoch 23/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.1061 - acc: 0.9672\n",
      "Epoch 00023: val_loss improved from 0.06746 to 0.06676, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_4_conv_checkpoint/023-0.0668.hdf5\n",
      "40200/40200 [==============================] - 6s 142us/sample - loss: 0.1058 - acc: 0.9673 - val_loss: 0.0668 - val_acc: 0.9805\n",
      "Epoch 24/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.1034 - acc: 0.9680\n",
      "Epoch 00024: val_loss improved from 0.06676 to 0.06374, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_4_conv_checkpoint/024-0.0637.hdf5\n",
      "40200/40200 [==============================] - 6s 144us/sample - loss: 0.1035 - acc: 0.9679 - val_loss: 0.0637 - val_acc: 0.9802\n",
      "Epoch 25/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.0980 - acc: 0.9697\n",
      "Epoch 00025: val_loss did not improve from 0.06374\n",
      "40200/40200 [==============================] - 6s 142us/sample - loss: 0.0980 - acc: 0.9697 - val_loss: 0.0641 - val_acc: 0.9813\n",
      "Epoch 26/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.0930 - acc: 0.9716\n",
      "Epoch 00026: val_loss improved from 0.06374 to 0.06230, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_4_conv_checkpoint/026-0.0623.hdf5\n",
      "40200/40200 [==============================] - 6s 145us/sample - loss: 0.0933 - acc: 0.9715 - val_loss: 0.0623 - val_acc: 0.9812\n",
      "Epoch 27/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.0893 - acc: 0.9718\n",
      "Epoch 00027: val_loss improved from 0.06230 to 0.06037, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_4_conv_checkpoint/027-0.0604.hdf5\n",
      "40200/40200 [==============================] - 5s 133us/sample - loss: 0.0893 - acc: 0.9718 - val_loss: 0.0604 - val_acc: 0.9815\n",
      "Epoch 28/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.0884 - acc: 0.9718\n",
      "Epoch 00028: val_loss did not improve from 0.06037\n",
      "40200/40200 [==============================] - 6s 142us/sample - loss: 0.0885 - acc: 0.9718 - val_loss: 0.0612 - val_acc: 0.9826\n",
      "Epoch 29/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.0840 - acc: 0.9750\n",
      "Epoch 00029: val_loss did not improve from 0.06037\n",
      "40200/40200 [==============================] - 6s 144us/sample - loss: 0.0839 - acc: 0.9751 - val_loss: 0.0617 - val_acc: 0.9821\n",
      "Epoch 30/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.0821 - acc: 0.9749\n",
      "Epoch 00030: val_loss improved from 0.06037 to 0.05839, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_4_conv_checkpoint/030-0.0584.hdf5\n",
      "40200/40200 [==============================] - 6s 143us/sample - loss: 0.0820 - acc: 0.9750 - val_loss: 0.0584 - val_acc: 0.9827\n",
      "Epoch 31/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.0766 - acc: 0.9753\n",
      "Epoch 00031: val_loss did not improve from 0.05839\n",
      "40200/40200 [==============================] - 6s 144us/sample - loss: 0.0765 - acc: 0.9753 - val_loss: 0.0603 - val_acc: 0.9830\n",
      "Epoch 32/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.0734 - acc: 0.9772\n",
      "Epoch 00032: val_loss did not improve from 0.05839\n",
      "40200/40200 [==============================] - 6s 142us/sample - loss: 0.0735 - acc: 0.9771 - val_loss: 0.0593 - val_acc: 0.9827\n",
      "Epoch 33/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.0748 - acc: 0.9771\n",
      "Epoch 00033: val_loss improved from 0.05839 to 0.05503, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_4_conv_checkpoint/033-0.0550.hdf5\n",
      "40200/40200 [==============================] - 6s 143us/sample - loss: 0.0747 - acc: 0.9771 - val_loss: 0.0550 - val_acc: 0.9833\n",
      "Epoch 34/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.0697 - acc: 0.9789\n",
      "Epoch 00034: val_loss did not improve from 0.05503\n",
      "40200/40200 [==============================] - 6s 141us/sample - loss: 0.0697 - acc: 0.9789 - val_loss: 0.0597 - val_acc: 0.9830\n",
      "Epoch 35/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.0698 - acc: 0.9785\n",
      "Epoch 00035: val_loss did not improve from 0.05503\n",
      "40200/40200 [==============================] - 6s 144us/sample - loss: 0.0699 - acc: 0.9784 - val_loss: 0.0572 - val_acc: 0.9834\n",
      "Epoch 36/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.0679 - acc: 0.9792\n",
      "Epoch 00036: val_loss did not improve from 0.05503\n",
      "40200/40200 [==============================] - 6s 141us/sample - loss: 0.0679 - acc: 0.9793 - val_loss: 0.0584 - val_acc: 0.9831\n",
      "Epoch 37/500\n",
      "39744/40200 [============================>.] - ETA: 0s - loss: 0.0673 - acc: 0.9798\n",
      "Epoch 00037: val_loss did not improve from 0.05503\n",
      "40200/40200 [==============================] - 6s 139us/sample - loss: 0.0670 - acc: 0.9798 - val_loss: 0.0551 - val_acc: 0.9841\n",
      "Epoch 38/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.0649 - acc: 0.9796\n",
      "Epoch 00038: val_loss improved from 0.05503 to 0.05477, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_4_conv_checkpoint/038-0.0548.hdf5\n",
      "40200/40200 [==============================] - 6s 140us/sample - loss: 0.0649 - acc: 0.9796 - val_loss: 0.0548 - val_acc: 0.9839\n",
      "Epoch 39/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.0614 - acc: 0.9803\n",
      "Epoch 00039: val_loss improved from 0.05477 to 0.05231, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_4_conv_checkpoint/039-0.0523.hdf5\n",
      "40200/40200 [==============================] - 6s 144us/sample - loss: 0.0614 - acc: 0.9803 - val_loss: 0.0523 - val_acc: 0.9848\n",
      "Epoch 40/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.0625 - acc: 0.9794\n",
      "Epoch 00040: val_loss did not improve from 0.05231\n",
      "40200/40200 [==============================] - 6s 143us/sample - loss: 0.0627 - acc: 0.9795 - val_loss: 0.0536 - val_acc: 0.9846\n",
      "Epoch 41/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.0570 - acc: 0.9818\n",
      "Epoch 00041: val_loss did not improve from 0.05231\n",
      "40200/40200 [==============================] - 6s 142us/sample - loss: 0.0570 - acc: 0.9818 - val_loss: 0.0552 - val_acc: 0.9841\n",
      "Epoch 42/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.0585 - acc: 0.9819\n",
      "Epoch 00042: val_loss did not improve from 0.05231\n",
      "40200/40200 [==============================] - 6s 142us/sample - loss: 0.0584 - acc: 0.9820 - val_loss: 0.0530 - val_acc: 0.9844\n",
      "Epoch 43/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.0551 - acc: 0.9818\n",
      "Epoch 00043: val_loss did not improve from 0.05231\n",
      "40200/40200 [==============================] - 6s 144us/sample - loss: 0.0551 - acc: 0.9818 - val_loss: 0.0529 - val_acc: 0.9846\n",
      "Epoch 44/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.0518 - acc: 0.9835\n",
      "Epoch 00044: val_loss improved from 0.05231 to 0.05089, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_4_conv_checkpoint/044-0.0509.hdf5\n",
      "40200/40200 [==============================] - 6s 141us/sample - loss: 0.0517 - acc: 0.9835 - val_loss: 0.0509 - val_acc: 0.9851\n",
      "Epoch 45/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.0538 - acc: 0.9834\n",
      "Epoch 00045: val_loss did not improve from 0.05089\n",
      "40200/40200 [==============================] - 6s 141us/sample - loss: 0.0542 - acc: 0.9834 - val_loss: 0.0514 - val_acc: 0.9850\n",
      "Epoch 46/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.0513 - acc: 0.9831\n",
      "Epoch 00046: val_loss did not improve from 0.05089\n",
      "40200/40200 [==============================] - 6s 138us/sample - loss: 0.0516 - acc: 0.9831 - val_loss: 0.0558 - val_acc: 0.9840\n",
      "Epoch 47/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.0500 - acc: 0.9837\n",
      "Epoch 00047: val_loss did not improve from 0.05089\n",
      "40200/40200 [==============================] - 6s 142us/sample - loss: 0.0499 - acc: 0.9838 - val_loss: 0.0517 - val_acc: 0.9856\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.0497 - acc: 0.9840\n",
      "Epoch 00048: val_loss did not improve from 0.05089\n",
      "40200/40200 [==============================] - 5s 131us/sample - loss: 0.0496 - acc: 0.9841 - val_loss: 0.0518 - val_acc: 0.9858\n",
      "Epoch 49/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.0465 - acc: 0.9851\n",
      "Epoch 00049: val_loss improved from 0.05089 to 0.04948, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_4_conv_checkpoint/049-0.0495.hdf5\n",
      "40200/40200 [==============================] - 6s 143us/sample - loss: 0.0465 - acc: 0.9851 - val_loss: 0.0495 - val_acc: 0.9853\n",
      "Epoch 50/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.0470 - acc: 0.9845\n",
      "Epoch 00050: val_loss did not improve from 0.04948\n",
      "40200/40200 [==============================] - 6s 141us/sample - loss: 0.0468 - acc: 0.9846 - val_loss: 0.0530 - val_acc: 0.9851\n",
      "Epoch 51/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.0472 - acc: 0.9850\n",
      "Epoch 00051: val_loss did not improve from 0.04948\n",
      "40200/40200 [==============================] - 6s 143us/sample - loss: 0.0474 - acc: 0.9849 - val_loss: 0.0514 - val_acc: 0.9862\n",
      "Epoch 52/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.0460 - acc: 0.9852\n",
      "Epoch 00052: val_loss did not improve from 0.04948\n",
      "40200/40200 [==============================] - 6s 143us/sample - loss: 0.0461 - acc: 0.9851 - val_loss: 0.0507 - val_acc: 0.9855\n",
      "Epoch 53/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.0446 - acc: 0.9862\n",
      "Epoch 00053: val_loss did not improve from 0.04948\n",
      "40200/40200 [==============================] - 6s 143us/sample - loss: 0.0446 - acc: 0.9862 - val_loss: 0.0513 - val_acc: 0.9856\n",
      "Epoch 54/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.0429 - acc: 0.9856\n",
      "Epoch 00054: val_loss did not improve from 0.04948\n",
      "40200/40200 [==============================] - 6s 144us/sample - loss: 0.0428 - acc: 0.9856 - val_loss: 0.0518 - val_acc: 0.9849\n",
      "Epoch 55/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.0410 - acc: 0.9866\n",
      "Epoch 00055: val_loss did not improve from 0.04948\n",
      "40200/40200 [==============================] - 6s 144us/sample - loss: 0.0410 - acc: 0.9866 - val_loss: 0.0499 - val_acc: 0.9855\n",
      "Epoch 56/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.0420 - acc: 0.9858\n",
      "Epoch 00056: val_loss improved from 0.04948 to 0.04843, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_4_conv_checkpoint/056-0.0484.hdf5\n",
      "40200/40200 [==============================] - 6s 144us/sample - loss: 0.0420 - acc: 0.9858 - val_loss: 0.0484 - val_acc: 0.9866\n",
      "Epoch 57/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.0412 - acc: 0.9866\n",
      "Epoch 00057: val_loss did not improve from 0.04843\n",
      "40200/40200 [==============================] - 6s 142us/sample - loss: 0.0412 - acc: 0.9866 - val_loss: 0.0499 - val_acc: 0.9858\n",
      "Epoch 58/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.0401 - acc: 0.9876\n",
      "Epoch 00058: val_loss did not improve from 0.04843\n",
      "40200/40200 [==============================] - 6s 138us/sample - loss: 0.0400 - acc: 0.9876 - val_loss: 0.0494 - val_acc: 0.9864\n",
      "Epoch 59/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.0384 - acc: 0.9873\n",
      "Epoch 00059: val_loss did not improve from 0.04843\n",
      "40200/40200 [==============================] - 6s 138us/sample - loss: 0.0385 - acc: 0.9872 - val_loss: 0.0509 - val_acc: 0.9862\n",
      "Epoch 60/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.0387 - acc: 0.9871\n",
      "Epoch 00060: val_loss did not improve from 0.04843\n",
      "40200/40200 [==============================] - 6s 144us/sample - loss: 0.0387 - acc: 0.9871 - val_loss: 0.0506 - val_acc: 0.9862\n",
      "Epoch 61/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.0389 - acc: 0.9874\n",
      "Epoch 00061: val_loss improved from 0.04843 to 0.04739, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_4_conv_checkpoint/061-0.0474.hdf5\n",
      "40200/40200 [==============================] - 6s 145us/sample - loss: 0.0389 - acc: 0.9874 - val_loss: 0.0474 - val_acc: 0.9869\n",
      "Epoch 62/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.0351 - acc: 0.9886\n",
      "Epoch 00062: val_loss did not improve from 0.04739\n",
      "40200/40200 [==============================] - 6s 143us/sample - loss: 0.0350 - acc: 0.9886 - val_loss: 0.0491 - val_acc: 0.9864\n",
      "Epoch 63/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.0341 - acc: 0.9887\n",
      "Epoch 00063: val_loss did not improve from 0.04739\n",
      "40200/40200 [==============================] - 6s 142us/sample - loss: 0.0341 - acc: 0.9887 - val_loss: 0.0506 - val_acc: 0.9867\n",
      "Epoch 64/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.0365 - acc: 0.9881\n",
      "Epoch 00064: val_loss did not improve from 0.04739\n",
      "40200/40200 [==============================] - 6s 142us/sample - loss: 0.0362 - acc: 0.9882 - val_loss: 0.0509 - val_acc: 0.9869\n",
      "Epoch 65/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.0363 - acc: 0.9881\n",
      "Epoch 00065: val_loss improved from 0.04739 to 0.04618, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_4_conv_checkpoint/065-0.0462.hdf5\n",
      "40200/40200 [==============================] - 6s 145us/sample - loss: 0.0364 - acc: 0.9881 - val_loss: 0.0462 - val_acc: 0.9873\n",
      "Epoch 66/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.0330 - acc: 0.9892\n",
      "Epoch 00066: val_loss did not improve from 0.04618\n",
      "40200/40200 [==============================] - 6s 141us/sample - loss: 0.0332 - acc: 0.9892 - val_loss: 0.0478 - val_acc: 0.9865\n",
      "Epoch 67/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.0347 - acc: 0.9888\n",
      "Epoch 00067: val_loss did not improve from 0.04618\n",
      "40200/40200 [==============================] - 6s 144us/sample - loss: 0.0349 - acc: 0.9888 - val_loss: 0.0501 - val_acc: 0.9875\n",
      "Epoch 68/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.0329 - acc: 0.9888\n",
      "Epoch 00068: val_loss did not improve from 0.04618\n",
      "40200/40200 [==============================] - 6s 143us/sample - loss: 0.0328 - acc: 0.9889 - val_loss: 0.0504 - val_acc: 0.9872\n",
      "Epoch 69/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.0332 - acc: 0.9890\n",
      "Epoch 00069: val_loss did not improve from 0.04618\n",
      "40200/40200 [==============================] - 5s 133us/sample - loss: 0.0331 - acc: 0.9890 - val_loss: 0.0465 - val_acc: 0.9874\n",
      "Epoch 70/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.0316 - acc: 0.9897\n",
      "Epoch 00070: val_loss did not improve from 0.04618\n",
      "40200/40200 [==============================] - 6s 142us/sample - loss: 0.0316 - acc: 0.9897 - val_loss: 0.0503 - val_acc: 0.9870\n",
      "Epoch 71/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.0329 - acc: 0.9897\n",
      "Epoch 00071: val_loss did not improve from 0.04618\n",
      "40200/40200 [==============================] - 6s 145us/sample - loss: 0.0328 - acc: 0.9898 - val_loss: 0.0474 - val_acc: 0.9876\n",
      "Epoch 72/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.0307 - acc: 0.9901\n",
      "Epoch 00072: val_loss improved from 0.04618 to 0.04529, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_4_conv_checkpoint/072-0.0453.hdf5\n",
      "40200/40200 [==============================] - 6s 144us/sample - loss: 0.0306 - acc: 0.9901 - val_loss: 0.0453 - val_acc: 0.9879\n",
      "Epoch 73/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.0300 - acc: 0.9903\n",
      "Epoch 00073: val_loss did not improve from 0.04529\n",
      "40200/40200 [==============================] - 6s 142us/sample - loss: 0.0299 - acc: 0.9904 - val_loss: 0.0468 - val_acc: 0.9871\n",
      "Epoch 74/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.0287 - acc: 0.9910\n",
      "Epoch 00074: val_loss did not improve from 0.04529\n",
      "40200/40200 [==============================] - 6s 144us/sample - loss: 0.0287 - acc: 0.9910 - val_loss: 0.0469 - val_acc: 0.9877\n",
      "Epoch 75/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.0300 - acc: 0.9902\n",
      "Epoch 00075: val_loss did not improve from 0.04529\n",
      "40200/40200 [==============================] - 6s 142us/sample - loss: 0.0301 - acc: 0.9902 - val_loss: 0.0474 - val_acc: 0.9866\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.0325 - acc: 0.9896\n",
      "Epoch 00076: val_loss did not improve from 0.04529\n",
      "40200/40200 [==============================] - 6s 144us/sample - loss: 0.0325 - acc: 0.9895 - val_loss: 0.0461 - val_acc: 0.9876\n",
      "Epoch 77/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.0292 - acc: 0.9903\n",
      "Epoch 00077: val_loss did not improve from 0.04529\n",
      "40200/40200 [==============================] - 6s 143us/sample - loss: 0.0295 - acc: 0.9902 - val_loss: 0.0473 - val_acc: 0.9866\n",
      "Epoch 78/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.0274 - acc: 0.9904\n",
      "Epoch 00078: val_loss did not improve from 0.04529\n",
      "40200/40200 [==============================] - 6s 144us/sample - loss: 0.0273 - acc: 0.9905 - val_loss: 0.0462 - val_acc: 0.9870\n",
      "Epoch 79/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.0294 - acc: 0.9903\n",
      "Epoch 00079: val_loss did not improve from 0.04529\n",
      "40200/40200 [==============================] - 5s 133us/sample - loss: 0.0294 - acc: 0.9903 - val_loss: 0.0456 - val_acc: 0.9876\n",
      "Epoch 80/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.0264 - acc: 0.9908\n",
      "Epoch 00080: val_loss did not improve from 0.04529\n",
      "40200/40200 [==============================] - 6s 142us/sample - loss: 0.0264 - acc: 0.9908 - val_loss: 0.0492 - val_acc: 0.9870\n",
      "Epoch 81/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.0268 - acc: 0.9909\n",
      "Epoch 00081: val_loss did not improve from 0.04529\n",
      "40200/40200 [==============================] - 6s 142us/sample - loss: 0.0267 - acc: 0.9910 - val_loss: 0.0512 - val_acc: 0.9866\n",
      "Epoch 82/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.0257 - acc: 0.9913\n",
      "Epoch 00082: val_loss did not improve from 0.04529\n",
      "40200/40200 [==============================] - 6s 142us/sample - loss: 0.0257 - acc: 0.9913 - val_loss: 0.0480 - val_acc: 0.9875\n",
      "Epoch 83/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.0278 - acc: 0.9907\n",
      "Epoch 00083: val_loss did not improve from 0.04529\n",
      "40200/40200 [==============================] - 6s 142us/sample - loss: 0.0279 - acc: 0.9906 - val_loss: 0.0491 - val_acc: 0.9865\n",
      "Epoch 84/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.0275 - acc: 0.9908\n",
      "Epoch 00084: val_loss did not improve from 0.04529\n",
      "40200/40200 [==============================] - 6s 141us/sample - loss: 0.0275 - acc: 0.9908 - val_loss: 0.0468 - val_acc: 0.9874\n",
      "Epoch 85/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.0247 - acc: 0.9917\n",
      "Epoch 00085: val_loss did not improve from 0.04529\n",
      "40200/40200 [==============================] - 6s 144us/sample - loss: 0.0247 - acc: 0.9917 - val_loss: 0.0477 - val_acc: 0.9872\n",
      "Epoch 86/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.0241 - acc: 0.9912\n",
      "Epoch 00086: val_loss did not improve from 0.04529\n",
      "40200/40200 [==============================] - 6s 143us/sample - loss: 0.0240 - acc: 0.9912 - val_loss: 0.0525 - val_acc: 0.9869\n",
      "Epoch 87/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.0256 - acc: 0.9917\n",
      "Epoch 00087: val_loss did not improve from 0.04529\n",
      "40200/40200 [==============================] - 6s 142us/sample - loss: 0.0256 - acc: 0.9917 - val_loss: 0.0485 - val_acc: 0.9877\n",
      "Epoch 88/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.0246 - acc: 0.9916\n",
      "Epoch 00088: val_loss did not improve from 0.04529\n",
      "40200/40200 [==============================] - 5s 136us/sample - loss: 0.0247 - acc: 0.9915 - val_loss: 0.0520 - val_acc: 0.9872\n",
      "Epoch 89/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.0264 - acc: 0.9912\n",
      "Epoch 00089: val_loss did not improve from 0.04529\n",
      "40200/40200 [==============================] - 6s 142us/sample - loss: 0.0263 - acc: 0.9912 - val_loss: 0.0488 - val_acc: 0.9881\n",
      "Epoch 90/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.0241 - acc: 0.9920\n",
      "Epoch 00090: val_loss did not improve from 0.04529\n",
      "40200/40200 [==============================] - 5s 135us/sample - loss: 0.0241 - acc: 0.9920 - val_loss: 0.0504 - val_acc: 0.9878\n",
      "Epoch 91/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.0237 - acc: 0.9917\n",
      "Epoch 00091: val_loss did not improve from 0.04529\n",
      "40200/40200 [==============================] - 6s 142us/sample - loss: 0.0237 - acc: 0.9917 - val_loss: 0.0527 - val_acc: 0.9873\n",
      "Epoch 92/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.0238 - acc: 0.9921\n",
      "Epoch 00092: val_loss did not improve from 0.04529\n",
      "40200/40200 [==============================] - 6s 138us/sample - loss: 0.0237 - acc: 0.9921 - val_loss: 0.0492 - val_acc: 0.9876\n",
      "Epoch 93/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.0242 - acc: 0.9917\n",
      "Epoch 00093: val_loss did not improve from 0.04529\n",
      "40200/40200 [==============================] - 6s 145us/sample - loss: 0.0244 - acc: 0.9917 - val_loss: 0.0492 - val_acc: 0.9875\n",
      "Epoch 94/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.0248 - acc: 0.9916\n",
      "Epoch 00094: val_loss did not improve from 0.04529\n",
      "40200/40200 [==============================] - 6s 140us/sample - loss: 0.0248 - acc: 0.9916 - val_loss: 0.0478 - val_acc: 0.9879\n",
      "Epoch 95/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.0217 - acc: 0.9927\n",
      "Epoch 00095: val_loss did not improve from 0.04529\n",
      "40200/40200 [==============================] - 6s 137us/sample - loss: 0.0216 - acc: 0.9928 - val_loss: 0.0490 - val_acc: 0.9874\n",
      "Epoch 96/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.0227 - acc: 0.9924\n",
      "Epoch 00096: val_loss did not improve from 0.04529\n",
      "40200/40200 [==============================] - 5s 134us/sample - loss: 0.0227 - acc: 0.9924 - val_loss: 0.0510 - val_acc: 0.9874\n",
      "Epoch 97/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.0219 - acc: 0.9927\n",
      "Epoch 00097: val_loss did not improve from 0.04529\n",
      "40200/40200 [==============================] - 6s 139us/sample - loss: 0.0218 - acc: 0.9927 - val_loss: 0.0529 - val_acc: 0.9872\n",
      "Epoch 98/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.0224 - acc: 0.9924\n",
      "Epoch 00098: val_loss did not improve from 0.04529\n",
      "40200/40200 [==============================] - 6s 139us/sample - loss: 0.0225 - acc: 0.9924 - val_loss: 0.0520 - val_acc: 0.9875\n",
      "Epoch 99/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.0216 - acc: 0.9929\n",
      "Epoch 00099: val_loss did not improve from 0.04529\n",
      "40200/40200 [==============================] - 5s 131us/sample - loss: 0.0216 - acc: 0.9929 - val_loss: 0.0549 - val_acc: 0.9874\n",
      "Epoch 100/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.0215 - acc: 0.9928\n",
      "Epoch 00100: val_loss did not improve from 0.04529\n",
      "40200/40200 [==============================] - 6s 140us/sample - loss: 0.0215 - acc: 0.9928 - val_loss: 0.0497 - val_acc: 0.9881\n",
      "Epoch 101/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.0220 - acc: 0.9923\n",
      "Epoch 00101: val_loss did not improve from 0.04529\n",
      "40200/40200 [==============================] - 5s 132us/sample - loss: 0.0220 - acc: 0.9924 - val_loss: 0.0480 - val_acc: 0.9883\n",
      "Epoch 102/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.0228 - acc: 0.9919\n",
      "Epoch 00102: val_loss did not improve from 0.04529\n",
      "40200/40200 [==============================] - 5s 133us/sample - loss: 0.0227 - acc: 0.9920 - val_loss: 0.0465 - val_acc: 0.9881\n",
      "Epoch 103/500\n",
      "39744/40200 [============================>.] - ETA: 0s - loss: 0.0200 - acc: 0.9928\n",
      "Epoch 00103: val_loss did not improve from 0.04529\n",
      "40200/40200 [==============================] - 5s 136us/sample - loss: 0.0199 - acc: 0.9929 - val_loss: 0.0526 - val_acc: 0.9873\n",
      "Epoch 104/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.0214 - acc: 0.9926\n",
      "Epoch 00104: val_loss did not improve from 0.04529\n",
      "40200/40200 [==============================] - 6s 138us/sample - loss: 0.0214 - acc: 0.9926 - val_loss: 0.0491 - val_acc: 0.9877\n",
      "Epoch 105/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.0185 - acc: 0.9932\n",
      "Epoch 00105: val_loss did not improve from 0.04529\n",
      "40200/40200 [==============================] - 5s 137us/sample - loss: 0.0190 - acc: 0.9932 - val_loss: 0.0521 - val_acc: 0.9877\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 106/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.0204 - acc: 0.9930\n",
      "Epoch 00106: val_loss did not improve from 0.04529\n",
      "40200/40200 [==============================] - 5s 136us/sample - loss: 0.0203 - acc: 0.9930 - val_loss: 0.0514 - val_acc: 0.9880\n",
      "Epoch 107/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.0191 - acc: 0.9938\n",
      "Epoch 00107: val_loss did not improve from 0.04529\n",
      "40200/40200 [==============================] - 6s 140us/sample - loss: 0.0190 - acc: 0.9939 - val_loss: 0.0482 - val_acc: 0.9880\n",
      "Epoch 108/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.0228 - acc: 0.9924\n",
      "Epoch 00108: val_loss did not improve from 0.04529\n",
      "40200/40200 [==============================] - 6s 144us/sample - loss: 0.0228 - acc: 0.9924 - val_loss: 0.0466 - val_acc: 0.9878\n",
      "Epoch 109/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.0191 - acc: 0.9935\n",
      "Epoch 00109: val_loss did not improve from 0.04529\n",
      "40200/40200 [==============================] - 6s 144us/sample - loss: 0.0191 - acc: 0.9935 - val_loss: 0.0476 - val_acc: 0.9885\n",
      "Epoch 110/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.0188 - acc: 0.9934\n",
      "Epoch 00110: val_loss did not improve from 0.04529\n",
      "40200/40200 [==============================] - 6s 147us/sample - loss: 0.0188 - acc: 0.9934 - val_loss: 0.0510 - val_acc: 0.9885\n",
      "Epoch 111/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.0211 - acc: 0.9929\n",
      "Epoch 00111: val_loss did not improve from 0.04529\n",
      "40200/40200 [==============================] - 5s 136us/sample - loss: 0.0211 - acc: 0.9929 - val_loss: 0.0474 - val_acc: 0.9881\n",
      "Epoch 112/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.0180 - acc: 0.9937\n",
      "Epoch 00112: val_loss did not improve from 0.04529\n",
      "40200/40200 [==============================] - 6s 143us/sample - loss: 0.0182 - acc: 0.9937 - val_loss: 0.0508 - val_acc: 0.9883\n",
      "Epoch 113/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.0177 - acc: 0.9939\n",
      "Epoch 00113: val_loss did not improve from 0.04529\n",
      "40200/40200 [==============================] - 6s 146us/sample - loss: 0.0177 - acc: 0.9939 - val_loss: 0.0501 - val_acc: 0.9885\n",
      "Epoch 114/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.0181 - acc: 0.9936\n",
      "Epoch 00114: val_loss did not improve from 0.04529\n",
      "40200/40200 [==============================] - 6s 145us/sample - loss: 0.0180 - acc: 0.9936 - val_loss: 0.0509 - val_acc: 0.9885\n",
      "Epoch 115/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.0181 - acc: 0.9939\n",
      "Epoch 00115: val_loss did not improve from 0.04529\n",
      "40200/40200 [==============================] - 6s 146us/sample - loss: 0.0181 - acc: 0.9939 - val_loss: 0.0516 - val_acc: 0.9888\n",
      "Epoch 116/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.0178 - acc: 0.9940\n",
      "Epoch 00116: val_loss did not improve from 0.04529\n",
      "40200/40200 [==============================] - 6s 144us/sample - loss: 0.0177 - acc: 0.9940 - val_loss: 0.0507 - val_acc: 0.9879\n",
      "Epoch 117/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.0167 - acc: 0.9945\n",
      "Epoch 00117: val_loss did not improve from 0.04529\n",
      "40200/40200 [==============================] - 6s 145us/sample - loss: 0.0166 - acc: 0.9945 - val_loss: 0.0499 - val_acc: 0.9885\n",
      "Epoch 118/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.0198 - acc: 0.9932\n",
      "Epoch 00118: val_loss did not improve from 0.04529\n",
      "40200/40200 [==============================] - 6s 144us/sample - loss: 0.0197 - acc: 0.9933 - val_loss: 0.0467 - val_acc: 0.9885\n",
      "Epoch 119/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.0178 - acc: 0.9937\n",
      "Epoch 00119: val_loss did not improve from 0.04529\n",
      "40200/40200 [==============================] - 6s 147us/sample - loss: 0.0178 - acc: 0.9937 - val_loss: 0.0504 - val_acc: 0.9888\n",
      "Epoch 120/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.0172 - acc: 0.9939\n",
      "Epoch 00120: val_loss did not improve from 0.04529\n",
      "40200/40200 [==============================] - 6s 146us/sample - loss: 0.0172 - acc: 0.9939 - val_loss: 0.0507 - val_acc: 0.9881\n",
      "Epoch 121/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.0164 - acc: 0.9945\n",
      "Epoch 00121: val_loss did not improve from 0.04529\n",
      "40200/40200 [==============================] - 5s 136us/sample - loss: 0.0164 - acc: 0.9945 - val_loss: 0.0497 - val_acc: 0.9886\n",
      "Epoch 122/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.0167 - acc: 0.9946\n",
      "Epoch 00122: val_loss did not improve from 0.04529\n",
      "40200/40200 [==============================] - 6s 144us/sample - loss: 0.0167 - acc: 0.9946 - val_loss: 0.0507 - val_acc: 0.9885\n",
      "\n",
      "vis_2D_CNN_custom_ch_16_DO_050_DO_4_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 108us/sample - loss: 0.0383 - acc: 0.9892\n",
      "Loss: 0.03831109365673383 Accuracy: 0.9892\n",
      "\n",
      "Train on 40200 samples, validate on 19800 samples\n",
      "Epoch 1/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 2.6548 - acc: 0.4303\n",
      "Epoch 00001: val_loss improved from inf to 0.57933, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_5_conv_checkpoint/001-0.5793.hdf5\n",
      "40200/40200 [==============================] - 9s 217us/sample - loss: 2.6518 - acc: 0.4308 - val_loss: 0.5793 - val_acc: 0.8361\n",
      "Epoch 2/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.6304 - acc: 0.7962\n",
      "Epoch 00002: val_loss improved from 0.57933 to 0.28240, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_5_conv_checkpoint/002-0.2824.hdf5\n",
      "40200/40200 [==============================] - 6s 152us/sample - loss: 0.6301 - acc: 0.7963 - val_loss: 0.2824 - val_acc: 0.9145\n",
      "Epoch 3/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.4003 - acc: 0.8775\n",
      "Epoch 00003: val_loss improved from 0.28240 to 0.20194, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_5_conv_checkpoint/003-0.2019.hdf5\n",
      "40200/40200 [==============================] - 6s 155us/sample - loss: 0.4005 - acc: 0.8774 - val_loss: 0.2019 - val_acc: 0.9375\n",
      "Epoch 4/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.3008 - acc: 0.9102\n",
      "Epoch 00004: val_loss improved from 0.20194 to 0.16090, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_5_conv_checkpoint/004-0.1609.hdf5\n",
      "40200/40200 [==============================] - 6s 153us/sample - loss: 0.3005 - acc: 0.9104 - val_loss: 0.1609 - val_acc: 0.9506\n",
      "Epoch 5/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.2474 - acc: 0.9271\n",
      "Epoch 00005: val_loss improved from 0.16090 to 0.14047, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_5_conv_checkpoint/005-0.1405.hdf5\n",
      "40200/40200 [==============================] - 6s 151us/sample - loss: 0.2477 - acc: 0.9270 - val_loss: 0.1405 - val_acc: 0.9566\n",
      "Epoch 6/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.2091 - acc: 0.9388\n",
      "Epoch 00006: val_loss improved from 0.14047 to 0.12328, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_5_conv_checkpoint/006-0.1233.hdf5\n",
      "40200/40200 [==============================] - 6s 150us/sample - loss: 0.2089 - acc: 0.9388 - val_loss: 0.1233 - val_acc: 0.9624\n",
      "Epoch 7/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.1786 - acc: 0.9482\n",
      "Epoch 00007: val_loss improved from 0.12328 to 0.11385, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_5_conv_checkpoint/007-0.1139.hdf5\n",
      "40200/40200 [==============================] - 6s 154us/sample - loss: 0.1786 - acc: 0.9482 - val_loss: 0.1139 - val_acc: 0.9652\n",
      "Epoch 8/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.1558 - acc: 0.9538\n",
      "Epoch 00008: val_loss improved from 0.11385 to 0.10076, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_5_conv_checkpoint/008-0.1008.hdf5\n",
      "40200/40200 [==============================] - 6s 154us/sample - loss: 0.1562 - acc: 0.9537 - val_loss: 0.1008 - val_acc: 0.9702\n",
      "Epoch 9/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.1426 - acc: 0.9583\n",
      "Epoch 00009: val_loss improved from 0.10076 to 0.09361, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_5_conv_checkpoint/009-0.0936.hdf5\n",
      "40200/40200 [==============================] - 6s 148us/sample - loss: 0.1426 - acc: 0.9583 - val_loss: 0.0936 - val_acc: 0.9717\n",
      "Epoch 10/500\n",
      "39808/40200 [============================>.] - ETA: 0s - loss: 0.1229 - acc: 0.9634\n",
      "Epoch 00010: val_loss improved from 0.09361 to 0.08738, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_5_conv_checkpoint/010-0.0874.hdf5\n",
      "40200/40200 [==============================] - 6s 147us/sample - loss: 0.1231 - acc: 0.9634 - val_loss: 0.0874 - val_acc: 0.9735\n",
      "Epoch 11/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.1130 - acc: 0.9669\n",
      "Epoch 00011: val_loss did not improve from 0.08738\n",
      "40200/40200 [==============================] - 6s 151us/sample - loss: 0.1130 - acc: 0.9669 - val_loss: 0.0896 - val_acc: 0.9740\n",
      "Epoch 12/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.1049 - acc: 0.9689\n",
      "Epoch 00012: val_loss improved from 0.08738 to 0.07865, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_5_conv_checkpoint/012-0.0787.hdf5\n",
      "40200/40200 [==============================] - 6s 150us/sample - loss: 0.1054 - acc: 0.9687 - val_loss: 0.0787 - val_acc: 0.9780\n",
      "Epoch 13/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.0981 - acc: 0.9715\n",
      "Epoch 00013: val_loss improved from 0.07865 to 0.07784, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_5_conv_checkpoint/013-0.0778.hdf5\n",
      "40200/40200 [==============================] - 6s 153us/sample - loss: 0.0978 - acc: 0.9715 - val_loss: 0.0778 - val_acc: 0.9774\n",
      "Epoch 14/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.0910 - acc: 0.9726\n",
      "Epoch 00014: val_loss improved from 0.07784 to 0.07117, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_5_conv_checkpoint/014-0.0712.hdf5\n",
      "40200/40200 [==============================] - 6s 149us/sample - loss: 0.0909 - acc: 0.9727 - val_loss: 0.0712 - val_acc: 0.9794\n",
      "Epoch 15/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.0808 - acc: 0.9760\n",
      "Epoch 00015: val_loss did not improve from 0.07117\n",
      "40200/40200 [==============================] - 6s 146us/sample - loss: 0.0808 - acc: 0.9760 - val_loss: 0.0741 - val_acc: 0.9795\n",
      "Epoch 16/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.0760 - acc: 0.9780\n",
      "Epoch 00016: val_loss improved from 0.07117 to 0.06953, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_5_conv_checkpoint/016-0.0695.hdf5\n",
      "40200/40200 [==============================] - 7s 162us/sample - loss: 0.0760 - acc: 0.9780 - val_loss: 0.0695 - val_acc: 0.9815\n",
      "Epoch 17/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.0714 - acc: 0.9794\n",
      "Epoch 00017: val_loss did not improve from 0.06953\n",
      "40200/40200 [==============================] - 6s 151us/sample - loss: 0.0714 - acc: 0.9794 - val_loss: 0.0709 - val_acc: 0.9805\n",
      "Epoch 18/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.0661 - acc: 0.9795\n",
      "Epoch 00018: val_loss improved from 0.06953 to 0.06599, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_5_conv_checkpoint/018-0.0660.hdf5\n",
      "40200/40200 [==============================] - 6s 160us/sample - loss: 0.0660 - acc: 0.9796 - val_loss: 0.0660 - val_acc: 0.9817\n",
      "Epoch 19/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.0620 - acc: 0.9816\n",
      "Epoch 00019: val_loss did not improve from 0.06599\n",
      "40200/40200 [==============================] - 6s 160us/sample - loss: 0.0621 - acc: 0.9816 - val_loss: 0.0661 - val_acc: 0.9817\n",
      "Epoch 20/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.0593 - acc: 0.9822\n",
      "Epoch 00020: val_loss improved from 0.06599 to 0.06540, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_5_conv_checkpoint/020-0.0654.hdf5\n",
      "40200/40200 [==============================] - 6s 159us/sample - loss: 0.0595 - acc: 0.9821 - val_loss: 0.0654 - val_acc: 0.9827\n",
      "Epoch 21/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.0538 - acc: 0.9832\n",
      "Epoch 00021: val_loss improved from 0.06540 to 0.06322, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_5_conv_checkpoint/021-0.0632.hdf5\n",
      "40200/40200 [==============================] - 6s 161us/sample - loss: 0.0538 - acc: 0.9832 - val_loss: 0.0632 - val_acc: 0.9829\n",
      "Epoch 22/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.0542 - acc: 0.9835\n",
      "Epoch 00022: val_loss did not improve from 0.06322\n",
      "40200/40200 [==============================] - 6s 159us/sample - loss: 0.0541 - acc: 0.9835 - val_loss: 0.0636 - val_acc: 0.9831\n",
      "Epoch 23/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.0479 - acc: 0.9852\n",
      "Epoch 00023: val_loss did not improve from 0.06322\n",
      "40200/40200 [==============================] - 6s 159us/sample - loss: 0.0480 - acc: 0.9852 - val_loss: 0.0688 - val_acc: 0.9818\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.0477 - acc: 0.9851\n",
      "Epoch 00024: val_loss did not improve from 0.06322\n",
      "40200/40200 [==============================] - 6s 161us/sample - loss: 0.0478 - acc: 0.9851 - val_loss: 0.0636 - val_acc: 0.9838\n",
      "Epoch 25/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.0460 - acc: 0.9851\n",
      "Epoch 00025: val_loss improved from 0.06322 to 0.06135, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_5_conv_checkpoint/025-0.0614.hdf5\n",
      "40200/40200 [==============================] - 6s 161us/sample - loss: 0.0459 - acc: 0.9851 - val_loss: 0.0614 - val_acc: 0.9843\n",
      "Epoch 26/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.0405 - acc: 0.9878\n",
      "Epoch 00026: val_loss did not improve from 0.06135\n",
      "40200/40200 [==============================] - 6s 153us/sample - loss: 0.0404 - acc: 0.9878 - val_loss: 0.0626 - val_acc: 0.9841\n",
      "Epoch 27/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.0410 - acc: 0.9868\n",
      "Epoch 00027: val_loss improved from 0.06135 to 0.06087, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_5_conv_checkpoint/027-0.0609.hdf5\n",
      "40200/40200 [==============================] - 6s 161us/sample - loss: 0.0409 - acc: 0.9868 - val_loss: 0.0609 - val_acc: 0.9848\n",
      "Epoch 28/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.0395 - acc: 0.9879\n",
      "Epoch 00028: val_loss did not improve from 0.06087\n",
      "40200/40200 [==============================] - 6s 158us/sample - loss: 0.0395 - acc: 0.9879 - val_loss: 0.0643 - val_acc: 0.9841\n",
      "Epoch 29/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.0380 - acc: 0.9879\n",
      "Epoch 00029: val_loss did not improve from 0.06087\n",
      "40200/40200 [==============================] - 6s 160us/sample - loss: 0.0379 - acc: 0.9879 - val_loss: 0.0614 - val_acc: 0.9852\n",
      "Epoch 30/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.0361 - acc: 0.9889\n",
      "Epoch 00030: val_loss did not improve from 0.06087\n",
      "40200/40200 [==============================] - 6s 159us/sample - loss: 0.0360 - acc: 0.9889 - val_loss: 0.0635 - val_acc: 0.9837\n",
      "Epoch 31/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.0339 - acc: 0.9893\n",
      "Epoch 00031: val_loss did not improve from 0.06087\n",
      "40200/40200 [==============================] - 6s 159us/sample - loss: 0.0338 - acc: 0.9893 - val_loss: 0.0613 - val_acc: 0.9848\n",
      "Epoch 32/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.0321 - acc: 0.9899\n",
      "Epoch 00032: val_loss did not improve from 0.06087\n",
      "40200/40200 [==============================] - 6s 161us/sample - loss: 0.0321 - acc: 0.9899 - val_loss: 0.0645 - val_acc: 0.9847\n",
      "Epoch 33/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.0294 - acc: 0.9904\n",
      "Epoch 00033: val_loss did not improve from 0.06087\n",
      "40200/40200 [==============================] - 6s 160us/sample - loss: 0.0294 - acc: 0.9904 - val_loss: 0.0658 - val_acc: 0.9851\n",
      "Epoch 34/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.0294 - acc: 0.9907\n",
      "Epoch 00034: val_loss did not improve from 0.06087\n",
      "40200/40200 [==============================] - 6s 159us/sample - loss: 0.0294 - acc: 0.9907 - val_loss: 0.0687 - val_acc: 0.9836\n",
      "Epoch 35/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.0283 - acc: 0.9906\n",
      "Epoch 00035: val_loss improved from 0.06087 to 0.06050, saving model to model/checkpoint/vis_2D_CNN_custom_ch_16_DO_050_DO_5_conv_checkpoint/035-0.0605.hdf5\n",
      "40200/40200 [==============================] - 6s 160us/sample - loss: 0.0283 - acc: 0.9906 - val_loss: 0.0605 - val_acc: 0.9853\n",
      "Epoch 36/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.0251 - acc: 0.9914\n",
      "Epoch 00036: val_loss did not improve from 0.06050\n",
      "40200/40200 [==============================] - 6s 157us/sample - loss: 0.0251 - acc: 0.9914 - val_loss: 0.0633 - val_acc: 0.9852\n",
      "Epoch 37/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.0270 - acc: 0.9913\n",
      "Epoch 00037: val_loss did not improve from 0.06050\n",
      "40200/40200 [==============================] - 6s 160us/sample - loss: 0.0270 - acc: 0.9913 - val_loss: 0.0749 - val_acc: 0.9833\n",
      "Epoch 38/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.0244 - acc: 0.9921\n",
      "Epoch 00038: val_loss did not improve from 0.06050\n",
      "40200/40200 [==============================] - 6s 156us/sample - loss: 0.0245 - acc: 0.9921 - val_loss: 0.0684 - val_acc: 0.9843\n",
      "Epoch 39/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.0254 - acc: 0.9916\n",
      "Epoch 00039: val_loss did not improve from 0.06050\n",
      "40200/40200 [==============================] - 6s 161us/sample - loss: 0.0254 - acc: 0.9915 - val_loss: 0.0699 - val_acc: 0.9849\n",
      "Epoch 40/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.0242 - acc: 0.9924\n",
      "Epoch 00040: val_loss did not improve from 0.06050\n",
      "40200/40200 [==============================] - 6s 161us/sample - loss: 0.0243 - acc: 0.9924 - val_loss: 0.0613 - val_acc: 0.9858\n",
      "Epoch 41/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.0220 - acc: 0.9931\n",
      "Epoch 00041: val_loss did not improve from 0.06050\n",
      "40200/40200 [==============================] - 6s 157us/sample - loss: 0.0220 - acc: 0.9931 - val_loss: 0.0680 - val_acc: 0.9850\n",
      "Epoch 42/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.0212 - acc: 0.9932\n",
      "Epoch 00042: val_loss did not improve from 0.06050\n",
      "40200/40200 [==============================] - 6s 160us/sample - loss: 0.0215 - acc: 0.9932 - val_loss: 0.0709 - val_acc: 0.9851\n",
      "Epoch 43/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.0213 - acc: 0.9933\n",
      "Epoch 00043: val_loss did not improve from 0.06050\n",
      "40200/40200 [==============================] - 6s 159us/sample - loss: 0.0213 - acc: 0.9933 - val_loss: 0.0689 - val_acc: 0.9849\n",
      "Epoch 44/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.0186 - acc: 0.9941\n",
      "Epoch 00044: val_loss did not improve from 0.06050\n",
      "40200/40200 [==============================] - 6s 159us/sample - loss: 0.0186 - acc: 0.9941 - val_loss: 0.0628 - val_acc: 0.9863\n",
      "Epoch 45/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.0210 - acc: 0.9934\n",
      "Epoch 00045: val_loss did not improve from 0.06050\n",
      "40200/40200 [==============================] - 6s 151us/sample - loss: 0.0210 - acc: 0.9934 - val_loss: 0.0636 - val_acc: 0.9864\n",
      "Epoch 46/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.0184 - acc: 0.9941\n",
      "Epoch 00046: val_loss did not improve from 0.06050\n",
      "40200/40200 [==============================] - 6s 158us/sample - loss: 0.0183 - acc: 0.9941 - val_loss: 0.0647 - val_acc: 0.9871\n",
      "Epoch 47/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.0186 - acc: 0.9941\n",
      "Epoch 00047: val_loss did not improve from 0.06050\n",
      "40200/40200 [==============================] - 6s 160us/sample - loss: 0.0186 - acc: 0.9942 - val_loss: 0.0631 - val_acc: 0.9867\n",
      "Epoch 48/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.0199 - acc: 0.9933\n",
      "Epoch 00048: val_loss did not improve from 0.06050\n",
      "40200/40200 [==============================] - 6s 158us/sample - loss: 0.0198 - acc: 0.9933 - val_loss: 0.0642 - val_acc: 0.9852\n",
      "Epoch 49/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.0189 - acc: 0.9938\n",
      "Epoch 00049: val_loss did not improve from 0.06050\n",
      "40200/40200 [==============================] - 6s 158us/sample - loss: 0.0189 - acc: 0.9938 - val_loss: 0.0686 - val_acc: 0.9857\n",
      "Epoch 50/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.0182 - acc: 0.9940\n",
      "Epoch 00050: val_loss did not improve from 0.06050\n",
      "40200/40200 [==============================] - 6s 162us/sample - loss: 0.0182 - acc: 0.9940 - val_loss: 0.0655 - val_acc: 0.9866\n",
      "Epoch 51/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.0171 - acc: 0.9941\n",
      "Epoch 00051: val_loss did not improve from 0.06050\n",
      "40200/40200 [==============================] - 6s 158us/sample - loss: 0.0171 - acc: 0.9941 - val_loss: 0.0656 - val_acc: 0.9867\n",
      "Epoch 52/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.0153 - acc: 0.9951\n",
      "Epoch 00052: val_loss did not improve from 0.06050\n",
      "40200/40200 [==============================] - 6s 158us/sample - loss: 0.0153 - acc: 0.9951 - val_loss: 0.0704 - val_acc: 0.9861\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.0150 - acc: 0.9952\n",
      "Epoch 00053: val_loss did not improve from 0.06050\n",
      "40200/40200 [==============================] - 7s 163us/sample - loss: 0.0150 - acc: 0.9951 - val_loss: 0.0727 - val_acc: 0.9860\n",
      "Epoch 54/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.0154 - acc: 0.9949\n",
      "Epoch 00054: val_loss did not improve from 0.06050\n",
      "40200/40200 [==============================] - 6s 152us/sample - loss: 0.0154 - acc: 0.9949 - val_loss: 0.0693 - val_acc: 0.9870\n",
      "Epoch 55/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.0166 - acc: 0.9949\n",
      "Epoch 00055: val_loss did not improve from 0.06050\n",
      "40200/40200 [==============================] - 6s 156us/sample - loss: 0.0166 - acc: 0.9949 - val_loss: 0.0624 - val_acc: 0.9866\n",
      "Epoch 56/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.0140 - acc: 0.9955\n",
      "Epoch 00056: val_loss did not improve from 0.06050\n",
      "40200/40200 [==============================] - 6s 160us/sample - loss: 0.0140 - acc: 0.9954 - val_loss: 0.0720 - val_acc: 0.9855\n",
      "Epoch 57/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.0140 - acc: 0.9955\n",
      "Epoch 00057: val_loss did not improve from 0.06050\n",
      "40200/40200 [==============================] - 6s 159us/sample - loss: 0.0142 - acc: 0.9955 - val_loss: 0.0711 - val_acc: 0.9858\n",
      "Epoch 58/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.0148 - acc: 0.9953\n",
      "Epoch 00058: val_loss did not improve from 0.06050\n",
      "40200/40200 [==============================] - 6s 160us/sample - loss: 0.0148 - acc: 0.9953 - val_loss: 0.0648 - val_acc: 0.9869\n",
      "Epoch 59/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.0124 - acc: 0.9958\n",
      "Epoch 00059: val_loss did not improve from 0.06050\n",
      "40200/40200 [==============================] - 6s 159us/sample - loss: 0.0126 - acc: 0.9958 - val_loss: 0.0683 - val_acc: 0.9874\n",
      "Epoch 60/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.0127 - acc: 0.9960\n",
      "Epoch 00060: val_loss did not improve from 0.06050\n",
      "40200/40200 [==============================] - 6s 159us/sample - loss: 0.0127 - acc: 0.9960 - val_loss: 0.0699 - val_acc: 0.9875\n",
      "Epoch 61/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.0136 - acc: 0.9957\n",
      "Epoch 00061: val_loss did not improve from 0.06050\n",
      "40200/40200 [==============================] - 6s 160us/sample - loss: 0.0136 - acc: 0.9957 - val_loss: 0.0742 - val_acc: 0.9869\n",
      "Epoch 62/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.0101 - acc: 0.9966\n",
      "Epoch 00062: val_loss did not improve from 0.06050\n",
      "40200/40200 [==============================] - 6s 159us/sample - loss: 0.0100 - acc: 0.9966 - val_loss: 0.0694 - val_acc: 0.9872\n",
      "Epoch 63/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.0125 - acc: 0.9958\n",
      "Epoch 00063: val_loss did not improve from 0.06050\n",
      "40200/40200 [==============================] - 6s 148us/sample - loss: 0.0125 - acc: 0.9957 - val_loss: 0.0751 - val_acc: 0.9867\n",
      "Epoch 64/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.0116 - acc: 0.9962\n",
      "Epoch 00064: val_loss did not improve from 0.06050\n",
      "40200/40200 [==============================] - 6s 158us/sample - loss: 0.0116 - acc: 0.9962 - val_loss: 0.0709 - val_acc: 0.9867\n",
      "Epoch 65/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.0126 - acc: 0.9959\n",
      "Epoch 00065: val_loss did not improve from 0.06050\n",
      "40200/40200 [==============================] - 6s 158us/sample - loss: 0.0125 - acc: 0.9958 - val_loss: 0.0713 - val_acc: 0.9873\n",
      "Epoch 66/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.0121 - acc: 0.9959\n",
      "Epoch 00066: val_loss did not improve from 0.06050\n",
      "40200/40200 [==============================] - 6s 160us/sample - loss: 0.0121 - acc: 0.9959 - val_loss: 0.0718 - val_acc: 0.9870\n",
      "Epoch 67/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.0103 - acc: 0.9965\n",
      "Epoch 00067: val_loss did not improve from 0.06050\n",
      "40200/40200 [==============================] - 6s 159us/sample - loss: 0.0103 - acc: 0.9965 - val_loss: 0.0686 - val_acc: 0.9873\n",
      "Epoch 68/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.0101 - acc: 0.9967\n",
      "Epoch 00068: val_loss did not improve from 0.06050\n",
      "40200/40200 [==============================] - 6s 158us/sample - loss: 0.0100 - acc: 0.9967 - val_loss: 0.0725 - val_acc: 0.9874\n",
      "Epoch 69/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.0114 - acc: 0.9967\n",
      "Epoch 00069: val_loss did not improve from 0.06050\n",
      "40200/40200 [==============================] - 6s 160us/sample - loss: 0.0114 - acc: 0.9967 - val_loss: 0.0732 - val_acc: 0.9874\n",
      "Epoch 70/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.0132 - acc: 0.9957\n",
      "Epoch 00070: val_loss did not improve from 0.06050\n",
      "40200/40200 [==============================] - 6s 159us/sample - loss: 0.0132 - acc: 0.9956 - val_loss: 0.0850 - val_acc: 0.9858\n",
      "Epoch 71/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.0097 - acc: 0.9966\n",
      "Epoch 00071: val_loss did not improve from 0.06050\n",
      "40200/40200 [==============================] - 6s 159us/sample - loss: 0.0097 - acc: 0.9966 - val_loss: 0.0729 - val_acc: 0.9879\n",
      "Epoch 72/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.0095 - acc: 0.9969\n",
      "Epoch 00072: val_loss did not improve from 0.06050\n",
      "40200/40200 [==============================] - 6s 158us/sample - loss: 0.0095 - acc: 0.9969 - val_loss: 0.0762 - val_acc: 0.9872\n",
      "Epoch 73/500\n",
      "39872/40200 [============================>.] - ETA: 0s - loss: 0.0105 - acc: 0.9969\n",
      "Epoch 00073: val_loss did not improve from 0.06050\n",
      "40200/40200 [==============================] - 6s 152us/sample - loss: 0.0106 - acc: 0.9969 - val_loss: 0.0781 - val_acc: 0.9860\n",
      "Epoch 74/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.0103 - acc: 0.9971\n",
      "Epoch 00074: val_loss did not improve from 0.06050\n",
      "40200/40200 [==============================] - 6s 158us/sample - loss: 0.0103 - acc: 0.9971 - val_loss: 0.0772 - val_acc: 0.9865\n",
      "Epoch 75/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.0096 - acc: 0.9968\n",
      "Epoch 00075: val_loss did not improve from 0.06050\n",
      "40200/40200 [==============================] - 6s 161us/sample - loss: 0.0096 - acc: 0.9968 - val_loss: 0.0718 - val_acc: 0.9873\n",
      "Epoch 76/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.0104 - acc: 0.9963\n",
      "Epoch 00076: val_loss did not improve from 0.06050\n",
      "40200/40200 [==============================] - 6s 160us/sample - loss: 0.0104 - acc: 0.9963 - val_loss: 0.0757 - val_acc: 0.9874\n",
      "Epoch 77/500\n",
      "40000/40200 [============================>.] - ETA: 0s - loss: 0.0100 - acc: 0.9966\n",
      "Epoch 00077: val_loss did not improve from 0.06050\n",
      "40200/40200 [==============================] - 6s 160us/sample - loss: 0.0100 - acc: 0.9966 - val_loss: 0.0912 - val_acc: 0.9847\n",
      "Epoch 78/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.0078 - acc: 0.9974\n",
      "Epoch 00078: val_loss did not improve from 0.06050\n",
      "40200/40200 [==============================] - 6s 158us/sample - loss: 0.0078 - acc: 0.9974 - val_loss: 0.0766 - val_acc: 0.9870\n",
      "Epoch 79/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.0083 - acc: 0.9971\n",
      "Epoch 00079: val_loss did not improve from 0.06050\n",
      "40200/40200 [==============================] - 6s 160us/sample - loss: 0.0083 - acc: 0.9971 - val_loss: 0.0759 - val_acc: 0.9870\n",
      "Epoch 80/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.0085 - acc: 0.9976\n",
      "Epoch 00080: val_loss did not improve from 0.06050\n",
      "40200/40200 [==============================] - 6s 159us/sample - loss: 0.0086 - acc: 0.9976 - val_loss: 0.0848 - val_acc: 0.9856\n",
      "Epoch 81/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.0102 - acc: 0.9967\n",
      "Epoch 00081: val_loss did not improve from 0.06050\n",
      "40200/40200 [==============================] - 6s 160us/sample - loss: 0.0101 - acc: 0.9968 - val_loss: 0.0744 - val_acc: 0.9879\n",
      "Epoch 82/500\n",
      "40128/40200 [============================>.] - ETA: 0s - loss: 0.0087 - acc: 0.9970\n",
      "Epoch 00082: val_loss did not improve from 0.06050\n",
      "40200/40200 [==============================] - 6s 154us/sample - loss: 0.0087 - acc: 0.9970 - val_loss: 0.0743 - val_acc: 0.9872\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83/500\n",
      "40064/40200 [============================>.] - ETA: 0s - loss: 0.0084 - acc: 0.9974\n",
      "Epoch 00083: val_loss did not improve from 0.06050\n",
      "40200/40200 [==============================] - 6s 161us/sample - loss: 0.0083 - acc: 0.9974 - val_loss: 0.0751 - val_acc: 0.9879\n",
      "Epoch 84/500\n",
      "40192/40200 [============================>.] - ETA: 0s - loss: 0.0074 - acc: 0.9975\n",
      "Epoch 00084: val_loss did not improve from 0.06050\n",
      "40200/40200 [==============================] - 6s 160us/sample - loss: 0.0074 - acc: 0.9975 - val_loss: 0.0743 - val_acc: 0.9875\n",
      "Epoch 85/500\n",
      "39936/40200 [============================>.] - ETA: 0s - loss: 0.0058 - acc: 0.9979\n",
      "Epoch 00085: val_loss did not improve from 0.06050\n",
      "40200/40200 [==============================] - 6s 159us/sample - loss: 0.0058 - acc: 0.9979 - val_loss: 0.0820 - val_acc: 0.9872\n",
      "\n",
      "vis_2D_CNN_custom_ch_16_DO_050_DO_5_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 126us/sample - loss: 0.0522 - acc: 0.9863\n",
      "Loss: 0.052200128448847 Accuracy: 0.9863\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 6):\n",
    "    base = 'vis_2D_CNN_custom_ch_16_DO_050_DO'\n",
    "    model_name = base+'_{}_conv'.format(i)\n",
    "    model = build_2d_cnn_custom_ch_16_DO(conv_num=i)\n",
    "#         model.summary()\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=1e-4),\n",
    "          metrics=['accuracy'])\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    os.makedirs(model_path, exist_ok=True)\n",
    "    model_filename = model_path+'{epoch:03d}-{val_loss:.4f}.hdf5'\n",
    "    checkpointer = ModelCheckpoint(filepath = model_filename, monitor = \"val_loss\", \n",
    "                                   verbose=1, save_best_only=True)\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=50)\n",
    "    hist = model.fit(x_train, y_train, batch_size=64, epochs=500, \n",
    "                     validation_data=[x_val, y_val], shuffle=True, \n",
    "                     callbacks = [checkpointer, early_stopping])\n",
    "\n",
    "    print()\n",
    "    print(model_name, 'Model')\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "    ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
    "    ax.plot(hist.history['acc'], 'b', label='train acc')\n",
    "    ax.plot(hist.history['val_acc'], 'g', label='val acc')\n",
    "    ax.set_xlabel('epoch')\n",
    "    ax.set_ylabel('loss')\n",
    "    ax.legend(loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    png_path = 'visualization/learning_curve/'\n",
    "    filename = model_name+'.png'\n",
    "    os.makedirs(png_path, exist_ok=True)\n",
    "    fig.savefig(png_path+filename, transparent=True)\n",
    "\n",
    "    model.save(model_path+'000_last.hdf5')\n",
    "    del(model)\n",
    "\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    model_filename = model_path + sorted(os.listdir(model_path))[-1]\n",
    "    model = load_model(model_filename)\n",
    "    [loss, accuracy] = model.evaluate(x_test, y_test)\n",
    "    print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "    print()\n",
    "\n",
    "    del(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "vis_2D_CNN_custom_ch_16_DO_050_DO_1_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 28, 28, 16)        160       \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 28, 28, 16)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                31370     \n",
      "=================================================================\n",
      "Total params: 31,530\n",
      "Trainable params: 31,530\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "10000/10000 [==============================] - 1s 107us/sample - loss: 0.0694 - acc: 0.9835\n",
      "Loss: 0.06943656803121558 Accuracy: 0.9835\n",
      "\n",
      "vis_2D_CNN_custom_ch_16_DO_050_DO_2_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_7 (InputLayer)         (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 28, 28, 16)        160       \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 28, 28, 16)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 14, 14, 16)        2320      \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_17 (MaxPooling (None, 7, 7, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                7850      \n",
      "=================================================================\n",
      "Total params: 10,330\n",
      "Trainable params: 10,330\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "10000/10000 [==============================] - 1s 113us/sample - loss: 0.0342 - acc: 0.9893\n",
      "Loss: 0.03422784412406909 Accuracy: 0.9893\n",
      "\n",
      "vis_2D_CNN_custom_ch_16_DO_050_DO_3_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_8 (InputLayer)         (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 28, 28, 16)        160       \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 28, 28, 16)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_18 (MaxPooling (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 14, 14, 16)        2320      \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_19 (MaxPooling (None, 7, 7, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 7, 7, 32)          4640      \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 7, 7, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_20 (MaxPooling (None, 4, 4, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 12,250\n",
      "Trainable params: 12,250\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "10000/10000 [==============================] - 1s 126us/sample - loss: 0.0297 - acc: 0.9901\n",
      "Loss: 0.029699888637179175 Accuracy: 0.9901\n",
      "\n",
      "vis_2D_CNN_custom_ch_16_DO_050_DO_4_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_9 (InputLayer)         (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 28, 28, 16)        160       \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 28, 28, 16)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_21 (MaxPooling (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_22 (Conv2D)           (None, 14, 14, 16)        2320      \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_22 (MaxPooling (None, 7, 7, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 7, 7, 32)          4640      \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 7, 7, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_23 (MaxPooling (None, 4, 4, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_24 (Conv2D)           (None, 4, 4, 32)          9248      \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 4, 4, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_24 (MaxPooling (None, 2, 2, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 17,658\n",
      "Trainable params: 17,658\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "10000/10000 [==============================] - 1s 132us/sample - loss: 0.0383 - acc: 0.9892\n",
      "Loss: 0.03831109365673383 Accuracy: 0.9892\n",
      "\n",
      "vis_2D_CNN_custom_ch_16_DO_050_DO_5_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_10 (InputLayer)        (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_25 (Conv2D)           (None, 28, 28, 16)        160       \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 28, 28, 16)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_25 (MaxPooling (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_26 (Conv2D)           (None, 14, 14, 16)        2320      \n",
      "_________________________________________________________________\n",
      "activation_26 (Activation)   (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_26 (MaxPooling (None, 7, 7, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_27 (Conv2D)           (None, 7, 7, 32)          4640      \n",
      "_________________________________________________________________\n",
      "activation_27 (Activation)   (None, 7, 7, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_27 (MaxPooling (None, 4, 4, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_28 (Conv2D)           (None, 4, 4, 32)          9248      \n",
      "_________________________________________________________________\n",
      "activation_28 (Activation)   (None, 4, 4, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_28 (MaxPooling (None, 2, 2, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_29 (Conv2D)           (None, 2, 2, 64)          18496     \n",
      "_________________________________________________________________\n",
      "activation_29 (Activation)   (None, 2, 2, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_29 (MaxPooling (None, 1, 1, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 35,514\n",
      "Trainable params: 35,514\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 134us/sample - loss: 0.0522 - acc: 0.9863\n",
      "Loss: 0.052200128448847 Accuracy: 0.9863\n"
     ]
    }
   ],
   "source": [
    "log_dir = 'log'\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "base = 'vis_2D_CNN_custom_ch_16_DO_050_DO'\n",
    "\n",
    "with open(path.join(log_dir, base), 'w') as log_file:\n",
    "    for i in range(1, 6):\n",
    "        model_name = base+'_{}_conv'.format(i)\n",
    "        print()\n",
    "        print(model_name, 'Model')\n",
    "        model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "        model_filename = model_path + sorted(os.listdir(model_path))[-1]\n",
    "\n",
    "        model = load_model(model_filename)\n",
    "        model.summary()\n",
    "\n",
    "        [loss, accuracy] = model.evaluate(x_test, y_test)\n",
    "        print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "\n",
    "        del(model)\n",
    "\n",
    "        log_file.write('\\t'.join([model_name, str(accuracy), str(loss)])+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "vis_2D_CNN_custom_ch_16_DO_050_DO_1_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 28, 28, 16)        160       \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 28, 28, 16)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                31370     \n",
      "=================================================================\n",
      "Total params: 31,530\n",
      "Trainable params: 31,530\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "10000/10000 [==============================] - 1s 123us/sample - loss: 0.0733 - acc: 0.9826\n",
      "Loss: 0.07325746181446594 Accuracy: 0.9826\n",
      "\n",
      "vis_2D_CNN_custom_ch_16_DO_050_DO_2_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_7 (InputLayer)         (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 28, 28, 16)        160       \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 28, 28, 16)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 14, 14, 16)        2320      \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_17 (MaxPooling (None, 7, 7, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                7850      \n",
      "=================================================================\n",
      "Total params: 10,330\n",
      "Trainable params: 10,330\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "10000/10000 [==============================] - 1s 129us/sample - loss: 0.0371 - acc: 0.9889\n",
      "Loss: 0.03711201855358668 Accuracy: 0.9889\n",
      "\n",
      "vis_2D_CNN_custom_ch_16_DO_050_DO_3_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_8 (InputLayer)         (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 28, 28, 16)        160       \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 28, 28, 16)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_18 (MaxPooling (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 14, 14, 16)        2320      \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_19 (MaxPooling (None, 7, 7, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 7, 7, 32)          4640      \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 7, 7, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_20 (MaxPooling (None, 4, 4, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 12,250\n",
      "Trainable params: 12,250\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "10000/10000 [==============================] - 1s 128us/sample - loss: 0.0342 - acc: 0.9899\n",
      "Loss: 0.03419729840050718 Accuracy: 0.9899\n",
      "\n",
      "vis_2D_CNN_custom_ch_16_DO_050_DO_4_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_9 (InputLayer)         (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 28, 28, 16)        160       \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 28, 28, 16)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_21 (MaxPooling (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_22 (Conv2D)           (None, 14, 14, 16)        2320      \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_22 (MaxPooling (None, 7, 7, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 7, 7, 32)          4640      \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 7, 7, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_23 (MaxPooling (None, 4, 4, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_24 (Conv2D)           (None, 4, 4, 32)          9248      \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 4, 4, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_24 (MaxPooling (None, 2, 2, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 17,658\n",
      "Trainable params: 17,658\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "10000/10000 [==============================] - 1s 137us/sample - loss: 0.0443 - acc: 0.9893\n",
      "Loss: 0.04431525687105809 Accuracy: 0.9893\n",
      "\n",
      "vis_2D_CNN_custom_ch_16_DO_050_DO_5_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_10 (InputLayer)        (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_25 (Conv2D)           (None, 28, 28, 16)        160       \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 28, 28, 16)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_25 (MaxPooling (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_26 (Conv2D)           (None, 14, 14, 16)        2320      \n",
      "_________________________________________________________________\n",
      "activation_26 (Activation)   (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_26 (MaxPooling (None, 7, 7, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_27 (Conv2D)           (None, 7, 7, 32)          4640      \n",
      "_________________________________________________________________\n",
      "activation_27 (Activation)   (None, 7, 7, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_27 (MaxPooling (None, 4, 4, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_28 (Conv2D)           (None, 4, 4, 32)          9248      \n",
      "_________________________________________________________________\n",
      "activation_28 (Activation)   (None, 4, 4, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_28 (MaxPooling (None, 2, 2, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_29 (Conv2D)           (None, 2, 2, 64)          18496     \n",
      "_________________________________________________________________\n",
      "activation_29 (Activation)   (None, 2, 2, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_29 (MaxPooling (None, 1, 1, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 35,514\n",
      "Trainable params: 35,514\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 2s 152us/sample - loss: 0.0636 - acc: 0.9891\n",
      "Loss: 0.06364045939534756 Accuracy: 0.9891\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 6):\n",
    "    model_name = base+'_{}_conv'.format(i)\n",
    "    print()\n",
    "    print(model_name, 'Model')\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    model_filename = model_path + '000_last.hdf5'\n",
    "\n",
    "    model = load_model(model_filename)\n",
    "    model.summary()\n",
    "\n",
    "    [loss, accuracy] = model.evaluate(x_test, y_test)\n",
    "    print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "\n",
    "    del(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

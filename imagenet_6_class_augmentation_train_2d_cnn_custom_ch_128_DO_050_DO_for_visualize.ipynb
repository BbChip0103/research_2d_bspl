{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import os.path as path\n",
    "import itertools\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.layers import Input,InputLayer, Dense, Activation, BatchNormalization, Flatten, Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D, Dropout\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,LearningRateScheduler, \\\n",
    "                                        EarlyStopping\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.utils import to_categorical, multi_gpu_model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.load(path.join(data_dir, 'imagenet_6_class_train_data.npz'))\n",
    "val_data = np.load(path.join(data_dir, 'imagenet_6_class_val_data.npz'))\n",
    "test_data = np.load(path.join(data_dir, 'imagenet_6_class_val_data.npz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4680, 341, 341, 3),\n",
       " (4680,),\n",
       " (1560, 341, 341, 3),\n",
       " (1560,),\n",
       " (1560, 341, 341, 3),\n",
       " (1560,),\n",
       " (6, 2))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = train_data['x_data']\n",
    "y_train = train_data['y_data']\n",
    "x_val = val_data['x_data']\n",
    "y_val = val_data['y_data']\n",
    "x_test = test_data['x_data']\n",
    "y_test = test_data['y_data']\n",
    "y_table_array = test_data['y_table_array']\n",
    "\n",
    "x_train.shape, y_train.shape, x_val.shape, y_val.shape, x_test.shape, y_test.shape, y_table_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4680, 341, 341, 3),\n",
       " (4680, 6),\n",
       " (1560, 341, 341, 3),\n",
       " (1560, 6),\n",
       " (1560, 341, 341, 3),\n",
       " (1560, 6))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = to_categorical(y_train)\n",
    "y_val = to_categorical(y_val)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "x_train.shape, y_train.shape, x_val.shape, y_val.shape, x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bed', 'bird', 'cat', 'dog', 'house', 'tree']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_list = [text for _, text in y_table_array]\n",
    "y_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = x_train[0].shape\n",
    "output_size = len(y_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_2d_cnn_custom_ch_128_DO(conv_num=1):\n",
    "    input_layer = Input(shape=input_shape)\n",
    "    x = input_layer\n",
    "\n",
    "    for i in range(conv_num):\n",
    "        x = Conv2D(kernel_size=5, filters=128*(2**(i//2)), strides=(1,1), padding='same')(x)\n",
    "#         x = BatchNormalization()(x)\n",
    "        x = Activation('relu')(x)\n",
    "        x = MaxPooling2D(pool_size=3, strides=(3,3), padding='same')(x)\n",
    "\n",
    "    x = Flatten()(x)\n",
    "  \n",
    "    x = Dropout(0.5)(x)\n",
    "    output_layer = Dense(output_size, activation='softmax')(x)\n",
    "    \n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 341, 341, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 341, 341, 128)     9728      \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 341, 341, 128)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 114, 114, 128)     0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1663488)           0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1663488)           0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 6)                 9980934   \n",
      "=================================================================\n",
      "Total params: 9,990,662\n",
      "Trainable params: 9,990,662\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 341, 341, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 341, 341, 128)     9728      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 341, 341, 128)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 114, 114, 128)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 114, 114, 128)     409728    \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 114, 114, 128)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 38, 38, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 184832)            0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 184832)            0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 6)                 1108998   \n",
      "=================================================================\n",
      "Total params: 1,528,454\n",
      "Trainable params: 1,528,454\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 341, 341, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 341, 341, 128)     9728      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 341, 341, 128)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 114, 114, 128)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 114, 114, 128)     409728    \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 114, 114, 128)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 38, 38, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 38, 38, 256)       819456    \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 38, 38, 256)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 13, 13, 256)       0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 43264)             0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 43264)             0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 6)                 259590    \n",
      "=================================================================\n",
      "Total params: 1,498,502\n",
      "Trainable params: 1,498,502\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, 341, 341, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 341, 341, 128)     9728      \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 341, 341, 128)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 114, 114, 128)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 114, 114, 128)     409728    \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 114, 114, 128)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 38, 38, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 38, 38, 256)       819456    \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 38, 38, 256)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 13, 13, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 13, 13, 256)       1638656   \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 13, 13, 256)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 5, 5, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 6400)              0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 6400)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 6)                 38406     \n",
      "=================================================================\n",
      "Total params: 2,915,974\n",
      "Trainable params: 2,915,974\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         (None, 341, 341, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 341, 341, 128)     9728      \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 341, 341, 128)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 114, 114, 128)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 114, 114, 128)     409728    \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 114, 114, 128)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 38, 38, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 38, 38, 256)       819456    \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 38, 38, 256)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 13, 13, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 13, 13, 256)       1638656   \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 13, 13, 256)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 5, 5, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 5, 5, 512)         3277312   \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 5, 5, 512)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 6)                 12294     \n",
      "=================================================================\n",
      "Total params: 6,167,174\n",
      "Trainable params: 6,167,174\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 6):\n",
    "    model = build_2d_cnn_custom_ch_128_DO(conv_num=i)\n",
    "    model.summary()\n",
    "    del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_generator = ImageDataGenerator(\n",
    "                    rotation_range=30,\n",
    "                    width_shift_range=0.15,\n",
    "                    height_shift_range=0.15,\n",
    "                    shear_range=0.2,\n",
    "                    zoom_range=0.2,\n",
    "                    horizontal_flip=True,\n",
    "                    fill_mode='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/1000\n",
      "25/25 [==============================] - 12s 499ms/step - loss: 1.4147 - acc: 0.4737\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.41472, saving model to model/checkpoint/vis_imagenet_6_class_augumentation_2D_CNN_custom_ch_128_DO_050_DO_3_conv_checkpoint/001-1.4147.hdf5\n",
      "74/74 [==============================] - 49s 659ms/step - loss: 1.5605 - acc: 0.3536 - val_loss: 1.4147 - val_acc: 0.4737\n",
      "Epoch 2/1000\n",
      "25/25 [==============================] - 12s 496ms/step - loss: 1.1738 - acc: 0.5506\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.41472 to 1.17383, saving model to model/checkpoint/vis_imagenet_6_class_augumentation_2D_CNN_custom_ch_128_DO_050_DO_3_conv_checkpoint/002-1.1738.hdf5\n",
      "74/74 [==============================] - 45s 606ms/step - loss: 1.2901 - acc: 0.4906 - val_loss: 1.1738 - val_acc: 0.5506\n",
      "Epoch 3/1000\n",
      "25/25 [==============================] - 12s 492ms/step - loss: 1.1659 - acc: 0.5571\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.17383 to 1.16595, saving model to model/checkpoint/vis_imagenet_6_class_augumentation_2D_CNN_custom_ch_128_DO_050_DO_3_conv_checkpoint/003-1.1659.hdf5\n",
      "74/74 [==============================] - 45s 602ms/step - loss: 1.1693 - acc: 0.5558 - val_loss: 1.1659 - val_acc: 0.5571\n",
      "Epoch 4/1000\n",
      "25/25 [==============================] - 12s 495ms/step - loss: 1.0327 - acc: 0.6192\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.16595 to 1.03269, saving model to model/checkpoint/vis_imagenet_6_class_augumentation_2D_CNN_custom_ch_128_DO_050_DO_3_conv_checkpoint/004-1.0327.hdf5\n",
      "74/74 [==============================] - 45s 604ms/step - loss: 1.0988 - acc: 0.5925 - val_loss: 1.0327 - val_acc: 0.6192\n",
      "Epoch 5/1000\n",
      "25/25 [==============================] - 12s 487ms/step - loss: 1.0321 - acc: 0.6122\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.03269 to 1.03215, saving model to model/checkpoint/vis_imagenet_6_class_augumentation_2D_CNN_custom_ch_128_DO_050_DO_3_conv_checkpoint/005-1.0321.hdf5\n",
      "74/74 [==============================] - 45s 606ms/step - loss: 1.0560 - acc: 0.6094 - val_loss: 1.0321 - val_acc: 0.6122\n",
      "Epoch 6/1000\n",
      "25/25 [==============================] - 12s 481ms/step - loss: 0.9938 - acc: 0.6224\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.03215 to 0.99384, saving model to model/checkpoint/vis_imagenet_6_class_augumentation_2D_CNN_custom_ch_128_DO_050_DO_3_conv_checkpoint/006-0.9938.hdf5\n",
      "74/74 [==============================] - 44s 600ms/step - loss: 0.9930 - acc: 0.6423 - val_loss: 0.9938 - val_acc: 0.6224\n",
      "Epoch 7/1000\n",
      "25/25 [==============================] - 12s 488ms/step - loss: 0.9491 - acc: 0.6468\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.99384 to 0.94914, saving model to model/checkpoint/vis_imagenet_6_class_augumentation_2D_CNN_custom_ch_128_DO_050_DO_3_conv_checkpoint/007-0.9491.hdf5\n",
      "74/74 [==============================] - 45s 602ms/step - loss: 0.9803 - acc: 0.6447 - val_loss: 0.9491 - val_acc: 0.6468\n",
      "Epoch 8/1000\n",
      "25/25 [==============================] - 12s 473ms/step - loss: 0.9304 - acc: 0.6660\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.94914 to 0.93042, saving model to model/checkpoint/vis_imagenet_6_class_augumentation_2D_CNN_custom_ch_128_DO_050_DO_3_conv_checkpoint/008-0.9304.hdf5\n",
      "74/74 [==============================] - 44s 595ms/step - loss: 0.9425 - acc: 0.6564 - val_loss: 0.9304 - val_acc: 0.6660\n",
      "Epoch 9/1000\n",
      "25/25 [==============================] - 12s 498ms/step - loss: 1.0958 - acc: 0.5782\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.93042\n",
      "74/74 [==============================] - 46s 619ms/step - loss: 0.9196 - acc: 0.6797 - val_loss: 1.0958 - val_acc: 0.5782\n",
      "Epoch 10/1000\n",
      "25/25 [==============================] - 12s 467ms/step - loss: 0.8582 - acc: 0.6808\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.93042 to 0.85823, saving model to model/checkpoint/vis_imagenet_6_class_augumentation_2D_CNN_custom_ch_128_DO_050_DO_3_conv_checkpoint/010-0.8582.hdf5\n",
      "74/74 [==============================] - 44s 600ms/step - loss: 0.9042 - acc: 0.6778 - val_loss: 0.8582 - val_acc: 0.6808\n",
      "Epoch 11/1000\n",
      "25/25 [==============================] - 12s 480ms/step - loss: 0.8802 - acc: 0.6769\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.85823\n",
      "74/74 [==============================] - 45s 607ms/step - loss: 0.8576 - acc: 0.6983 - val_loss: 0.8802 - val_acc: 0.6769\n",
      "Epoch 12/1000\n",
      "25/25 [==============================] - 12s 495ms/step - loss: 0.8565 - acc: 0.6936\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.85823 to 0.85645, saving model to model/checkpoint/vis_imagenet_6_class_augumentation_2D_CNN_custom_ch_128_DO_050_DO_3_conv_checkpoint/012-0.8565.hdf5\n",
      "74/74 [==============================] - 45s 606ms/step - loss: 0.8412 - acc: 0.6934 - val_loss: 0.8565 - val_acc: 0.6936\n",
      "Epoch 13/1000\n",
      "25/25 [==============================] - 12s 484ms/step - loss: 0.8071 - acc: 0.7109\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.85645 to 0.80713, saving model to model/checkpoint/vis_imagenet_6_class_augumentation_2D_CNN_custom_ch_128_DO_050_DO_3_conv_checkpoint/013-0.8071.hdf5\n",
      "74/74 [==============================] - 44s 598ms/step - loss: 0.8230 - acc: 0.7058 - val_loss: 0.8071 - val_acc: 0.7109\n",
      "Epoch 14/1000\n",
      "25/25 [==============================] - 12s 491ms/step - loss: 0.8077 - acc: 0.7032\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.80713\n",
      "74/74 [==============================] - 46s 615ms/step - loss: 0.7694 - acc: 0.7239 - val_loss: 0.8077 - val_acc: 0.7032\n",
      "Epoch 15/1000\n",
      "25/25 [==============================] - 12s 482ms/step - loss: 0.7688 - acc: 0.7212\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.80713 to 0.76883, saving model to model/checkpoint/vis_imagenet_6_class_augumentation_2D_CNN_custom_ch_128_DO_050_DO_3_conv_checkpoint/015-0.7688.hdf5\n",
      "74/74 [==============================] - 44s 594ms/step - loss: 0.7572 - acc: 0.7340 - val_loss: 0.7688 - val_acc: 0.7212\n",
      "Epoch 16/1000\n",
      "25/25 [==============================] - 12s 494ms/step - loss: 0.7339 - acc: 0.7333\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.76883 to 0.73392, saving model to model/checkpoint/vis_imagenet_6_class_augumentation_2D_CNN_custom_ch_128_DO_050_DO_3_conv_checkpoint/016-0.7339.hdf5\n",
      "74/74 [==============================] - 44s 600ms/step - loss: 0.7333 - acc: 0.7361 - val_loss: 0.7339 - val_acc: 0.7333\n",
      "Epoch 17/1000\n",
      "25/25 [==============================] - 12s 478ms/step - loss: 0.7111 - acc: 0.7423\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.73392 to 0.71113, saving model to model/checkpoint/vis_imagenet_6_class_augumentation_2D_CNN_custom_ch_128_DO_050_DO_3_conv_checkpoint/017-0.7111.hdf5\n",
      "74/74 [==============================] - 44s 600ms/step - loss: 0.7415 - acc: 0.7427 - val_loss: 0.7111 - val_acc: 0.7423\n",
      "Epoch 18/1000\n",
      "25/25 [==============================] - 12s 492ms/step - loss: 0.7136 - acc: 0.7506\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.71113\n",
      "74/74 [==============================] - 44s 601ms/step - loss: 0.7318 - acc: 0.7397 - val_loss: 0.7136 - val_acc: 0.7506\n",
      "Epoch 19/1000\n",
      "25/25 [==============================] - 12s 486ms/step - loss: 0.7404 - acc: 0.7391\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.71113\n",
      "74/74 [==============================] - 44s 600ms/step - loss: 0.6845 - acc: 0.7468 - val_loss: 0.7404 - val_acc: 0.7391\n",
      "Epoch 20/1000\n",
      "25/25 [==============================] - 12s 474ms/step - loss: 0.7321 - acc: 0.7378\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.71113\n",
      "74/74 [==============================] - 44s 588ms/step - loss: 0.7011 - acc: 0.7502 - val_loss: 0.7321 - val_acc: 0.7378\n",
      "Epoch 21/1000\n",
      "25/25 [==============================] - 12s 472ms/step - loss: 0.7849 - acc: 0.7179\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.71113\n",
      "74/74 [==============================] - 44s 596ms/step - loss: 0.6832 - acc: 0.7521 - val_loss: 0.7849 - val_acc: 0.7179\n",
      "Epoch 22/1000\n",
      "25/25 [==============================] - 12s 496ms/step - loss: 0.6858 - acc: 0.7545\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.71113 to 0.68583, saving model to model/checkpoint/vis_imagenet_6_class_augumentation_2D_CNN_custom_ch_128_DO_050_DO_3_conv_checkpoint/022-0.6858.hdf5\n",
      "74/74 [==============================] - 45s 608ms/step - loss: 0.6744 - acc: 0.7585 - val_loss: 0.6858 - val_acc: 0.7545\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/1000\n",
      "25/25 [==============================] - 12s 480ms/step - loss: 0.7360 - acc: 0.7423\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.68583\n",
      "74/74 [==============================] - 44s 597ms/step - loss: 0.6632 - acc: 0.7600 - val_loss: 0.7360 - val_acc: 0.7423\n",
      "Epoch 24/1000\n",
      "25/25 [==============================] - 12s 497ms/step - loss: 0.6649 - acc: 0.7654\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.68583 to 0.66490, saving model to model/checkpoint/vis_imagenet_6_class_augumentation_2D_CNN_custom_ch_128_DO_050_DO_3_conv_checkpoint/024-0.6649.hdf5\n",
      "74/74 [==============================] - 44s 601ms/step - loss: 0.6332 - acc: 0.7767 - val_loss: 0.6649 - val_acc: 0.7654\n",
      "Epoch 25/1000\n",
      "25/25 [==============================] - 12s 470ms/step - loss: 0.6992 - acc: 0.7487\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.66490\n",
      "74/74 [==============================] - 44s 591ms/step - loss: 0.6727 - acc: 0.7615 - val_loss: 0.6992 - val_acc: 0.7487\n",
      "Epoch 26/1000\n",
      "25/25 [==============================] - 12s 482ms/step - loss: 0.6419 - acc: 0.7564\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.66490 to 0.64190, saving model to model/checkpoint/vis_imagenet_6_class_augumentation_2D_CNN_custom_ch_128_DO_050_DO_3_conv_checkpoint/026-0.6419.hdf5\n",
      "74/74 [==============================] - 45s 606ms/step - loss: 0.6371 - acc: 0.7767 - val_loss: 0.6419 - val_acc: 0.7564\n",
      "Epoch 27/1000\n",
      "25/25 [==============================] - 13s 501ms/step - loss: 0.7275 - acc: 0.7519\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.64190\n",
      "74/74 [==============================] - 45s 602ms/step - loss: 0.6202 - acc: 0.7885 - val_loss: 0.7275 - val_acc: 0.7519\n",
      "Epoch 28/1000\n",
      "25/25 [==============================] - 13s 502ms/step - loss: 0.6636 - acc: 0.7763\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.64190\n",
      "74/74 [==============================] - 45s 610ms/step - loss: 0.6213 - acc: 0.7823 - val_loss: 0.6636 - val_acc: 0.7763\n",
      "Epoch 29/1000\n",
      "25/25 [==============================] - 12s 489ms/step - loss: 0.6694 - acc: 0.7718\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.64190\n",
      "74/74 [==============================] - 45s 602ms/step - loss: 0.5966 - acc: 0.7882 - val_loss: 0.6694 - val_acc: 0.7718\n",
      "Epoch 30/1000\n",
      "25/25 [==============================] - 12s 488ms/step - loss: 0.6447 - acc: 0.7705\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.64190\n",
      "74/74 [==============================] - 44s 601ms/step - loss: 0.5893 - acc: 0.7964 - val_loss: 0.6447 - val_acc: 0.7705\n",
      "Epoch 31/1000\n",
      "25/25 [==============================] - 12s 497ms/step - loss: 0.6550 - acc: 0.7654\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.64190\n",
      "74/74 [==============================] - 45s 606ms/step - loss: 0.5722 - acc: 0.8049 - val_loss: 0.6550 - val_acc: 0.7654\n",
      "Epoch 32/1000\n",
      "25/25 [==============================] - 12s 497ms/step - loss: 0.7062 - acc: 0.7442\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.64190\n",
      "74/74 [==============================] - 45s 604ms/step - loss: 0.5746 - acc: 0.7938 - val_loss: 0.7062 - val_acc: 0.7442\n",
      "Epoch 33/1000\n",
      "25/25 [==============================] - 12s 496ms/step - loss: 0.6149 - acc: 0.7885\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.64190 to 0.61494, saving model to model/checkpoint/vis_imagenet_6_class_augumentation_2D_CNN_custom_ch_128_DO_050_DO_3_conv_checkpoint/033-0.6149.hdf5\n",
      "74/74 [==============================] - 45s 604ms/step - loss: 0.5783 - acc: 0.7957 - val_loss: 0.6149 - val_acc: 0.7885\n",
      "Epoch 34/1000\n",
      "25/25 [==============================] - 12s 493ms/step - loss: 0.6249 - acc: 0.7923\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.61494\n",
      "74/74 [==============================] - 44s 600ms/step - loss: 0.5652 - acc: 0.8000 - val_loss: 0.6249 - val_acc: 0.7923\n",
      "Epoch 35/1000\n",
      "25/25 [==============================] - 12s 497ms/step - loss: 0.6499 - acc: 0.7731\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.61494\n",
      "74/74 [==============================] - 45s 609ms/step - loss: 0.5656 - acc: 0.8019 - val_loss: 0.6499 - val_acc: 0.7731\n",
      "Epoch 36/1000\n",
      "25/25 [==============================] - 13s 508ms/step - loss: 0.6348 - acc: 0.7756\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.61494\n",
      "74/74 [==============================] - 45s 613ms/step - loss: 0.5425 - acc: 0.8111 - val_loss: 0.6348 - val_acc: 0.7756\n",
      "Epoch 37/1000\n",
      "25/25 [==============================] - 13s 501ms/step - loss: 0.5973 - acc: 0.7968\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.61494 to 0.59733, saving model to model/checkpoint/vis_imagenet_6_class_augumentation_2D_CNN_custom_ch_128_DO_050_DO_3_conv_checkpoint/037-0.5973.hdf5\n",
      "74/74 [==============================] - 46s 615ms/step - loss: 0.5591 - acc: 0.8041 - val_loss: 0.5973 - val_acc: 0.7968\n",
      "Epoch 38/1000\n",
      "25/25 [==============================] - 13s 504ms/step - loss: 0.6239 - acc: 0.7801\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.59733\n",
      "74/74 [==============================] - 45s 612ms/step - loss: 0.5237 - acc: 0.8137 - val_loss: 0.6239 - val_acc: 0.7801\n",
      "Epoch 39/1000\n",
      "25/25 [==============================] - 12s 493ms/step - loss: 0.6211 - acc: 0.7885\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.59733\n",
      "74/74 [==============================] - 45s 604ms/step - loss: 0.5201 - acc: 0.8139 - val_loss: 0.6211 - val_acc: 0.7885\n",
      "Epoch 40/1000\n",
      "25/25 [==============================] - 12s 482ms/step - loss: 0.5970 - acc: 0.7942\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.59733 to 0.59705, saving model to model/checkpoint/vis_imagenet_6_class_augumentation_2D_CNN_custom_ch_128_DO_050_DO_3_conv_checkpoint/040-0.5970.hdf5\n",
      "74/74 [==============================] - 44s 598ms/step - loss: 0.5124 - acc: 0.8254 - val_loss: 0.5970 - val_acc: 0.7942\n",
      "Epoch 41/1000\n",
      "25/25 [==============================] - 12s 500ms/step - loss: 0.6305 - acc: 0.7865\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.59705\n",
      "74/74 [==============================] - 45s 606ms/step - loss: 0.5437 - acc: 0.8229 - val_loss: 0.6305 - val_acc: 0.7865\n",
      "Epoch 42/1000\n",
      "25/25 [==============================] - 12s 479ms/step - loss: 0.5746 - acc: 0.8103\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.59705 to 0.57464, saving model to model/checkpoint/vis_imagenet_6_class_augumentation_2D_CNN_custom_ch_128_DO_050_DO_3_conv_checkpoint/042-0.5746.hdf5\n",
      "74/74 [==============================] - 45s 608ms/step - loss: 0.5175 - acc: 0.8177 - val_loss: 0.5746 - val_acc: 0.8103\n",
      "Epoch 43/1000\n",
      "25/25 [==============================] - 12s 493ms/step - loss: 0.5795 - acc: 0.8051\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.57464\n",
      "74/74 [==============================] - 44s 601ms/step - loss: 0.5355 - acc: 0.8139 - val_loss: 0.5795 - val_acc: 0.8051\n",
      "Epoch 44/1000\n",
      "25/25 [==============================] - 13s 516ms/step - loss: 0.5481 - acc: 0.8154\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.57464 to 0.54811, saving model to model/checkpoint/vis_imagenet_6_class_augumentation_2D_CNN_custom_ch_128_DO_050_DO_3_conv_checkpoint/044-0.5481.hdf5\n",
      "74/74 [==============================] - 45s 607ms/step - loss: 0.5104 - acc: 0.8212 - val_loss: 0.5481 - val_acc: 0.8154\n",
      "Epoch 45/1000\n",
      "25/25 [==============================] - 13s 515ms/step - loss: 0.5663 - acc: 0.8109\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.54811\n",
      "74/74 [==============================] - 45s 609ms/step - loss: 0.5144 - acc: 0.8216 - val_loss: 0.5663 - val_acc: 0.8109\n",
      "Epoch 46/1000\n",
      "25/25 [==============================] - 12s 498ms/step - loss: 0.5872 - acc: 0.7955\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.54811\n",
      "74/74 [==============================] - 45s 605ms/step - loss: 0.5000 - acc: 0.8284 - val_loss: 0.5872 - val_acc: 0.7955\n",
      "Epoch 47/1000\n",
      "25/25 [==============================] - 12s 482ms/step - loss: 0.5133 - acc: 0.8231\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.54811 to 0.51326, saving model to model/checkpoint/vis_imagenet_6_class_augumentation_2D_CNN_custom_ch_128_DO_050_DO_3_conv_checkpoint/047-0.5133.hdf5\n",
      "74/74 [==============================] - 45s 602ms/step - loss: 0.4835 - acc: 0.8325 - val_loss: 0.5133 - val_acc: 0.8231\n",
      "\bEpoch 48/1000\n",
      "25/25 [==============================] - 12s 487ms/step - loss: 0.5844 - acc: 0.8032\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.51326\n",
      "74/74 [==============================] - 45s 604ms/step - loss: 0.4896 - acc: 0.8271 - val_loss: 0.5844 - val_acc: 0.8032\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/1000\n",
      "25/25 [==============================] - 13s 503ms/step - loss: 0.5673 - acc: 0.8032\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.51326\n",
      "74/74 [==============================] - 45s 605ms/step - loss: 0.4934 - acc: 0.8340 - val_loss: 0.5673 - val_acc: 0.8032\n",
      "Epoch 50/1000\n",
      "25/25 [==============================] - 12s 481ms/step - loss: 0.5872 - acc: 0.8058\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.51326\n",
      "74/74 [==============================] - 45s 602ms/step - loss: 0.4596 - acc: 0.8391 - val_loss: 0.5872 - val_acc: 0.8058\n",
      "Epoch 51/1000\n",
      "25/25 [==============================] - 12s 496ms/step - loss: 0.5442 - acc: 0.8186\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.51326\n",
      "74/74 [==============================] - 44s 601ms/step - loss: 0.4653 - acc: 0.8378 - val_loss: 0.5442 - val_acc: 0.8186\n",
      "Epoch 52/1000\n",
      "25/25 [==============================] - 12s 491ms/step - loss: 0.5352 - acc: 0.8160\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.51326\n",
      "74/74 [==============================] - 44s 601ms/step - loss: 0.4782 - acc: 0.8344 - val_loss: 0.5352 - val_acc: 0.8160\n",
      "Epoch 53/1000\n",
      "25/25 [==============================] - 12s 491ms/step - loss: 0.5601 - acc: 0.8167\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.51326\n",
      "74/74 [==============================] - 45s 606ms/step - loss: 0.4511 - acc: 0.8395 - val_loss: 0.5601 - val_acc: 0.8167\n",
      "Epoch 54/1000\n",
      "25/25 [==============================] - 12s 496ms/step - loss: 0.5348 - acc: 0.8212\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.51326\n",
      "74/74 [==============================] - 45s 602ms/step - loss: 0.4342 - acc: 0.8483 - val_loss: 0.5348 - val_acc: 0.8212\n",
      "Epoch 55/1000\n",
      "25/25 [==============================] - 13s 503ms/step - loss: 0.5770 - acc: 0.8160\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.51326\n",
      "74/74 [==============================] - 45s 609ms/step - loss: 0.4296 - acc: 0.8494 - val_loss: 0.5770 - val_acc: 0.8160\n",
      "Epoch 56/1000\n",
      "25/25 [==============================] - 12s 482ms/step - loss: 0.5125 - acc: 0.8372\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.51326 to 0.51248, saving model to model/checkpoint/vis_imagenet_6_class_augumentation_2D_CNN_custom_ch_128_DO_050_DO_3_conv_checkpoint/056-0.5125.hdf5\n",
      "74/74 [==============================] - 44s 595ms/step - loss: 0.4384 - acc: 0.8515 - val_loss: 0.5125 - val_acc: 0.8372\n",
      "Epoch 57/1000\n",
      "25/25 [==============================] - 13s 518ms/step - loss: 0.5090 - acc: 0.8205\n",
      "\n",
      "Epoch 00057: val_loss improved from 0.51248 to 0.50904, saving model to model/checkpoint/vis_imagenet_6_class_augumentation_2D_CNN_custom_ch_128_DO_050_DO_3_conv_checkpoint/057-0.5090.hdf5\n",
      "74/74 [==============================] - 46s 619ms/step - loss: 0.4405 - acc: 0.8464 - val_loss: 0.5090 - val_acc: 0.8205\n",
      "Epoch 58/1000\n",
      "25/25 [==============================] - 13s 517ms/step - loss: 0.4983 - acc: 0.8353\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.50904 to 0.49831, saving model to model/checkpoint/vis_imagenet_6_class_augumentation_2D_CNN_custom_ch_128_DO_050_DO_3_conv_checkpoint/058-0.4983.hdf5\n",
      "74/74 [==============================] - 45s 612ms/step - loss: 0.4194 - acc: 0.8502 - val_loss: 0.4983 - val_acc: 0.8353\n",
      "Epoch 59/1000\n",
      "25/25 [==============================] - 13s 514ms/step - loss: 0.5509 - acc: 0.8141\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.49831\n",
      "74/74 [==============================] - 45s 611ms/step - loss: 0.4502 - acc: 0.8410 - val_loss: 0.5509 - val_acc: 0.8141\n",
      "Epoch 60/1000\n",
      "25/25 [==============================] - 12s 494ms/step - loss: 0.5246 - acc: 0.8276\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.49831\n",
      "74/74 [==============================] - 45s 602ms/step - loss: 0.4365 - acc: 0.8513 - val_loss: 0.5246 - val_acc: 0.8276\n",
      "Epoch 61/1000\n",
      "25/25 [==============================] - 13s 500ms/step - loss: 0.5682 - acc: 0.8154\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.49831\n",
      "74/74 [==============================] - 45s 603ms/step - loss: 0.4410 - acc: 0.8472 - val_loss: 0.5682 - val_acc: 0.8154\n",
      "Epoch 62/1000\n",
      "25/25 [==============================] - 12s 494ms/step - loss: 0.5283 - acc: 0.8026\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.49831\n",
      "74/74 [==============================] - 45s 606ms/step - loss: 0.4117 - acc: 0.8592 - val_loss: 0.5283 - val_acc: 0.8026\n",
      "Epoch 63/1000\n",
      "25/25 [==============================] - 12s 492ms/step - loss: 0.5330 - acc: 0.8231\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.49831\n",
      "74/74 [==============================] - 44s 600ms/step - loss: 0.4264 - acc: 0.8519 - val_loss: 0.5330 - val_acc: 0.8231\n",
      "Epoch 64/1000\n",
      "25/25 [==============================] - 12s 497ms/step - loss: 0.5478 - acc: 0.8154\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.49831\n",
      "74/74 [==============================] - 45s 604ms/step - loss: 0.4165 - acc: 0.8556 - val_loss: 0.5478 - val_acc: 0.8154\n",
      "Epoch 65/1000\n",
      "38/74 [==============>...............] - ETA: 15s - loss: 0.3960 - acc: 0.8602"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[64,128,341,341] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node training/Adam/gradients/max_pooling2d_15/MaxPool_grad/MaxPoolGrad}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-6e12e9eaf700>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcheckpointer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearly_stopping\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     )\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1424\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1425\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1426\u001b[0;31m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1428\u001b[0m   def evaluate_generator(self,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, **kwargs)\u001b[0m\n\u001b[1;32m    189\u001b[0m       \u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m       \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m   1189\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_fit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1191\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1193\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3074\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3075\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3076\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3077\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3078\u001b[0m     return nest.pack_sequence_as(self._outputs_structure,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    526\u001b[0m             \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 528\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    529\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m     \u001b[0;31m# as there is a reference to status from this from the traceback due to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[64,128,341,341] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node training/Adam/gradients/max_pooling2d_15/MaxPool_grad/MaxPoolGrad}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n"
     ]
    }
   ],
   "source": [
    "for i in range(3, 6):\n",
    "    base = 'vis_imagenet_6_class_augmentation_2D_CNN_custom_ch_128_DO_050_DO'\n",
    "    model_name = base+'_{}_conv'.format(i)\n",
    "    model = build_2d_cnn_custom_ch_128_DO(conv_num=i)\n",
    "#     model = multi_gpu_model(model, gpus=2)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=1e-4),\n",
    "          metrics=['accuracy'])\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    os.makedirs(model_path, exist_ok=True)\n",
    "    model_filename = model_path+'{epoch:03d}-{val_loss:.4f}.hdf5'\n",
    "    checkpointer = ModelCheckpoint(filepath = model_filename, monitor = \"val_loss\", \n",
    "                                   verbose=1, save_best_only=True)\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=100)\n",
    "    hist = model.fit_generator(\n",
    "            data_generator.flow(x_train, y_train, batch_size=64),\n",
    "            steps_per_epoch=len(x_train)//64,\n",
    "            epochs=10000,\n",
    "            validation_data=data_generator.flow(x_val, y_val, batch_size=64),\n",
    "            validation_steps=len(x_val)//64,\n",
    "            callbacks = [checkpointer, early_stopping],\n",
    "            workers=4, \n",
    "            use_multiprocessing=True\n",
    "    )\n",
    "    \n",
    "    print()\n",
    "    print(model_name, 'Model')\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "    ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
    "    ax.plot(hist.history['acc'], 'b', label='train acc')\n",
    "    ax.plot(hist.history['val_acc'], 'g', label='val acc')\n",
    "    ax.set_xlabel('epoch')\n",
    "    ax.set_ylabel('loss')\n",
    "    ax.legend(loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    png_path = 'visualization/learning_curve/'\n",
    "    filename = model_name+'.png'\n",
    "    os.makedirs(png_path, exist_ok=True)\n",
    "    fig.savefig(png_path+filename, transparent=True)\n",
    "\n",
    "    model.save(model_path+'000_last.hdf5')\n",
    "    del(model)\n",
    "\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    model_filename = model_path + sorted(os.listdir(model_path))[-1]\n",
    "    model = load_model(model_filename)\n",
    "    [loss, accuracy] = model.evaluate(x_test, y_test)\n",
    "    print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "    print()\n",
    "\n",
    "    del(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = 'log'\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "base = 'vis_imagenet_6_class_augmentation_2D_CNN_custom_ch_128_DO_050_DO'\n",
    "\n",
    "with open(path.join(log_dir, base), 'w') as log_file:\n",
    "    for i in range(3, 6):\n",
    "        model_name = base+'_{}_conv'.format(i)\n",
    "        print()\n",
    "        print(model_name, 'Model')\n",
    "        model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "        model_filename = model_path + sorted(os.listdir(model_path))[-1]\n",
    "\n",
    "        model = load_model(model_filename)\n",
    "        model.summary()\n",
    "\n",
    "        [loss, accuracy] = model.evaluate(x_test, y_test)\n",
    "        print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "\n",
    "        del(model)\n",
    "\n",
    "        log_file.write('\\t'.join([model_name, str(accuracy), str(loss)])+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3, 6):\n",
    "    model_name = base+'_{}_conv'.format(i)\n",
    "    print()\n",
    "    print(model_name, 'Model')\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    model_filename = model_path + '000_last.hdf5'\n",
    "\n",
    "    model = load_model(model_filename)\n",
    "    model.summary()\n",
    "\n",
    "    [loss, accuracy] = model.evaluate(x_test, y_test)\n",
    "    print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "\n",
    "    del(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

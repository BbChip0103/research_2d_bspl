{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import os.path as path\n",
    "import itertools\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.layers import Input,InputLayer, Dense, Activation, BatchNormalization, Flatten, Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D, Dropout\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,LearningRateScheduler, \\\n",
    "                                        EarlyStopping\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.utils import to_categorical, multi_gpu_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.load(path.join(data_dir, 'imagenet_6_class_train_data.npz'))\n",
    "val_data = np.load(path.join(data_dir, 'imagenet_6_class_val_data.npz'))\n",
    "test_data = np.load(path.join(data_dir, 'imagenet_6_class_val_data.npz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4680, 341, 341, 3),\n",
       " (4680,),\n",
       " (1560, 341, 341, 3),\n",
       " (1560,),\n",
       " (1560, 341, 341, 3),\n",
       " (1560,),\n",
       " (6, 2))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = train_data['x_data']\n",
    "y_train = train_data['y_data']\n",
    "x_val = val_data['x_data']\n",
    "y_val = val_data['y_data']\n",
    "x_test = test_data['x_data']\n",
    "y_test = test_data['y_data']\n",
    "y_table_array = test_data['y_table_array']\n",
    "\n",
    "x_train.shape, y_train.shape, x_val.shape, y_val.shape, x_test.shape, y_test.shape, y_table_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4680, 341, 341, 3),\n",
       " (4680, 6),\n",
       " (1560, 341, 341, 3),\n",
       " (1560, 6),\n",
       " (1560, 341, 341, 3),\n",
       " (1560, 6))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = to_categorical(y_train)\n",
    "y_val = to_categorical(y_val)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "x_train.shape, y_train.shape, x_val.shape, y_val.shape, x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bed', 'bird', 'cat', 'dog', 'house', 'tree']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_list = [text for _, text in y_table_array]\n",
    "y_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = x_train[0].shape\n",
    "output_size = len(y_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_2d_cnn_custom_ch_64_DO(conv_num=1):\n",
    "    input_layer = Input(shape=input_shape)\n",
    "    x = input_layer\n",
    "\n",
    "    for i in range(conv_num):\n",
    "        x = Conv2D(kernel_size=5, filters=64*(2**(i//2)), strides=(1,1), padding='same')(x)\n",
    "#         x = BatchNormalization()(x)\n",
    "        x = Activation('relu')(x)\n",
    "        x = MaxPooling2D(pool_size=3, strides=(3,3), padding='same')(x)\n",
    "\n",
    "    x = Flatten()(x)\n",
    "  \n",
    "    x = Dropout(0.75)(x)\n",
    "    output_layer = Dense(output_size, activation='softmax')(x)\n",
    "    \n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 341, 341, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 341, 341, 64)      4864      \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 341, 341, 64)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 114, 114, 64)      0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 831744)            0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 831744)            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 6)                 4990470   \n",
      "=================================================================\n",
      "Total params: 4,995,334\n",
      "Trainable params: 4,995,334\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 341, 341, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 341, 341, 64)      4864      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 341, 341, 64)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 114, 114, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 114, 114, 64)      102464    \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 114, 114, 64)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 38, 38, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 92416)             0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 92416)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 6)                 554502    \n",
      "=================================================================\n",
      "Total params: 661,830\n",
      "Trainable params: 661,830\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 341, 341, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 341, 341, 64)      4864      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 341, 341, 64)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 114, 114, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 114, 114, 64)      102464    \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 114, 114, 64)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 38, 38, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 38, 38, 128)       204928    \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 38, 38, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 13, 13, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 21632)             0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 21632)             0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 6)                 129798    \n",
      "=================================================================\n",
      "Total params: 442,054\n",
      "Trainable params: 442,054\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, 341, 341, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 341, 341, 64)      4864      \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 341, 341, 64)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 114, 114, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 114, 114, 64)      102464    \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 114, 114, 64)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 38, 38, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 38, 38, 128)       204928    \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 38, 38, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 13, 13, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 13, 13, 128)       409728    \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 13, 13, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 5, 5, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 3200)              0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 3200)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 6)                 19206     \n",
      "=================================================================\n",
      "Total params: 741,190\n",
      "Trainable params: 741,190\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         (None, 341, 341, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 341, 341, 64)      4864      \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 341, 341, 64)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 114, 114, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 114, 114, 64)      102464    \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 114, 114, 64)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 38, 38, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 38, 38, 128)       204928    \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 38, 38, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 13, 13, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 13, 13, 128)       409728    \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 13, 13, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 5, 5, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 5, 5, 256)         819456    \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 5, 5, 256)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 6)                 6150      \n",
      "=================================================================\n",
      "Total params: 1,547,590\n",
      "Trainable params: 1,547,590\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 6):\n",
    "    model = build_2d_cnn_custom_ch_64_DO(conv_num=i)\n",
    "    model.summary()\n",
    "    del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4680 samples, validate on 1560 samples\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 1.4816 - acc: 0.4112\n",
      "Epoch 00001: val_loss improved from inf to 1.21644, saving model to model/checkpoint/vis_imagenet_6_class_2D_CNN_custom_ch_64_DO_075_DO_2_conv_checkpoint/001-1.2164.hdf5\n",
      "4680/4680 [==============================] - 25s 5ms/sample - loss: 1.4808 - acc: 0.4120 - val_loss: 1.2164 - val_acc: 0.5474\n",
      "Epoch 2/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 1.1342 - acc: 0.5786\n",
      "Epoch 00002: val_loss improved from 1.21644 to 1.03582, saving model to model/checkpoint/vis_imagenet_6_class_2D_CNN_custom_ch_64_DO_075_DO_2_conv_checkpoint/002-1.0358.hdf5\n",
      "4680/4680 [==============================] - 23s 5ms/sample - loss: 1.1337 - acc: 0.5788 - val_loss: 1.0358 - val_acc: 0.6231\n",
      "Epoch 3/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 1.0011 - acc: 0.6415\n",
      "Epoch 00003: val_loss improved from 1.03582 to 0.95966, saving model to model/checkpoint/vis_imagenet_6_class_2D_CNN_custom_ch_64_DO_075_DO_2_conv_checkpoint/003-0.9597.hdf5\n",
      "4680/4680 [==============================] - 23s 5ms/sample - loss: 1.0014 - acc: 0.6410 - val_loss: 0.9597 - val_acc: 0.6340\n",
      "Epoch 4/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.9109 - acc: 0.6845\n",
      "Epoch 00004: val_loss improved from 0.95966 to 0.92263, saving model to model/checkpoint/vis_imagenet_6_class_2D_CNN_custom_ch_64_DO_075_DO_2_conv_checkpoint/004-0.9226.hdf5\n",
      "4680/4680 [==============================] - 23s 5ms/sample - loss: 0.9108 - acc: 0.6846 - val_loss: 0.9226 - val_acc: 0.6635\n",
      "Epoch 5/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.8519 - acc: 0.6999\n",
      "Epoch 00005: val_loss improved from 0.92263 to 0.89468, saving model to model/checkpoint/vis_imagenet_6_class_2D_CNN_custom_ch_64_DO_075_DO_2_conv_checkpoint/005-0.8947.hdf5\n",
      "4680/4680 [==============================] - 23s 5ms/sample - loss: 0.8522 - acc: 0.7002 - val_loss: 0.8947 - val_acc: 0.6712\n",
      "Epoch 6/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.7919 - acc: 0.7217\n",
      "Epoch 00006: val_loss improved from 0.89468 to 0.86296, saving model to model/checkpoint/vis_imagenet_6_class_2D_CNN_custom_ch_64_DO_075_DO_2_conv_checkpoint/006-0.8630.hdf5\n",
      "4680/4680 [==============================] - 23s 5ms/sample - loss: 0.7913 - acc: 0.7220 - val_loss: 0.8630 - val_acc: 0.6994\n",
      "Epoch 7/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.7537 - acc: 0.7399\n",
      "Epoch 00007: val_loss improved from 0.86296 to 0.83528, saving model to model/checkpoint/vis_imagenet_6_class_2D_CNN_custom_ch_64_DO_075_DO_2_conv_checkpoint/007-0.8353.hdf5\n",
      "4680/4680 [==============================] - 23s 5ms/sample - loss: 0.7535 - acc: 0.7402 - val_loss: 0.8353 - val_acc: 0.7090\n",
      "Epoch 8/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.7127 - acc: 0.7598\n",
      "Epoch 00008: val_loss improved from 0.83528 to 0.82788, saving model to model/checkpoint/vis_imagenet_6_class_2D_CNN_custom_ch_64_DO_075_DO_2_conv_checkpoint/008-0.8279.hdf5\n",
      "4680/4680 [==============================] - 23s 5ms/sample - loss: 0.7120 - acc: 0.7603 - val_loss: 0.8279 - val_acc: 0.7000\n",
      "Epoch 9/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.6551 - acc: 0.7808\n",
      "Epoch 00009: val_loss improved from 0.82788 to 0.79972, saving model to model/checkpoint/vis_imagenet_6_class_2D_CNN_custom_ch_64_DO_075_DO_2_conv_checkpoint/009-0.7997.hdf5\n",
      "4680/4680 [==============================] - 23s 5ms/sample - loss: 0.6563 - acc: 0.7803 - val_loss: 0.7997 - val_acc: 0.7128\n",
      "Epoch 10/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.6400 - acc: 0.7804\n",
      "Epoch 00010: val_loss improved from 0.79972 to 0.79182, saving model to model/checkpoint/vis_imagenet_6_class_2D_CNN_custom_ch_64_DO_075_DO_2_conv_checkpoint/010-0.7918.hdf5\n",
      "4680/4680 [==============================] - 23s 5ms/sample - loss: 0.6396 - acc: 0.7806 - val_loss: 0.7918 - val_acc: 0.7327\n",
      "Epoch 11/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.5921 - acc: 0.7973\n",
      "Epoch 00011: val_loss improved from 0.79182 to 0.75907, saving model to model/checkpoint/vis_imagenet_6_class_2D_CNN_custom_ch_64_DO_075_DO_2_conv_checkpoint/011-0.7591.hdf5\n",
      "4680/4680 [==============================] - 23s 5ms/sample - loss: 0.5918 - acc: 0.7974 - val_loss: 0.7591 - val_acc: 0.7192\n",
      "Epoch 12/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.5646 - acc: 0.8093\n",
      "Epoch 00012: val_loss did not improve from 0.75907\n",
      "4680/4680 [==============================] - 23s 5ms/sample - loss: 0.5645 - acc: 0.8096 - val_loss: 0.7858 - val_acc: 0.7218\n",
      "Epoch 13/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.5273 - acc: 0.8232\n",
      "Epoch 00013: val_loss did not improve from 0.75907\n",
      "4680/4680 [==============================] - 23s 5ms/sample - loss: 0.5267 - acc: 0.8235 - val_loss: 0.7608 - val_acc: 0.7224\n",
      "Epoch 14/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.5084 - acc: 0.8337\n",
      "Epoch 00014: val_loss improved from 0.75907 to 0.74260, saving model to model/checkpoint/vis_imagenet_6_class_2D_CNN_custom_ch_64_DO_075_DO_2_conv_checkpoint/014-0.7426.hdf5\n",
      "4680/4680 [==============================] - 23s 5ms/sample - loss: 0.5081 - acc: 0.8338 - val_loss: 0.7426 - val_acc: 0.7314\n",
      "Epoch 15/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.4717 - acc: 0.8423\n",
      "Epoch 00015: val_loss did not improve from 0.74260\n",
      "4680/4680 [==============================] - 23s 5ms/sample - loss: 0.4742 - acc: 0.8417 - val_loss: 0.8123 - val_acc: 0.7038\n",
      "Epoch 16/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.4877 - acc: 0.8397\n",
      "Epoch 00016: val_loss improved from 0.74260 to 0.73640, saving model to model/checkpoint/vis_imagenet_6_class_2D_CNN_custom_ch_64_DO_075_DO_2_conv_checkpoint/016-0.7364.hdf5\n",
      "4680/4680 [==============================] - 23s 5ms/sample - loss: 0.4878 - acc: 0.8397 - val_loss: 0.7364 - val_acc: 0.7500\n",
      "Epoch 17/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.4427 - acc: 0.8572\n",
      "Epoch 00017: val_loss did not improve from 0.73640\n",
      "4680/4680 [==============================] - 23s 5ms/sample - loss: 0.4430 - acc: 0.8571 - val_loss: 0.7428 - val_acc: 0.7397\n",
      "Epoch 18/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.4104 - acc: 0.8675\n",
      "Epoch 00018: val_loss improved from 0.73640 to 0.72477, saving model to model/checkpoint/vis_imagenet_6_class_2D_CNN_custom_ch_64_DO_075_DO_2_conv_checkpoint/018-0.7248.hdf5\n",
      "4680/4680 [==============================] - 23s 5ms/sample - loss: 0.4106 - acc: 0.8675 - val_loss: 0.7248 - val_acc: 0.7545\n",
      "Epoch 19/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.3984 - acc: 0.8696\n",
      "Epoch 00019: val_loss did not improve from 0.72477\n",
      "4680/4680 [==============================] - 23s 5ms/sample - loss: 0.3983 - acc: 0.8697 - val_loss: 0.7257 - val_acc: 0.7423\n",
      "Epoch 20/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.3701 - acc: 0.8823\n",
      "Epoch 00020: val_loss did not improve from 0.72477\n",
      "4680/4680 [==============================] - 23s 5ms/sample - loss: 0.3703 - acc: 0.8821 - val_loss: 0.7562 - val_acc: 0.7487\n",
      "Epoch 21/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.3591 - acc: 0.8821\n",
      "Epoch 00021: val_loss improved from 0.72477 to 0.71359, saving model to model/checkpoint/vis_imagenet_6_class_2D_CNN_custom_ch_64_DO_075_DO_2_conv_checkpoint/021-0.7136.hdf5\n",
      "4680/4680 [==============================] - 23s 5ms/sample - loss: 0.3592 - acc: 0.8818 - val_loss: 0.7136 - val_acc: 0.7494\n",
      "Epoch 22/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.3364 - acc: 0.8913\n",
      "Epoch 00022: val_loss did not improve from 0.71359\n",
      "4680/4680 [==============================] - 23s 5ms/sample - loss: 0.3362 - acc: 0.8915 - val_loss: 0.7365 - val_acc: 0.7532\n",
      "Epoch 23/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.3262 - acc: 0.8940\n",
      "Epoch 00023: val_loss improved from 0.71359 to 0.71302, saving model to model/checkpoint/vis_imagenet_6_class_2D_CNN_custom_ch_64_DO_075_DO_2_conv_checkpoint/023-0.7130.hdf5\n",
      "4680/4680 [==============================] - 23s 5ms/sample - loss: 0.3259 - acc: 0.8940 - val_loss: 0.7130 - val_acc: 0.7474\n",
      "Epoch 24/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.3053 - acc: 0.9067\n",
      "Epoch 00024: val_loss did not improve from 0.71302\n",
      "4680/4680 [==============================] - 23s 5ms/sample - loss: 0.3051 - acc: 0.9068 - val_loss: 0.7285 - val_acc: 0.7564\n",
      "Epoch 25/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.2713 - acc: 0.9180\n",
      "Epoch 00025: val_loss did not improve from 0.71302\n",
      "4680/4680 [==============================] - 23s 5ms/sample - loss: 0.2720 - acc: 0.9177 - val_loss: 0.7872 - val_acc: 0.7327\n",
      "Epoch 26/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.2686 - acc: 0.9133\n",
      "Epoch 00026: val_loss did not improve from 0.71302\n",
      "4680/4680 [==============================] - 23s 5ms/sample - loss: 0.2685 - acc: 0.9132 - val_loss: 0.7248 - val_acc: 0.7487\n",
      "Epoch 27/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.2546 - acc: 0.9157\n",
      "Epoch 00027: val_loss did not improve from 0.71302\n",
      "4680/4680 [==============================] - 23s 5ms/sample - loss: 0.2543 - acc: 0.9158 - val_loss: 0.7617 - val_acc: 0.7577\n",
      "Epoch 28/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.2561 - acc: 0.9167\n",
      "Epoch 00028: val_loss did not improve from 0.71302\n",
      "4680/4680 [==============================] - 23s 5ms/sample - loss: 0.2572 - acc: 0.9167 - val_loss: 0.7455 - val_acc: 0.7596\n",
      "Epoch 29/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.2374 - acc: 0.9244\n",
      "Epoch 00029: val_loss did not improve from 0.71302\n",
      "4680/4680 [==============================] - 23s 5ms/sample - loss: 0.2370 - acc: 0.9246 - val_loss: 0.7375 - val_acc: 0.7513\n",
      "Epoch 30/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.2282 - acc: 0.9294\n",
      "Epoch 00030: val_loss did not improve from 0.71302\n",
      "4680/4680 [==============================] - 23s 5ms/sample - loss: 0.2280 - acc: 0.9295 - val_loss: 0.7923 - val_acc: 0.7308\n",
      "Epoch 31/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.2273 - acc: 0.9330\n",
      "Epoch 00031: val_loss did not improve from 0.71302\n",
      "4680/4680 [==============================] - 23s 5ms/sample - loss: 0.2274 - acc: 0.9329 - val_loss: 0.7448 - val_acc: 0.7532\n",
      "Epoch 32/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.2077 - acc: 0.9345\n",
      "Epoch 00032: val_loss did not improve from 0.71302\n",
      "4680/4680 [==============================] - 23s 5ms/sample - loss: 0.2080 - acc: 0.9344 - val_loss: 0.7605 - val_acc: 0.7500\n",
      "Epoch 33/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.1857 - acc: 0.9448\n",
      "Epoch 00033: val_loss did not improve from 0.71302\n",
      "4680/4680 [==============================] - 23s 5ms/sample - loss: 0.1857 - acc: 0.9449 - val_loss: 0.7844 - val_acc: 0.7526\n",
      "Epoch 34/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.1793 - acc: 0.9469\n",
      "Epoch 00034: val_loss did not improve from 0.71302\n",
      "4680/4680 [==============================] - 23s 5ms/sample - loss: 0.1791 - acc: 0.9470 - val_loss: 0.7606 - val_acc: 0.7583\n",
      "Epoch 35/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.1703 - acc: 0.9503\n",
      "Epoch 00035: val_loss did not improve from 0.71302\n",
      "4680/4680 [==============================] - 23s 5ms/sample - loss: 0.1706 - acc: 0.9500 - val_loss: 0.7811 - val_acc: 0.7545\n",
      "Epoch 36/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.1627 - acc: 0.9501\n",
      "Epoch 00036: val_loss did not improve from 0.71302\n",
      "4680/4680 [==============================] - 23s 5ms/sample - loss: 0.1632 - acc: 0.9500 - val_loss: 0.7753 - val_acc: 0.7622\n",
      "Epoch 37/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.1657 - acc: 0.9508\n",
      "Epoch 00037: val_loss did not improve from 0.71302\n",
      "4680/4680 [==============================] - 23s 5ms/sample - loss: 0.1654 - acc: 0.9509 - val_loss: 0.7822 - val_acc: 0.7577\n",
      "Epoch 38/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.1587 - acc: 0.9518\n",
      "Epoch 00038: val_loss did not improve from 0.71302\n",
      "4680/4680 [==============================] - 23s 5ms/sample - loss: 0.1589 - acc: 0.9517 - val_loss: 0.8283 - val_acc: 0.7551\n",
      "Epoch 39/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.1564 - acc: 0.9488\n",
      "Epoch 00039: val_loss did not improve from 0.71302\n",
      "4680/4680 [==============================] - 23s 5ms/sample - loss: 0.1564 - acc: 0.9489 - val_loss: 0.8308 - val_acc: 0.7365\n",
      "Epoch 40/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.1359 - acc: 0.9570\n",
      "Epoch 00040: val_loss did not improve from 0.71302\n",
      "4680/4680 [==============================] - 23s 5ms/sample - loss: 0.1357 - acc: 0.9571 - val_loss: 0.8173 - val_acc: 0.7538\n",
      "Epoch 41/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.1472 - acc: 0.9551\n",
      "Epoch 00041: val_loss did not improve from 0.71302\n",
      "4680/4680 [==============================] - 23s 5ms/sample - loss: 0.1472 - acc: 0.9551 - val_loss: 0.8658 - val_acc: 0.7397\n",
      "Epoch 42/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.1319 - acc: 0.9606\n",
      "Epoch 00042: val_loss did not improve from 0.71302\n",
      "4680/4680 [==============================] - 23s 5ms/sample - loss: 0.1319 - acc: 0.9605 - val_loss: 0.8328 - val_acc: 0.7603\n",
      "Epoch 43/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.1368 - acc: 0.9623\n",
      "Epoch 00043: val_loss did not improve from 0.71302\n",
      "4680/4680 [==============================] - 23s 5ms/sample - loss: 0.1367 - acc: 0.9624 - val_loss: 0.9665 - val_acc: 0.7353\n",
      "Epoch 44/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.1243 - acc: 0.9625\n",
      "Epoch 00044: val_loss did not improve from 0.71302\n",
      "4680/4680 [==============================] - 23s 5ms/sample - loss: 0.1241 - acc: 0.9626 - val_loss: 0.8987 - val_acc: 0.7436\n",
      "Epoch 45/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.1183 - acc: 0.9660\n",
      "Epoch 00045: val_loss did not improve from 0.71302\n",
      "4680/4680 [==============================] - 23s 5ms/sample - loss: 0.1185 - acc: 0.9658 - val_loss: 0.9701 - val_acc: 0.7263\n",
      "Epoch 46/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.1079 - acc: 0.9681\n",
      "Epoch 00046: val_loss did not improve from 0.71302\n",
      "4680/4680 [==============================] - 23s 5ms/sample - loss: 0.1077 - acc: 0.9682 - val_loss: 0.9276 - val_acc: 0.7487\n",
      "Epoch 47/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.1102 - acc: 0.9668\n",
      "Epoch 00047: val_loss did not improve from 0.71302\n",
      "4680/4680 [==============================] - 23s 5ms/sample - loss: 0.1101 - acc: 0.9669 - val_loss: 0.8703 - val_acc: 0.7558\n",
      "Epoch 48/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.0936 - acc: 0.9760\n",
      "Epoch 00048: val_loss did not improve from 0.71302\n",
      "4680/4680 [==============================] - 23s 5ms/sample - loss: 0.0936 - acc: 0.9761 - val_loss: 0.9224 - val_acc: 0.7365\n",
      "Epoch 49/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.1089 - acc: 0.9662\n",
      "Epoch 00049: val_loss did not improve from 0.71302\n",
      "4680/4680 [==============================] - 23s 5ms/sample - loss: 0.1087 - acc: 0.9662 - val_loss: 0.9314 - val_acc: 0.7500\n",
      "Epoch 50/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.0943 - acc: 0.9737\n",
      "Epoch 00050: val_loss did not improve from 0.71302\n",
      "4680/4680 [==============================] - 23s 5ms/sample - loss: 0.0946 - acc: 0.9735 - val_loss: 0.9173 - val_acc: 0.7532\n",
      "Epoch 51/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.1076 - acc: 0.9696\n",
      "Epoch 00051: val_loss did not improve from 0.71302\n",
      "4680/4680 [==============================] - 23s 5ms/sample - loss: 0.1077 - acc: 0.9694 - val_loss: 0.9145 - val_acc: 0.7487\n",
      "Epoch 52/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.0989 - acc: 0.9668\n",
      "Epoch 00052: val_loss did not improve from 0.71302\n",
      "4680/4680 [==============================] - 23s 5ms/sample - loss: 0.0987 - acc: 0.9669 - val_loss: 0.9121 - val_acc: 0.7558\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.0863 - acc: 0.9739\n",
      "Epoch 00053: val_loss did not improve from 0.71302\n",
      "4680/4680 [==============================] - 23s 5ms/sample - loss: 0.0862 - acc: 0.9739 - val_loss: 0.9473 - val_acc: 0.7532\n",
      "Epoch 54/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.0826 - acc: 0.9745\n",
      "Epoch 00054: val_loss did not improve from 0.71302\n",
      "4680/4680 [==============================] - 23s 5ms/sample - loss: 0.0826 - acc: 0.9746 - val_loss: 0.9959 - val_acc: 0.7404\n",
      "Epoch 55/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.0962 - acc: 0.9722\n",
      "Epoch 00055: val_loss did not improve from 0.71302\n",
      "4680/4680 [==============================] - 23s 5ms/sample - loss: 0.0961 - acc: 0.9722 - val_loss: 0.9301 - val_acc: 0.7532\n",
      "Epoch 56/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.0806 - acc: 0.9771\n",
      "Epoch 00056: val_loss did not improve from 0.71302\n",
      "4680/4680 [==============================] - 23s 5ms/sample - loss: 0.0807 - acc: 0.9769 - val_loss: 0.9189 - val_acc: 0.7667\n",
      "Epoch 57/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.0824 - acc: 0.9758\n",
      "Epoch 00057: val_loss did not improve from 0.71302\n",
      "4680/4680 [==============================] - 23s 5ms/sample - loss: 0.0824 - acc: 0.9759 - val_loss: 0.9215 - val_acc: 0.7532\n",
      "Epoch 58/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.0718 - acc: 0.9786\n",
      "Epoch 00058: val_loss did not improve from 0.71302\n",
      "4680/4680 [==============================] - 23s 5ms/sample - loss: 0.0717 - acc: 0.9786 - val_loss: 1.0002 - val_acc: 0.7526\n",
      "Epoch 59/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.0661 - acc: 0.9831\n",
      "Epoch 00059: val_loss did not improve from 0.71302\n",
      "4680/4680 [==============================] - 23s 5ms/sample - loss: 0.0660 - acc: 0.9831 - val_loss: 0.9595 - val_acc: 0.7506\n",
      "Epoch 60/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.0699 - acc: 0.9801\n",
      "Epoch 00060: val_loss did not improve from 0.71302\n",
      "4680/4680 [==============================] - 23s 5ms/sample - loss: 0.0699 - acc: 0.9801 - val_loss: 0.9668 - val_acc: 0.7558\n",
      "Epoch 61/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.0649 - acc: 0.9816\n",
      "Epoch 00061: val_loss did not improve from 0.71302\n",
      "4680/4680 [==============================] - 23s 5ms/sample - loss: 0.0648 - acc: 0.9816 - val_loss: 0.9697 - val_acc: 0.7615\n",
      "Epoch 62/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.0651 - acc: 0.9829\n",
      "Epoch 00062: val_loss did not improve from 0.71302\n",
      "4680/4680 [==============================] - 23s 5ms/sample - loss: 0.0651 - acc: 0.9829 - val_loss: 1.0264 - val_acc: 0.7449\n",
      "Epoch 63/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.0623 - acc: 0.9827\n",
      "Epoch 00063: val_loss did not improve from 0.71302\n",
      "4680/4680 [==============================] - 23s 5ms/sample - loss: 0.0623 - acc: 0.9827 - val_loss: 1.0304 - val_acc: 0.7538\n",
      "Epoch 64/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.0642 - acc: 0.9801\n",
      "Epoch 00064: val_loss did not improve from 0.71302\n",
      "4680/4680 [==============================] - 23s 5ms/sample - loss: 0.0644 - acc: 0.9799 - val_loss: 0.9652 - val_acc: 0.7590\n",
      "Epoch 65/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.0634 - acc: 0.9807\n",
      "Epoch 00065: val_loss did not improve from 0.71302\n",
      "4680/4680 [==============================] - 23s 5ms/sample - loss: 0.0635 - acc: 0.9808 - val_loss: 0.9713 - val_acc: 0.7622\n",
      "Epoch 66/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.0567 - acc: 0.9850\n",
      "Epoch 00066: val_loss did not improve from 0.71302\n",
      "4680/4680 [==============================] - 23s 5ms/sample - loss: 0.0567 - acc: 0.9850 - val_loss: 0.9907 - val_acc: 0.7487\n",
      "Epoch 67/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.0554 - acc: 0.9865\n",
      "Epoch 00067: val_loss did not improve from 0.71302\n",
      "4680/4680 [==============================] - 23s 5ms/sample - loss: 0.0554 - acc: 0.9865 - val_loss: 1.0458 - val_acc: 0.7519\n",
      "Epoch 68/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.0590 - acc: 0.9827\n",
      "Epoch 00068: val_loss did not improve from 0.71302\n",
      "4680/4680 [==============================] - 23s 5ms/sample - loss: 0.0590 - acc: 0.9827 - val_loss: 1.0025 - val_acc: 0.7590\n",
      "Epoch 69/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.0545 - acc: 0.9839\n",
      "Epoch 00069: val_loss did not improve from 0.71302\n",
      "4680/4680 [==============================] - 23s 5ms/sample - loss: 0.0549 - acc: 0.9838 - val_loss: 1.1007 - val_acc: 0.7359\n",
      "Epoch 70/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.0633 - acc: 0.9831\n",
      "Epoch 00070: val_loss did not improve from 0.71302\n",
      "4680/4680 [==============================] - 23s 5ms/sample - loss: 0.0632 - acc: 0.9831 - val_loss: 1.0644 - val_acc: 0.7494\n",
      "Epoch 71/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.0546 - acc: 0.9833\n",
      "Epoch 00071: val_loss did not improve from 0.71302\n",
      "4680/4680 [==============================] - 23s 5ms/sample - loss: 0.0545 - acc: 0.9833 - val_loss: 1.0443 - val_acc: 0.7474\n",
      "Epoch 72/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.0508 - acc: 0.9876\n",
      "Epoch 00072: val_loss did not improve from 0.71302\n",
      "4680/4680 [==============================] - 23s 5ms/sample - loss: 0.0509 - acc: 0.9874 - val_loss: 1.0275 - val_acc: 0.7583\n",
      "Epoch 73/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.0549 - acc: 0.9831\n",
      "Epoch 00073: val_loss did not improve from 0.71302\n",
      "4680/4680 [==============================] - 23s 5ms/sample - loss: 0.0548 - acc: 0.9831 - val_loss: 1.0149 - val_acc: 0.7583\n",
      "\n",
      "vis_imagenet_6_class_2D_CNN_custom_ch_64_DO_075_DO_2_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1560/1560 [==============================] - 4s 3ms/sample - loss: 0.7130 - acc: 0.7474\n",
      "Loss: 0.7130152032925532 Accuracy: 0.74743587\n",
      "\n",
      "Train on 4680 samples, validate on 1560 samples\n",
      "Epoch 1/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 1.6416 - acc: 0.3157\n",
      "Epoch 00001: val_loss improved from inf to 1.36706, saving model to model/checkpoint/vis_imagenet_6_class_2D_CNN_custom_ch_64_DO_075_DO_3_conv_checkpoint/001-1.3671.hdf5\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 1.6409 - acc: 0.3165 - val_loss: 1.3671 - val_acc: 0.4776\n",
      "Epoch 2/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 1.2872 - acc: 0.4944\n",
      "Epoch 00002: val_loss improved from 1.36706 to 1.16384, saving model to model/checkpoint/vis_imagenet_6_class_2D_CNN_custom_ch_64_DO_075_DO_3_conv_checkpoint/002-1.1638.hdf5\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 1.2873 - acc: 0.4938 - val_loss: 1.1638 - val_acc: 0.5442\n",
      "Epoch 3/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 1.1400 - acc: 0.5683\n",
      "Epoch 00003: val_loss improved from 1.16384 to 1.03026, saving model to model/checkpoint/vis_imagenet_6_class_2D_CNN_custom_ch_64_DO_075_DO_3_conv_checkpoint/003-1.0303.hdf5\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 1.1393 - acc: 0.5688 - val_loss: 1.0303 - val_acc: 0.6231\n",
      "Epoch 4/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 1.0500 - acc: 0.6177\n",
      "Epoch 00004: val_loss improved from 1.03026 to 0.94342, saving model to model/checkpoint/vis_imagenet_6_class_2D_CNN_custom_ch_64_DO_075_DO_3_conv_checkpoint/004-0.9434.hdf5\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 1.0495 - acc: 0.6179 - val_loss: 0.9434 - val_acc: 0.6526\n",
      "Epoch 5/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.9717 - acc: 0.6464\n",
      "Epoch 00005: val_loss improved from 0.94342 to 0.90709, saving model to model/checkpoint/vis_imagenet_6_class_2D_CNN_custom_ch_64_DO_075_DO_3_conv_checkpoint/005-0.9071.hdf5\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.9708 - acc: 0.6466 - val_loss: 0.9071 - val_acc: 0.6756\n",
      "Epoch 6/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.9084 - acc: 0.6757\n",
      "Epoch 00006: val_loss improved from 0.90709 to 0.88893, saving model to model/checkpoint/vis_imagenet_6_class_2D_CNN_custom_ch_64_DO_075_DO_3_conv_checkpoint/006-0.8889.hdf5\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.9095 - acc: 0.6756 - val_loss: 0.8889 - val_acc: 0.6814\n",
      "Epoch 7/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.8702 - acc: 0.6914\n",
      "Epoch 00007: val_loss improved from 0.88893 to 0.84962, saving model to model/checkpoint/vis_imagenet_6_class_2D_CNN_custom_ch_64_DO_075_DO_3_conv_checkpoint/007-0.8496.hdf5\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.8700 - acc: 0.6912 - val_loss: 0.8496 - val_acc: 0.6897\n",
      "Epoch 8/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.8328 - acc: 0.7048\n",
      "Epoch 00008: val_loss improved from 0.84962 to 0.84286, saving model to model/checkpoint/vis_imagenet_6_class_2D_CNN_custom_ch_64_DO_075_DO_3_conv_checkpoint/008-0.8429.hdf5\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.8327 - acc: 0.7047 - val_loss: 0.8429 - val_acc: 0.7000\n",
      "Epoch 9/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.8058 - acc: 0.7160\n",
      "Epoch 00009: val_loss improved from 0.84286 to 0.81581, saving model to model/checkpoint/vis_imagenet_6_class_2D_CNN_custom_ch_64_DO_075_DO_3_conv_checkpoint/009-0.8158.hdf5\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.8058 - acc: 0.7160 - val_loss: 0.8158 - val_acc: 0.7077\n",
      "Epoch 10/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.7755 - acc: 0.7241\n",
      "Epoch 00010: val_loss improved from 0.81581 to 0.77028, saving model to model/checkpoint/vis_imagenet_6_class_2D_CNN_custom_ch_64_DO_075_DO_3_conv_checkpoint/010-0.7703.hdf5\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.7773 - acc: 0.7235 - val_loss: 0.7703 - val_acc: 0.7308\n",
      "Epoch 11/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.7695 - acc: 0.7307\n",
      "Epoch 00011: val_loss did not improve from 0.77028\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.7693 - acc: 0.7310 - val_loss: 0.8111 - val_acc: 0.7083\n",
      "Epoch 12/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.7453 - acc: 0.7378\n",
      "Epoch 00012: val_loss did not improve from 0.77028\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.7446 - acc: 0.7380 - val_loss: 0.7927 - val_acc: 0.7128\n",
      "Epoch 13/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.7023 - acc: 0.7521\n",
      "Epoch 00013: val_loss improved from 0.77028 to 0.73407, saving model to model/checkpoint/vis_imagenet_6_class_2D_CNN_custom_ch_64_DO_075_DO_3_conv_checkpoint/013-0.7341.hdf5\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.7021 - acc: 0.7521 - val_loss: 0.7341 - val_acc: 0.7462\n",
      "Epoch 14/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.6777 - acc: 0.7633\n",
      "Epoch 00014: val_loss did not improve from 0.73407\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.6776 - acc: 0.7632 - val_loss: 0.7506 - val_acc: 0.7301\n",
      "Epoch 15/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.6529 - acc: 0.7680\n",
      "Epoch 00015: val_loss improved from 0.73407 to 0.71780, saving model to model/checkpoint/vis_imagenet_6_class_2D_CNN_custom_ch_64_DO_075_DO_3_conv_checkpoint/015-0.7178.hdf5\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.6539 - acc: 0.7675 - val_loss: 0.7178 - val_acc: 0.7462\n",
      "Epoch 16/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.6538 - acc: 0.7742\n",
      "Epoch 00016: val_loss improved from 0.71780 to 0.68711, saving model to model/checkpoint/vis_imagenet_6_class_2D_CNN_custom_ch_64_DO_075_DO_3_conv_checkpoint/016-0.6871.hdf5\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.6534 - acc: 0.7744 - val_loss: 0.6871 - val_acc: 0.7571\n",
      "Epoch 17/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.6072 - acc: 0.7853\n",
      "Epoch 00017: val_loss did not improve from 0.68711\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.6069 - acc: 0.7855 - val_loss: 0.7154 - val_acc: 0.7596\n",
      "Epoch 18/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.6178 - acc: 0.7877\n",
      "Epoch 00018: val_loss improved from 0.68711 to 0.66823, saving model to model/checkpoint/vis_imagenet_6_class_2D_CNN_custom_ch_64_DO_075_DO_3_conv_checkpoint/018-0.6682.hdf5\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.6198 - acc: 0.7872 - val_loss: 0.6682 - val_acc: 0.7603\n",
      "Epoch 19/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.5775 - acc: 0.7997\n",
      "Epoch 00019: val_loss improved from 0.66823 to 0.64802, saving model to model/checkpoint/vis_imagenet_6_class_2D_CNN_custom_ch_64_DO_075_DO_3_conv_checkpoint/019-0.6480.hdf5\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.5770 - acc: 0.7998 - val_loss: 0.6480 - val_acc: 0.7718\n",
      "Epoch 20/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.5510 - acc: 0.8108\n",
      "Epoch 00020: val_loss did not improve from 0.64802\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.5514 - acc: 0.8105 - val_loss: 0.6686 - val_acc: 0.7801\n",
      "Epoch 21/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.5457 - acc: 0.8116\n",
      "Epoch 00021: val_loss improved from 0.64802 to 0.63547, saving model to model/checkpoint/vis_imagenet_6_class_2D_CNN_custom_ch_64_DO_075_DO_3_conv_checkpoint/021-0.6355.hdf5\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.5477 - acc: 0.8107 - val_loss: 0.6355 - val_acc: 0.7814\n",
      "Epoch 22/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.5364 - acc: 0.8127\n",
      "Epoch 00022: val_loss did not improve from 0.63547\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.5362 - acc: 0.8128 - val_loss: 0.6383 - val_acc: 0.7744\n",
      "Epoch 23/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.5095 - acc: 0.8208\n",
      "Epoch 00023: val_loss improved from 0.63547 to 0.62476, saving model to model/checkpoint/vis_imagenet_6_class_2D_CNN_custom_ch_64_DO_075_DO_3_conv_checkpoint/023-0.6248.hdf5\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.5094 - acc: 0.8209 - val_loss: 0.6248 - val_acc: 0.7801\n",
      "Epoch 24/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.4938 - acc: 0.8303\n",
      "Epoch 00024: val_loss improved from 0.62476 to 0.61392, saving model to model/checkpoint/vis_imagenet_6_class_2D_CNN_custom_ch_64_DO_075_DO_3_conv_checkpoint/024-0.6139.hdf5\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.4938 - acc: 0.8299 - val_loss: 0.6139 - val_acc: 0.7853\n",
      "Epoch 25/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.4942 - acc: 0.8217\n",
      "Epoch 00025: val_loss improved from 0.61392 to 0.59089, saving model to model/checkpoint/vis_imagenet_6_class_2D_CNN_custom_ch_64_DO_075_DO_3_conv_checkpoint/025-0.5909.hdf5\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.4946 - acc: 0.8214 - val_loss: 0.5909 - val_acc: 0.7897\n",
      "Epoch 26/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.4660 - acc: 0.8356\n",
      "Epoch 00026: val_loss did not improve from 0.59089\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.4655 - acc: 0.8359 - val_loss: 0.5933 - val_acc: 0.7917\n",
      "Epoch 27/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.4464 - acc: 0.8482\n",
      "Epoch 00027: val_loss improved from 0.59089 to 0.58482, saving model to model/checkpoint/vis_imagenet_6_class_2D_CNN_custom_ch_64_DO_075_DO_3_conv_checkpoint/027-0.5848.hdf5\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.4461 - acc: 0.8483 - val_loss: 0.5848 - val_acc: 0.8038\n",
      "Epoch 28/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.4350 - acc: 0.8512\n",
      "Epoch 00028: val_loss improved from 0.58482 to 0.57809, saving model to model/checkpoint/vis_imagenet_6_class_2D_CNN_custom_ch_64_DO_075_DO_3_conv_checkpoint/028-0.5781.hdf5\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.4347 - acc: 0.8515 - val_loss: 0.5781 - val_acc: 0.7987\n",
      "Epoch 29/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.4241 - acc: 0.8523\n",
      "Epoch 00029: val_loss did not improve from 0.57809\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.4245 - acc: 0.8521 - val_loss: 0.5852 - val_acc: 0.7865\n",
      "Epoch 30/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.4174 - acc: 0.8553\n",
      "Epoch 00030: val_loss did not improve from 0.57809\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.4178 - acc: 0.8553 - val_loss: 0.5910 - val_acc: 0.8038\n",
      "Epoch 31/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.4107 - acc: 0.8577\n",
      "Epoch 00031: val_loss did not improve from 0.57809\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.4119 - acc: 0.8571 - val_loss: 0.6240 - val_acc: 0.7763\n",
      "Epoch 32/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.4250 - acc: 0.8545\n",
      "Epoch 00032: val_loss did not improve from 0.57809\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.4246 - acc: 0.8545 - val_loss: 0.5851 - val_acc: 0.7878\n",
      "Epoch 33/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.3836 - acc: 0.8686\n",
      "Epoch 00033: val_loss did not improve from 0.57809\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.3831 - acc: 0.8688 - val_loss: 0.5784 - val_acc: 0.7955\n",
      "Epoch 34/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.3677 - acc: 0.8709\n",
      "Epoch 00034: val_loss did not improve from 0.57809\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.3675 - acc: 0.8712 - val_loss: 0.5826 - val_acc: 0.8147\n",
      "Epoch 35/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.3790 - acc: 0.8696\n",
      "Epoch 00035: val_loss did not improve from 0.57809\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.3786 - acc: 0.8699 - val_loss: 0.6539 - val_acc: 0.7692\n",
      "Epoch 36/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.3719 - acc: 0.8701\n",
      "Epoch 00036: val_loss improved from 0.57809 to 0.56828, saving model to model/checkpoint/vis_imagenet_6_class_2D_CNN_custom_ch_64_DO_075_DO_3_conv_checkpoint/036-0.5683.hdf5\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.3714 - acc: 0.8703 - val_loss: 0.5683 - val_acc: 0.8045\n",
      "Epoch 37/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.3480 - acc: 0.8778\n",
      "Epoch 00037: val_loss improved from 0.56828 to 0.56524, saving model to model/checkpoint/vis_imagenet_6_class_2D_CNN_custom_ch_64_DO_075_DO_3_conv_checkpoint/037-0.5652.hdf5\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.3479 - acc: 0.8778 - val_loss: 0.5652 - val_acc: 0.8103\n",
      "Epoch 38/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.3409 - acc: 0.8771\n",
      "Epoch 00038: val_loss did not improve from 0.56524\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.3411 - acc: 0.8771 - val_loss: 0.6673 - val_acc: 0.7673\n",
      "Epoch 39/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.3492 - acc: 0.8784\n",
      "Epoch 00039: val_loss did not improve from 0.56524\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.3491 - acc: 0.8786 - val_loss: 0.5744 - val_acc: 0.8077\n",
      "Epoch 40/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.3255 - acc: 0.8842\n",
      "Epoch 00040: val_loss improved from 0.56524 to 0.54351, saving model to model/checkpoint/vis_imagenet_6_class_2D_CNN_custom_ch_64_DO_075_DO_3_conv_checkpoint/040-0.5435.hdf5\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.3253 - acc: 0.8844 - val_loss: 0.5435 - val_acc: 0.8147\n",
      "Epoch 41/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.3159 - acc: 0.8930\n",
      "Epoch 00041: val_loss improved from 0.54351 to 0.54258, saving model to model/checkpoint/vis_imagenet_6_class_2D_CNN_custom_ch_64_DO_075_DO_3_conv_checkpoint/041-0.5426.hdf5\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.3161 - acc: 0.8929 - val_loss: 0.5426 - val_acc: 0.8199\n",
      "Epoch 42/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.3040 - acc: 0.8913\n",
      "Epoch 00042: val_loss did not improve from 0.54258\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.3037 - acc: 0.8915 - val_loss: 0.5442 - val_acc: 0.8199\n",
      "Epoch 43/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.3030 - acc: 0.8898\n",
      "Epoch 00043: val_loss improved from 0.54258 to 0.53878, saving model to model/checkpoint/vis_imagenet_6_class_2D_CNN_custom_ch_64_DO_075_DO_3_conv_checkpoint/043-0.5388.hdf5\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.3031 - acc: 0.8897 - val_loss: 0.5388 - val_acc: 0.8141\n",
      "Epoch 44/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.2889 - acc: 0.9007\n",
      "Epoch 00044: val_loss did not improve from 0.53878\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.2887 - acc: 0.9006 - val_loss: 0.5537 - val_acc: 0.8167\n",
      "Epoch 45/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.2931 - acc: 0.8970\n",
      "Epoch 00045: val_loss did not improve from 0.53878\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.2930 - acc: 0.8972 - val_loss: 0.5431 - val_acc: 0.8173\n",
      "Epoch 46/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.2813 - acc: 0.9045\n",
      "Epoch 00046: val_loss did not improve from 0.53878\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.2811 - acc: 0.9047 - val_loss: 0.5568 - val_acc: 0.8212\n",
      "Epoch 47/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.2747 - acc: 0.9003\n",
      "Epoch 00047: val_loss did not improve from 0.53878\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.2749 - acc: 0.9002 - val_loss: 0.5567 - val_acc: 0.8167\n",
      "Epoch 48/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.2623 - acc: 0.9077\n",
      "Epoch 00048: val_loss did not improve from 0.53878\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.2622 - acc: 0.9079 - val_loss: 0.5512 - val_acc: 0.8051\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.2538 - acc: 0.9137\n",
      "Epoch 00049: val_loss did not improve from 0.53878\n",
      "4680/4680 [==============================] - 23s 5ms/sample - loss: 0.2537 - acc: 0.9139 - val_loss: 0.5681 - val_acc: 0.8218\n",
      "Epoch 50/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.2477 - acc: 0.9146\n",
      "Epoch 00050: val_loss did not improve from 0.53878\n",
      "4680/4680 [==============================] - 23s 5ms/sample - loss: 0.2473 - acc: 0.9147 - val_loss: 0.5550 - val_acc: 0.8212\n",
      "Epoch 51/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.2459 - acc: 0.9116\n",
      "Epoch 00051: val_loss did not improve from 0.53878\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.2471 - acc: 0.9113 - val_loss: 0.5952 - val_acc: 0.7981\n",
      "Epoch 52/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.2721 - acc: 0.9050\n",
      "Epoch 00052: val_loss improved from 0.53878 to 0.53628, saving model to model/checkpoint/vis_imagenet_6_class_2D_CNN_custom_ch_64_DO_075_DO_3_conv_checkpoint/052-0.5363.hdf5\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.2723 - acc: 0.9049 - val_loss: 0.5363 - val_acc: 0.8115\n",
      "Epoch 53/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.2383 - acc: 0.9204\n",
      "Epoch 00053: val_loss did not improve from 0.53628\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.2381 - acc: 0.9205 - val_loss: 0.5452 - val_acc: 0.8205\n",
      "Epoch 54/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.2356 - acc: 0.9227\n",
      "Epoch 00054: val_loss did not improve from 0.53628\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.2356 - acc: 0.9226 - val_loss: 0.5452 - val_acc: 0.8212\n",
      "Epoch 55/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.2199 - acc: 0.9227\n",
      "Epoch 00055: val_loss did not improve from 0.53628\n",
      "4680/4680 [==============================] - 23s 5ms/sample - loss: 0.2195 - acc: 0.9229 - val_loss: 0.5473 - val_acc: 0.8256\n",
      "Epoch 56/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.2174 - acc: 0.9197\n",
      "Epoch 00056: val_loss did not improve from 0.53628\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.2174 - acc: 0.9197 - val_loss: 0.6116 - val_acc: 0.8103\n",
      "Epoch 57/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.2120 - acc: 0.9251\n",
      "Epoch 00057: val_loss did not improve from 0.53628\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.2119 - acc: 0.9250 - val_loss: 0.5543 - val_acc: 0.8263\n",
      "Epoch 58/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.2179 - acc: 0.9251\n",
      "Epoch 00058: val_loss did not improve from 0.53628\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.2179 - acc: 0.9250 - val_loss: 0.5429 - val_acc: 0.8205\n",
      "Epoch 59/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.1995 - acc: 0.9287\n",
      "Epoch 00059: val_loss did not improve from 0.53628\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.1993 - acc: 0.9288 - val_loss: 0.5454 - val_acc: 0.8256\n",
      "Epoch 60/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.1925 - acc: 0.9330\n",
      "Epoch 00060: val_loss improved from 0.53628 to 0.53046, saving model to model/checkpoint/vis_imagenet_6_class_2D_CNN_custom_ch_64_DO_075_DO_3_conv_checkpoint/060-0.5305.hdf5\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.1925 - acc: 0.9329 - val_loss: 0.5305 - val_acc: 0.8276\n",
      "Epoch 61/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.1824 - acc: 0.9369\n",
      "Epoch 00061: val_loss did not improve from 0.53046\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.1822 - acc: 0.9370 - val_loss: 0.5548 - val_acc: 0.8212\n",
      "Epoch 62/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.1941 - acc: 0.9315\n",
      "Epoch 00062: val_loss did not improve from 0.53046\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.1941 - acc: 0.9314 - val_loss: 0.6003 - val_acc: 0.8141\n",
      "Epoch 63/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.1815 - acc: 0.9394\n",
      "Epoch 00063: val_loss did not improve from 0.53046\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.1812 - acc: 0.9395 - val_loss: 0.5922 - val_acc: 0.8224\n",
      "Epoch 64/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.1807 - acc: 0.9371\n",
      "Epoch 00064: val_loss did not improve from 0.53046\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.1809 - acc: 0.9372 - val_loss: 0.5579 - val_acc: 0.8244\n",
      "Epoch 65/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.1831 - acc: 0.9377\n",
      "Epoch 00065: val_loss did not improve from 0.53046\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.1829 - acc: 0.9378 - val_loss: 0.5686 - val_acc: 0.8237\n",
      "Epoch 66/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.1677 - acc: 0.9435\n",
      "Epoch 00066: val_loss did not improve from 0.53046\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.1674 - acc: 0.9436 - val_loss: 0.6016 - val_acc: 0.8128\n",
      "Epoch 67/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.1680 - acc: 0.9435\n",
      "Epoch 00067: val_loss did not improve from 0.53046\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.1679 - acc: 0.9436 - val_loss: 0.5732 - val_acc: 0.8269\n",
      "Epoch 68/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.1528 - acc: 0.9484\n",
      "Epoch 00068: val_loss did not improve from 0.53046\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.1526 - acc: 0.9485 - val_loss: 0.5506 - val_acc: 0.8340\n",
      "Epoch 69/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.1541 - acc: 0.9463\n",
      "Epoch 00069: val_loss did not improve from 0.53046\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.1539 - acc: 0.9464 - val_loss: 0.5692 - val_acc: 0.8231\n",
      "Epoch 70/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.1436 - acc: 0.9491\n",
      "Epoch 00070: val_loss did not improve from 0.53046\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.1433 - acc: 0.9491 - val_loss: 0.5917 - val_acc: 0.8276\n",
      "Epoch 71/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.1580 - acc: 0.9465\n",
      "Epoch 00071: val_loss did not improve from 0.53046\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.1578 - acc: 0.9466 - val_loss: 0.5687 - val_acc: 0.8263\n",
      "Epoch 72/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.1403 - acc: 0.9508\n",
      "Epoch 00072: val_loss did not improve from 0.53046\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.1404 - acc: 0.9506 - val_loss: 0.6080 - val_acc: 0.8205\n",
      "Epoch 73/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.1524 - acc: 0.9456\n",
      "Epoch 00073: val_loss did not improve from 0.53046\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.1523 - acc: 0.9457 - val_loss: 0.5992 - val_acc: 0.8212\n",
      "Epoch 74/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.1535 - acc: 0.9493\n",
      "Epoch 00074: val_loss did not improve from 0.53046\n",
      "4680/4680 [==============================] - 23s 5ms/sample - loss: 0.1535 - acc: 0.9494 - val_loss: 0.6452 - val_acc: 0.8167\n",
      "Epoch 75/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.1535 - acc: 0.9493\n",
      "Epoch 00075: val_loss did not improve from 0.53046\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.1536 - acc: 0.9491 - val_loss: 0.5853 - val_acc: 0.8244\n",
      "Epoch 76/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.1442 - acc: 0.9521\n",
      "Epoch 00076: val_loss did not improve from 0.53046\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.1440 - acc: 0.9521 - val_loss: 0.6097 - val_acc: 0.8218\n",
      "Epoch 77/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.1263 - acc: 0.9578\n",
      "Epoch 00077: val_loss did not improve from 0.53046\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.1266 - acc: 0.9575 - val_loss: 0.5896 - val_acc: 0.8276\n",
      "Epoch 78/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.1311 - acc: 0.9574\n",
      "Epoch 00078: val_loss did not improve from 0.53046\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.1310 - acc: 0.9575 - val_loss: 0.6046 - val_acc: 0.8250\n",
      "Epoch 79/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.1201 - acc: 0.9563\n",
      "Epoch 00079: val_loss did not improve from 0.53046\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.1205 - acc: 0.9560 - val_loss: 0.6086 - val_acc: 0.8212\n",
      "Epoch 80/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.1189 - acc: 0.9636\n",
      "Epoch 00080: val_loss did not improve from 0.53046\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.1189 - acc: 0.9637 - val_loss: 0.6145 - val_acc: 0.8212\n",
      "Epoch 81/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.1219 - acc: 0.9576\n",
      "Epoch 00081: val_loss did not improve from 0.53046\n",
      "4680/4680 [==============================] - 23s 5ms/sample - loss: 0.1217 - acc: 0.9577 - val_loss: 0.6330 - val_acc: 0.8179\n",
      "Epoch 82/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.1146 - acc: 0.9600\n",
      "Epoch 00082: val_loss did not improve from 0.53046\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.1149 - acc: 0.9598 - val_loss: 0.6263 - val_acc: 0.8160\n",
      "Epoch 83/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.1308 - acc: 0.9540\n",
      "Epoch 00083: val_loss did not improve from 0.53046\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.1306 - acc: 0.9541 - val_loss: 0.6276 - val_acc: 0.8244\n",
      "Epoch 84/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.1199 - acc: 0.9621\n",
      "Epoch 00084: val_loss did not improve from 0.53046\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.1197 - acc: 0.9622 - val_loss: 0.6223 - val_acc: 0.8212\n",
      "Epoch 85/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.1224 - acc: 0.9578\n",
      "Epoch 00085: val_loss did not improve from 0.53046\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.1224 - acc: 0.9577 - val_loss: 0.6298 - val_acc: 0.8237\n",
      "Epoch 86/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.1052 - acc: 0.9628\n",
      "Epoch 00086: val_loss did not improve from 0.53046\n",
      "4680/4680 [==============================] - 23s 5ms/sample - loss: 0.1051 - acc: 0.9628 - val_loss: 0.5835 - val_acc: 0.8353\n",
      "Epoch 87/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.0956 - acc: 0.9628\n",
      "Epoch 00087: val_loss did not improve from 0.53046\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.0963 - acc: 0.9626 - val_loss: 0.6075 - val_acc: 0.8276\n",
      "Epoch 88/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.1207 - acc: 0.9583\n",
      "Epoch 00088: val_loss did not improve from 0.53046\n",
      "4680/4680 [==============================] - 23s 5ms/sample - loss: 0.1206 - acc: 0.9583 - val_loss: 0.6346 - val_acc: 0.8064\n",
      "Epoch 89/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.1129 - acc: 0.9583\n",
      "Epoch 00089: val_loss did not improve from 0.53046\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.1131 - acc: 0.9581 - val_loss: 0.6380 - val_acc: 0.8301\n",
      "Epoch 90/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.1193 - acc: 0.9589\n",
      "Epoch 00090: val_loss did not improve from 0.53046\n",
      "4680/4680 [==============================] - 23s 5ms/sample - loss: 0.1191 - acc: 0.9590 - val_loss: 0.6179 - val_acc: 0.8282\n",
      "Epoch 91/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.1052 - acc: 0.9617\n",
      "Epoch 00091: val_loss did not improve from 0.53046\n",
      "4680/4680 [==============================] - 23s 5ms/sample - loss: 0.1052 - acc: 0.9618 - val_loss: 0.6291 - val_acc: 0.8353\n",
      "Epoch 92/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.0952 - acc: 0.9698\n",
      "Epoch 00092: val_loss did not improve from 0.53046\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.0951 - acc: 0.9699 - val_loss: 0.6022 - val_acc: 0.8359\n",
      "Epoch 93/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.0920 - acc: 0.9702\n",
      "Epoch 00093: val_loss did not improve from 0.53046\n",
      "4680/4680 [==============================] - 23s 5ms/sample - loss: 0.0919 - acc: 0.9703 - val_loss: 0.6522 - val_acc: 0.8135\n",
      "Epoch 94/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.0872 - acc: 0.9720\n",
      "Epoch 00094: val_loss did not improve from 0.53046\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.0870 - acc: 0.9720 - val_loss: 0.6696 - val_acc: 0.8218\n",
      "Epoch 95/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.0994 - acc: 0.9681\n",
      "Epoch 00095: val_loss did not improve from 0.53046\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.0993 - acc: 0.9682 - val_loss: 0.5997 - val_acc: 0.8372\n",
      "Epoch 96/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.0857 - acc: 0.9726\n",
      "Epoch 00096: val_loss did not improve from 0.53046\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.0857 - acc: 0.9726 - val_loss: 0.6171 - val_acc: 0.8340\n",
      "Epoch 97/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.0833 - acc: 0.9732\n",
      "Epoch 00097: val_loss did not improve from 0.53046\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.0831 - acc: 0.9733 - val_loss: 0.6846 - val_acc: 0.8250\n",
      "Epoch 98/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.0953 - acc: 0.9649\n",
      "Epoch 00098: val_loss did not improve from 0.53046\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.0953 - acc: 0.9647 - val_loss: 0.6296 - val_acc: 0.8256\n",
      "Epoch 99/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.0945 - acc: 0.9673\n",
      "Epoch 00099: val_loss did not improve from 0.53046\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.0944 - acc: 0.9673 - val_loss: 0.6473 - val_acc: 0.8256\n",
      "Epoch 100/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.0876 - acc: 0.9717\n",
      "Epoch 00100: val_loss did not improve from 0.53046\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.0880 - acc: 0.9716 - val_loss: 0.6016 - val_acc: 0.8295\n",
      "Epoch 101/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.0778 - acc: 0.9745\n",
      "Epoch 00101: val_loss did not improve from 0.53046\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.0778 - acc: 0.9746 - val_loss: 0.6215 - val_acc: 0.8333\n",
      "Epoch 102/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.0765 - acc: 0.9737\n",
      "Epoch 00102: val_loss did not improve from 0.53046\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.0764 - acc: 0.9737 - val_loss: 0.6457 - val_acc: 0.8333\n",
      "Epoch 103/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.0809 - acc: 0.9750\n",
      "Epoch 00103: val_loss did not improve from 0.53046\n",
      "4680/4680 [==============================] - 23s 5ms/sample - loss: 0.0811 - acc: 0.9748 - val_loss: 0.6706 - val_acc: 0.8192\n",
      "Epoch 104/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.0804 - acc: 0.9728\n",
      "Epoch 00104: val_loss did not improve from 0.53046\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.0804 - acc: 0.9729 - val_loss: 0.6780 - val_acc: 0.8276\n",
      "Epoch 105/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.0877 - acc: 0.9711\n",
      "Epoch 00105: val_loss did not improve from 0.53046\n",
      "4680/4680 [==============================] - 23s 5ms/sample - loss: 0.0877 - acc: 0.9712 - val_loss: 0.6394 - val_acc: 0.8263\n",
      "Epoch 106/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.0785 - acc: 0.9739\n",
      "Epoch 00106: val_loss did not improve from 0.53046\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.0785 - acc: 0.9739 - val_loss: 0.6128 - val_acc: 0.8378\n",
      "Epoch 107/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.0722 - acc: 0.9741\n",
      "Epoch 00107: val_loss did not improve from 0.53046\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.0723 - acc: 0.9741 - val_loss: 0.6274 - val_acc: 0.8276\n",
      "Epoch 108/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.0806 - acc: 0.9741\n",
      "Epoch 00108: val_loss did not improve from 0.53046\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.0809 - acc: 0.9739 - val_loss: 0.6473 - val_acc: 0.8301\n",
      "Epoch 109/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.0707 - acc: 0.9762\n",
      "Epoch 00109: val_loss did not improve from 0.53046\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.0706 - acc: 0.9763 - val_loss: 0.6335 - val_acc: 0.8314\n",
      "Epoch 110/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.0701 - acc: 0.9788\n",
      "Epoch 00110: val_loss did not improve from 0.53046\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.0700 - acc: 0.9788 - val_loss: 0.6511 - val_acc: 0.8288\n",
      "\n",
      "vis_imagenet_6_class_2D_CNN_custom_ch_64_DO_075_DO_3_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1560/1560 [==============================] - 4s 3ms/sample - loss: 0.5305 - acc: 0.8276\n",
      "Loss: 0.5304544613911555 Accuracy: 0.8275641\n",
      "\n",
      "Train on 4680 samples, validate on 1560 samples\n",
      "Epoch 1/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 1.7423 - acc: 0.2468\n",
      "Epoch 00001: val_loss improved from inf to 1.52437, saving model to model/checkpoint/vis_imagenet_6_class_2D_CNN_custom_ch_64_DO_075_DO_4_conv_checkpoint/001-1.5244.hdf5\n",
      "4680/4680 [==============================] - 25s 5ms/sample - loss: 1.7419 - acc: 0.2472 - val_loss: 1.5244 - val_acc: 0.3955\n",
      "Epoch 2/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 1.4600 - acc: 0.4028\n",
      "Epoch 00002: val_loss improved from 1.52437 to 1.33028, saving model to model/checkpoint/vis_imagenet_6_class_2D_CNN_custom_ch_64_DO_075_DO_4_conv_checkpoint/002-1.3303.hdf5\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 1.4610 - acc: 0.4026 - val_loss: 1.3303 - val_acc: 0.4558\n",
      "Epoch 3/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 1.3061 - acc: 0.4754\n",
      "Epoch 00003: val_loss improved from 1.33028 to 1.13157, saving model to model/checkpoint/vis_imagenet_6_class_2D_CNN_custom_ch_64_DO_075_DO_4_conv_checkpoint/003-1.1316.hdf5\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 1.3058 - acc: 0.4756 - val_loss: 1.1316 - val_acc: 0.5654\n",
      "Epoch 4/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 1.1892 - acc: 0.5360\n",
      "Epoch 00004: val_loss improved from 1.13157 to 1.06530, saving model to model/checkpoint/vis_imagenet_6_class_2D_CNN_custom_ch_64_DO_075_DO_4_conv_checkpoint/004-1.0653.hdf5\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 1.1894 - acc: 0.5363 - val_loss: 1.0653 - val_acc: 0.5987\n",
      "Epoch 5/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 1.1085 - acc: 0.5781\n",
      "Epoch 00005: val_loss improved from 1.06530 to 0.97825, saving model to model/checkpoint/vis_imagenet_6_class_2D_CNN_custom_ch_64_DO_075_DO_4_conv_checkpoint/005-0.9783.hdf5\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 1.1080 - acc: 0.5784 - val_loss: 0.9783 - val_acc: 0.6378\n",
      "Epoch 6/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 1.0569 - acc: 0.6124\n",
      "Epoch 00006: val_loss improved from 0.97825 to 0.90827, saving model to model/checkpoint/vis_imagenet_6_class_2D_CNN_custom_ch_64_DO_075_DO_4_conv_checkpoint/006-0.9083.hdf5\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 1.0563 - acc: 0.6126 - val_loss: 0.9083 - val_acc: 0.6705\n",
      "Epoch 7/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.9824 - acc: 0.6378\n",
      "Epoch 00007: val_loss improved from 0.90827 to 0.88828, saving model to model/checkpoint/vis_imagenet_6_class_2D_CNN_custom_ch_64_DO_075_DO_4_conv_checkpoint/007-0.8883.hdf5\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.9825 - acc: 0.6378 - val_loss: 0.8883 - val_acc: 0.6750\n",
      "Epoch 8/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.9354 - acc: 0.6601\n",
      "Epoch 00008: val_loss did not improve from 0.88828\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.9344 - acc: 0.6605 - val_loss: 0.8919 - val_acc: 0.6756\n",
      "Epoch 9/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.9172 - acc: 0.6687\n",
      "Epoch 00009: val_loss improved from 0.88828 to 0.82109, saving model to model/checkpoint/vis_imagenet_6_class_2D_CNN_custom_ch_64_DO_075_DO_4_conv_checkpoint/009-0.8211.hdf5\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.9170 - acc: 0.6688 - val_loss: 0.8211 - val_acc: 0.7064\n",
      "Epoch 10/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.8515 - acc: 0.6920\n",
      "Epoch 00010: val_loss did not improve from 0.82109\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.8515 - acc: 0.6921 - val_loss: 0.8540 - val_acc: 0.6917\n",
      "Epoch 11/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.8221 - acc: 0.7087\n",
      "Epoch 00011: val_loss improved from 0.82109 to 0.72960, saving model to model/checkpoint/vis_imagenet_6_class_2D_CNN_custom_ch_64_DO_075_DO_4_conv_checkpoint/011-0.7296.hdf5\n",
      "4680/4680 [==============================] - 25s 5ms/sample - loss: 0.8227 - acc: 0.7083 - val_loss: 0.7296 - val_acc: 0.7404\n",
      "Epoch 12/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.7758 - acc: 0.7232\n",
      "Epoch 00012: val_loss improved from 0.72960 to 0.71888, saving model to model/checkpoint/vis_imagenet_6_class_2D_CNN_custom_ch_64_DO_075_DO_4_conv_checkpoint/012-0.7189.hdf5\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.7762 - acc: 0.7233 - val_loss: 0.7189 - val_acc: 0.7449\n",
      "Epoch 13/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.7391 - acc: 0.7410\n",
      "Epoch 00013: val_loss improved from 0.71888 to 0.69693, saving model to model/checkpoint/vis_imagenet_6_class_2D_CNN_custom_ch_64_DO_075_DO_4_conv_checkpoint/013-0.6969.hdf5\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.7401 - acc: 0.7408 - val_loss: 0.6969 - val_acc: 0.7545\n",
      "Epoch 14/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.7070 - acc: 0.7521\n",
      "Epoch 00014: val_loss improved from 0.69693 to 0.69105, saving model to model/checkpoint/vis_imagenet_6_class_2D_CNN_custom_ch_64_DO_075_DO_4_conv_checkpoint/014-0.6910.hdf5\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.7070 - acc: 0.7519 - val_loss: 0.6910 - val_acc: 0.7506\n",
      "Epoch 15/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.6671 - acc: 0.7639\n",
      "Epoch 00015: val_loss improved from 0.69105 to 0.63791, saving model to model/checkpoint/vis_imagenet_6_class_2D_CNN_custom_ch_64_DO_075_DO_4_conv_checkpoint/015-0.6379.hdf5\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.6681 - acc: 0.7632 - val_loss: 0.6379 - val_acc: 0.7731\n",
      "Epoch 16/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.6638 - acc: 0.7671\n",
      "Epoch 00016: val_loss improved from 0.63791 to 0.63354, saving model to model/checkpoint/vis_imagenet_6_class_2D_CNN_custom_ch_64_DO_075_DO_4_conv_checkpoint/016-0.6335.hdf5\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.6642 - acc: 0.7669 - val_loss: 0.6335 - val_acc: 0.7641\n",
      "Epoch 17/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.6359 - acc: 0.7727\n",
      "Epoch 00017: val_loss improved from 0.63354 to 0.62301, saving model to model/checkpoint/vis_imagenet_6_class_2D_CNN_custom_ch_64_DO_075_DO_4_conv_checkpoint/017-0.6230.hdf5\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.6361 - acc: 0.7726 - val_loss: 0.6230 - val_acc: 0.7776\n",
      "Epoch 18/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.6327 - acc: 0.7763\n",
      "Epoch 00018: val_loss did not improve from 0.62301\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.6329 - acc: 0.7761 - val_loss: 0.6325 - val_acc: 0.7750\n",
      "Epoch 19/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.5991 - acc: 0.7868\n",
      "Epoch 00019: val_loss improved from 0.62301 to 0.58882, saving model to model/checkpoint/vis_imagenet_6_class_2D_CNN_custom_ch_64_DO_075_DO_4_conv_checkpoint/019-0.5888.hdf5\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.5989 - acc: 0.7868 - val_loss: 0.5888 - val_acc: 0.7782\n",
      "Epoch 20/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.5685 - acc: 0.8033\n",
      "Epoch 00020: val_loss improved from 0.58882 to 0.58611, saving model to model/checkpoint/vis_imagenet_6_class_2D_CNN_custom_ch_64_DO_075_DO_4_conv_checkpoint/020-0.5861.hdf5\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.5680 - acc: 0.8036 - val_loss: 0.5861 - val_acc: 0.7821\n",
      "Epoch 21/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.5381 - acc: 0.8076\n",
      "Epoch 00021: val_loss improved from 0.58611 to 0.56888, saving model to model/checkpoint/vis_imagenet_6_class_2D_CNN_custom_ch_64_DO_075_DO_4_conv_checkpoint/021-0.5689.hdf5\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.5381 - acc: 0.8075 - val_loss: 0.5689 - val_acc: 0.7788\n",
      "Epoch 22/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.5358 - acc: 0.8091\n",
      "Epoch 00022: val_loss improved from 0.56888 to 0.55441, saving model to model/checkpoint/vis_imagenet_6_class_2D_CNN_custom_ch_64_DO_075_DO_4_conv_checkpoint/022-0.5544.hdf5\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.5357 - acc: 0.8092 - val_loss: 0.5544 - val_acc: 0.8032\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.5105 - acc: 0.8164\n",
      "Epoch 00023: val_loss did not improve from 0.55441\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.5110 - acc: 0.8160 - val_loss: 0.5699 - val_acc: 0.7885\n",
      "Epoch 24/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.4985 - acc: 0.8273\n",
      "Epoch 00024: val_loss improved from 0.55441 to 0.55125, saving model to model/checkpoint/vis_imagenet_6_class_2D_CNN_custom_ch_64_DO_075_DO_4_conv_checkpoint/024-0.5512.hdf5\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.4979 - acc: 0.8276 - val_loss: 0.5512 - val_acc: 0.8083\n",
      "Epoch 25/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.4953 - acc: 0.8208\n",
      "Epoch 00025: val_loss did not improve from 0.55125\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.4971 - acc: 0.8201 - val_loss: 0.5647 - val_acc: 0.7968\n",
      "Epoch 26/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.4816 - acc: 0.8330\n",
      "Epoch 00026: val_loss did not improve from 0.55125\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.4818 - acc: 0.8329 - val_loss: 0.5607 - val_acc: 0.8090\n",
      "Epoch 27/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.4738 - acc: 0.8266\n",
      "Epoch 00027: val_loss improved from 0.55125 to 0.51784, saving model to model/checkpoint/vis_imagenet_6_class_2D_CNN_custom_ch_64_DO_075_DO_4_conv_checkpoint/027-0.5178.hdf5\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.4736 - acc: 0.8267 - val_loss: 0.5178 - val_acc: 0.8083\n",
      "Epoch 28/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.4518 - acc: 0.8371\n",
      "Epoch 00028: val_loss improved from 0.51784 to 0.50927, saving model to model/checkpoint/vis_imagenet_6_class_2D_CNN_custom_ch_64_DO_075_DO_4_conv_checkpoint/028-0.5093.hdf5\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.4522 - acc: 0.8368 - val_loss: 0.5093 - val_acc: 0.8109\n",
      "Epoch 29/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.4544 - acc: 0.8367\n",
      "Epoch 00029: val_loss did not improve from 0.50927\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.4548 - acc: 0.8365 - val_loss: 0.5165 - val_acc: 0.8167\n",
      "Epoch 30/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.4314 - acc: 0.8461\n",
      "Epoch 00030: val_loss did not improve from 0.50927\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.4308 - acc: 0.8464 - val_loss: 0.5183 - val_acc: 0.8026\n",
      "Epoch 31/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.4106 - acc: 0.8504\n",
      "Epoch 00031: val_loss improved from 0.50927 to 0.50149, saving model to model/checkpoint/vis_imagenet_6_class_2D_CNN_custom_ch_64_DO_075_DO_4_conv_checkpoint/031-0.5015.hdf5\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.4103 - acc: 0.8506 - val_loss: 0.5015 - val_acc: 0.8244\n",
      "Epoch 32/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.3910 - acc: 0.8609\n",
      "Epoch 00032: val_loss did not improve from 0.50149\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.3909 - acc: 0.8609 - val_loss: 0.5091 - val_acc: 0.8231\n",
      "Epoch 33/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.4043 - acc: 0.8534\n",
      "Epoch 00033: val_loss did not improve from 0.50149\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.4044 - acc: 0.8534 - val_loss: 0.5213 - val_acc: 0.8096\n",
      "Epoch 34/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.4094 - acc: 0.8562\n",
      "Epoch 00034: val_loss improved from 0.50149 to 0.49580, saving model to model/checkpoint/vis_imagenet_6_class_2D_CNN_custom_ch_64_DO_075_DO_4_conv_checkpoint/034-0.4958.hdf5\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.4092 - acc: 0.8562 - val_loss: 0.4958 - val_acc: 0.8276\n",
      "Epoch 35/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.3583 - acc: 0.8714\n",
      "Epoch 00035: val_loss improved from 0.49580 to 0.49440, saving model to model/checkpoint/vis_imagenet_6_class_2D_CNN_custom_ch_64_DO_075_DO_4_conv_checkpoint/035-0.4944.hdf5\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.3579 - acc: 0.8716 - val_loss: 0.4944 - val_acc: 0.8250\n",
      "Epoch 36/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.3655 - acc: 0.8711\n",
      "Epoch 00036: val_loss improved from 0.49440 to 0.47691, saving model to model/checkpoint/vis_imagenet_6_class_2D_CNN_custom_ch_64_DO_075_DO_4_conv_checkpoint/036-0.4769.hdf5\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.3654 - acc: 0.8709 - val_loss: 0.4769 - val_acc: 0.8321\n",
      "Epoch 37/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.3619 - acc: 0.8724\n",
      "Epoch 00037: val_loss did not improve from 0.47691\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.3618 - acc: 0.8724 - val_loss: 0.4845 - val_acc: 0.8250\n",
      "Epoch 38/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.3383 - acc: 0.8797\n",
      "Epoch 00038: val_loss improved from 0.47691 to 0.46394, saving model to model/checkpoint/vis_imagenet_6_class_2D_CNN_custom_ch_64_DO_075_DO_4_conv_checkpoint/038-0.4639.hdf5\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.3383 - acc: 0.8797 - val_loss: 0.4639 - val_acc: 0.8353\n",
      "Epoch 39/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.3445 - acc: 0.8795\n",
      "Epoch 00039: val_loss did not improve from 0.46394\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.3454 - acc: 0.8791 - val_loss: 0.4665 - val_acc: 0.8391\n",
      "Epoch 40/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.3381 - acc: 0.8756\n",
      "Epoch 00040: val_loss did not improve from 0.46394\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.3381 - acc: 0.8756 - val_loss: 0.5062 - val_acc: 0.8244\n",
      "Epoch 41/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.3118 - acc: 0.8863\n",
      "Epoch 00041: val_loss did not improve from 0.46394\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.3119 - acc: 0.8861 - val_loss: 0.4998 - val_acc: 0.8288\n",
      "Epoch 42/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.3216 - acc: 0.8857\n",
      "Epoch 00042: val_loss improved from 0.46394 to 0.45584, saving model to model/checkpoint/vis_imagenet_6_class_2D_CNN_custom_ch_64_DO_075_DO_4_conv_checkpoint/042-0.4558.hdf5\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.3214 - acc: 0.8857 - val_loss: 0.4558 - val_acc: 0.8365\n",
      "Epoch 43/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.3120 - acc: 0.8876\n",
      "Epoch 00043: val_loss did not improve from 0.45584\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.3115 - acc: 0.8878 - val_loss: 0.4901 - val_acc: 0.8288\n",
      "Epoch 44/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.2914 - acc: 0.8998\n",
      "Epoch 00044: val_loss improved from 0.45584 to 0.45504, saving model to model/checkpoint/vis_imagenet_6_class_2D_CNN_custom_ch_64_DO_075_DO_4_conv_checkpoint/044-0.4550.hdf5\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.2910 - acc: 0.9000 - val_loss: 0.4550 - val_acc: 0.8346\n",
      "Epoch 45/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.2920 - acc: 0.9003\n",
      "Epoch 00045: val_loss did not improve from 0.45504\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.2918 - acc: 0.9004 - val_loss: 0.4609 - val_acc: 0.8385\n",
      "Epoch 46/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.2735 - acc: 0.9030\n",
      "Epoch 00046: val_loss improved from 0.45504 to 0.44451, saving model to model/checkpoint/vis_imagenet_6_class_2D_CNN_custom_ch_64_DO_075_DO_4_conv_checkpoint/046-0.4445.hdf5\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.2734 - acc: 0.9030 - val_loss: 0.4445 - val_acc: 0.8436\n",
      "Epoch 47/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.2826 - acc: 0.8958\n",
      "Epoch 00047: val_loss did not improve from 0.44451\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.2834 - acc: 0.8955 - val_loss: 0.4615 - val_acc: 0.8397\n",
      "Epoch 48/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.2891 - acc: 0.8960\n",
      "Epoch 00048: val_loss did not improve from 0.44451\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.2888 - acc: 0.8962 - val_loss: 0.4592 - val_acc: 0.8397\n",
      "Epoch 49/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.2566 - acc: 0.9073\n",
      "Epoch 00049: val_loss did not improve from 0.44451\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.2563 - acc: 0.9075 - val_loss: 0.4578 - val_acc: 0.8372\n",
      "Epoch 50/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.2455 - acc: 0.9152\n",
      "Epoch 00050: val_loss did not improve from 0.44451\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.2459 - acc: 0.9152 - val_loss: 0.4747 - val_acc: 0.8359\n",
      "Epoch 51/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.2489 - acc: 0.9086\n",
      "Epoch 00051: val_loss did not improve from 0.44451\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.2494 - acc: 0.9085 - val_loss: 0.6002 - val_acc: 0.8000\n",
      "Epoch 52/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.2594 - acc: 0.9084\n",
      "Epoch 00052: val_loss did not improve from 0.44451\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.2595 - acc: 0.9081 - val_loss: 0.4576 - val_acc: 0.8449\n",
      "Epoch 53/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.2383 - acc: 0.9159\n",
      "Epoch 00053: val_loss did not improve from 0.44451\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.2399 - acc: 0.9156 - val_loss: 0.4481 - val_acc: 0.8487\n",
      "Epoch 54/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.2548 - acc: 0.9088\n",
      "Epoch 00054: val_loss did not improve from 0.44451\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.2547 - acc: 0.9090 - val_loss: 0.4474 - val_acc: 0.8481\n",
      "Epoch 55/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.2304 - acc: 0.9180\n",
      "Epoch 00055: val_loss did not improve from 0.44451\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.2308 - acc: 0.9177 - val_loss: 0.4856 - val_acc: 0.8404\n",
      "Epoch 56/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.2378 - acc: 0.9182\n",
      "Epoch 00056: val_loss did not improve from 0.44451\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.2376 - acc: 0.9184 - val_loss: 0.4512 - val_acc: 0.8481\n",
      "Epoch 57/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.2051 - acc: 0.9270\n",
      "Epoch 00057: val_loss did not improve from 0.44451\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.2049 - acc: 0.9271 - val_loss: 0.4645 - val_acc: 0.8404\n",
      "Epoch 58/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.2151 - acc: 0.9244\n",
      "Epoch 00058: val_loss did not improve from 0.44451\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.2160 - acc: 0.9239 - val_loss: 0.4737 - val_acc: 0.8455\n",
      "Epoch 59/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.2247 - acc: 0.9180\n",
      "Epoch 00059: val_loss improved from 0.44451 to 0.43743, saving model to model/checkpoint/vis_imagenet_6_class_2D_CNN_custom_ch_64_DO_075_DO_4_conv_checkpoint/059-0.4374.hdf5\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.2245 - acc: 0.9182 - val_loss: 0.4374 - val_acc: 0.8513\n",
      "Epoch 60/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.1965 - acc: 0.9326\n",
      "Epoch 00060: val_loss did not improve from 0.43743\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.1965 - acc: 0.9325 - val_loss: 0.5015 - val_acc: 0.8442\n",
      "Epoch 61/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.2035 - acc: 0.9300\n",
      "Epoch 00061: val_loss did not improve from 0.43743\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.2033 - acc: 0.9301 - val_loss: 0.4649 - val_acc: 0.8468\n",
      "Epoch 62/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.2004 - acc: 0.9274\n",
      "Epoch 00062: val_loss did not improve from 0.43743\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.2004 - acc: 0.9276 - val_loss: 0.4552 - val_acc: 0.8494\n",
      "Epoch 63/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.1824 - acc: 0.9377\n",
      "Epoch 00063: val_loss did not improve from 0.43743\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.1828 - acc: 0.9372 - val_loss: 0.4630 - val_acc: 0.8462\n",
      "Epoch 64/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.2086 - acc: 0.9268\n",
      "Epoch 00064: val_loss did not improve from 0.43743\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.2083 - acc: 0.9269 - val_loss: 0.4565 - val_acc: 0.8538\n",
      "Epoch 65/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.1787 - acc: 0.9377\n",
      "Epoch 00065: val_loss did not improve from 0.43743\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.1790 - acc: 0.9376 - val_loss: 0.4392 - val_acc: 0.8532\n",
      "Epoch 66/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.1882 - acc: 0.9347\n",
      "Epoch 00066: val_loss did not improve from 0.43743\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.1885 - acc: 0.9342 - val_loss: 0.4907 - val_acc: 0.8436\n",
      "Epoch 67/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.1904 - acc: 0.9341\n",
      "Epoch 00067: val_loss did not improve from 0.43743\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.1902 - acc: 0.9342 - val_loss: 0.4756 - val_acc: 0.8442\n",
      "Epoch 68/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.1675 - acc: 0.9424\n",
      "Epoch 00068: val_loss did not improve from 0.43743\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.1674 - acc: 0.9425 - val_loss: 0.4425 - val_acc: 0.8551\n",
      "Epoch 69/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.1657 - acc: 0.9409\n",
      "Epoch 00069: val_loss did not improve from 0.43743\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.1655 - acc: 0.9410 - val_loss: 0.4917 - val_acc: 0.8487\n",
      "Epoch 70/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.1742 - acc: 0.9381\n",
      "Epoch 00070: val_loss did not improve from 0.43743\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.1745 - acc: 0.9380 - val_loss: 0.4389 - val_acc: 0.8545\n",
      "Epoch 71/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.1532 - acc: 0.9458\n",
      "Epoch 00071: val_loss did not improve from 0.43743\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.1543 - acc: 0.9453 - val_loss: 0.4721 - val_acc: 0.8500\n",
      "Epoch 72/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.1652 - acc: 0.9399\n",
      "Epoch 00072: val_loss did not improve from 0.43743\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.1649 - acc: 0.9400 - val_loss: 0.4735 - val_acc: 0.8519\n",
      "Epoch 73/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.1416 - acc: 0.9536\n",
      "Epoch 00073: val_loss did not improve from 0.43743\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.1420 - acc: 0.9534 - val_loss: 0.4629 - val_acc: 0.8564\n",
      "Epoch 74/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.1588 - acc: 0.9431\n",
      "Epoch 00074: val_loss did not improve from 0.43743\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.1587 - acc: 0.9432 - val_loss: 0.4690 - val_acc: 0.8481\n",
      "Epoch 75/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.1348 - acc: 0.9540\n",
      "Epoch 00075: val_loss did not improve from 0.43743\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.1347 - acc: 0.9541 - val_loss: 0.4864 - val_acc: 0.8494\n",
      "Epoch 76/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.1435 - acc: 0.9540\n",
      "Epoch 00076: val_loss did not improve from 0.43743\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.1433 - acc: 0.9541 - val_loss: 0.4623 - val_acc: 0.8551\n",
      "Epoch 77/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.1506 - acc: 0.9465\n",
      "Epoch 00077: val_loss did not improve from 0.43743\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.1508 - acc: 0.9464 - val_loss: 0.4628 - val_acc: 0.8532\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.1350 - acc: 0.9525\n",
      "Epoch 00078: val_loss did not improve from 0.43743\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.1348 - acc: 0.9526 - val_loss: 0.4557 - val_acc: 0.8571\n",
      "Epoch 79/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.1142 - acc: 0.9604\n",
      "Epoch 00079: val_loss did not improve from 0.43743\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.1141 - acc: 0.9605 - val_loss: 0.4915 - val_acc: 0.8577\n",
      "Epoch 80/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.1089 - acc: 0.9645\n",
      "Epoch 00080: val_loss did not improve from 0.43743\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.1087 - acc: 0.9645 - val_loss: 0.5077 - val_acc: 0.8481\n",
      "Epoch 81/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.1250 - acc: 0.9557\n",
      "Epoch 00081: val_loss did not improve from 0.43743\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.1248 - acc: 0.9558 - val_loss: 0.5026 - val_acc: 0.8494\n",
      "Epoch 82/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.1150 - acc: 0.9580\n",
      "Epoch 00082: val_loss did not improve from 0.43743\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.1151 - acc: 0.9579 - val_loss: 0.4841 - val_acc: 0.8468\n",
      "Epoch 83/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.1301 - acc: 0.9527\n",
      "Epoch 00083: val_loss did not improve from 0.43743\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.1300 - acc: 0.9528 - val_loss: 0.4803 - val_acc: 0.8551\n",
      "Epoch 84/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.1304 - acc: 0.9518\n",
      "Epoch 00084: val_loss did not improve from 0.43743\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.1303 - acc: 0.9519 - val_loss: 0.4668 - val_acc: 0.8564\n",
      "Epoch 85/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.1054 - acc: 0.9655\n",
      "Epoch 00085: val_loss did not improve from 0.43743\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.1052 - acc: 0.9656 - val_loss: 0.4696 - val_acc: 0.8609\n",
      "Epoch 86/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.1169 - acc: 0.9595\n",
      "Epoch 00086: val_loss did not improve from 0.43743\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.1168 - acc: 0.9596 - val_loss: 0.5542 - val_acc: 0.8295\n",
      "Epoch 87/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.1225 - acc: 0.9595\n",
      "Epoch 00087: val_loss did not improve from 0.43743\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.1224 - acc: 0.9596 - val_loss: 0.4520 - val_acc: 0.8718\n",
      "Epoch 88/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.1047 - acc: 0.9632\n",
      "Epoch 00088: val_loss did not improve from 0.43743\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.1046 - acc: 0.9632 - val_loss: 0.4828 - val_acc: 0.8500\n",
      "Epoch 89/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.0943 - acc: 0.9681\n",
      "Epoch 00089: val_loss did not improve from 0.43743\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.0944 - acc: 0.9679 - val_loss: 0.4798 - val_acc: 0.8583\n",
      "Epoch 90/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.1174 - acc: 0.9600\n",
      "Epoch 00090: val_loss did not improve from 0.43743\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.1173 - acc: 0.9600 - val_loss: 0.4584 - val_acc: 0.8622\n",
      "Epoch 91/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.0912 - acc: 0.9702\n",
      "Epoch 00091: val_loss did not improve from 0.43743\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.0911 - acc: 0.9703 - val_loss: 0.5114 - val_acc: 0.8603\n",
      "Epoch 92/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.0896 - acc: 0.9696\n",
      "Epoch 00092: val_loss did not improve from 0.43743\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.0895 - acc: 0.9697 - val_loss: 0.5157 - val_acc: 0.8526\n",
      "Epoch 93/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.1052 - acc: 0.9643\n",
      "Epoch 00093: val_loss did not improve from 0.43743\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.1052 - acc: 0.9643 - val_loss: 0.5009 - val_acc: 0.8532\n",
      "Epoch 94/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.0878 - acc: 0.9700\n",
      "Epoch 00094: val_loss did not improve from 0.43743\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.0877 - acc: 0.9701 - val_loss: 0.4990 - val_acc: 0.8647\n",
      "Epoch 95/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.0905 - acc: 0.9715\n",
      "Epoch 00095: val_loss did not improve from 0.43743\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.0904 - acc: 0.9716 - val_loss: 0.4968 - val_acc: 0.8513\n",
      "Epoch 96/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.0860 - acc: 0.9685\n",
      "Epoch 00096: val_loss did not improve from 0.43743\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.0860 - acc: 0.9686 - val_loss: 0.5515 - val_acc: 0.8526\n",
      "Epoch 97/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.0980 - acc: 0.9683\n",
      "Epoch 00097: val_loss did not improve from 0.43743\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.0978 - acc: 0.9684 - val_loss: 0.5086 - val_acc: 0.8551\n",
      "Epoch 98/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.0887 - acc: 0.9720\n",
      "Epoch 00098: val_loss did not improve from 0.43743\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.0890 - acc: 0.9718 - val_loss: 0.5007 - val_acc: 0.8583\n",
      "Epoch 99/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.1102 - acc: 0.9615\n",
      "Epoch 00099: val_loss did not improve from 0.43743\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.1100 - acc: 0.9615 - val_loss: 0.4866 - val_acc: 0.8513\n",
      "Epoch 100/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.0811 - acc: 0.9722\n",
      "Epoch 00100: val_loss did not improve from 0.43743\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.0811 - acc: 0.9722 - val_loss: 0.5198 - val_acc: 0.8622\n",
      "Epoch 101/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.0777 - acc: 0.9735\n",
      "Epoch 00101: val_loss did not improve from 0.43743\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.0776 - acc: 0.9735 - val_loss: 0.5119 - val_acc: 0.8564\n",
      "Epoch 102/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.0791 - acc: 0.9735\n",
      "Epoch 00102: val_loss did not improve from 0.43743\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.0790 - acc: 0.9735 - val_loss: 0.5585 - val_acc: 0.8526\n",
      "Epoch 103/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.0740 - acc: 0.9775\n",
      "Epoch 00103: val_loss did not improve from 0.43743\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.0742 - acc: 0.9774 - val_loss: 0.5328 - val_acc: 0.8622\n",
      "Epoch 104/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.0729 - acc: 0.9762\n",
      "Epoch 00104: val_loss did not improve from 0.43743\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.0730 - acc: 0.9763 - val_loss: 0.5408 - val_acc: 0.8532\n",
      "Epoch 105/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.0759 - acc: 0.9756\n",
      "Epoch 00105: val_loss did not improve from 0.43743\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.0759 - acc: 0.9756 - val_loss: 0.4935 - val_acc: 0.8712\n",
      "Epoch 106/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.0719 - acc: 0.9745\n",
      "Epoch 00106: val_loss did not improve from 0.43743\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.0719 - acc: 0.9746 - val_loss: 0.5145 - val_acc: 0.8635\n",
      "Epoch 107/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.0829 - acc: 0.9711\n",
      "Epoch 00107: val_loss did not improve from 0.43743\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.0829 - acc: 0.9712 - val_loss: 0.5300 - val_acc: 0.8596\n",
      "Epoch 108/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.0560 - acc: 0.9837\n",
      "Epoch 00108: val_loss did not improve from 0.43743\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.0559 - acc: 0.9838 - val_loss: 0.5561 - val_acc: 0.8583\n",
      "Epoch 109/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.0795 - acc: 0.9726\n",
      "Epoch 00109: val_loss did not improve from 0.43743\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.0795 - acc: 0.9726 - val_loss: 0.5183 - val_acc: 0.8615\n",
      "\n",
      "vis_imagenet_6_class_2D_CNN_custom_ch_64_DO_075_DO_4_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1560/1560 [==============================] - 4s 3ms/sample - loss: 0.4374 - acc: 0.8513\n",
      "Loss: 0.4374293573391743 Accuracy: 0.85128206\n",
      "\n",
      "Train on 4680 samples, validate on 1560 samples\n",
      "Epoch 1/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 1.6553 - acc: 0.2860\n",
      "Epoch 00001: val_loss improved from inf to 1.41945, saving model to model/checkpoint/vis_imagenet_6_class_2D_CNN_custom_ch_64_DO_075_DO_5_conv_checkpoint/001-1.4194.hdf5\n",
      "4680/4680 [==============================] - 26s 6ms/sample - loss: 1.6552 - acc: 0.2861 - val_loss: 1.4194 - val_acc: 0.4295\n",
      "Epoch 2/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 1.4018 - acc: 0.4167\n",
      "Epoch 00002: val_loss improved from 1.41945 to 1.24160, saving model to model/checkpoint/vis_imagenet_6_class_2D_CNN_custom_ch_64_DO_075_DO_5_conv_checkpoint/002-1.2416.hdf5\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 1.4017 - acc: 0.4167 - val_loss: 1.2416 - val_acc: 0.4917\n",
      "Epoch 3/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 1.2562 - acc: 0.5054\n",
      "Epoch 00003: val_loss improved from 1.24160 to 1.20818, saving model to model/checkpoint/vis_imagenet_6_class_2D_CNN_custom_ch_64_DO_075_DO_5_conv_checkpoint/003-1.2082.hdf5\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 1.2564 - acc: 0.5051 - val_loss: 1.2082 - val_acc: 0.5455\n",
      "Epoch 4/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 1.1436 - acc: 0.5629\n",
      "Epoch 00004: val_loss improved from 1.20818 to 1.04621, saving model to model/checkpoint/vis_imagenet_6_class_2D_CNN_custom_ch_64_DO_075_DO_5_conv_checkpoint/004-1.0462.hdf5\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 1.1439 - acc: 0.5628 - val_loss: 1.0462 - val_acc: 0.5994\n",
      "Epoch 5/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 1.1123 - acc: 0.5777\n",
      "Epoch 00005: val_loss improved from 1.04621 to 0.97321, saving model to model/checkpoint/vis_imagenet_6_class_2D_CNN_custom_ch_64_DO_075_DO_5_conv_checkpoint/005-0.9732.hdf5\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 1.1120 - acc: 0.5778 - val_loss: 0.9732 - val_acc: 0.6327\n",
      "Epoch 6/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 1.0071 - acc: 0.6289\n",
      "Epoch 00006: val_loss improved from 0.97321 to 0.91329, saving model to model/checkpoint/vis_imagenet_6_class_2D_CNN_custom_ch_64_DO_075_DO_5_conv_checkpoint/006-0.9133.hdf5\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 1.0074 - acc: 0.6286 - val_loss: 0.9133 - val_acc: 0.6609\n",
      "Epoch 7/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.9305 - acc: 0.6663\n",
      "Epoch 00007: val_loss did not improve from 0.91329\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.9310 - acc: 0.6656 - val_loss: 1.0901 - val_acc: 0.5756\n",
      "Epoch 8/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.9103 - acc: 0.6712\n",
      "Epoch 00008: val_loss did not improve from 0.91329\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.9098 - acc: 0.6714 - val_loss: 0.9296 - val_acc: 0.6365\n",
      "Epoch 9/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.8335 - acc: 0.7014\n",
      "Epoch 00009: val_loss improved from 0.91329 to 0.79256, saving model to model/checkpoint/vis_imagenet_6_class_2D_CNN_custom_ch_64_DO_075_DO_5_conv_checkpoint/009-0.7926.hdf5\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.8335 - acc: 0.7015 - val_loss: 0.7926 - val_acc: 0.7109\n",
      "Epoch 10/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.7817 - acc: 0.7192\n",
      "Epoch 00010: val_loss improved from 0.79256 to 0.73817, saving model to model/checkpoint/vis_imagenet_6_class_2D_CNN_custom_ch_64_DO_075_DO_5_conv_checkpoint/010-0.7382.hdf5\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.7819 - acc: 0.7192 - val_loss: 0.7382 - val_acc: 0.7269\n",
      "Epoch 11/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.7381 - acc: 0.7397\n",
      "Epoch 00011: val_loss did not improve from 0.73817\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.7383 - acc: 0.7395 - val_loss: 0.7438 - val_acc: 0.7269\n",
      "Epoch 12/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.6995 - acc: 0.7485\n",
      "Epoch 00012: val_loss improved from 0.73817 to 0.69253, saving model to model/checkpoint/vis_imagenet_6_class_2D_CNN_custom_ch_64_DO_075_DO_5_conv_checkpoint/012-0.6925.hdf5\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.6991 - acc: 0.7487 - val_loss: 0.6925 - val_acc: 0.7474\n",
      "Epoch 13/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.6682 - acc: 0.7682\n",
      "Epoch 00013: val_loss improved from 0.69253 to 0.66238, saving model to model/checkpoint/vis_imagenet_6_class_2D_CNN_custom_ch_64_DO_075_DO_5_conv_checkpoint/013-0.6624.hdf5\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.6692 - acc: 0.7679 - val_loss: 0.6624 - val_acc: 0.7641\n",
      "Epoch 14/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.6231 - acc: 0.7845\n",
      "Epoch 00014: val_loss did not improve from 0.66238\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.6232 - acc: 0.7846 - val_loss: 0.6775 - val_acc: 0.7462\n",
      "Epoch 15/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.6252 - acc: 0.7783\n",
      "Epoch 00015: val_loss did not improve from 0.66238\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.6251 - acc: 0.7784 - val_loss: 0.6762 - val_acc: 0.7596\n",
      "Epoch 16/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.5675 - acc: 0.7994\n",
      "Epoch 00016: val_loss improved from 0.66238 to 0.58371, saving model to model/checkpoint/vis_imagenet_6_class_2D_CNN_custom_ch_64_DO_075_DO_5_conv_checkpoint/016-0.5837.hdf5\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.5689 - acc: 0.7994 - val_loss: 0.5837 - val_acc: 0.7872\n",
      "Epoch 17/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.5152 - acc: 0.8211\n",
      "Epoch 00017: val_loss did not improve from 0.58371\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.5154 - acc: 0.8209 - val_loss: 0.5951 - val_acc: 0.7808\n",
      "Epoch 18/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.4959 - acc: 0.8253\n",
      "Epoch 00018: val_loss improved from 0.58371 to 0.55695, saving model to model/checkpoint/vis_imagenet_6_class_2D_CNN_custom_ch_64_DO_075_DO_5_conv_checkpoint/018-0.5570.hdf5\n",
      "4680/4680 [==============================] - 25s 5ms/sample - loss: 0.4957 - acc: 0.8254 - val_loss: 0.5570 - val_acc: 0.7974\n",
      "Epoch 19/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.4993 - acc: 0.8251\n",
      "Epoch 00019: val_loss improved from 0.55695 to 0.55291, saving model to model/checkpoint/vis_imagenet_6_class_2D_CNN_custom_ch_64_DO_075_DO_5_conv_checkpoint/019-0.5529.hdf5\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.4988 - acc: 0.8252 - val_loss: 0.5529 - val_acc: 0.7981\n",
      "Epoch 20/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.4447 - acc: 0.8423\n",
      "Epoch 00020: val_loss improved from 0.55291 to 0.53658, saving model to model/checkpoint/vis_imagenet_6_class_2D_CNN_custom_ch_64_DO_075_DO_5_conv_checkpoint/020-0.5366.hdf5\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.4441 - acc: 0.8425 - val_loss: 0.5366 - val_acc: 0.8019\n",
      "Epoch 21/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.4515 - acc: 0.8427\n",
      "Epoch 00021: val_loss did not improve from 0.53658\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.4515 - acc: 0.8425 - val_loss: 0.7066 - val_acc: 0.7436\n",
      "Epoch 22/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.4365 - acc: 0.8444\n",
      "Epoch 00022: val_loss improved from 0.53658 to 0.53103, saving model to model/checkpoint/vis_imagenet_6_class_2D_CNN_custom_ch_64_DO_075_DO_5_conv_checkpoint/022-0.5310.hdf5\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.4359 - acc: 0.8447 - val_loss: 0.5310 - val_acc: 0.8237\n",
      "Epoch 23/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.3843 - acc: 0.8649\n",
      "Epoch 00023: val_loss did not improve from 0.53103\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.3841 - acc: 0.8650 - val_loss: 0.5485 - val_acc: 0.7987\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.3648 - acc: 0.8692\n",
      "Epoch 00024: val_loss did not improve from 0.53103\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.3648 - acc: 0.8692 - val_loss: 0.5975 - val_acc: 0.7949\n",
      "Epoch 25/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.3593 - acc: 0.8720\n",
      "Epoch 00025: val_loss improved from 0.53103 to 0.48458, saving model to model/checkpoint/vis_imagenet_6_class_2D_CNN_custom_ch_64_DO_075_DO_5_conv_checkpoint/025-0.4846.hdf5\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.3591 - acc: 0.8722 - val_loss: 0.4846 - val_acc: 0.8179\n",
      "Epoch 26/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.3417 - acc: 0.8793\n",
      "Epoch 00026: val_loss did not improve from 0.48458\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.3420 - acc: 0.8791 - val_loss: 0.5699 - val_acc: 0.7974\n",
      "Epoch 27/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.3468 - acc: 0.8799\n",
      "Epoch 00027: val_loss improved from 0.48458 to 0.48106, saving model to model/checkpoint/vis_imagenet_6_class_2D_CNN_custom_ch_64_DO_075_DO_5_conv_checkpoint/027-0.4811.hdf5\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.3472 - acc: 0.8797 - val_loss: 0.4811 - val_acc: 0.8231\n",
      "Epoch 28/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.3253 - acc: 0.8881\n",
      "Epoch 00028: val_loss did not improve from 0.48106\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.3257 - acc: 0.8878 - val_loss: 0.5135 - val_acc: 0.8154\n",
      "Epoch 29/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.2892 - acc: 0.8973\n",
      "Epoch 00029: val_loss did not improve from 0.48106\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.2904 - acc: 0.8970 - val_loss: 0.4906 - val_acc: 0.8269\n",
      "Epoch 30/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.2855 - acc: 0.9030\n",
      "Epoch 00030: val_loss did not improve from 0.48106\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.2852 - acc: 0.9032 - val_loss: 0.4982 - val_acc: 0.8301\n",
      "Epoch 31/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.2850 - acc: 0.8990\n",
      "Epoch 00031: val_loss did not improve from 0.48106\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.2855 - acc: 0.8987 - val_loss: 0.5130 - val_acc: 0.8186\n",
      "Epoch 32/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.2735 - acc: 0.9071\n",
      "Epoch 00032: val_loss did not improve from 0.48106\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.2731 - acc: 0.9073 - val_loss: 0.6021 - val_acc: 0.7962\n",
      "Epoch 33/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.2610 - acc: 0.9107\n",
      "Epoch 00033: val_loss did not improve from 0.48106\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.2606 - acc: 0.9109 - val_loss: 0.5002 - val_acc: 0.8423\n",
      "Epoch 34/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.2339 - acc: 0.9214\n",
      "Epoch 00034: val_loss did not improve from 0.48106\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.2339 - acc: 0.9214 - val_loss: 0.5438 - val_acc: 0.8192\n",
      "Epoch 35/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.2276 - acc: 0.9210\n",
      "Epoch 00035: val_loss did not improve from 0.48106\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.2273 - acc: 0.9212 - val_loss: 0.5115 - val_acc: 0.8282\n",
      "Epoch 36/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.2220 - acc: 0.9244\n",
      "Epoch 00036: val_loss did not improve from 0.48106\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.2219 - acc: 0.9246 - val_loss: 0.5108 - val_acc: 0.8237\n",
      "Epoch 37/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.2072 - acc: 0.9268\n",
      "Epoch 00037: val_loss did not improve from 0.48106\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.2072 - acc: 0.9267 - val_loss: 0.5246 - val_acc: 0.8340\n",
      "Epoch 38/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.1948 - acc: 0.9321\n",
      "Epoch 00038: val_loss did not improve from 0.48106\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.1946 - acc: 0.9323 - val_loss: 0.5796 - val_acc: 0.8128\n",
      "Epoch 39/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.1967 - acc: 0.9324\n",
      "Epoch 00039: val_loss did not improve from 0.48106\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.1965 - acc: 0.9325 - val_loss: 0.4986 - val_acc: 0.8423\n",
      "Epoch 40/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.1729 - acc: 0.9375\n",
      "Epoch 00040: val_loss did not improve from 0.48106\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.1729 - acc: 0.9376 - val_loss: 0.4967 - val_acc: 0.8423\n",
      "Epoch 41/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.1863 - acc: 0.9384\n",
      "Epoch 00041: val_loss did not improve from 0.48106\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.1863 - acc: 0.9385 - val_loss: 0.5003 - val_acc: 0.8468\n",
      "Epoch 42/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.1838 - acc: 0.9328\n",
      "Epoch 00042: val_loss did not improve from 0.48106\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.1837 - acc: 0.9327 - val_loss: 0.5466 - val_acc: 0.8282\n",
      "Epoch 43/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.1539 - acc: 0.9476\n",
      "Epoch 00043: val_loss did not improve from 0.48106\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.1536 - acc: 0.9476 - val_loss: 0.5068 - val_acc: 0.8404\n",
      "Epoch 44/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.1430 - acc: 0.9521\n",
      "Epoch 00044: val_loss did not improve from 0.48106\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.1439 - acc: 0.9517 - val_loss: 0.5359 - val_acc: 0.8365\n",
      "Epoch 45/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.1667 - acc: 0.9405\n",
      "Epoch 00045: val_loss did not improve from 0.48106\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.1664 - acc: 0.9406 - val_loss: 0.5348 - val_acc: 0.8372\n",
      "Epoch 46/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.1126 - acc: 0.9606\n",
      "Epoch 00046: val_loss did not improve from 0.48106\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.1127 - acc: 0.9605 - val_loss: 0.5180 - val_acc: 0.8526\n",
      "Epoch 47/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.1163 - acc: 0.9625\n",
      "Epoch 00047: val_loss did not improve from 0.48106\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.1161 - acc: 0.9626 - val_loss: 0.4993 - val_acc: 0.8545\n",
      "Epoch 48/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.1047 - acc: 0.9679\n",
      "Epoch 00048: val_loss did not improve from 0.48106\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.1049 - acc: 0.9675 - val_loss: 0.5385 - val_acc: 0.8500\n",
      "Epoch 49/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.1138 - acc: 0.9630\n",
      "Epoch 00049: val_loss did not improve from 0.48106\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.1138 - acc: 0.9630 - val_loss: 0.6172 - val_acc: 0.8295\n",
      "Epoch 50/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.1122 - acc: 0.9638\n",
      "Epoch 00050: val_loss did not improve from 0.48106\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.1124 - acc: 0.9637 - val_loss: 0.5943 - val_acc: 0.8353\n",
      "Epoch 51/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.1171 - acc: 0.9589\n",
      "Epoch 00051: val_loss did not improve from 0.48106\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.1173 - acc: 0.9588 - val_loss: 0.5292 - val_acc: 0.8494\n",
      "Epoch 52/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.0950 - acc: 0.9694\n",
      "Epoch 00052: val_loss did not improve from 0.48106\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.0949 - acc: 0.9694 - val_loss: 0.5165 - val_acc: 0.8500\n",
      "Epoch 53/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.0842 - acc: 0.9711\n",
      "Epoch 00053: val_loss did not improve from 0.48106\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.0841 - acc: 0.9712 - val_loss: 0.6141 - val_acc: 0.8333\n",
      "Epoch 54/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.0847 - acc: 0.9728\n",
      "Epoch 00054: val_loss did not improve from 0.48106\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.0847 - acc: 0.9729 - val_loss: 0.5524 - val_acc: 0.8468\n",
      "Epoch 55/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.0883 - acc: 0.9673\n",
      "Epoch 00055: val_loss did not improve from 0.48106\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.0882 - acc: 0.9673 - val_loss: 0.6174 - val_acc: 0.8333\n",
      "Epoch 56/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.1003 - acc: 0.9628\n",
      "Epoch 00056: val_loss did not improve from 0.48106\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.1003 - acc: 0.9628 - val_loss: 0.5480 - val_acc: 0.8391\n",
      "Epoch 57/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.0666 - acc: 0.9790\n",
      "Epoch 00057: val_loss did not improve from 0.48106\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.0666 - acc: 0.9791 - val_loss: 0.6080 - val_acc: 0.8506\n",
      "Epoch 58/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.0716 - acc: 0.9773\n",
      "Epoch 00058: val_loss did not improve from 0.48106\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.0715 - acc: 0.9774 - val_loss: 0.5883 - val_acc: 0.8449\n",
      "Epoch 59/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.0770 - acc: 0.9750\n",
      "Epoch 00059: val_loss did not improve from 0.48106\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.0772 - acc: 0.9748 - val_loss: 0.6614 - val_acc: 0.8250\n",
      "Epoch 60/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.0806 - acc: 0.9745\n",
      "Epoch 00060: val_loss did not improve from 0.48106\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.0806 - acc: 0.9746 - val_loss: 0.5718 - val_acc: 0.8397\n",
      "Epoch 61/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.0504 - acc: 0.9850\n",
      "Epoch 00061: val_loss did not improve from 0.48106\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.0504 - acc: 0.9850 - val_loss: 0.6083 - val_acc: 0.8455\n",
      "Epoch 62/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.0625 - acc: 0.9784\n",
      "Epoch 00062: val_loss did not improve from 0.48106\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.0625 - acc: 0.9784 - val_loss: 0.6011 - val_acc: 0.8429\n",
      "Epoch 63/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.0740 - acc: 0.9750\n",
      "Epoch 00063: val_loss did not improve from 0.48106\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.0740 - acc: 0.9750 - val_loss: 0.6056 - val_acc: 0.8462\n",
      "Epoch 64/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.0448 - acc: 0.9876\n",
      "Epoch 00064: val_loss did not improve from 0.48106\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.0448 - acc: 0.9876 - val_loss: 0.6193 - val_acc: 0.8519\n",
      "Epoch 65/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.0510 - acc: 0.9846\n",
      "Epoch 00065: val_loss did not improve from 0.48106\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.0509 - acc: 0.9846 - val_loss: 0.6517 - val_acc: 0.8436\n",
      "Epoch 66/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.0370 - acc: 0.9904\n",
      "Epoch 00066: val_loss did not improve from 0.48106\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.0370 - acc: 0.9904 - val_loss: 0.5926 - val_acc: 0.8526\n",
      "Epoch 67/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.0387 - acc: 0.9876\n",
      "Epoch 00067: val_loss did not improve from 0.48106\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.0387 - acc: 0.9876 - val_loss: 0.5849 - val_acc: 0.8487\n",
      "Epoch 68/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.0428 - acc: 0.9867\n",
      "Epoch 00068: val_loss did not improve from 0.48106\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.0427 - acc: 0.9868 - val_loss: 0.6300 - val_acc: 0.8468\n",
      "Epoch 69/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.0362 - acc: 0.9889\n",
      "Epoch 00069: val_loss did not improve from 0.48106\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.0361 - acc: 0.9889 - val_loss: 0.5829 - val_acc: 0.8590\n",
      "Epoch 70/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.0368 - acc: 0.9878\n",
      "Epoch 00070: val_loss did not improve from 0.48106\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.0368 - acc: 0.9878 - val_loss: 0.5943 - val_acc: 0.8571\n",
      "Epoch 71/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.0620 - acc: 0.9795\n",
      "Epoch 00071: val_loss did not improve from 0.48106\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.0620 - acc: 0.9795 - val_loss: 0.6794 - val_acc: 0.8429\n",
      "Epoch 72/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.0593 - acc: 0.9801\n",
      "Epoch 00072: val_loss did not improve from 0.48106\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.0592 - acc: 0.9801 - val_loss: 0.6476 - val_acc: 0.8462\n",
      "Epoch 73/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.0341 - acc: 0.9906\n",
      "Epoch 00073: val_loss did not improve from 0.48106\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.0342 - acc: 0.9904 - val_loss: 0.6845 - val_acc: 0.8333\n",
      "Epoch 74/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.0585 - acc: 0.9797\n",
      "Epoch 00074: val_loss did not improve from 0.48106\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.0585 - acc: 0.9797 - val_loss: 0.6555 - val_acc: 0.8519\n",
      "Epoch 75/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.0324 - acc: 0.9899\n",
      "Epoch 00075: val_loss did not improve from 0.48106\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.0324 - acc: 0.9900 - val_loss: 0.6458 - val_acc: 0.8455\n",
      "Epoch 76/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.0246 - acc: 0.9929\n",
      "Epoch 00076: val_loss did not improve from 0.48106\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.0246 - acc: 0.9929 - val_loss: 0.7492 - val_acc: 0.8327\n",
      "Epoch 77/500\n",
      "4672/4680 [============================>.] - ETA: 0s - loss: 0.0352 - acc: 0.9889\n",
      "Epoch 00077: val_loss did not improve from 0.48106\n",
      "4680/4680 [==============================] - 24s 5ms/sample - loss: 0.0353 - acc: 0.9887 - val_loss: 0.6622 - val_acc: 0.8487\n",
      "\n",
      "vis_imagenet_6_class_2D_CNN_custom_ch_64_DO_075_DO_5_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1560/1560 [==============================] - 4s 3ms/sample - loss: 0.4811 - acc: 0.8224\n",
      "Loss: 0.4810634467846308 Accuracy: 0.8224359\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(2, 6):\n",
    "    base = 'vis_imagenet_6_class_2D_CNN_custom_ch_64_DO_075_DO'\n",
    "    model_name = base+'_{}_conv'.format(i)\n",
    "    model = build_2d_cnn_custom_ch_64_DO(conv_num=i)\n",
    "#     model = multi_gpu_model(model, gpus=2)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=1e-4),\n",
    "          metrics=['accuracy'])\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    os.makedirs(model_path, exist_ok=True)\n",
    "    model_filename = model_path+'{epoch:03d}-{val_loss:.4f}.hdf5'\n",
    "    checkpointer = ModelCheckpoint(filepath = model_filename, monitor = \"val_loss\", \n",
    "                                   verbose=1, save_best_only=True)\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=50)\n",
    "    hist = model.fit(x_train, y_train, batch_size=64, epochs=500, \n",
    "                     validation_data=[x_val, y_val], shuffle=True, \n",
    "                     callbacks = [checkpointer, early_stopping])\n",
    "\n",
    "    print()\n",
    "    print(model_name, 'Model')\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "    ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
    "    ax.plot(hist.history['acc'], 'b', label='train acc')\n",
    "    ax.plot(hist.history['val_acc'], 'g', label='val acc')\n",
    "    ax.set_xlabel('epoch')\n",
    "    ax.set_ylabel('loss')\n",
    "    ax.legend(loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    png_path = 'visualization/learning_curve/'\n",
    "    filename = model_name+'.png'\n",
    "    os.makedirs(png_path, exist_ok=True)\n",
    "    fig.savefig(png_path+filename, transparent=True)\n",
    "\n",
    "    model.save(model_path+'000_last.hdf5')\n",
    "    del(model)\n",
    "\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    model_filename = model_path + sorted(os.listdir(model_path))[-1]\n",
    "    model = load_model(model_filename)\n",
    "    [loss, accuracy] = model.evaluate(x_test, y_test)\n",
    "    print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "    print()\n",
    "\n",
    "    del(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "vis_imagenet_6_class_2D_CNN_custom_ch_64_DO_075_DO_2_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         (None, 341, 341, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 341, 341, 64)      4864      \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 341, 341, 64)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling (None, 114, 114, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 114, 114, 64)      102464    \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 114, 114, 64)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling (None, 38, 38, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 92416)             0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 92416)             0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 6)                 554502    \n",
      "=================================================================\n",
      "Total params: 661,830\n",
      "Trainable params: 661,830\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "1560/1560 [==============================] - 4s 3ms/sample - loss: 0.7130 - acc: 0.7474\n",
      "Loss: 0.7130152032925532 Accuracy: 0.74743587\n",
      "\n",
      "vis_imagenet_6_class_2D_CNN_custom_ch_64_DO_075_DO_3_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_7 (InputLayer)         (None, 341, 341, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 341, 341, 64)      4864      \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 341, 341, 64)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_17 (MaxPooling (None, 114, 114, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 114, 114, 64)      102464    \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 114, 114, 64)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_18 (MaxPooling (None, 38, 38, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 38, 38, 128)       204928    \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 38, 38, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_19 (MaxPooling (None, 13, 13, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 21632)             0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 21632)             0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 6)                 129798    \n",
      "=================================================================\n",
      "Total params: 442,054\n",
      "Trainable params: 442,054\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "1560/1560 [==============================] - 4s 3ms/sample - loss: 0.5305 - acc: 0.8276\n",
      "Loss: 0.5304544613911555 Accuracy: 0.8275641\n",
      "\n",
      "vis_imagenet_6_class_2D_CNN_custom_ch_64_DO_075_DO_4_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_8 (InputLayer)         (None, 341, 341, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 341, 341, 64)      4864      \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 341, 341, 64)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_20 (MaxPooling (None, 114, 114, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 114, 114, 64)      102464    \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 114, 114, 64)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_21 (MaxPooling (None, 38, 38, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_22 (Conv2D)           (None, 38, 38, 128)       204928    \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 38, 38, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_22 (MaxPooling (None, 13, 13, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 13, 13, 128)       409728    \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 13, 13, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_23 (MaxPooling (None, 5, 5, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 3200)              0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 3200)              0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 6)                 19206     \n",
      "=================================================================\n",
      "Total params: 741,190\n",
      "Trainable params: 741,190\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "1560/1560 [==============================] - 4s 3ms/sample - loss: 0.4374 - acc: 0.8513\n",
      "Loss: 0.4374293573391743 Accuracy: 0.85128206\n",
      "\n",
      "vis_imagenet_6_class_2D_CNN_custom_ch_64_DO_075_DO_5_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_9 (InputLayer)         (None, 341, 341, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_24 (Conv2D)           (None, 341, 341, 64)      4864      \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 341, 341, 64)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_24 (MaxPooling (None, 114, 114, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_25 (Conv2D)           (None, 114, 114, 64)      102464    \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 114, 114, 64)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_25 (MaxPooling (None, 38, 38, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_26 (Conv2D)           (None, 38, 38, 128)       204928    \n",
      "_________________________________________________________________\n",
      "activation_26 (Activation)   (None, 38, 38, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_26 (MaxPooling (None, 13, 13, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_27 (Conv2D)           (None, 13, 13, 128)       409728    \n",
      "_________________________________________________________________\n",
      "activation_27 (Activation)   (None, 13, 13, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_27 (MaxPooling (None, 5, 5, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_28 (Conv2D)           (None, 5, 5, 256)         819456    \n",
      "_________________________________________________________________\n",
      "activation_28 (Activation)   (None, 5, 5, 256)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_28 (MaxPooling (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 6)                 6150      \n",
      "=================================================================\n",
      "Total params: 1,547,590\n",
      "Trainable params: 1,547,590\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1560/1560 [==============================] - 4s 3ms/sample - loss: 0.4811 - acc: 0.8224\n",
      "Loss: 0.4810634467846308 Accuracy: 0.8224359\n"
     ]
    }
   ],
   "source": [
    "log_dir = 'log'\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "base = 'vis_imagenet_6_class_2D_CNN_custom_ch_64_DO_075_DO'\n",
    "\n",
    "with open(path.join(log_dir, base), 'w') as log_file:\n",
    "    for i in range(2, 6):\n",
    "        model_name = base+'_{}_conv'.format(i)\n",
    "        print()\n",
    "        print(model_name, 'Model')\n",
    "        model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "        model_filename = model_path + sorted(os.listdir(model_path))[-1]\n",
    "\n",
    "        model = load_model(model_filename)\n",
    "        model.summary()\n",
    "\n",
    "        [loss, accuracy] = model.evaluate(x_test, y_test)\n",
    "        print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "\n",
    "        del(model)\n",
    "\n",
    "        log_file.write('\\t'.join([model_name, str(accuracy), str(loss)])+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "vis_imagenet_6_class_2D_CNN_custom_ch_64_DO_075_DO_2_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         (None, 341, 341, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 341, 341, 64)      4864      \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 341, 341, 64)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling (None, 114, 114, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 114, 114, 64)      102464    \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 114, 114, 64)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling (None, 38, 38, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 92416)             0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 92416)             0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 6)                 554502    \n",
      "=================================================================\n",
      "Total params: 661,830\n",
      "Trainable params: 661,830\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "1560/1560 [==============================] - 4s 3ms/sample - loss: 1.0149 - acc: 0.7583\n",
      "Loss: 1.0149399726818769 Accuracy: 0.7583333\n",
      "\n",
      "vis_imagenet_6_class_2D_CNN_custom_ch_64_DO_075_DO_3_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_7 (InputLayer)         (None, 341, 341, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 341, 341, 64)      4864      \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 341, 341, 64)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_17 (MaxPooling (None, 114, 114, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 114, 114, 64)      102464    \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 114, 114, 64)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_18 (MaxPooling (None, 38, 38, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 38, 38, 128)       204928    \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 38, 38, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_19 (MaxPooling (None, 13, 13, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 21632)             0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 21632)             0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 6)                 129798    \n",
      "=================================================================\n",
      "Total params: 442,054\n",
      "Trainable params: 442,054\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "1560/1560 [==============================] - 4s 3ms/sample - loss: 0.6511 - acc: 0.8288\n",
      "Loss: 0.6511488446822533 Accuracy: 0.82884616\n",
      "\n",
      "vis_imagenet_6_class_2D_CNN_custom_ch_64_DO_075_DO_4_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_8 (InputLayer)         (None, 341, 341, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 341, 341, 64)      4864      \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 341, 341, 64)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_20 (MaxPooling (None, 114, 114, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 114, 114, 64)      102464    \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 114, 114, 64)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_21 (MaxPooling (None, 38, 38, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_22 (Conv2D)           (None, 38, 38, 128)       204928    \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 38, 38, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_22 (MaxPooling (None, 13, 13, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 13, 13, 128)       409728    \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 13, 13, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_23 (MaxPooling (None, 5, 5, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 3200)              0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 3200)              0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 6)                 19206     \n",
      "=================================================================\n",
      "Total params: 741,190\n",
      "Trainable params: 741,190\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "1560/1560 [==============================] - 4s 3ms/sample - loss: 0.5183 - acc: 0.8615\n",
      "Loss: 0.518265105669315 Accuracy: 0.86153847\n",
      "\n",
      "vis_imagenet_6_class_2D_CNN_custom_ch_64_DO_075_DO_5_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_9 (InputLayer)         (None, 341, 341, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_24 (Conv2D)           (None, 341, 341, 64)      4864      \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 341, 341, 64)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_24 (MaxPooling (None, 114, 114, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_25 (Conv2D)           (None, 114, 114, 64)      102464    \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 114, 114, 64)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_25 (MaxPooling (None, 38, 38, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_26 (Conv2D)           (None, 38, 38, 128)       204928    \n",
      "_________________________________________________________________\n",
      "activation_26 (Activation)   (None, 38, 38, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_26 (MaxPooling (None, 13, 13, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_27 (Conv2D)           (None, 13, 13, 128)       409728    \n",
      "_________________________________________________________________\n",
      "activation_27 (Activation)   (None, 13, 13, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_27 (MaxPooling (None, 5, 5, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_28 (Conv2D)           (None, 5, 5, 256)         819456    \n",
      "_________________________________________________________________\n",
      "activation_28 (Activation)   (None, 5, 5, 256)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_28 (MaxPooling (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 6)                 6150      \n",
      "=================================================================\n",
      "Total params: 1,547,590\n",
      "Trainable params: 1,547,590\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1560/1560 [==============================] - 5s 3ms/sample - loss: 0.6622 - acc: 0.8487\n",
      "Loss: 0.6621536756173159 Accuracy: 0.8487179\n"
     ]
    }
   ],
   "source": [
    "for i in range(2, 6):\n",
    "    model_name = base+'_{}_conv'.format(i)\n",
    "    print()\n",
    "    print(model_name, 'Model')\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    model_filename = model_path + '000_last.hdf5'\n",
    "\n",
    "    model = load_model(model_filename)\n",
    "    model.summary()\n",
    "\n",
    "    [loss, accuracy] = model.evaluate(x_test, y_test)\n",
    "    print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "\n",
    "    del(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import os.path as path\n",
    "import itertools\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.layers import Input,InputLayer, Dense, Activation, BatchNormalization, Flatten, Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D, Dropout\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,LearningRateScheduler, \\\n",
    "                                        EarlyStopping\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.utils import to_categorical, multi_gpu_model, Sequence\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.load(path.join(data_dir, 'imagenet_6_class_172_train_data.npz'))\n",
    "val_data = np.load(path.join(data_dir, 'imagenet_6_class_172_val_data.npz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((235111, 172, 172, 3),\n",
       " (235111,),\n",
       " (3183, 172, 172, 3),\n",
       " (3183,),\n",
       " (3183, 172, 172, 3),\n",
       " (3183,),\n",
       " (6,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = train_data['x_data']\n",
    "y_train = train_data['y_data']\n",
    "x_val = val_data['x_data']\n",
    "y_val = val_data['y_data']\n",
    "x_test = x_val\n",
    "y_test = y_val\n",
    "y_list = val_data['y_list']\n",
    "\n",
    "x_train.shape, y_train.shape, x_val.shape, y_val.shape, x_test.shape, y_test.shape, y_list.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((235111, 172, 172, 3),\n",
       " (235111, 6),\n",
       " (3183, 172, 172, 3),\n",
       " (3183, 6),\n",
       " (3183, 172, 172, 3),\n",
       " (3183, 6))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = to_categorical(y_train)\n",
    "y_val = to_categorical(y_val)\n",
    "y_test = y_val\n",
    "\n",
    "x_train.shape, y_train.shape, x_val.shape, y_val.shape, x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = x_train[0].shape\n",
    "output_size = len(y_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_2d_cnn_custom_ch_64_DO(conv_num=1):\n",
    "    input_layer = Input(shape=input_shape)\n",
    "    x = input_layer\n",
    "\n",
    "    for i in range(conv_num):\n",
    "        x = Conv2D(kernel_size=5, filters=64*(2**(i//2)), strides=(1,1), padding='same')(x)\n",
    "#         x = BatchNormalization()(x)\n",
    "        x = Activation('relu')(x)\n",
    "        x = MaxPooling2D(pool_size=3, strides=(2,2), padding='same')(x)\n",
    "\n",
    "    x = Flatten()(x)\n",
    "  \n",
    "    x = Dropout(0.75)(x)\n",
    "    output_layer = Dense(output_size, activation='softmax')(x)\n",
    "    \n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 172, 172, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 172, 172, 64)      4864      \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 172, 172, 64)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 86, 86, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 473344)            0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 473344)            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 6)                 2840070   \n",
      "=================================================================\n",
      "Total params: 2,844,934\n",
      "Trainable params: 2,844,934\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 172, 172, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 172, 172, 64)      4864      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 172, 172, 64)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 86, 86, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 86, 86, 64)        102464    \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 86, 86, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 43, 43, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 118336)            0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 118336)            0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 6)                 710022    \n",
      "=================================================================\n",
      "Total params: 817,350\n",
      "Trainable params: 817,350\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 172, 172, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 172, 172, 64)      4864      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 172, 172, 64)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 86, 86, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 86, 86, 64)        102464    \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 86, 86, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 43, 43, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 43, 43, 128)       204928    \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 43, 43, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 22, 22, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 61952)             0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 61952)             0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 6)                 371718    \n",
      "=================================================================\n",
      "Total params: 683,974\n",
      "Trainable params: 683,974\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, 172, 172, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 172, 172, 64)      4864      \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 172, 172, 64)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 86, 86, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 86, 86, 64)        102464    \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 86, 86, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 43, 43, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 43, 43, 128)       204928    \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 43, 43, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 22, 22, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 22, 22, 128)       409728    \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 22, 22, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 11, 11, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 15488)             0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 15488)             0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 6)                 92934     \n",
      "=================================================================\n",
      "Total params: 814,918\n",
      "Trainable params: 814,918\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         (None, 172, 172, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 172, 172, 64)      4864      \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 172, 172, 64)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 86, 86, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 86, 86, 64)        102464    \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 86, 86, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 43, 43, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 43, 43, 128)       204928    \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 43, 43, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 22, 22, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 22, 22, 128)       409728    \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 22, 22, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 11, 11, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 11, 11, 256)       819456    \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 11, 11, 256)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 6, 6, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 9216)              0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 9216)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 6)                 55302     \n",
      "=================================================================\n",
      "Total params: 1,596,742\n",
      "Trainable params: 1,596,742\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         (None, 172, 172, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 172, 172, 64)      4864      \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 172, 172, 64)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling (None, 86, 86, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 86, 86, 64)        102464    \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 86, 86, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling (None, 43, 43, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 43, 43, 128)       204928    \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 43, 43, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_17 (MaxPooling (None, 22, 22, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 22, 22, 128)       409728    \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 22, 22, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_18 (MaxPooling (None, 11, 11, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 11, 11, 256)       819456    \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 11, 11, 256)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_19 (MaxPooling (None, 6, 6, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 6, 6, 256)         1638656   \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 6, 6, 256)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_20 (MaxPooling (None, 3, 3, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 6)                 13830     \n",
      "=================================================================\n",
      "Total params: 3,193,926\n",
      "Trainable params: 3,193,926\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_7 (InputLayer)         (None, 172, 172, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 172, 172, 64)      4864      \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 172, 172, 64)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_21 (MaxPooling (None, 86, 86, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_22 (Conv2D)           (None, 86, 86, 64)        102464    \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 86, 86, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_22 (MaxPooling (None, 43, 43, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 43, 43, 128)       204928    \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 43, 43, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_23 (MaxPooling (None, 22, 22, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_24 (Conv2D)           (None, 22, 22, 128)       409728    \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 22, 22, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_24 (MaxPooling (None, 11, 11, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_25 (Conv2D)           (None, 11, 11, 256)       819456    \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 11, 11, 256)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_25 (MaxPooling (None, 6, 6, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_26 (Conv2D)           (None, 6, 6, 256)         1638656   \n",
      "_________________________________________________________________\n",
      "activation_26 (Activation)   (None, 6, 6, 256)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_26 (MaxPooling (None, 3, 3, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_27 (Conv2D)           (None, 3, 3, 512)         3277312   \n",
      "_________________________________________________________________\n",
      "activation_27 (Activation)   (None, 3, 3, 512)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_27 (MaxPooling (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 6)                 12294     \n",
      "=================================================================\n",
      "Total params: 6,469,702\n",
      "Trainable params: 6,469,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 8):\n",
    "    model = build_2d_cnn_custom_ch_64_DO(conv_num=i)\n",
    "    model.summary()\n",
    "    del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BalanceDataGenerator(Sequence):\n",
    "    def __init__(self, x_data, y_data, batch_size, shuffle=True):\n",
    "        self.x_data = x_data\n",
    "        self.y_data = y_data\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.sample_size = int(np.sum(y_data, axis=0).min())\n",
    "        self.data_shape = x_data.shape[1:]\n",
    "        self.y_label = self.y_data.argmax(axis=1)\n",
    "        self.labels = np.unique(self.y_label)\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.labels) * self.sample_size / self.batch_size))\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        self.indexes = np.zeros((len(self.labels), self.sample_size))\n",
    "        for i, label in enumerate(self.labels):\n",
    "            y_index = np.argwhere(self.y_label==label).squeeze()\n",
    "            if self.shuffle == True:\n",
    "                self.indexes[i] = np.random.choice(y_index, \n",
    "                                   self.sample_size, \n",
    "                                   replace=False)\n",
    "            else:\n",
    "                self.indexes[i] = y_index[:self.sample_size]\n",
    "                \n",
    "        self.indexes = self.indexes.flatten().astype(np.int32)\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "                \n",
    "    def __getitem__(self, batch_idx):\n",
    "        indices = self.indexes[batch_idx*self.batch_size: (batch_idx+1)*self.batch_size]\n",
    "        return self.x_data[indices], self.y_data[indices]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 40\n",
    "data_generator = BalanceDataGenerator(x_train, y_train,\n",
    "                                      batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/10000\n",
      "241/242 [============================>.] - ETA: 0s - loss: 1.4185 - acc: 0.4188WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 37s 12ms/sample - loss: 1.2729 - acc: 0.5591\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.27287, saving model to model/checkpoint/vis_imagenet_6_class_augmentation_2D_CNN_custom_ch_64_DO_075_DO_3_conv_checkpoint/001-1.2729.hdf5\n",
      "242/242 [==============================] - 58s 238ms/step - loss: 1.4174 - acc: 0.4193 - val_loss: 1.2729 - val_acc: 0.5591\n",
      "Epoch 2/10000\n",
      "241/242 [============================>.] - ETA: 0s - loss: 1.1275 - acc: 0.5677WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 43s 14ms/sample - loss: 1.1862 - acc: 0.5297\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.27287 to 1.18617, saving model to model/checkpoint/vis_imagenet_6_class_augmentation_2D_CNN_custom_ch_64_DO_075_DO_3_conv_checkpoint/002-1.1862.hdf5\n",
      "242/242 [==============================] - 78s 322ms/step - loss: 1.1258 - acc: 0.5685 - val_loss: 1.1862 - val_acc: 0.5297\n",
      "Epoch 3/10000\n",
      "241/242 [============================>.] - ETA: 0s - loss: 1.0139 - acc: 0.6101WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 39s 12ms/sample - loss: 1.1651 - acc: 0.5447\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.18617 to 1.16507, saving model to model/checkpoint/vis_imagenet_6_class_augmentation_2D_CNN_custom_ch_64_DO_075_DO_3_conv_checkpoint/003-1.1651.hdf5\n",
      "242/242 [==============================] - 80s 330ms/step - loss: 1.0141 - acc: 0.6099 - val_loss: 1.1651 - val_acc: 0.5447\n",
      "Epoch 4/10000\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.9381 - acc: 0.6452WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 39s 12ms/sample - loss: 1.0189 - acc: 0.6203\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.16507 to 1.01893, saving model to model/checkpoint/vis_imagenet_6_class_augmentation_2D_CNN_custom_ch_64_DO_075_DO_3_conv_checkpoint/004-1.0189.hdf5\n",
      "242/242 [==============================] - 62s 258ms/step - loss: 0.9384 - acc: 0.6451 - val_loss: 1.0189 - val_acc: 0.6203\n",
      "Epoch 5/10000\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.8858 - acc: 0.6611WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 47s 15ms/sample - loss: 1.1697 - acc: 0.5275\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.01893\n",
      "242/242 [==============================] - 68s 280ms/step - loss: 0.8856 - acc: 0.6612 - val_loss: 1.1697 - val_acc: 0.5275\n",
      "Epoch 6/10000\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.8162 - acc: 0.6927WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 45s 14ms/sample - loss: 0.9344 - acc: 0.6506\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.01893 to 0.93438, saving model to model/checkpoint/vis_imagenet_6_class_augmentation_2D_CNN_custom_ch_64_DO_075_DO_3_conv_checkpoint/006-0.9344.hdf5\n",
      "242/242 [==============================] - 74s 306ms/step - loss: 0.8169 - acc: 0.6922 - val_loss: 0.9344 - val_acc: 0.6506\n",
      "Epoch 7/10000\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.7932 - acc: 0.6975WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 46s 14ms/sample - loss: 1.0907 - acc: 0.5556\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.93438\n",
      "242/242 [==============================] - 73s 301ms/step - loss: 0.7935 - acc: 0.6973 - val_loss: 1.0907 - val_acc: 0.5556\n",
      "Epoch 8/10000\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.7440 - acc: 0.7218WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 42s 13ms/sample - loss: 0.8855 - acc: 0.6500\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.93438 to 0.88555, saving model to model/checkpoint/vis_imagenet_6_class_augmentation_2D_CNN_custom_ch_64_DO_075_DO_3_conv_checkpoint/008-0.8855.hdf5\n",
      "242/242 [==============================] - 72s 296ms/step - loss: 0.7448 - acc: 0.7214 - val_loss: 0.8855 - val_acc: 0.6500\n",
      "Epoch 9/10000\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.7164 - acc: 0.7309WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 40s 12ms/sample - loss: 0.7353 - acc: 0.7316\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.88555 to 0.73527, saving model to model/checkpoint/vis_imagenet_6_class_augmentation_2D_CNN_custom_ch_64_DO_075_DO_3_conv_checkpoint/009-0.7353.hdf5\n",
      "242/242 [==============================] - 77s 316ms/step - loss: 0.7159 - acc: 0.7308 - val_loss: 0.7353 - val_acc: 0.7316\n",
      "Epoch 10/10000\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.7037 - acc: 0.7378WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 46s 14ms/sample - loss: 0.8654 - acc: 0.6600\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.73527\n",
      "242/242 [==============================] - 64s 265ms/step - loss: 0.7037 - acc: 0.7378 - val_loss: 0.8654 - val_acc: 0.6600\n",
      "Epoch 11/10000\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.6927 - acc: 0.7406WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 54s 17ms/sample - loss: 1.0506 - acc: 0.5575\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.73527\n",
      "242/242 [==============================] - 89s 370ms/step - loss: 0.6924 - acc: 0.7407 - val_loss: 1.0506 - val_acc: 0.5575\n",
      "Epoch 12/10000\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.6686 - acc: 0.7444WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 56s 17ms/sample - loss: 0.9723 - acc: 0.6250\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.73527\n",
      "242/242 [==============================] - 81s 337ms/step - loss: 0.6694 - acc: 0.7443 - val_loss: 0.9723 - val_acc: 0.6250\n",
      "Epoch 13/10000\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.6446 - acc: 0.7579WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 32s 10ms/sample - loss: 0.7577 - acc: 0.7169\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.73527\n",
      "242/242 [==============================] - 64s 264ms/step - loss: 0.6438 - acc: 0.7584 - val_loss: 0.7577 - val_acc: 0.7169\n",
      "Epoch 14/10000\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.6352 - acc: 0.7614WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3200/3183 [==============================] - 49s 15ms/sample - loss: 0.7074 - acc: 0.7400\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.73527 to 0.70739, saving model to model/checkpoint/vis_imagenet_6_class_augmentation_2D_CNN_custom_ch_64_DO_075_DO_3_conv_checkpoint/014-0.7074.hdf5\n",
      "242/242 [==============================] - 81s 333ms/step - loss: 0.6352 - acc: 0.7614 - val_loss: 0.7074 - val_acc: 0.7400\n",
      "Epoch 15/10000\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.6185 - acc: 0.7690WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 34s 11ms/sample - loss: 0.8684 - acc: 0.6675\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.70739\n",
      "242/242 [==============================] - 60s 250ms/step - loss: 0.6193 - acc: 0.7685 - val_loss: 0.8684 - val_acc: 0.6675\n",
      "Epoch 16/10000\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.6067 - acc: 0.7757WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 30s 9ms/sample - loss: 0.4959 - acc: 0.8269\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.70739 to 0.49586, saving model to model/checkpoint/vis_imagenet_6_class_augmentation_2D_CNN_custom_ch_64_DO_075_DO_3_conv_checkpoint/016-0.4959.hdf5\n",
      "242/242 [==============================] - 56s 233ms/step - loss: 0.6063 - acc: 0.7760 - val_loss: 0.4959 - val_acc: 0.8269\n",
      "Epoch 17/10000\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.6100 - acc: 0.7723WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3198/3183 [==============================] - 38s 12ms/sample - loss: 0.5279 - acc: 0.8102\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.49586\n",
      "242/242 [==============================] - 70s 287ms/step - loss: 0.6114 - acc: 0.7720 - val_loss: 0.5279 - val_acc: 0.8102\n",
      "Epoch 18/10000\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.5886 - acc: 0.7756WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 34s 11ms/sample - loss: 0.6899 - acc: 0.7412s - loss: 0.6590 - acc\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.49586\n",
      "242/242 [==============================] - 63s 258ms/step - loss: 0.5885 - acc: 0.7753 - val_loss: 0.6899 - val_acc: 0.7412\n",
      "Epoch 19/10000\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.5854 - acc: 0.7779WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 38s 12ms/sample - loss: 0.5586 - acc: 0.8131\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.49586\n",
      "242/242 [==============================] - 76s 314ms/step - loss: 0.5858 - acc: 0.7779 - val_loss: 0.5586 - val_acc: 0.8131\n",
      "Epoch 20/10000\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.5789 - acc: 0.7839WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 38s 12ms/sample - loss: 0.6183 - acc: 0.7825\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.49586\n",
      "242/242 [==============================] - 67s 279ms/step - loss: 0.5789 - acc: 0.7839 - val_loss: 0.6183 - val_acc: 0.7825\n",
      "Epoch 21/10000\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.5521 - acc: 0.7896WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 36s 11ms/sample - loss: 0.6005 - acc: 0.7700\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.49586\n",
      "242/242 [==============================] - 72s 297ms/step - loss: 0.5517 - acc: 0.7896 - val_loss: 0.6005 - val_acc: 0.7700\n",
      "Epoch 22/10000\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.5506 - acc: 0.7931WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 41s 13ms/sample - loss: 0.6835 - acc: 0.7450\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.49586\n",
      "242/242 [==============================] - 81s 335ms/step - loss: 0.5504 - acc: 0.7933 - val_loss: 0.6835 - val_acc: 0.7450\n",
      "Epoch 23/10000\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.5438 - acc: 0.7985WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 48s 15ms/sample - loss: 0.6848 - acc: 0.7500\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.49586\n",
      "242/242 [==============================] - 70s 290ms/step - loss: 0.5443 - acc: 0.7978 - val_loss: 0.6848 - val_acc: 0.7500\n",
      "Epoch 24/10000\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.5232 - acc: 0.8103WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 42s 13ms/sample - loss: 0.6728 - acc: 0.7700\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.49586\n",
      "242/242 [==============================] - 81s 334ms/step - loss: 0.5225 - acc: 0.8105 - val_loss: 0.6728 - val_acc: 0.7700\n",
      "Epoch 25/10000\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.5220 - acc: 0.8069WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 32s 10ms/sample - loss: 0.6971 - acc: 0.7375\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.49586\n",
      "242/242 [==============================] - 76s 315ms/step - loss: 0.5217 - acc: 0.8072 - val_loss: 0.6971 - val_acc: 0.7375\n",
      "Epoch 26/10000\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.5127 - acc: 0.8071WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 39s 12ms/sample - loss: 0.5945 - acc: 0.8025\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.49586\n",
      "242/242 [==============================] - 74s 307ms/step - loss: 0.5124 - acc: 0.8072 - val_loss: 0.5945 - val_acc: 0.8025\n",
      "Epoch 27/10000\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.4975 - acc: 0.8139WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 37s 11ms/sample - loss: 0.5161 - acc: 0.8200\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.49586\n",
      "242/242 [==============================] - 65s 270ms/step - loss: 0.4974 - acc: 0.8138 - val_loss: 0.5161 - val_acc: 0.8200\n",
      "Epoch 28/10000\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.4958 - acc: 0.8145WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 31s 10ms/sample - loss: 0.6948 - acc: 0.7494\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.49586\n",
      "242/242 [==============================] - 63s 259ms/step - loss: 0.4958 - acc: 0.8145 - val_loss: 0.6948 - val_acc: 0.7494\n",
      "Epoch 29/10000\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.4959 - acc: 0.8148WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3200/3183 [==============================] - 34s 11ms/sample - loss: 0.6655 - acc: 0.7556\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.49586\n",
      "242/242 [==============================] - 66s 274ms/step - loss: 0.4969 - acc: 0.8146 - val_loss: 0.6655 - val_acc: 0.7556\n",
      "Epoch 30/10000\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.4839 - acc: 0.8212WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 41s 13ms/sample - loss: 0.7126 - acc: 0.7525\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.49586\n",
      "242/242 [==============================] - 71s 295ms/step - loss: 0.4831 - acc: 0.8216 - val_loss: 0.7126 - val_acc: 0.7525\n",
      "Epoch 31/10000\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.4601 - acc: 0.8283WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 34s 11ms/sample - loss: 0.7422 - acc: 0.7250\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.49586\n",
      "242/242 [==============================] - 62s 257ms/step - loss: 0.4606 - acc: 0.8284 - val_loss: 0.7422 - val_acc: 0.7250\n",
      "Epoch 32/10000\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.4650 - acc: 0.8257WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 43s 14ms/sample - loss: 0.3645 - acc: 0.8797\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.49586 to 0.36449, saving model to model/checkpoint/vis_imagenet_6_class_augmentation_2D_CNN_custom_ch_64_DO_075_DO_3_conv_checkpoint/032-0.3645.hdf5\n",
      "242/242 [==============================] - 73s 301ms/step - loss: 0.4645 - acc: 0.8260 - val_loss: 0.3645 - val_acc: 0.8797\n",
      "Epoch 33/10000\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.4639 - acc: 0.8259WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 38s 12ms/sample - loss: 0.5147 - acc: 0.8125\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.36449\n",
      "242/242 [==============================] - 65s 270ms/step - loss: 0.4637 - acc: 0.8258 - val_loss: 0.5147 - val_acc: 0.8125\n",
      "Epoch 34/10000\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.4559 - acc: 0.8278WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 38s 12ms/sample - loss: 0.5885 - acc: 0.7875\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.36449\n",
      "242/242 [==============================] - 73s 301ms/step - loss: 0.4558 - acc: 0.8274 - val_loss: 0.5885 - val_acc: 0.7875\n",
      "Epoch 35/10000\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.4538 - acc: 0.8315WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 24s 8ms/sample - loss: 0.4019 - acc: 0.8775\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.36449\n",
      "242/242 [==============================] - 60s 248ms/step - loss: 0.4538 - acc: 0.8315 - val_loss: 0.4019 - val_acc: 0.8775\n",
      "Epoch 36/10000\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.4386 - acc: 0.8346WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 44s 14ms/sample - loss: 0.5456 - acc: 0.8128\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.36449\n",
      "242/242 [==============================] - 72s 296ms/step - loss: 0.4384 - acc: 0.8347 - val_loss: 0.5456 - val_acc: 0.8128\n",
      "Epoch 37/10000\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.4440 - acc: 0.8391WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 36s 11ms/sample - loss: 0.5821 - acc: 0.8000\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.36449\n",
      "242/242 [==============================] - 68s 283ms/step - loss: 0.4432 - acc: 0.8394 - val_loss: 0.5821 - val_acc: 0.8000\n",
      "Epoch 38/10000\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.4267 - acc: 0.8401WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 38s 12ms/sample - loss: 0.3814 - acc: 0.8600\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.36449\n",
      "242/242 [==============================] - 67s 275ms/step - loss: 0.4271 - acc: 0.8402 - val_loss: 0.3814 - val_acc: 0.8600\n",
      "Epoch 39/10000\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.4275 - acc: 0.8389WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 30s 9ms/sample - loss: 0.4816 - acc: 0.8275\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.36449\n",
      "242/242 [==============================] - 52s 214ms/step - loss: 0.4275 - acc: 0.8390 - val_loss: 0.4816 - val_acc: 0.8275\n",
      "Epoch 40/10000\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.4218 - acc: 0.8405WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 32s 10ms/sample - loss: 0.5137 - acc: 0.8259\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.36449\n",
      "242/242 [==============================] - 71s 295ms/step - loss: 0.4220 - acc: 0.8407 - val_loss: 0.5137 - val_acc: 0.8259\n",
      "Epoch 41/10000\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.4278 - acc: 0.8408WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 53s 17ms/sample - loss: 0.3719 - acc: 0.8647\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.36449\n",
      "242/242 [==============================] - 90s 374ms/step - loss: 0.4279 - acc: 0.8409 - val_loss: 0.3719 - val_acc: 0.8647\n",
      "Epoch 42/10000\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.4153 - acc: 0.8446WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 39s 12ms/sample - loss: 0.3888 - acc: 0.8650\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.36449\n",
      "242/242 [==============================] - 64s 264ms/step - loss: 0.4154 - acc: 0.8447 - val_loss: 0.3888 - val_acc: 0.8650\n",
      "Epoch 43/10000\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.4234 - acc: 0.8445WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 37s 11ms/sample - loss: 0.2622 - acc: 0.9219\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.36449 to 0.26223, saving model to model/checkpoint/vis_imagenet_6_class_augmentation_2D_CNN_custom_ch_64_DO_075_DO_3_conv_checkpoint/043-0.2622.hdf5\n",
      "242/242 [==============================] - 72s 297ms/step - loss: 0.4245 - acc: 0.8442 - val_loss: 0.2622 - val_acc: 0.9219\n",
      "Epoch 44/10000\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.4077 - acc: 0.8504WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3200/3183 [==============================] - 41s 13ms/sample - loss: 0.4959 - acc: 0.8400\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.26223\n",
      "242/242 [==============================] - 67s 276ms/step - loss: 0.4089 - acc: 0.8504 - val_loss: 0.4959 - val_acc: 0.8400\n",
      "Epoch 45/10000\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.4098 - acc: 0.8496WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 38s 12ms/sample - loss: 0.4368 - acc: 0.8481\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.26223\n",
      "242/242 [==============================] - 66s 272ms/step - loss: 0.4104 - acc: 0.8494 - val_loss: 0.4368 - val_acc: 0.8481\n",
      "Epoch 46/10000\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.3910 - acc: 0.8529WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 40s 13ms/sample - loss: 0.4479 - acc: 0.8528\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.26223\n",
      "242/242 [==============================] - 60s 249ms/step - loss: 0.3903 - acc: 0.8533 - val_loss: 0.4479 - val_acc: 0.8528\n",
      "Epoch 47/10000\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.3912 - acc: 0.8575WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 38s 12ms/sample - loss: 0.4051 - acc: 0.8650\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.26223\n",
      "242/242 [==============================] - 70s 291ms/step - loss: 0.3916 - acc: 0.8571 - val_loss: 0.4051 - val_acc: 0.8650\n",
      "Epoch 48/10000\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.3793 - acc: 0.8607WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 31s 10ms/sample - loss: 0.4935 - acc: 0.8284\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.26223\n",
      "242/242 [==============================] - 72s 298ms/step - loss: 0.3794 - acc: 0.8605 - val_loss: 0.4935 - val_acc: 0.8284\n",
      "Epoch 49/10000\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.3886 - acc: 0.8539WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 42s 13ms/sample - loss: 0.6657 - acc: 0.7700\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.26223\n",
      "242/242 [==============================] - 81s 337ms/step - loss: 0.3898 - acc: 0.8534 - val_loss: 0.6657 - val_acc: 0.7700\n",
      "Epoch 50/10000\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.3998 - acc: 0.8549WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 40s 13ms/sample - loss: 0.3797 - acc: 0.8625\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.26223\n",
      "242/242 [==============================] - 63s 260ms/step - loss: 0.4001 - acc: 0.8545 - val_loss: 0.3797 - val_acc: 0.8625\n",
      "Epoch 51/10000\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.3742 - acc: 0.8647WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 30s 9ms/sample - loss: 0.3296 - acc: 0.8900\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.26223\n",
      "242/242 [==============================] - 60s 249ms/step - loss: 0.3750 - acc: 0.8644 - val_loss: 0.3296 - val_acc: 0.8900\n",
      "Epoch 52/10000\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.3863 - acc: 0.8538WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 41s 13ms/sample - loss: 0.4514 - acc: 0.8425\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.26223\n",
      "242/242 [==============================] - 81s 334ms/step - loss: 0.3857 - acc: 0.8539 - val_loss: 0.4514 - val_acc: 0.8425\n",
      "Epoch 53/10000\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.3740 - acc: 0.8615- ETA: 1s - loss: 0.3760 - WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 30s 9ms/sample - loss: 0.4215 - acc: 0.8575\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.26223\n",
      "242/242 [==============================] - 59s 244ms/step - loss: 0.3741 - acc: 0.8613 - val_loss: 0.4215 - val_acc: 0.8575\n",
      "Epoch 54/10000\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.3676 - acc: 0.8622WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 39s 12ms/sample - loss: 0.3219 - acc: 0.8875\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.26223\n",
      "242/242 [==============================] - 63s 261ms/step - loss: 0.3671 - acc: 0.8625 - val_loss: 0.3219 - val_acc: 0.8875\n",
      "Epoch 55/10000\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.3638 - acc: 0.8654WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 36s 11ms/sample - loss: 0.4296 - acc: 0.8319\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.26223\n",
      "242/242 [==============================] - 65s 270ms/step - loss: 0.3636 - acc: 0.8655 - val_loss: 0.4296 - val_acc: 0.8319\n",
      "Epoch 56/10000\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.3566 - acc: 0.8680WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 41s 13ms/sample - loss: 0.4460 - acc: 0.8469\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.26223\n",
      "242/242 [==============================] - 69s 286ms/step - loss: 0.3569 - acc: 0.8679 - val_loss: 0.4460 - val_acc: 0.8469\n",
      "Epoch 57/10000\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.3504 - acc: 0.8733WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 38s 12ms/sample - loss: 0.4042 - acc: 0.8575\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.26223\n",
      "242/242 [==============================] - 70s 290ms/step - loss: 0.3500 - acc: 0.8733 - val_loss: 0.4042 - val_acc: 0.8575\n",
      "Epoch 58/10000\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.3608 - acc: 0.8671WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 36s 11ms/sample - loss: 0.4179 - acc: 0.8506 3:02 - loss: \n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.26223\n",
      "242/242 [==============================] - 56s 231ms/step - loss: 0.3603 - acc: 0.8674 - val_loss: 0.4179 - val_acc: 0.8506\n",
      "Epoch 59/10000\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.3558 - acc: 0.8696WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 49s 15ms/sample - loss: 0.4174 - acc: 0.8619\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.26223\n",
      "242/242 [==============================] - 87s 358ms/step - loss: 0.3556 - acc: 0.8696 - val_loss: 0.4174 - val_acc: 0.8619\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/10000\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.3563 - acc: 0.8728WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 43s 13ms/sample - loss: 0.4810 - acc: 0.8325\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.26223\n",
      "242/242 [==============================] - 73s 303ms/step - loss: 0.3564 - acc: 0.8729 - val_loss: 0.4810 - val_acc: 0.8325\n",
      "Epoch 61/10000\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.3489 - acc: 0.8696WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 41s 13ms/sample - loss: 0.4365 - acc: 0.8444\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.26223\n",
      "242/242 [==============================] - 74s 307ms/step - loss: 0.3487 - acc: 0.8697 - val_loss: 0.4365 - val_acc: 0.8444\n",
      "Epoch 62/10000\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.3509 - acc: 0.8745WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 46s 14ms/sample - loss: 0.3318 - acc: 0.8875\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.26223\n",
      "242/242 [==============================] - 87s 360ms/step - loss: 0.3508 - acc: 0.8745 - val_loss: 0.3318 - val_acc: 0.8875\n",
      "Epoch 63/10000\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.3450 - acc: 0.8729WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 47s 15ms/sample - loss: 0.3699 - acc: 0.8650\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.26223\n",
      "242/242 [==============================] - 77s 318ms/step - loss: 0.3447 - acc: 0.8732 - val_loss: 0.3699 - val_acc: 0.8650\n",
      "Epoch 64/10000\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.3489 - acc: 0.8740WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 57s 18ms/sample - loss: 0.4266 - acc: 0.8600\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.26223\n",
      "242/242 [==============================] - 86s 354ms/step - loss: 0.3486 - acc: 0.8741 - val_loss: 0.4266 - val_acc: 0.8600\n",
      "Epoch 65/10000\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.3593 - acc: 0.8678WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 43s 13ms/sample - loss: 0.3829 - acc: 0.8675\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.26223\n",
      "242/242 [==============================] - 76s 314ms/step - loss: 0.3591 - acc: 0.8677 - val_loss: 0.3829 - val_acc: 0.8675\n",
      "Epoch 66/10000\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.3276 - acc: 0.8786WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 38s 12ms/sample - loss: 0.4831 - acc: 0.8434\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.26223\n",
      "242/242 [==============================] - 77s 318ms/step - loss: 0.3273 - acc: 0.8788 - val_loss: 0.4831 - val_acc: 0.8434\n",
      "Epoch 67/10000\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.3398 - acc: 0.8776WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 55s 17ms/sample - loss: 0.3505 - acc: 0.8850\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.26223\n",
      "242/242 [==============================] - 92s 379ms/step - loss: 0.3397 - acc: 0.8775 - val_loss: 0.3505 - val_acc: 0.8850\n",
      "Epoch 68/10000\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.3239 - acc: 0.8815WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 37s 12ms/sample - loss: 0.4919 - acc: 0.8275\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.26223\n",
      "242/242 [==============================] - 73s 302ms/step - loss: 0.3238 - acc: 0.8816 - val_loss: 0.4919 - val_acc: 0.8275\n",
      "Epoch 69/10000\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.3260 - acc: 0.8802WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 54s 17ms/sample - loss: 0.3895 - acc: 0.8575\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.26223\n",
      "242/242 [==============================] - 93s 385ms/step - loss: 0.3260 - acc: 0.8802 - val_loss: 0.3895 - val_acc: 0.8575\n",
      "Epoch 70/10000\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.3312 - acc: 0.8771WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 46s 14ms/sample - loss: 0.3118 - acc: 0.8959\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.26223\n",
      "242/242 [==============================] - 82s 341ms/step - loss: 0.3315 - acc: 0.8769 - val_loss: 0.3118 - val_acc: 0.8959\n",
      "Epoch 71/10000\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.3249 - acc: 0.8809WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 47s 15ms/sample - loss: 0.3180 - acc: 0.8884\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.26223\n",
      "242/242 [==============================] - 75s 311ms/step - loss: 0.3255 - acc: 0.8807 - val_loss: 0.3180 - val_acc: 0.8884\n",
      "Epoch 72/10000\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.3102 - acc: 0.8880WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 35s 11ms/sample - loss: 0.3529 - acc: 0.8825\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.26223\n",
      "242/242 [==============================] - 80s 330ms/step - loss: 0.3109 - acc: 0.8876 - val_loss: 0.3529 - val_acc: 0.8825\n",
      "Epoch 73/10000\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.3187 - acc: 0.8826WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 39s 12ms/sample - loss: 0.4542 - acc: 0.8450\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.26223\n",
      "242/242 [==============================] - 63s 258ms/step - loss: 0.3183 - acc: 0.8828 - val_loss: 0.4542 - val_acc: 0.8450\n",
      "Epoch 74/10000\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.3162 - acc: 0.8821WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 57s 18ms/sample - loss: 0.3535 - acc: 0.8859\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.26223\n",
      "242/242 [==============================] - 88s 363ms/step - loss: 0.3168 - acc: 0.8819 - val_loss: 0.3535 - val_acc: 0.8859\n",
      "Epoch 75/10000\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.3125 - acc: 0.8838WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3200/3183 [==============================] - 42s 13ms/sample - loss: 0.4288 - acc: 0.8562\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.26223\n",
      "242/242 [==============================] - 76s 316ms/step - loss: 0.3129 - acc: 0.8835 - val_loss: 0.4288 - val_acc: 0.8562\n",
      "Epoch 76/10000\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.3128 - acc: 0.8848WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 44s 14ms/sample - loss: 0.3615 - acc: 0.8775\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.26223\n",
      "242/242 [==============================] - 82s 340ms/step - loss: 0.3128 - acc: 0.8848 - val_loss: 0.3615 - val_acc: 0.8775\n",
      "Epoch 77/10000\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.3094 - acc: 0.8869WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 47s 15ms/sample - loss: 0.3018 - acc: 0.8884\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.26223\n",
      "242/242 [==============================] - 74s 306ms/step - loss: 0.3086 - acc: 0.8872 - val_loss: 0.3018 - val_acc: 0.8884\n",
      "Epoch 78/10000\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.3152 - acc: 0.8843WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 33s 10ms/sample - loss: 0.3671 - acc: 0.8831\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.26223\n",
      "242/242 [==============================] - 82s 338ms/step - loss: 0.3153 - acc: 0.8843 - val_loss: 0.3671 - val_acc: 0.8831\n",
      "Epoch 79/10000\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.3165 - acc: 0.8831WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 36s 11ms/sample - loss: 0.3950 - acc: 0.8603\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.26223\n",
      "242/242 [==============================] - 71s 295ms/step - loss: 0.3169 - acc: 0.8830 - val_loss: 0.3950 - val_acc: 0.8603\n",
      "Epoch 80/10000\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.3206 - acc: 0.8815WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 48s 15ms/sample - loss: 0.2756 - acc: 0.9056\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.26223\n",
      "242/242 [==============================] - 81s 334ms/step - loss: 0.3213 - acc: 0.8810 - val_loss: 0.2756 - val_acc: 0.9056\n",
      "Epoch 81/10000\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.3157 - acc: 0.8846WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 31s 10ms/sample - loss: 0.4104 - acc: 0.8525\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.26223\n",
      "242/242 [==============================] - 65s 267ms/step - loss: 0.3157 - acc: 0.8843 - val_loss: 0.4104 - val_acc: 0.8525\n",
      "Epoch 82/10000\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.3122 - acc: 0.8868WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 44s 14ms/sample - loss: 0.3579 - acc: 0.8775\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.26223\n",
      "242/242 [==============================] - 74s 304ms/step - loss: 0.3120 - acc: 0.8868 - val_loss: 0.3579 - val_acc: 0.8775\n",
      "Epoch 83/10000\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.2980 - acc: 0.8875WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 43s 14ms/sample - loss: 0.4524 - acc: 0.8512\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.26223\n",
      "242/242 [==============================] - 61s 254ms/step - loss: 0.2975 - acc: 0.8878 - val_loss: 0.4524 - val_acc: 0.8512\n",
      "Epoch 84/10000\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.3006 - acc: 0.8906WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 37s 12ms/sample - loss: 0.4372 - acc: 0.8519\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.26223\n",
      "242/242 [==============================] - 60s 246ms/step - loss: 0.3004 - acc: 0.8905 - val_loss: 0.4372 - val_acc: 0.8519\n",
      "Epoch 85/10000\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.3088 - acc: 0.8865WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 43s 13ms/sample - loss: 0.4184 - acc: 0.8425\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.26223\n",
      "242/242 [==============================] - 85s 352ms/step - loss: 0.3087 - acc: 0.8864 - val_loss: 0.4184 - val_acc: 0.8425\n",
      "Epoch 86/10000\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.2990 - acc: 0.8908WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 34s 11ms/sample - loss: 0.2751 - acc: 0.9128\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.26223\n",
      "242/242 [==============================] - 69s 285ms/step - loss: 0.2991 - acc: 0.8909 - val_loss: 0.2751 - val_acc: 0.9128\n",
      "Epoch 87/10000\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.2982 - acc: 0.8909WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 38s 12ms/sample - loss: 0.2549 - acc: 0.9109\n",
      "\n",
      "Epoch 00087: val_loss improved from 0.26223 to 0.25493, saving model to model/checkpoint/vis_imagenet_6_class_augmentation_2D_CNN_custom_ch_64_DO_075_DO_3_conv_checkpoint/087-0.2549.hdf5\n",
      "242/242 [==============================] - 76s 314ms/step - loss: 0.2975 - acc: 0.8914 - val_loss: 0.2549 - val_acc: 0.9109\n",
      "Epoch 88/10000\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.2973 - acc: 0.8915WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 34s 11ms/sample - loss: 0.3131 - acc: 0.8969\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.25493\n",
      "242/242 [==============================] - 81s 335ms/step - loss: 0.2972 - acc: 0.8917 - val_loss: 0.3131 - val_acc: 0.8969\n",
      "Epoch 89/10000\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.2933 - acc: 0.8906WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 51s 16ms/sample - loss: 0.3387 - acc: 0.8900\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.25493\n",
      "242/242 [==============================] - 81s 334ms/step - loss: 0.2941 - acc: 0.8903 - val_loss: 0.3387 - val_acc: 0.8900\n",
      "Epoch 90/10000\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.2790 - acc: 0.8990WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 38s 12ms/sample - loss: 0.2926 - acc: 0.9050\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.25493\n",
      "242/242 [==============================] - 84s 347ms/step - loss: 0.2791 - acc: 0.8989 - val_loss: 0.2926 - val_acc: 0.9050\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91/10000\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.3015 - acc: 0.8909WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 44s 14ms/sample - loss: 0.3406 - acc: 0.8859\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.25493\n",
      "242/242 [==============================] - 72s 296ms/step - loss: 0.3016 - acc: 0.8910 - val_loss: 0.3406 - val_acc: 0.8859\n",
      "Epoch 92/10000\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.2829 - acc: 0.8973WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 42s 13ms/sample - loss: 0.5169 - acc: 0.8225\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.25493\n",
      "242/242 [==============================] - 78s 320ms/step - loss: 0.2825 - acc: 0.8975 - val_loss: 0.5169 - val_acc: 0.8225\n",
      "Epoch 93/10000\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.2892 - acc: 0.8984WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 34s 10ms/sample - loss: 0.3011 - acc: 0.8950\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.25493\n",
      "242/242 [==============================] - 69s 286ms/step - loss: 0.2899 - acc: 0.8982 - val_loss: 0.3011 - val_acc: 0.8950\n",
      "Epoch 94/10000\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.2784 - acc: 0.8995WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 37s 11ms/sample - loss: 0.6324 - acc: 0.7850\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.25493\n",
      "242/242 [==============================] - 73s 302ms/step - loss: 0.2789 - acc: 0.8993 - val_loss: 0.6324 - val_acc: 0.7850\n",
      "Epoch 95/10000\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.2749 - acc: 0.8972WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 40s 12ms/sample - loss: 0.3253 - acc: 0.8850\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.25493\n",
      "242/242 [==============================] - 68s 280ms/step - loss: 0.2743 - acc: 0.8975 - val_loss: 0.3253 - val_acc: 0.8850\n",
      "Epoch 96/10000\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.2831 - acc: 0.8985WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 36s 11ms/sample - loss: 0.3380 - acc: 0.8794\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.25493\n",
      "242/242 [==============================] - 72s 299ms/step - loss: 0.2825 - acc: 0.8988 - val_loss: 0.3380 - val_acc: 0.8794\n",
      "Epoch 97/10000\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.2748 - acc: 0.9018WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 47s 15ms/sample - loss: 0.4240 - acc: 0.8600\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.25493\n",
      "242/242 [==============================] - 75s 308ms/step - loss: 0.2743 - acc: 0.9019 - val_loss: 0.4240 - val_acc: 0.8600\n",
      "Epoch 98/10000\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.2821 - acc: 0.8972WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 36s 11ms/sample - loss: 0.4260 - acc: 0.8550\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.25493\n",
      "242/242 [==============================] - 72s 299ms/step - loss: 0.2819 - acc: 0.8974 - val_loss: 0.4260 - val_acc: 0.8550\n",
      "Epoch 99/10000\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.2831 - acc: 0.8958WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 32s 10ms/sample - loss: 0.3343 - acc: 0.8750\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.25493\n",
      "242/242 [==============================] - 54s 224ms/step - loss: 0.2826 - acc: 0.8958 - val_loss: 0.3343 - val_acc: 0.8750\n",
      "Epoch 100/10000\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.2670 - acc: 0.9021WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 46s 14ms/sample - loss: 0.3658 - acc: 0.8775\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.25493\n",
      "242/242 [==============================] - 86s 354ms/step - loss: 0.2671 - acc: 0.9019 - val_loss: 0.3658 - val_acc: 0.8775\n",
      "Epoch 101/10000\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.2721 - acc: 0.9031WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 43s 13ms/sample - loss: 0.4072 - acc: 0.8606\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 0.25493\n",
      "242/242 [==============================] - 75s 309ms/step - loss: 0.2715 - acc: 0.9034 - val_loss: 0.4072 - val_acc: 0.8606\n",
      "Epoch 102/10000\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.2619 - acc: 0.9049WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 39s 12ms/sample - loss: 0.2684 - acc: 0.9050\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 0.25493\n",
      "242/242 [==============================] - 77s 319ms/step - loss: 0.2615 - acc: 0.9051 - val_loss: 0.2684 - val_acc: 0.9050\n",
      "Epoch 103/10000\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.2709 - acc: 0.8994WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 41s 13ms/sample - loss: 0.2928 - acc: 0.9000\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 0.25493\n",
      "242/242 [==============================] - 63s 260ms/step - loss: 0.2721 - acc: 0.8990 - val_loss: 0.2928 - val_acc: 0.9000\n",
      "Epoch 104/10000\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.2737 - acc: 0.9016WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 45s 14ms/sample - loss: 0.3924 - acc: 0.8691\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 0.25493\n",
      "242/242 [==============================] - 78s 322ms/step - loss: 0.2737 - acc: 0.9018 - val_loss: 0.3924 - val_acc: 0.8691\n",
      "Epoch 105/10000\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.2671 - acc: 0.9029WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 49s 15ms/sample - loss: 0.3100 - acc: 0.8959\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 0.25493\n",
      "242/242 [==============================] - 81s 334ms/step - loss: 0.2669 - acc: 0.9030 - val_loss: 0.3100 - val_acc: 0.8959\n",
      "Epoch 106/10000\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.2690 - acc: 0.9031WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3200/3183 [==============================] - 40s 12ms/sample - loss: 0.4013 - acc: 0.8550\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 0.25493\n",
      "242/242 [==============================] - 70s 290ms/step - loss: 0.2682 - acc: 0.9034 - val_loss: 0.4013 - val_acc: 0.8550\n",
      "Epoch 107/10000\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.2654 - acc: 0.9046WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 33s 10ms/sample - loss: 0.3780 - acc: 0.8725\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 0.25493\n",
      "242/242 [==============================] - 54s 223ms/step - loss: 0.2660 - acc: 0.9042 - val_loss: 0.3780 - val_acc: 0.8725\n",
      "Epoch 108/10000\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.2677 - acc: 0.9027WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 40s 13ms/sample - loss: 0.3000 - acc: 0.9125\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 0.25493\n",
      "242/242 [==============================] - 82s 341ms/step - loss: 0.2673 - acc: 0.9028 - val_loss: 0.3000 - val_acc: 0.9125\n",
      "Epoch 109/10000\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.2712 - acc: 0.8963WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 40s 12ms/sample - loss: 0.2862 - acc: 0.9000\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 0.25493\n",
      "242/242 [==============================] - 58s 241ms/step - loss: 0.2713 - acc: 0.8964 - val_loss: 0.2862 - val_acc: 0.9000\n",
      "Epoch 110/10000\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.2564 - acc: 0.9070WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 41s 13ms/sample - loss: 0.2959 - acc: 0.8900\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 0.25493\n",
      "242/242 [==============================] - 71s 293ms/step - loss: 0.2560 - acc: 0.9070 - val_loss: 0.2959 - val_acc: 0.8900\n",
      "Epoch 111/10000\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.2677 - acc: 0.9041WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 39s 12ms/sample - loss: 0.3414 - acc: 0.8838\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 0.25493\n",
      "242/242 [==============================] - 83s 343ms/step - loss: 0.2671 - acc: 0.9044 - val_loss: 0.3414 - val_acc: 0.8838\n",
      "Epoch 112/10000\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.2683 - acc: 0.9028WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 38s 12ms/sample - loss: 0.3597 - acc: 0.8653\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 0.25493\n",
      "242/242 [==============================] - 79s 328ms/step - loss: 0.2686 - acc: 0.9028 - val_loss: 0.3597 - val_acc: 0.8653\n",
      "Epoch 113/10000\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.2652 - acc: 0.9037WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 35s 11ms/sample - loss: 0.3606 - acc: 0.8700\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 0.25493\n",
      "242/242 [==============================] - 76s 315ms/step - loss: 0.2651 - acc: 0.9039 - val_loss: 0.3606 - val_acc: 0.8700\n",
      "Epoch 114/10000\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.2568 - acc: 0.9045WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 36s 11ms/sample - loss: 0.4393 - acc: 0.8462\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 0.25493\n",
      "242/242 [==============================] - 65s 269ms/step - loss: 0.2564 - acc: 0.9046 - val_loss: 0.4393 - val_acc: 0.8462\n",
      "Epoch 115/10000\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.2422 - acc: 0.9099WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 37s 11ms/sample - loss: 0.3632 - acc: 0.8750\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 0.25493\n",
      "242/242 [==============================] - 53s 218ms/step - loss: 0.2421 - acc: 0.9099 - val_loss: 0.3632 - val_acc: 0.8750\n",
      "Epoch 116/10000\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.2481 - acc: 0.9095WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 44s 14ms/sample - loss: 0.2597 - acc: 0.9075\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 0.25493\n",
      "242/242 [==============================] - 80s 330ms/step - loss: 0.2490 - acc: 0.9092 - val_loss: 0.2597 - val_acc: 0.9075\n",
      "Epoch 117/10000\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.2540 - acc: 0.9100WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 42s 13ms/sample - loss: 0.4248 - acc: 0.8550\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 0.25493\n",
      "242/242 [==============================] - 62s 257ms/step - loss: 0.2536 - acc: 0.9103 - val_loss: 0.4248 - val_acc: 0.8550\n",
      "Epoch 118/10000\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.2552 - acc: 0.9092WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 43s 13ms/sample - loss: 0.3293 - acc: 0.8859\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 0.25493\n",
      "242/242 [==============================] - 68s 279ms/step - loss: 0.2550 - acc: 0.9094 - val_loss: 0.3293 - val_acc: 0.8859\n",
      "Epoch 119/10000\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.2470 - acc: 0.9068WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 35s 11ms/sample - loss: 0.3818 - acc: 0.8731\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 0.25493\n",
      "242/242 [==============================] - 59s 242ms/step - loss: 0.2476 - acc: 0.9065 - val_loss: 0.3818 - val_acc: 0.8731\n",
      "Epoch 120/10000\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.2463 - acc: 0.9122WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 36s 11ms/sample - loss: 0.3365 - acc: 0.8925\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 0.25493\n",
      "242/242 [==============================] - 64s 263ms/step - loss: 0.2463 - acc: 0.9123 - val_loss: 0.3365 - val_acc: 0.8925\n",
      "Epoch 121/10000\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.2668 - acc: 0.9027WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 37s 12ms/sample - loss: 0.3593 - acc: 0.8819\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 0.25493\n",
      "242/242 [==============================] - 77s 319ms/step - loss: 0.2672 - acc: 0.9026 - val_loss: 0.3593 - val_acc: 0.8819\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 122/10000\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.2484 - acc: 0.9109WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 42s 13ms/sample - loss: 0.2464 - acc: 0.9284\n",
      "\n",
      "Epoch 00122: val_loss improved from 0.25493 to 0.24645, saving model to model/checkpoint/vis_imagenet_6_class_augmentation_2D_CNN_custom_ch_64_DO_075_DO_3_conv_checkpoint/122-0.2464.hdf5\n",
      "242/242 [==============================] - 61s 250ms/step - loss: 0.2488 - acc: 0.9106 - val_loss: 0.2464 - val_acc: 0.9284\n",
      "Epoch 123/10000\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.2504 - acc: 0.9095WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 31s 10ms/sample - loss: 0.3874 - acc: 0.8763\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 0.24645\n",
      "242/242 [==============================] - 70s 290ms/step - loss: 0.2503 - acc: 0.9096 - val_loss: 0.3874 - val_acc: 0.8763\n",
      "Epoch 124/10000\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.2533 - acc: 0.9062WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 45s 14ms/sample - loss: 0.2362 - acc: 0.9175\n",
      "\n",
      "Epoch 00124: val_loss improved from 0.24645 to 0.23620, saving model to model/checkpoint/vis_imagenet_6_class_augmentation_2D_CNN_custom_ch_64_DO_075_DO_3_conv_checkpoint/124-0.2362.hdf5\n",
      "242/242 [==============================] - 73s 303ms/step - loss: 0.2527 - acc: 0.9065 - val_loss: 0.2362 - val_acc: 0.9175\n",
      "Epoch 125/10000\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.2382 - acc: 0.9101WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 41s 13ms/sample - loss: 0.2744 - acc: 0.9000\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 0.23620\n",
      "242/242 [==============================] - 79s 326ms/step - loss: 0.2381 - acc: 0.9101 - val_loss: 0.2744 - val_acc: 0.9000\n",
      "Epoch 126/10000\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.2444 - acc: 0.9114WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 38s 12ms/sample - loss: 0.3578 - acc: 0.8800\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 0.23620\n",
      "242/242 [==============================] - 103s 427ms/step - loss: 0.2440 - acc: 0.9116 - val_loss: 0.3578 - val_acc: 0.8800\n",
      "Epoch 127/10000\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.2439 - acc: 0.9133WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 38s 12ms/sample - loss: 0.3719 - acc: 0.8750\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 0.23620\n",
      "242/242 [==============================] - 62s 256ms/step - loss: 0.2441 - acc: 0.9131 - val_loss: 0.3719 - val_acc: 0.8750\n",
      "Epoch 128/10000\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.2321 - acc: 0.9172WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 52s 16ms/sample - loss: 0.3273 - acc: 0.8900\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 0.23620\n",
      "242/242 [==============================] - 86s 354ms/step - loss: 0.2325 - acc: 0.9170 - val_loss: 0.3273 - val_acc: 0.8900\n",
      "Epoch 129/10000\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.2439 - acc: 0.9141WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 36s 11ms/sample - loss: 0.4086 - acc: 0.8662\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 0.23620\n",
      "242/242 [==============================] - 67s 277ms/step - loss: 0.2440 - acc: 0.9140 - val_loss: 0.4086 - val_acc: 0.8662\n",
      "Epoch 130/10000\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.2429 - acc: 0.9098WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 38s 12ms/sample - loss: 0.2589 - acc: 0.9062\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 0.23620\n",
      "242/242 [==============================] - 76s 313ms/step - loss: 0.2428 - acc: 0.9098 - val_loss: 0.2589 - val_acc: 0.9062\n",
      "Epoch 131/10000\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.2547 - acc: 0.9077WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 46s 14ms/sample - loss: 0.3069 - acc: 0.8934\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 0.23620\n",
      "242/242 [==============================] - 76s 313ms/step - loss: 0.2549 - acc: 0.9077 - val_loss: 0.3069 - val_acc: 0.8934\n",
      "Epoch 132/10000\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.2389 - acc: 0.9135WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 42s 13ms/sample - loss: 0.3685 - acc: 0.8587\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 0.23620\n",
      "242/242 [==============================] - 80s 329ms/step - loss: 0.2389 - acc: 0.9136 - val_loss: 0.3685 - val_acc: 0.8587\n",
      "Epoch 133/10000\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.2439 - acc: 0.9112WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 42s 13ms/sample - loss: 0.4170 - acc: 0.85413s - loss:\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 0.23620\n",
      "242/242 [==============================] - 76s 312ms/step - loss: 0.2440 - acc: 0.9110 - val_loss: 0.4170 - val_acc: 0.8541\n",
      "Epoch 134/10000\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.2423 - acc: 0.9103WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 46s 14ms/sample - loss: 0.3394 - acc: 0.8859\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 0.23620\n",
      "242/242 [==============================] - 87s 361ms/step - loss: 0.2421 - acc: 0.9104 - val_loss: 0.3394 - val_acc: 0.8859\n",
      "Epoch 135/10000\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.2409 - acc: 0.9130WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 29s 9ms/sample - loss: 0.3577 - acc: 0.8781\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 0.23620\n",
      "242/242 [==============================] - 72s 297ms/step - loss: 0.2407 - acc: 0.9131 - val_loss: 0.3577 - val_acc: 0.8781\n",
      "Epoch 136/10000\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.2434 - acc: 0.9120WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 42s 13ms/sample - loss: 0.3204 - acc: 0.9025\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 0.23620\n",
      "242/242 [==============================] - 75s 310ms/step - loss: 0.2437 - acc: 0.9119 - val_loss: 0.3204 - val_acc: 0.9025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 137/10000\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.2291 - acc: 0.9130WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 35s 11ms/sample - loss: 0.3487 - acc: 0.8894\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 0.23620\n",
      "242/242 [==============================] - 91s 374ms/step - loss: 0.2292 - acc: 0.9127 - val_loss: 0.3487 - val_acc: 0.8894\n",
      "Epoch 138/10000\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.2255 - acc: 0.9190WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 36s 11ms/sample - loss: 0.3191 - acc: 0.8800\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 0.23620\n",
      "242/242 [==============================] - 84s 348ms/step - loss: 0.2261 - acc: 0.9187 - val_loss: 0.3191 - val_acc: 0.8800\n",
      "Epoch 139/10000\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.2392 - acc: 0.9111WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 43s 13ms/sample - loss: 0.3144 - acc: 0.8950s - loss: 0.3059 - ac - ETA: 2s - loss: 0.3134 - acc: 0\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 0.23620\n",
      "242/242 [==============================] - 92s 379ms/step - loss: 0.2386 - acc: 0.9112 - val_loss: 0.3144 - val_acc: 0.8950\n",
      "Epoch 140/10000\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.2288 - acc: 0.9165WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 45s 14ms/sample - loss: 0.3871 - acc: 0.8675\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 0.23620\n",
      "242/242 [==============================] - 87s 358ms/step - loss: 0.2295 - acc: 0.9163 - val_loss: 0.3871 - val_acc: 0.8675\n",
      "Epoch 141/10000\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.2358 - acc: 0.9147WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 40s 12ms/sample - loss: 0.3028 - acc: 0.8888\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 0.23620\n",
      "242/242 [==============================] - 66s 274ms/step - loss: 0.2357 - acc: 0.9149 - val_loss: 0.3028 - val_acc: 0.8888\n",
      "Epoch 142/10000\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.2340 - acc: 0.9144WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 35s 11ms/sample - loss: 0.3262 - acc: 0.8909\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 0.23620\n",
      "242/242 [==============================] - 75s 309ms/step - loss: 0.2341 - acc: 0.9144 - val_loss: 0.3262 - val_acc: 0.8909\n",
      "Epoch 143/10000\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.2250 - acc: 0.9197WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 45s 14ms/sample - loss: 0.4161 - acc: 0.8700\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 0.23620\n",
      "242/242 [==============================] - 83s 345ms/step - loss: 0.2250 - acc: 0.9198 - val_loss: 0.4161 - val_acc: 0.8700\n",
      "Epoch 144/10000\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.2253 - acc: 0.9177WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 39s 12ms/sample - loss: 0.2936 - acc: 0.8897\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 0.23620\n",
      "242/242 [==============================] - 72s 296ms/step - loss: 0.2248 - acc: 0.9181 - val_loss: 0.2936 - val_acc: 0.8897\n",
      "Epoch 145/10000\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.2259 - acc: 0.9154WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 43s 13ms/sample - loss: 0.2334 - acc: 0.9200\n",
      "\n",
      "Epoch 00145: val_loss improved from 0.23620 to 0.23345, saving model to model/checkpoint/vis_imagenet_6_class_augmentation_2D_CNN_custom_ch_64_DO_075_DO_3_conv_checkpoint/145-0.2334.hdf5\n",
      "242/242 [==============================] - 94s 389ms/step - loss: 0.2253 - acc: 0.9156 - val_loss: 0.2334 - val_acc: 0.9200\n",
      "Epoch 146/10000\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.2238 - acc: 0.9180WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 39s 12ms/sample - loss: 0.3211 - acc: 0.8950\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 0.23345\n",
      "242/242 [==============================] - 69s 285ms/step - loss: 0.2238 - acc: 0.9179 - val_loss: 0.3211 - val_acc: 0.8950\n",
      "Epoch 147/10000\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.2245 - acc: 0.9188WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 45s 14ms/sample - loss: 0.2319 - acc: 0.9109\n",
      "\n",
      "Epoch 00147: val_loss improved from 0.23345 to 0.23194, saving model to model/checkpoint/vis_imagenet_6_class_augmentation_2D_CNN_custom_ch_64_DO_075_DO_3_conv_checkpoint/147-0.2319.hdf5\n",
      "242/242 [==============================] - 106s 438ms/step - loss: 0.2244 - acc: 0.9189 - val_loss: 0.2319 - val_acc: 0.9109\n",
      "Epoch 148/10000\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.2162 - acc: 0.9204WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 47s 15ms/sample - loss: 0.3799 - acc: 0.8775\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 0.23194\n",
      "242/242 [==============================] - 88s 362ms/step - loss: 0.2160 - acc: 0.9204 - val_loss: 0.3799 - val_acc: 0.8775\n",
      "Epoch 149/10000\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.2227 - acc: 0.9173WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 48s 15ms/sample - loss: 0.3945 - acc: 0.8575\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 0.23194\n",
      "242/242 [==============================] - 82s 340ms/step - loss: 0.2228 - acc: 0.9173 - val_loss: 0.3945 - val_acc: 0.8575\n",
      "Epoch 150/10000\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.2134 - acc: 0.9231WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 36s 11ms/sample - loss: 0.2819 - acc: 0.9000\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 0.23194\n",
      "242/242 [==============================] - 58s 242ms/step - loss: 0.2134 - acc: 0.9231 - val_loss: 0.2819 - val_acc: 0.9000\n",
      "Epoch 151/10000\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.2260 - acc: 0.9213WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 46s 14ms/sample - loss: 0.2757 - acc: 0.9069\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 0.23194\n",
      "242/242 [==============================] - 87s 358ms/step - loss: 0.2259 - acc: 0.9213 - val_loss: 0.2757 - val_acc: 0.9069\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 152/10000\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.2297 - acc: 0.9139WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 41s 13ms/sample - loss: 0.3255 - acc: 0.8875\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 0.23194\n",
      "242/242 [==============================] - 59s 243ms/step - loss: 0.2293 - acc: 0.9140 - val_loss: 0.3255 - val_acc: 0.8875\n",
      "Epoch 153/10000\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.2115 - acc: 0.9221WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 43s 14ms/sample - loss: 0.3366 - acc: 0.8900\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 0.23194\n",
      "242/242 [==============================] - 84s 345ms/step - loss: 0.2114 - acc: 0.9222 - val_loss: 0.3366 - val_acc: 0.8900\n",
      "Epoch 154/10000\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.2178 - acc: 0.9216WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 41s 13ms/sample - loss: 0.2353 - acc: 0.9038\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 0.23194\n",
      "242/242 [==============================] - 72s 296ms/step - loss: 0.2182 - acc: 0.9214 - val_loss: 0.2353 - val_acc: 0.9038\n",
      "Epoch 155/10000\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.2305 - acc: 0.9157WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 37s 12ms/sample - loss: 0.3871 - acc: 0.8675\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 0.23194\n",
      "242/242 [==============================] - 54s 224ms/step - loss: 0.2299 - acc: 0.9160 - val_loss: 0.3871 - val_acc: 0.8675\n",
      "Epoch 156/10000\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.2160 - acc: 0.9202WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 35s 11ms/sample - loss: 0.3212 - acc: 0.8906\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 0.23194\n",
      "242/242 [==============================] - 74s 308ms/step - loss: 0.2156 - acc: 0.9203 - val_loss: 0.3212 - val_acc: 0.8906\n",
      "Epoch 157/10000\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.2212 - acc: 0.9186WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 44s 14ms/sample - loss: 0.2720 - acc: 0.9000\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 0.23194\n",
      "242/242 [==============================] - 78s 324ms/step - loss: 0.2207 - acc: 0.9188 - val_loss: 0.2720 - val_acc: 0.9000\n",
      "Epoch 158/10000\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.2148 - acc: 0.9227WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 46s 14ms/sample - loss: 0.3549 - acc: 0.8744\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 0.23194\n",
      "242/242 [==============================] - 81s 335ms/step - loss: 0.2148 - acc: 0.9228 - val_loss: 0.3549 - val_acc: 0.8744\n",
      "Epoch 159/10000\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.2309 - acc: 0.9135WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 34s 11ms/sample - loss: 0.2517 - acc: 0.9038\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 0.23194\n",
      "242/242 [==============================] - 70s 291ms/step - loss: 0.2307 - acc: 0.9136 - val_loss: 0.2517 - val_acc: 0.9038\n",
      "Epoch 160/10000\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.2077 - acc: 0.9214WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 40s 12ms/sample - loss: 0.4469 - acc: 0.8509\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 0.23194\n",
      "242/242 [==============================] - 77s 318ms/step - loss: 0.2078 - acc: 0.9213 - val_loss: 0.4469 - val_acc: 0.8509\n",
      "Epoch 161/10000\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.2125 - acc: 0.9221WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 39s 12ms/sample - loss: 0.2977 - acc: 0.9025\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 0.23194\n",
      "242/242 [==============================] - 79s 325ms/step - loss: 0.2130 - acc: 0.9220 - val_loss: 0.2977 - val_acc: 0.9025\n",
      "Epoch 162/10000\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.2226 - acc: 0.9208WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 31s 10ms/sample - loss: 0.3031 - acc: 0.8891\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 0.23194\n",
      "242/242 [==============================] - 68s 279ms/step - loss: 0.2224 - acc: 0.9211 - val_loss: 0.3031 - val_acc: 0.8891\n",
      "Epoch 163/10000\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.2218 - acc: 0.9195WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 46s 14ms/sample - loss: 0.2604 - acc: 0.9106\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 0.23194\n",
      "242/242 [==============================] - 85s 352ms/step - loss: 0.2214 - acc: 0.9197 - val_loss: 0.2604 - val_acc: 0.9106\n",
      "Epoch 164/10000\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.2124 - acc: 0.9228WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 37s 12ms/sample - loss: 0.2807 - acc: 0.9000\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 0.23194\n",
      "242/242 [==============================] - 87s 358ms/step - loss: 0.2126 - acc: 0.9228 - val_loss: 0.2807 - val_acc: 0.9000\n",
      "Epoch 165/10000\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.2182 - acc: 0.9228WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 51s 16ms/sample - loss: 0.2312 - acc: 0.9225\n",
      "\n",
      "Epoch 00165: val_loss improved from 0.23194 to 0.23119, saving model to model/checkpoint/vis_imagenet_6_class_augmentation_2D_CNN_custom_ch_64_DO_075_DO_3_conv_checkpoint/165-0.2312.hdf5\n",
      "242/242 [==============================] - 69s 284ms/step - loss: 0.2178 - acc: 0.9229 - val_loss: 0.2312 - val_acc: 0.9225\n",
      "Epoch 166/10000\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.2051 - acc: 0.9277WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 55s 17ms/sample - loss: 0.2729 - acc: 0.8975\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 0.23119\n",
      "242/242 [==============================] - 94s 387ms/step - loss: 0.2049 - acc: 0.9278 - val_loss: 0.2729 - val_acc: 0.8975\n",
      "Epoch 167/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "241/242 [============================>.] - ETA: 0s - loss: 0.2133 - acc: 0.9227WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 49s 15ms/sample - loss: 0.2214 - acc: 0.9200\n",
      "\n",
      "Epoch 00167: val_loss improved from 0.23119 to 0.22144, saving model to model/checkpoint/vis_imagenet_6_class_augmentation_2D_CNN_custom_ch_64_DO_075_DO_3_conv_checkpoint/167-0.2214.hdf5\n",
      "242/242 [==============================] - 84s 345ms/step - loss: 0.2135 - acc: 0.9225 - val_loss: 0.2214 - val_acc: 0.9200\n",
      "Epoch 168/10000\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.2173 - acc: 0.9222WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 46s 14ms/sample - loss: 0.3286 - acc: 0.8769\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 0.22144\n",
      "242/242 [==============================] - 79s 326ms/step - loss: 0.2169 - acc: 0.9225 - val_loss: 0.3286 - val_acc: 0.8769\n",
      "Epoch 169/10000\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.2133 - acc: 0.9206WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 42s 13ms/sample - loss: 0.4111 - acc: 0.8525\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 0.22144\n",
      "242/242 [==============================] - 76s 312ms/step - loss: 0.2135 - acc: 0.9206 - val_loss: 0.4111 - val_acc: 0.8525\n",
      "Epoch 170/10000\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.2126 - acc: 0.9217WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 45s 14ms/sample - loss: 0.2324 - acc: 0.9178\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 0.22144\n",
      "242/242 [==============================] - 82s 337ms/step - loss: 0.2128 - acc: 0.9217 - val_loss: 0.2324 - val_acc: 0.9178\n",
      "Epoch 171/10000\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.2133 - acc: 0.9249WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 48s 15ms/sample - loss: 0.2498 - acc: 0.9134\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 0.22144\n",
      "242/242 [==============================] - 85s 350ms/step - loss: 0.2130 - acc: 0.9249 - val_loss: 0.2498 - val_acc: 0.9134\n",
      "Epoch 172/10000\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.2105 - acc: 0.9215WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 54s 17ms/sample - loss: 0.2335 - acc: 0.9075\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 0.22144\n",
      "242/242 [==============================] - 87s 361ms/step - loss: 0.2102 - acc: 0.9215 - val_loss: 0.2335 - val_acc: 0.9075\n",
      "Epoch 173/10000\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.2014 - acc: 0.9287WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 40s 12ms/sample - loss: 0.3511 - acc: 0.8709\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 0.22144\n",
      "242/242 [==============================] - 63s 260ms/step - loss: 0.2011 - acc: 0.9289 - val_loss: 0.3511 - val_acc: 0.8709\n",
      "Epoch 174/10000\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.2021 - acc: 0.9262WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 43s 13ms/sample - loss: 0.3007 - acc: 0.8913\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 0.22144\n",
      "242/242 [==============================] - 80s 332ms/step - loss: 0.2021 - acc: 0.9262 - val_loss: 0.3007 - val_acc: 0.8913\n",
      "Epoch 175/10000\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.1949 - acc: 0.9297WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 45s 14ms/sample - loss: 0.3912 - acc: 0.8691\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 0.22144\n",
      "242/242 [==============================] - 64s 265ms/step - loss: 0.1951 - acc: 0.9295 - val_loss: 0.3912 - val_acc: 0.8691\n",
      "Epoch 176/10000\n",
      "241/242 [============================>.] - ETA: 0s - loss: 0.2068 - acc: 0.9255WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "3200/3183 [==============================] - 48s 15ms/sample - loss: 0.2349 - acc: 0.9150\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 0.22144\n",
      "242/242 [==============================] - 83s 343ms/step - loss: 0.2061 - acc: 0.9258 - val_loss: 0.2349 - val_acc: 0.9150\n",
      "Epoch 177/10000\n",
      "116/242 [=============>................] - ETA: 16s - loss: 0.2105 - acc: 0.9198"
     ]
    }
   ],
   "source": [
    "for i in range(5, 8):\n",
    "    base = 'vis_imagenet_6_class_augmentation_2D_CNN_custom_ch_64_DO_075_DO'\n",
    "    model_name = base+'_{}_conv'.format(i)\n",
    "    model = build_2d_cnn_custom_ch_64_DO(conv_num=i)\n",
    "#     model = multi_gpu_model(model, gpus=2)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=1e-4),\n",
    "          metrics=['accuracy'])\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    os.makedirs(model_path, exist_ok=True)\n",
    "    model_filename = model_path+'{epoch:03d}-{val_loss:.4f}.hdf5'\n",
    "    checkpointer = ModelCheckpoint(filepath = model_filename, monitor = \"val_loss\", \n",
    "                                   verbose=1, save_best_only=True)\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=100)\n",
    "    hist = model.fit_generator(data_generator,\n",
    "            steps_per_epoch=len(x_train)//batch_size,\n",
    "            epochs=10000,\n",
    "            validation_data=(x_val, y_val),\n",
    "            callbacks = [checkpointer, early_stopping],\n",
    "            workers=8, \n",
    "            use_multiprocessing=True\n",
    "    )\n",
    "\n",
    "    print()\n",
    "    print(model_name, 'Model')\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "    ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
    "    ax.plot(hist.history['acc'], 'b', label='train acc')\n",
    "    ax.plot(hist.history['val_acc'], 'g', label='val acc')\n",
    "    ax.set_xlabel('epoch')\n",
    "    ax.set_ylabel('loss')\n",
    "    ax.legend(loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    png_path = 'visualization/learning_curve/'\n",
    "    filename = model_name+'.png'\n",
    "    os.makedirs(png_path, exist_ok=True)\n",
    "    fig.savefig(png_path+filename, transparent=True)\n",
    "\n",
    "    model.save(model_path+'000_last.hdf5')\n",
    "    del(model)\n",
    "\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    model_filename = model_path + sorted(os.listdir(model_path))[-1]\n",
    "    model = load_model(model_filename)\n",
    "    [loss, accuracy] = model.evaluate(x_test, y_test)\n",
    "    print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "    print()\n",
    "\n",
    "    del(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = 'log'\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "base = 'vis_imagenet_6_class_augmentation_2D_CNN_custom_ch_64_DO_075_DO'\n",
    "\n",
    "with open(path.join(log_dir, base), 'w') as log_file:\n",
    "    for i in range(5, 8):\n",
    "        model_name = base+'_{}_conv'.format(i)\n",
    "        print()\n",
    "        print(model_name, 'Model')\n",
    "        model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "        model_filename = model_path + sorted(os.listdir(model_path))[-1]\n",
    "\n",
    "        model = load_model(model_filename)\n",
    "        model.summary()\n",
    "\n",
    "        [loss, accuracy] = model.evaluate(x_test, y_test)\n",
    "        print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "\n",
    "        del(model)\n",
    "\n",
    "        log_file.write('\\t'.join([model_name, str(accuracy), str(loss)])+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5, 8):\n",
    "    model_name = base+'_{}_conv'.format(i)\n",
    "    print()\n",
    "    print(model_name, 'Model')\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    model_filename = model_path + '000_last.hdf5'\n",
    "\n",
    "    model = load_model(model_filename)\n",
    "    model.summary()\n",
    "\n",
    "    [loss, accuracy] = model.evaluate(x_test, y_test)\n",
    "    print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "\n",
    "    del(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
